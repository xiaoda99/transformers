{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7292808a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from IPython import get_ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "54a886cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['HF_HOME'] = '/raid/xd/.cache/torch'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\"\n",
    "\n",
    "from types import MethodType\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, OrderedDict, Counter\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "from itertools import chain\n",
    "import math\n",
    "from functools import reduce, partial\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data.sampler import RandomSampler, Sampler, SequentialSampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from transformers.data.data_collator import DataCollator, default_data_collator\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from transformers import RobertaForMaskedLM, RobertaTokenizer, GPT2LMHeadModel, GPT2Tokenizer, GPTNeoForCausalLM\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import HfArgumentParser, Trainer, TrainingArguments, set_seed, AdamW\n",
    "# from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "# from transformers.trainer_utils import EvaluationStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "49c8f3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/nas/xd/projects/PyFunctional')\n",
    "from functional import seq\n",
    "from functional.pipeline import Sequence\n",
    "from fn import _\n",
    "from collections import namedtuple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "58cba5e2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from child_utils import *\n",
    "from common_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90f62ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = {}\n",
    "# cache_dir = '/nas/xd/.cache/torch/transformers/'  # for models besides t5-3b/11b\n",
    "# proxies = {'http': '192.168.50.1:1081'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ab655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"EleutherAI/gpt-neo-1.3B\"\n",
    "for model_name in ['gpt2-large']:#, 'gpt2-xl', 'KoboldAI/fairseq-dense-6.7B']:\n",
    "    if model_name not in models:\n",
    "        with Timer(model_name):\n",
    "            model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=cache_dir)  \n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "            models[model_name] = model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "fd0bbbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_model(engine):\n",
    "    def forward(input_ids, attention_mask=None):\n",
    "        text = tokenizer.decode(input_ids[0])\n",
    "        response = openai.Completion.create(engine=engine, prompt=text, max_tokens=0, echo=True, logprobs=5)\n",
    "        return Outputs(logits=response.choices[0].logprobs)\n",
    "    return forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "ebbfc0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt2-large\n",
      "gpt2-xl\n",
      "EleutherAI/gpt-neo-1.3B\n",
      "EleutherAI/gpt-j-6B\n",
      "KoboldAI/fairseq-dense-6.7B\n",
      "KoboldAI/fairseq-dense-13B\n",
      "text-babbage-001\n",
      "text-curie-001\n",
      "text-davinci-001\n",
      "text-davinci-002\n"
     ]
    }
   ],
   "source": [
    "for model_name in models: print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "4427a63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "engines = ['text-babbage-001', 'text-curie-001', 'text-davinci-001', 'text-davinci-002']\n",
    "for engine in engines:\n",
    "    model = get_openai_model(engine)\n",
    "    models[engine] = model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64283f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# openai.api_key = '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'\n",
    "# openai.api_key = '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'\n",
    "openai.api_key = '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' # 2022.3.30\n",
    "# text = 'Once upon a time'\n",
    "response = openai.Completion.create(engine=engines[1], prompt=text, max_tokens=0, echo=True, logprobs=5)\n",
    "# print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "052c1e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_token = 'Ġ!'; prompt_id = tokenizer._convert_token_to_id(prompt_token)\n",
    "bop_str = 'Instruction: '; bop_id = tokenizer.encode(bop_str)[0]  # 'Inst'\n",
    "eop_str = '. For example:'; eop_id = tokenizer.encode(eop_str)[2] # 'Ġexample'\n",
    "bos_id = tokenizer._convert_token_to_id('Ġ->')\n",
    "eos_id = tokenizer._convert_token_to_id('Ċ')\n",
    "\n",
    "\n",
    "class CHILDDataset(Dataset):\n",
    "    def __init__(self, input_strs, tokenizer):\n",
    "        if tokenizer.pad_token is None: tokenizer.pad_token = '!'\n",
    "        self.inputs = tokenizer.batch_encode_plus(input_strs, add_special_tokens=False, padding=True, return_tensors='pt')\n",
    "        input_ids = self.inputs.input_ids\n",
    "        self.labels = torch.ones_like(input_ids) * (-100)\n",
    "        for bi in range(input_ids.size(0)):\n",
    "            bop_idx = (input_ids[bi] == bop_id).nonzero().squeeze(1)\n",
    "            eop_idx = (input_ids[bi] == eop_id).nonzero().squeeze(1)\n",
    "            if len(bop_idx) > 0:\n",
    "                assert len(bop_idx) == 1 and len(eop_idx) == 1\n",
    "                bop_idx, eop_idx = bop_idx.item(), eop_idx.item()\n",
    "                input_ids[bi, bop_idx: eop_idx + 2] *= -1  # use prompt embedding for prompt tokens\n",
    "            \n",
    "            bos_indices = (input_ids[bi] == bos_id).nonzero().squeeze(1)\n",
    "            eos_indices = (input_ids[bi] == eos_id).nonzero()[-len(bos_indices):].squeeze(1)\n",
    "            for i, (bos_i, eos_i) in enumerate(zip(bos_indices.tolist(), eos_indices.tolist())):\n",
    "                assert eos_i > bos_i + 1\n",
    "                if i >= 2: self.labels[bi, bos_i + 1: eos_i] = input_ids[bi, bos_i + 1: eos_i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(sel f.inputs['input_ids'])\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {'input_ids': self.inputs['input_ids'][i],\n",
    "                'attention_mask': self.inputs['attention_mask'][i],\n",
    "                'labels': self.labels[i]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "56fcd441",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedEmbedding(nn.Module):\n",
    "    def __init__(self, \n",
    "                wte: nn.Embedding,\n",
    "                prompt_id: int = None,\n",
    "                prompt_len: int = 10, \n",
    "                random_range: float = 0.5,\n",
    "                initialize_from_vocab: bool = True):\n",
    "        super(WrappedEmbedding, self).__init__()\n",
    "#         self.wte = wte\n",
    "#         self.prompt_id = prompt_id\n",
    "#         self.prompt_len = prompt_len\n",
    "        self.__dict__.update(locals()); del self.self\n",
    "        if self.prompt_id is not None:\n",
    "            self.prompt_embedding = nn.parameter.Parameter(\n",
    "                self.initialize_embedding(random_range, initialize_from_vocab)).to(self.wte.weight.device)\n",
    "        else:\n",
    "            self.prompt_embedding = nn.Embedding(self.prompt_len, self.wte.weight.size(1)).to(self.wte.weight.device)\n",
    "            assert initialize_from_vocab\n",
    "            self.init_prompt_embedding_()\n",
    "#             self.prompt_embedding.weight.data = self.initialize_embedding(random_range, initialize_from_vocab)     \n",
    "            \n",
    "    def initialize_embedding(self, random_range: float = 0.5, initialize_from_vocab: bool = True):\n",
    "        if initialize_from_vocab: return self.wte.weight[:self.prompt_len].clone().detach()\n",
    "        return torch.FloatTensor(self.prompt_len, self.wte.weight.size(1)).uniform_(-random_range, random_range)\n",
    "    \n",
    "    def init_prompt_embedding_(self):\n",
    "        self.prompt_embedding.weight.data[:] = self.wte.weight[:self.prompt_len]\n",
    "            \n",
    "    def forward(self, input_ids):\n",
    "        if self.prompt_id is not None:\n",
    "            input_embeds = self.wte(input_ids)\n",
    "            input_embeds[input_ids == self.prompt_id] = self.prompt_embedding.expand(input_embeds.size(0), -1, -1)\n",
    "        else: # adapted from cpm-2\n",
    "            prompt_mask = input_ids < 0\n",
    "            prompt_ids = -input_ids * prompt_mask\n",
    "            assert torch.all(prompt_ids < self.prompt_len)\n",
    "            p_embeds = self.prompt_embedding(prompt_ids) * prompt_mask.float().unsqueeze(-1)\n",
    "            input_ids = input_ids * ~prompt_mask\n",
    "            w_embeds = self.wte(input_ids) * (~prompt_mask).float().unsqueeze(-1)\n",
    "            input_embeds = w_embeds + p_embeds\n",
    "        return input_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b17b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from cpm-2: https://github.com/TsinghuaAI/CPM-2-Finetune/blob/master/utils.py#L133-L164\n",
    "def get_params_for_prompt_optimization(module: nn.Module):\n",
    "    params = []\n",
    "    for t in module.named_modules():\n",
    "        if \"prompt_embedding\" in t[0]:\n",
    "            params.append({'params': [p for p in list(t[1]._parameters.values()) if p is not None]})\n",
    "    for t in module.named_parameters():\n",
    "        if \"prompt\" not in t[0]:\n",
    "            t[1].requires_grad_(False)    \n",
    "    return params\n",
    "\n",
    "def create_optimizer(model, training_args):\n",
    "    from torch.nn.parallel.distributed import DistributedDataParallel as DDP\n",
    "    while isinstance(model, (DDP, )): model = model.module\n",
    "    we.init_prompt_embedding_()\n",
    "    param_groups = get_params_for_prompt_optimization(model)\n",
    "    optimizer = AdamW(param_groups, lr=training_args.learning_rate, \n",
    "                      betas=(training_args.adam_beta1, training_args.adam_beta2),eps=training_args.adam_epsilon)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "39b4f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "wte = model.get_input_embeddings()\n",
    "if hasattr(wte, 'wte'): wte = wte.wte  # already been wrapped\n",
    "we = WrappedEmbedding(wte, prompt_len=10000)\n",
    "model.set_input_embeddings(we)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "ae3bb45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbalize(obj):\n",
    "    if type(obj) == bool: return 'Yes' if obj else 'No'\n",
    "    return str(obj)\n",
    "    \n",
    "def make_query_str(instruction, query):\n",
    "    if instruction is None and query is None: return ''\n",
    "    s = '.'\n",
    "    if instruction is not None: s = s + ' ' + instruction\n",
    "    if query is not None:\n",
    "        if type(query) in [int, bool, str]: query = [query]\n",
    "        if type(query) == dict:\n",
    "    #         return '. ' + '{' + ','.join([' %s: %s' % (str(k), str(v)) for k, v in query.items()]) + ' }'\n",
    "            s = s + ' ' + '{' + ','.join([' replace %s with %s' % (str(k), str(v)) for k, v in query.items()]) + ' }'\n",
    "        elif type(query) in [list,]:\n",
    "            s = s + ' ' + ' '.join([str(i) for i in query])\n",
    "    return s\n",
    "\n",
    "def make_example_str(example, with_instruction=False):\n",
    "    instruction, l, query, ans = example\n",
    "    if type(ans) not in [Sequence, list]: ans = [ans]\n",
    "    ans = [verbalize(a) for a in ans]\n",
    "    return '%s -> %s' % (' '.join(l) + make_query_str(instruction if with_instruction else None, query), ' '.join(ans))\n",
    "\n",
    "def sample_rand_len(vocab, k): return sample(vocab, k=randint(1, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "5d1d0b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _str(l, sep=' '):\n",
    "    if l is None: l = []\n",
    "    if isinstance(l, str) or not isinstance(l, collections.abc.Iterable): l = [l]\n",
    "    if isinstance(l, (dict, OrderedDict)): l = [f'{k}: {v}' for k, v in l.items()]\n",
    "    return sep.join(str(i) for i in l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "df63ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def promptize(s):\n",
    "#     return prompt_token * len(s.split())\n",
    "    return bop_str + s + eop_str\n",
    "    \n",
    "def make_input_str(task, nrows=4, ncols=4, full_vocab=None):\n",
    "    if full_vocab is None: full_vocab = string.ascii_uppercase + string.digits\n",
    "    transform_fn, vocab_fn, sample_fn, query_fn = task[:4]\n",
    "    instruction = transform_fn.__name__.replace('_', ' ')\n",
    "    if vocab_fn is None: vocab_fn = lambda: full_vocab\n",
    "    if query_fn is None: query_fn = lambda *_: None\n",
    "\n",
    "    task += (_str,) * (4 + 3 - len(task))\n",
    "    cxt2str, query2str, ans2str = task[4:]\n",
    "        \n",
    "    examples = []\n",
    "    query = None\n",
    "    for i in range(nrows):\n",
    "        vocab = vocab_fn()\n",
    "        cxt = sample_fn(vocab)#, k=ncols)\n",
    "        query = query_fn(cxt, vocab)#, ncols)\n",
    "        examples.append([cxt, query, transform_fn(cxt, query)])\n",
    "    # return examples\n",
    "\n",
    "    def example2str(example, with_instruction=False):\n",
    "        cxt, query, ans = example\n",
    "        return '. '.join(s for s in [cxt2str(cxt), query2str(query)] if s != '') + ' -> ' + ans2str(ans)\n",
    "\n",
    "    desc = promptize(instruction) + '\\n' if False else ''\n",
    "    # text = '\\n'.join([make_example_str(e, with_instruction=False) for e in examples])\n",
    "    text = '\\n'.join(example2str(e) for e in examples)\n",
    "    text = desc + text + '\\n'\n",
    "    return text, examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "ce0d0420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(examples, ans_vocab=[True, False]):\n",
    "    groups = seq(examples).group_by(_[-1]).map(_[1])  # 按ans分组\n",
    "    assert groups.len() == len(ans_vocab)  # 保证每种ans都出现\n",
    "    min_cnt = groups.map(lambda x: len(x)).min()\n",
    "    examples = groups.map(lambda x: sample(x, min_cnt)).flatten().list() # 每组都采样最小个数后去分组\n",
    "    return sample(examples, len(examples))  # 重新打乱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "856bb512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_a(cxt, query):\n",
    "    SC, CD = cxt  # SC paris: studeng-course relation, CD pairs: course-department function\n",
    "    ss, d = query  # ss: 学生子集（可以*不止两个学生*），d: 课程\n",
    "#     return seq(ss).map(lambda s: seq(SC).filter(_[0] == s).map(_[1]).intersection(CD.filter(_[1] == d).map(_[0])).non_empty()).all()\n",
    "    return (seq(ss)\n",
    "            .map(lambda s: seq(SC).filter(_[0] == s).map(_[1])  # 学生s选的所有课程\n",
    "                 .intersection(\n",
    "                     seq(CD).filter(_[1] == d).map(_[0])) # d系的课程\n",
    "                 .non_empty())  # s选了d系的课程\n",
    "            .all())  # 学生子集ss都选了d系的课程\n",
    "\n",
    "def all_a_sample(vocab, k):\n",
    "    S_vocab, C_vocab, D_vocab = vocab  # vocabs of students, courses, departments\n",
    "    k_S, k_C, k_D, k_SC = k  # default values: k_S = 3, k_C = 3, k_D = 2, k_SC = 5\n",
    "    S, C, D = sample(S_vocab, k_S), sample(C_vocab, k_C), sample(D_vocab, k_D)\n",
    "    \n",
    "    while len(set(CD := choices(D, k=k_C))) < k_D: continue  # ds里每个系的课都要出现\n",
    "    CD = list(zip(C, CD))  # 得到每门课所属的系\n",
    "    \n",
    "    all_SC = list(itertools.product(S, C))  # or seq(S).cartesian(C).list()\n",
    "    while seq(SC := sample(all_SC, k_SC)).map(_[0]).distinct().len() < k_S: continue  # ss里每个学生都要选课\n",
    "    return SC, CD\n",
    "\n",
    "def select_distinct(tuples, col): return seq(tuples).map(_[col]).distinct().list()\n",
    "    \n",
    "def all_a_query(cxt,vocab,k):\n",
    "    SC, CD = cxt\n",
    "    k_S, k_C, k_D, k_SC = k\n",
    "    S, D = select_distinct(SC, 0), select_distinct(CD, 1)\n",
    "    k_ss = randint(2, len(S))\n",
    "    ss = sample(S, k_ss)\n",
    "    d = choice(D)\n",
    "    return ss, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "62aee837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ith_element(l, query=None): return seq(l).slice(1, 2)\n",
    "def ith_group(l, query=None): return seq(l).group_by(_).select(_[1]).slice(1, 2).flatten()#.distinct()# davinci F w/ and wo dist\n",
    "# def element_at_index(l, query): return seq(l).slice(query, query + 1) # davinci F\n",
    "def element_at_index(l, query): return seq(l).enumerate().filter(_[0] == query).select(_[1])\n",
    "def replace(l, query): return seq(l).map(lambda x: query.get(x, x))\n",
    "def replace_with_the_other(l, query): # davinci F\n",
    "    query = {k: (set(l) - {k}).pop() for k in l}\n",
    "    return replace(l, query)\n",
    "def replace_all_with(l, query): return seq(l).map(lambda x: query)  # davinci F?!\n",
    "def interleave_with(l, query): return seq(l).flat_map(lambda x: [x, query])  # davinci T!!\n",
    "def unique_elements(l, query=None): return seq(l).distinct() # davinci F\n",
    "def how_many_unique_elements(l, query=None): return seq(l).distinct().len()  # davinci F\n",
    "def how_many(l, query): return seq(l).filter(_ == query).len() # davinci F\n",
    "def select_same_as(l, query): return seq(l).filter(_ == query) # simpler version of how_many. davinci F\n",
    "def select_same_number_as(l, query): return seq(l).group_by(_).select(_[1]).filter(lambda x: len(x) == len(query)).flatten() # F\n",
    "def includes(l, query): return seq(l).union(seq(query)).distinct().len() == seq(l).distinct().len() # davinci F\n",
    "def is_included_by(l, query): return seq(l).difference(seq(query)).empty() # davinci F\n",
    "\n",
    "def after(r, q): return r.image(q).map(next())[0]\n",
    "def before(r, q): return r.image(q).map(prev())[0]\n",
    "def between(r, q): \n",
    "    return r.image(q[0]).map(nexts)[0].intersection(r.image(q[1]).map(prevs)[0]).union(\n",
    "    r.image(q[0]).map(prevs)[0].intersection(r.image(q[1]).map(nexts)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "f10e9306",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_fn = lambda: choice(posets)\n",
    "sample_fn = p2r\n",
    "query_fn = lambda r, p: r.dom().a(choice)\n",
    "transform_fn = lambda r, q: r.image(q).map(next())[0]\n",
    "cxt2str = lambda r: ''\n",
    "task = (transform_fn, vocab_fn, sample_fn, query_fn, cxt2str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "f199b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\n",
    "    (ith_element,            None,                               sample,    None),\n",
    "    (ith_group,              None, lambda vocab, k: seq(sample(vocab, k)).map(lambda x:[x]*randint(1, 3)).flatten().list(),None),\n",
    "    (element_at_index,       lambda: upper_letters,              sample,    lambda l,vocab,k: randint(0, min(2,len(l)-1))),\n",
    "    (replace,                None,                               sample,    lambda l,vocab,k: {choice(l): choice(vocab)}),\n",
    "    (replace_with_the_other, lambda: sample(full_vocab, 2),   lambda vocab,k: sample(vocab+choices(vocab, k=k-2),k), None),\n",
    "    (replace_all_with,       None,                               sample_rand_len, lambda l,vocab,k: choice(vocab)),\n",
    "    (interleave_with,        None,                               sample_rand_len, lambda l,vocab,k: choice(vocab)),\n",
    "    (unique_elements,        lambda: sample(upper_letters, 3),   choices,   None),\n",
    "    (how_many_unique_elements,lambda: sample(upper_letters, 3),  choices,   None),\n",
    "    (how_many,               lambda: sample(upper_letters, 3),   choices,   lambda l,vocab,k: choice(list(set(l)))),\n",
    "    (select_same_as,         lambda: sample(upper_letters, 3),   choices,   lambda l,vocab,k: choice(list(set(l)))),\n",
    "    (select_same_number_as,  None, lambda vocab, k: seq(sample(vocab, k)).map(lambda x:[x]*randint(1, 3)).flatten().list(),   \n",
    "     lambda l,vocab,k: [choice(vocab)]*randint(1, 3)),\n",
    "    (includes,               lambda: sample(upper_letters, 6),   sample,    lambda l,vocab,k: sample(vocab, 3)),\n",
    "    (is_included_by,         lambda: sample(upper_letters, 6),   sample,    lambda l,vocab,k: sample(vocab, 5)),\n",
    "\n",
    "    (after, lambda: choice(posets), p2r, lambda r, p: r.dom().init().a(choice), lambda r: ''),\n",
    "    (before, lambda: choice(posets), p2r, lambda r, p: r.dom().tail().a(choice), lambda r: ''),\n",
    "    (between, lambda: choice(posets), p2r, lambda r, p: r.image(r.dom().init().tail().a(choice)).map(beside)[0].a(sample, 2), lambda r: ''),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "298d0141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polygons = ['triangle', 'quadrangle', 'pentagon', 'hexagon', 'heptagon', 'octagon', 'nonagon', 'decagon',]# 'undecagon', 'dodecagon']\n",
    "times_of_day = ['dawn', 'morning', 'noon', 'afternoon', 'evening', 'night', 'midnight']\n",
    "days_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "seasons = ['spring', 'summer', 'autumn', 'winter']\n",
    "ages_of_life = ['baby', 'child', 'teenager', 'young', 'adult', 'elder']\n",
    "times_of_history = ['primitive', 'medieval', 'renaissance', 'modern', 'contemporary']\n",
    "units_of_time = ['nanosecond', 'microsecond', 'millisecond', 'second', 'minute', 'hour', 'day', 'week', 'month', 'year', 'decade', 'century', 'millennium'] # first 3 multi-token\n",
    "units_of_length = ['nanometer', 'micrometer', 'millimeter', 'meter', 'kilometer', 'mile']\n",
    "units_of_mass = ['nanogram', 'microgram', 'milligram', 'gram', 'kilogram', 'ton']\n",
    "SI_prefixes_small = ['pico', 'nana', 'micro', 'milli', 'centi', 'deci']\n",
    "SI_prefixes_large = ['kilo', 'mega', 'giga', 'tera', 'peta', 'exa', 'zetta', 'yotta']\n",
    "\n",
    "things = ['atom', 'molecule', 'cell', 'tissue', 'organ', 'system', 'person', 'community', 'city', 'state', 'country', 'continent', 'planet', 'star', 'galaxy', 'universe']\n",
    "\n",
    "posets = [list(string.ascii_uppercase), list(string.ascii_lowercase), digits, times_of_day, days_of_week, months, seasons, ages_of_life, times_of_history, units_of_time, units_of_length, units_of_mass, things]#, SI_prefixes_small, SI_prefixes_large]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92834550",
   "metadata": {},
   "source": [
    "**TODO: read children books for more posets**  \n",
    "**TODO: Prompt gpt3 to elicit the posets it knows**  \n",
    "$x \\to f(x)$ where $f \\in \\{\\text{prev/next in posets of numbers/letters/months/days, antonym, hypernym, hyponym, ...}\\}$  \n",
    "$x \\to f^2(x)$  \n",
    "one poset or mixed posets  \n",
    "$x, f(x).~y \\to Ff^{[-1]}(y)$ one poset or mixed posets  \n",
    "$x, f^k(x).~y \\to Ff^{[-1]}(y)~/Ff^{[-]k}(y)$  \n",
    "$x, f(f(x))~/f(f(x)), x \\to f(x)$ in between, the simplest form of sequence completion  \n",
    "$x, f(x) \\to Gf$ where $Gf \\in \\{<, >\\}$  \n",
    "$x, f(x); y, g(y) \\to Ff \\stackrel{?}{=} g^{[-1]}$ where $\\text{output} \\in \\{\\text{True}, \\text{False}\\}$  \n",
    "sort\n",
    "\n",
    "There is a *natural* monotone map/functor $F$ between posets/sets $A$ and $B$.  Compose the computation (set operations, sorting etc.) between $A$ and $B$ with $F$ to make harder tasks.  \n",
    "$P(A) ,P(B) \\to F(P(A)) \\setminus ~/ \\cap ~/ \\triangle P(B)$. Harder form of set difference/intersection.  \n",
    "$P(A) \\to F(\\text{sorted}(P(A)))$. Harder form of sorting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "4059d4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May March -> April\n",
      "I K -> J\n",
      "August June -> July\n",
      "June April -> May\n",
      "microsecond second -> millisecond\n",
      "Sunday Friday -> Saturday\n",
      "n l -> m\n",
      "q s -> r\n",
      "Monday Wednesday -> Tuesday\n",
      "adult teenager -> young\n",
      "child young -> teenager\n",
      "adult teenager -> young\n",
      "week hour -> day\n",
      "contemporary renaissance -> modern\n",
      "meter mile -> kilometer\n",
      "Monday Wednesday -> Tuesday\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text, examples = make_input_str(tasks[-1], nrows=16)\n",
    "examples = text.strip().split('\\n')\n",
    "print(text)\n",
    "inputs = tokenizer.encode_plus(text, return_tensors='pt')\n",
    "input_ids = inputs.input_ids\n",
    "bos_indices, eos_indices, answers, labels = locate_answers(input_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "fbc67151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt2-large ... done 0:00:00\n",
      "\n",
      "  J 0.017 {'\\n': 0.078, ' I': 0.065, ' May': 0.04, ' D': 0.031, ' April': 0.028}\tI K -> J\n",
      "* July 0.339 {' July': 0.339, ' August': 0.297, ' September': 0.166, ' October': 0.046, '\\n': 0.016}\tAugust June -> July\n",
      "* May 0.629 {' May': 0.629, ' July': 0.126, ' June': 0.074, ' August': 0.029, ' April': 0.015}\tJune April -> May\n",
      "  millisec 0.022 {' micro': 0.148, '\\n': 0.049, ' second': 0.04, ' 1': 0.029, ' millisec': 0.022}\n",
      "*ond 0.999 {'ond': 0.999, 'OND': 0.0, 'onds': 0.0, 'on': 0.0, 'ons': 0.0}\tmicrosecond second -> millisecond\n",
      "* Saturday 0.31 {' Saturday': 0.31, ' Sunday': 0.183, ' Monday': 0.182, ' Friday': 0.035, ' Wednesday': 0.017}\tSunday Friday -> Saturday\n",
      "* m 0.279 {' m': 0.279, ' o': 0.095, ' r': 0.067, ' n': 0.062, ' d': 0.04}\tn l -> m\n",
      "  r 0.07 {' t': 0.266, ' v': 0.092, ' r': 0.07, ' w': 0.058, ' d': 0.05}\tq s -> r\n",
      "  Tuesday 0.015 {' Thursday': 0.776, ' Sunday': 0.078, ' Friday': 0.022, ' Tuesday': 0.015, ' Wednesday': 0.011}\tMonday Wednesday -> Tuesday\n",
      "  young 0.077 {' teen': 0.078, ' young': 0.077, ' child': 0.071, ' adult': 0.061, ' teenager': 0.024}\tadult teenager -> young\n",
      "  teenager 0.011 {' adult': 0.332, ' old': 0.19, ' young': 0.133, ' child': 0.037, ' teen': 0.034}\tchild young -> teenager\n",
      "* young 0.423 {' young': 0.423, ' adult': 0.116, ' child': 0.069, ' teen': 0.064, ' teenager': 0.041}\tadult teenager -> young\n",
      "  day 0.187 {' minute': 0.233, ' day': 0.187, ' hour': 0.108, ' half': 0.046, ' min': 0.029}\tweek hour -> day\n",
      "  modern 0.134 {' contemporary': 0.16, ' modern': 0.134, ' renaissance': 0.045, ' classical': 0.035, ' post': 0.019}\tcontemporary renaissance -> modern\n",
      "  kilomet 0.05 {' meter': 0.179, ' mile': 0.161, ' metre': 0.051, ' kilomet': 0.05, ' minute': 0.038}\n",
      "*er 0.868 {'er': 0.868, 're': 0.124, '\\n': 0.001, 'r': 0.001, 'e': 0.001}\tmeter mile -> kilometer\n",
      "  Tuesday 0.337 {' Thursday': 0.431, ' Tuesday': 0.337, ' Wednesday': 0.082, ' Sunday': 0.048, ' Friday': 0.037}\tMonday Wednesday -> Tuesday\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(2.0543, grad_fn=<NllLossBackward>), False)"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt2-xl ... done 0:00:00\n",
      "\n",
      "  J 0.029 {' May': 0.237, ' I': 0.146, ' April': 0.112, ' June': 0.055, ' J': 0.029}\tI K -> J\n",
      "* July 0.734 {' July': 0.734, ' August': 0.087, ' September': 0.044, ' J': 0.013, ' A': 0.01}\tAugust June -> July\n",
      "* May 0.894 {' May': 0.894, ' June': 0.029, ' July': 0.026, ' August': 0.017, ' April': 0.004}\tJune April -> May\n",
      "  millisec 0.024 {' micro': 0.316, ' nan': 0.04, ' 1': 0.035, ' second': 0.031, ' mill': 0.028}\n",
      "*ond 0.99 {'ond': 0.99, '\\n': 0.002, 'on': 0.0, 'il': 0.0, 'OND': 0.0}\tmicrosecond second -> millisecond\n",
      "* Saturday 0.756 {' Saturday': 0.756, ' Monday': 0.088, ' Sunday': 0.031, ' Sat': 0.021, ' Tuesday': 0.014}\tSunday Friday -> Saturday\n",
      "  m 0.093 {' n': 0.564, ' m': 0.093, ' 1': 0.041, ' l': 0.022, ' nm': 0.013}\tn l -> m\n",
      "  r 0.117 {' s': 0.289, ' t': 0.151, ' q': 0.118, ' r': 0.117, ' z': 0.027}\tq s -> r\n",
      "  Tuesday 0.001 {' Thursday': 0.968, ' Friday': 0.014, ' Sunday': 0.003, ' Thurs': 0.003, ' Wednesday': 0.002}\tMonday Wednesday -> Tuesday\n",
      "  young 0.109 {' child': 0.148, ' adult': 0.121, ' young': 0.109, ' teenager': 0.048, ' teen': 0.041}\tadult teenager -> young\n",
      "  teenager 0.045 {' adult': 0.369, ' young': 0.08, ' child': 0.064, ' old': 0.059, ' teenager': 0.045}\tchild young -> teenager\n",
      "* young 0.456 {' young': 0.456, ' adult': 0.17, ' old': 0.059, ' child': 0.045, ' teenager': 0.025}\tadult teenager -> young\n",
      "* day 0.395 {' day': 0.395, ' minute': 0.268, ' min': 0.073, ' m': 0.023, ' month': 0.02}\tweek hour -> day\n",
      "* modern 0.125 {' modern': 0.125, ' renaissance': 0.103, ' antique': 0.074, ' classical': 0.051, ' ancient': 0.033}\tcontemporary renaissance -> modern\n",
      "  kilomet 0.184 {' mile': 0.189, ' kilomet': 0.184, ' meter': 0.041, ' yard': 0.035, ' km': 0.035}\n",
      "*er 0.97 {'er': 0.97, 're': 0.025, 'e': 0.001, 'ers': 0.0, '\\n': 0.0}\tmeter mile -> kilometer\n",
      "* Tuesday 0.478 {' Tuesday': 0.478, ' Wednesday': 0.222, ' Thursday': 0.194, ' Friday': 0.045, ' Sunday': 0.012}\tMonday Wednesday -> Tuesday\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.8412, grad_fn=<NllLossBackward>), False)"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EleutherAI/gpt-neo-1.3B ... done 0:00:00\n",
      "\n",
      "  J 0.021 {' I': 0.287, ' K': 0.07, ' A': 0.027, ' II': 0.024, ' J': 0.021}\tI K -> J\n",
      "* July 0.309 {' July': 0.309, ' August': 0.251, ' September': 0.177, ' October': 0.063, ' June': 0.032}\tAugust June -> July\n",
      "* May 0.402 {' May': 0.402, ' April': 0.4, ' March': 0.071, ' June': 0.038, ' July': 0.022}\tJune April -> May\n",
      "* millisec 0.248 {' millisec': 0.248, ' micro': 0.244, ' second': 0.095, ' mill': 0.069, ' nan': 0.067}\n",
      "*ond 0.999 {'ond': 0.999, 'onde': 0.0, '\\n': 0.0, 'second': 0.0, 'isec': 0.0}\tmicrosecond second -> millisecond\n",
      "  Saturday 0.194 {' Monday': 0.388, ' Sunday': 0.301, ' Saturday': 0.194, ' Tuesday': 0.03, ' Thursday': 0.021}\tSunday Friday -> Saturday\n",
      "  m 0.1 {' n': 0.524, ' m': 0.1, ' N': 0.078, ' r': 0.022, ' p': 0.013}\tn l -> m\n",
      "* r 0.218 {' r': 0.218, ' p': 0.19, ' z': 0.18, ' t': 0.063, ' d': 0.05}\tq s -> r\n",
      "  Tuesday 0.022 {' Thursday': 0.913, ' Tuesday': 0.022, ' Saturday': 0.021, ' Monday': 0.018, ' Friday': 0.011}\tMonday Wednesday -> Tuesday\n",
      "  young 0.058 {' child': 0.241, ' adult': 0.152, ' teen': 0.13, ' teenager': 0.128, ' young': 0.058}\tadult teenager -> young\n",
      "  teenager 0.02 {' adult': 0.409, ' child': 0.175, ' young': 0.085, ' old': 0.075, ' teen': 0.052}\tchild young -> teenager\n",
      "  young 0.211 {' adult': 0.296, ' young': 0.211, ' child': 0.154, ' teenager': 0.087, ' teen': 0.065}\tadult teenager -> young\n",
      "* day 0.332 {' day': 0.332, ' hour': 0.267, ' half': 0.04, ' minute': 0.033, ' week': 0.021}\tweek hour -> day\n",
      "* modern 0.155 {' modern': 0.155, ' contemporary': 0.14, ' renaissance': 0.134, ' medieval': 0.05, ' classical': 0.049}\tcontemporary renaissance -> modern\n",
      "* kilomet 0.739 {' kilomet': 0.739, ' mile': 0.077, ' meter': 0.012, ' hour': 0.01, ' kil': 0.009}\n",
      "*er 0.967 {'er': 0.967, 're': 0.03, 'e': 0.001, 'ere': 0.001, 'erm': 0.0}\tmeter mile -> kilometer\n",
      "* Tuesday 0.933 {' Tuesday': 0.933, ' Monday': 0.046, ' Thursday': 0.006, ' Saturday': 0.005, ' Wednesday': 0.003}\tMonday Wednesday -> Tuesday\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.7087, grad_fn=<NllLossBackward>), False)"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EleutherAI/gpt-j-6B ... done 0:00:01\n",
      "\n",
      "  J 0.1 {' I': 0.331, ' K': 0.103, ' J': 0.1, ' II': 0.02, ' A': 0.019}\tI K -> J\n",
      "* July 0.45 {' July': 0.45, ' September': 0.198, ' August': 0.11, ' October': 0.039, ' November': 0.02}\tAugust June -> July\n",
      "* May 0.77 {' May': 0.77, ' July': 0.038, ' March': 0.033, ' September': 0.033, ' April': 0.024}\tJune April -> May\n",
      "* millisec 0.411 {' millisec': 0.411, ' micro': 0.195, ' minute': 0.071, ' second': 0.049, ' milliseconds': 0.043}\n",
      "*ond 0.994 {'ond': 0.994, '\\n': 0.002, 'second': 0.001, 'onde': 0.0, ' second': 0.0}\tmicrosecond second -> millisecond\n",
      "* Saturday 0.555 {' Saturday': 0.555, ' Monday': 0.34, ' Thursday': 0.044, ' Tuesday': 0.009, ' Wednesday': 0.006}\tSunday Friday -> Saturday\n",
      "* m 0.27 {' m': 0.27, ' n': 0.164, ' o': 0.058, ' N': 0.053, ' r': 0.039}\tn l -> m\n",
      "* r 0.335 {' r': 0.335, ' t': 0.22, ' p': 0.13, ' w': 0.055, ' u': 0.045}\tq s -> r\n",
      "* Tuesday 0.954 {' Tuesday': 0.954, ' Thursday': 0.031, ' Wednesday': 0.007, ' Monday': 0.002, 'Tuesday': 0.001}\tMonday Wednesday -> Tuesday\n",
      "  young 0.086 {' child': 0.422, ' teenager': 0.109, ' adult': 0.093, ' young': 0.086, ' teen': 0.038}\tadult teenager -> young\n",
      "  teenager 0.06 {' adult': 0.621, ' child': 0.074, ' teenager': 0.06, ' adolescent': 0.048, ' young': 0.044}\tchild young -> teenager\n",
      "  young 0.206 {' adult': 0.496, ' young': 0.206, ' child': 0.136, ' teenager': 0.028, ' old': 0.019}\tadult teenager -> young\n",
      "* day 0.601 {' day': 0.601, ' minute': 0.273, ' week': 0.017, ' weekend': 0.016, ' month': 0.01}\tweek hour -> day\n",
      "* modern 0.384 {' modern': 0.384, ' bar': 0.188, ' contemporary': 0.058, ' renaissance': 0.057, ' medieval': 0.053}\tcontemporary renaissance -> modern\n",
      "* kilomet 0.466 {' kilomet': 0.466, ' yard': 0.114, ' foot': 0.065, ' cent': 0.047, ' kil': 0.038}\n",
      "*er 0.969 {'er': 0.969, 're': 0.029, 'r': 0.0, 'e': 0.0, 'ric': 0.0}\tmeter mile -> kilometer\n",
      "* Tuesday 0.823 {' Tuesday': 0.823, ' Thursday': 0.126, ' Friday': 0.013, ' Wednesday': 0.007, ' Saturday': 0.007}\tMonday Wednesday -> Tuesday\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.2291, grad_fn=<NllLossBackward>), False)"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KoboldAI/fairseq-dense-6.7B ... done 0:00:01\n",
      "\n",
      "  J 0.02 {' May': 0.238, ' June': 0.115, ' I': 0.045, '</s>': 0.03, ' K': 0.023}\tI K -> J\n",
      "* July 0.681 {' July': 0.681, ' September': 0.116, ' August': 0.066, ' October': 0.022, ' Jul': 0.009}\tAugust June -> July\n",
      "* May 0.782 {' May': 0.782, ' June': 0.11, ' July': 0.028, ' August': 0.02, 'May': 0.005}\tJune April -> May\n",
      "* millisec 0.485 {' millisec': 0.485, ' micro': 0.099, ' second': 0.033, ' milliseconds': 0.031, ' 1': 0.018}\n",
      "*ond 0.956 {'ond': 0.956, 'second': 0.026, ' second': 0.001, ' millisec': 0.001, 'onse': 0.001}\tmicrosecond second -> millisecond\n",
      "* Saturday 0.528 {' Saturday': 0.528, ' Monday': 0.086, ' weekday': 0.026, ' Sunday': 0.022, ' Thursday': 0.021}\tSunday Friday -> Saturday\n",
      "* m 0.106 {' m': 0.106, ' n': 0.103, ' 2': 0.031, ' 1': 0.03, ' min': 0.029}\tn l -> m\n",
      "  r 0.019 {' s': 0.143, ' t': 0.1, ' n': 0.079, ' q': 0.062, ' ms': 0.042}\tq s -> r\n",
      "  Tuesday 0.039 {' Thursday': 0.547, ' Friday': 0.263, ' Tuesday': 0.039, ' Saturday': 0.032, ' Sunday': 0.027}\tMonday Wednesday -> Tuesday\n",
      "  young 0.086 {' juven': 0.107, ' young': 0.086, ' child': 0.056, ' junior': 0.022, ' twent': 0.022}\tadult teenager -> young\n",
      "  teenager 0.029 {' young': 0.16, ' adolescent': 0.057, ' old': 0.051, ' adult': 0.03, ' teenager': 0.029}\tchild young -> teenager\n",
      "* young 0.511 {' young': 0.511, ' old': 0.082, ' adult': 0.049, ' middle': 0.03, ' mature': 0.025}\tadult teenager -> young\n",
      "  day 0.099 {' minute': 0.271, ' millisec': 0.26, ' day': 0.099, ' micro': 0.027, ' second': 0.026}\tweek hour -> day\n",
      "* modern 0.145 {' modern': 0.145, ' bar': 0.107, ' medieval': 0.08, ' post': 0.03, ' early': 0.026}\tcontemporary renaissance -> modern\n",
      "* kilomet 0.518 {' kilomet': 0.518, ' yard': 0.054, ' km': 0.048, ' foot': 0.035, ' mile': 0.029}\n",
      "*er 0.948 {'er': 0.948, 're': 0.031, 'ric': 0.008, 'ere': 0.001, 'r': 0.001}\tmeter mile -> kilometer\n",
      "* Tuesday 0.337 {' Tuesday': 0.337, ' Friday': 0.227, ' Thursday': 0.207, ' Saturday': 0.079, ' Sunday': 0.048}\tMonday Wednesday -> Tuesday\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.7334, grad_fn=<NllLossBackward>), False)"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KoboldAI/fairseq-dense-13B ... done 0:00:02\n",
      "\n",
      "  J 0.054 {' May': 0.158, ' I': 0.101, ' June': 0.065, ' J': 0.054, ' July': 0.05}\tI K -> J\n",
      "* July 0.818 {' July': 0.818, ' August': 0.04, ' Jul': 0.032, ' J': 0.023, ' September': 0.023}\tAugust June -> July\n",
      "* May 0.732 {' May': 0.732, ' June': 0.063, ' July': 0.047, ' J': 0.026, ' August': 0.019}\tJune April -> May\n",
      "  millisec 0.136 {' second': 0.195, ' millisec': 0.136, ' micro': 0.074, ' mill': 0.055, ' 1': 0.046}\n",
      "*ond 0.979 {'ond': 0.979, 'onde': 0.006, 'ong': 0.003, 'ont': 0.002, 'on': 0.001}\tmicrosecond second -> millisecond\n",
      "* Saturday 0.535 {' Saturday': 0.535, ' Thursday': 0.136, ' Sunday': 0.042, ' Friday': 0.029, ' Monday': 0.025}\tSunday Friday -> Saturday\n",
      "  m 0.18 {' n': 0.313, ' m': 0.18, ' l': 0.035, ' t': 0.025, ' r': 0.018}\tn l -> m\n",
      "  r 0.041 {' s': 0.154, ' m': 0.126, ' p': 0.069, ' n': 0.067, ' t': 0.048}\tq s -> r\n",
      "  Tuesday 0.116 {' Thursday': 0.545, ' Friday': 0.12, ' Tuesday': 0.116, ' th': 0.054, ' t': 0.032}\tMonday Wednesday -> Tuesday\n",
      "  young 0.179 {' adult': 0.473, ' young': 0.179, ' youth': 0.029, ' teenager': 0.029, ' child': 0.016}\tadult teenager -> young\n",
      "  teenager 0.007 {' child': 0.405, ' young': 0.073, ' infant': 0.068, ' baby': 0.065, ' toddler': 0.04}\tchild young -> teenager\n",
      "* young 0.674 {' young': 0.674, ' adult': 0.23, ' old': 0.014, ' mature': 0.01, ' middle': 0.009}\tadult teenager -> young\n",
      "* day 0.382 {' day': 0.382, ' hour': 0.151, ' minute': 0.08, ' week': 0.059, ' half': 0.034}\tweek hour -> day\n",
      "  modern 0.188 {' renaissance': 0.254, ' modern': 0.188, ' contemporary': 0.044, ' classical': 0.037, ' medieval': 0.037}\tcontemporary renaissance -> modern\n",
      "* kilomet 0.789 {' kilomet': 0.789, ' mile': 0.041, ' meter': 0.023, ' kilometers': 0.015, ' yard': 0.014}\n",
      "*er 0.882 {'er': 0.882, 're': 0.07, 'erg': 0.005, 'ern': 0.003, 'erm': 0.002}\tmeter mile -> kilometer\n",
      "  Tuesday 0.16 {' Thursday': 0.475, ' Friday': 0.318, ' Tuesday': 0.16, ' Saturday': 0.015, ' Sunday': 0.008}\tMonday Wednesday -> Tuesday\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.5233, grad_fn=<NllLossBackward>), False)"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-babbage-001 ... done 0:00:01\n",
      "\n",
      "  J 0.177 {' I': 0.369, ' J': 0.177, ' Q': 0.104, ' A': 0.032, '\\n': 0.028}\tI K -> J\n",
      "* July 0.903 {' July': 0.903, ' September': 0.04, 'July': 0.022, ' October': 0.013, ' August': 0.006}\tAugust June -> July\n",
      "* May 0.988 {' May': 0.988, ' March': 0.005, 'May': 0.005, ' July': 0.001, ' October': 0.0}\tJune April -> May\n",
      "  millisec 0.176 {' milliseconds': 0.442, ' millisec': 0.176, ' nan': 0.057, '\\n': 0.024, ' second': 0.023}\n",
      "*ond 0.999 {'ond': 0.999, 'onde': 0.0, 'OND': 0.0, 'onder': 0.0, 'und': 0.0}\tmicrosecond second -> millisecond\n",
      "* Saturday 0.942 {' Saturday': 0.942, ' Monday': 0.025, ' Thursday': 0.012, ' Sunday': 0.007, ' Wednesday': 0.003}\tSunday Friday -> Saturday\n",
      "  m 0.287 {' n': 0.411, ' m': 0.287, ' N': 0.05, ' nm': 0.028, ' number': 0.014}\tn l -> m\n",
      "* r 0.421 {' r': 0.421, ' p': 0.165, ' t': 0.119, ' q': 0.108, ' u': 0.058}\tq s -> r\n",
      "  Tuesday 0.002 {' Thursday': 0.988, 'Thursday': 0.009, ' Tuesday': 0.002, ' Friday': 0.0, ' Saturday': 0.0}\tMonday Wednesday -> Tuesday\n",
      "* young 0.548 {' young': 0.548, ' child': 0.149, ' teenager': 0.062, ' adult': 0.03, ' high': 0.027}\tadult teenager -> young\n",
      "  teenager 0.011 {' child': 0.309, ' infant': 0.245, ' toddler': 0.142, ' baby': 0.103, ' young': 0.023}\tchild young -> teenager\n",
      "* young 0.442 {' young': 0.442, ' adult': 0.435, ' older': 0.028, 'adult': 0.027, ' Adult': 0.008}\tadult teenager -> young\n",
      "* day 0.559 {' day': 0.559, ' hour': 0.259, ' working': 0.038, ' weekday': 0.031, ' work': 0.012}\tweek hour -> day\n",
      "  modern 0.1 {' renaissance': 0.665, ' modern': 0.1, ' post': 0.045, ' Renaissance': 0.026, ' old': 0.014}\tcontemporary renaissance -> modern\n",
      "* kilomet 0.967 {' kilomet': 0.967, ' mile': 0.008, ' foot': 0.003, ' minute': 0.002, ' meter': 0.002}\n",
      "*er 1.0 {'er': 1.0, 're': 0.0, 'ers': 0.0, 'ER': 0.0, 'ering': 0.0}\tmeter mile -> kilometer\n",
      "* Tuesday 0.997 {' Tuesday': 0.997, 'Tuesday': 0.002, ' Thursday': 0.0, ' Saturday': 0.0, ' Tues': 0.0}\tMonday Wednesday -> Tuesday\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.214442932065059, False)"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-curie-001 ... done 0:00:02\n",
      "\n",
      "* J 0.681 {' J': 0.681, ' I': 0.239, ' 1': 0.013, ' Q': 0.012, ' Ka': 0.005}\tI K -> J\n",
      "* July 0.997 {' July': 0.997, 'July': 0.001, ' August': 0.001, ' September': 0.001, '\\n': 0.0}\tAugust June -> July\n",
      "* May 0.992 {' May': 0.992, ' March': 0.007, ' July': 0.001, 'May': 0.001, ' August': 0.0}\tJune April -> May\n",
      "* millisec 0.815 {' millisec': 0.815, ' milliseconds': 0.145, ' nan': 0.031, ' mill': 0.002, ' minute': 0.002}\n",
      "*ond 1.0 {'ond': 1.0, 'OND': 0.0, 'onde': 0.0, 'op': 0.0, 'one': 0.0}\tmicrosecond second -> millisecond\n",
      "* Saturday 0.973 {' Saturday': 0.973, ' Monday': 0.021, ' Thursday': 0.003, ' Wednesday': 0.001, ' Tuesday': 0.001}\tSunday Friday -> Saturday\n",
      "* m 0.227 {' m': 0.227, ' 1': 0.121, ' h': 0.095, ' r': 0.066, ' n': 0.054}\tn l -> m\n",
      "  r 0.288 {' t': 0.544, ' r': 0.288, ' p': 0.147, ' w': 0.007, '\\n': 0.003}\tq s -> r\n",
      "  Tuesday 0.008 {' Thursday': 0.989, ' Tuesday': 0.008, ' Wednesday': 0.001, 'Thursday': 0.001, ' Friday': 0.0}\tMonday Wednesday -> Tuesday\n",
      "  young 0.092 {' child': 0.601, ' young': 0.092, ' adult': 0.076, ' juvenile': 0.038, ' teenager': 0.036}\tadult teenager -> young\n",
      "  teenager 0.019 {' adult': 0.897, ' infant': 0.045, ' adolescent': 0.021, ' teenager': 0.019, ' toddler': 0.006}\tchild young -> teenager\n",
      "  young 0.328 {' adult': 0.43, ' young': 0.328, ' middle': 0.171, ' old': 0.016, ' baby': 0.012}\tadult teenager -> young\n",
      "* day 0.988 {' day': 0.988, ' minute': 0.008, ' half': 0.001, ' hour': 0.001, ' weekday': 0.001}\tweek hour -> day\n",
      "  modern 0.08 {' medieval': 0.441, ' renaissance': 0.243, ' modern': 0.08, ' traditional': 0.071, ' classical': 0.051}\tcontemporary renaissance -> modern\n",
      "* kilomet 0.839 {' kilomet': 0.839, ' kilometers': 0.057, ' n': 0.032, ' mile': 0.012, ' kil': 0.012}\n",
      "*er 1.0 {'er': 1.0, 're': 0.0, 'ER': 0.0, 'ric': 0.0, 'rage': 0.0}\tmeter mile -> kilometer\n",
      "* Tuesday 0.994 {' Tuesday': 0.994, ' Thursday': 0.003, ' Wednesday': 0.001, ' Friday': 0.001, 'Tuesday': 0.0}\tMonday Wednesday -> Tuesday\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0786956708422941, False)"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-davinci-001 ... done 0:00:00\n",
      "\n",
      "  J 0.208 {' L': 0.464, ' J': 0.208, ' I': 0.048, '\\n': 0.039, ' K': 0.027}\tI K -> J\n",
      "* July 0.602 {' July': 0.602, ' September': 0.207, ' ': 0.052, ' October': 0.028, ' December': 0.023}\tAugust June -> July\n",
      "* May 0.966 {' May': 0.966, ' March': 0.01, ' ': 0.007, 'May': 0.004, '\\n': 0.003}\tJune April -> May\n",
      "* millisec 0.923 {' millisec': 0.923, ' minute': 0.072, ' nan': 0.001, ' day': 0.001, ' hour': 0.001}\n",
      "*ond 1.0 {'ond': 1.0, 'OND': 0.0, '\\n': 0.0, 'onde': 0.0, 'on': 0.0}\tmicrosecond second -> millisecond\n",
      "* Saturday 0.746 {' Saturday': 0.746, ' Thursday': 0.237, ' Monday': 0.011, ' Friday': 0.003, 'Saturday': 0.001}\tSunday Friday -> Saturday\n",
      "  m 0.114 {' n': 0.377, ' k': 0.12, ' m': 0.114, ' r': 0.106, ' 1': 0.087}\tn l -> m\n",
      "  r 0.34 {' p': 0.485, ' r': 0.34, ' t': 0.078, ' z': 0.057, ' u': 0.03}\tq s -> r\n",
      "* Tuesday 0.959 {' Tuesday': 0.959, ' Thursday': 0.038, ' Friday': 0.002, 'Tuesday': 0.001, ' Tues': 0.0}\tMonday Wednesday -> Tuesday\n",
      "  young 0.0 {' child': 0.988, ' kid': 0.003, ' children': 0.002, ' juvenile': 0.001, ' pediatric': 0.001}\tadult teenager -> young\n",
      "  teenager 0.001 {' baby': 0.34, ' infant': 0.318, ' toddler': 0.31, ' adult': 0.014, ' child': 0.009}\tchild young -> teenager\n",
      "* young 0.478 {' young': 0.478, ' child': 0.261, ' adult': 0.242, ' old': 0.004, ' infant': 0.004}\tadult teenager -> young\n",
      "* day 0.978 {' day': 0.978, ' minute': 0.018, ' minutes': 0.001, ' hour': 0.001, ' month': 0.0}\tweek hour -> day\n",
      "  modern 0.098 {' medieval': 0.663, ' modern': 0.098, ' bar': 0.069, ' traditional': 0.052, ' classical': 0.039}\tcontemporary renaissance -> modern\n",
      "* kilomet 0.997 {' kilomet': 0.997, ' foot': 0.001, ' kil': 0.0, ' cent': 0.0, ' meter': 0.0}\n",
      "*er 1.0 {'er': 1.0, 're': 0.0, 'e': 0.0, 'ric': 0.0, 'ER': 0.0}\tmeter mile -> kilometer\n",
      "* Tuesday 0.543 {' Tuesday': 0.543, ' Thursday': 0.397, ' Friday': 0.054, 'Tuesday': 0.002, 'Thursday': 0.001}\tMonday Wednesday -> Tuesday\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.4341133341075825, False)"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-davinci-002 ... done 0:00:00\n",
      "\n",
      "* J 0.503 {' J': 0.503, ' L': 0.381, ' I': 0.029, ' K': 0.019, ' M': 0.009}\tI K -> J\n",
      "* July 0.941 {' July': 0.941, ' September': 0.023, ' August': 0.007, ' May': 0.006, 'July': 0.005}\tAugust June -> July\n",
      "* May 0.993 {' May': 0.993, ' March': 0.003, ' September': 0.0, ' April': 0.0, ' June': 0.0}\tJune April -> May\n",
      "* millisec 0.648 {' millisec': 0.648, ' minute': 0.336, ' third': 0.004, ' second': 0.002, ' micro': 0.001}\n",
      "*ond 1.0 {'ond': 1.0, 'o': 0.0, 'on': 0.0, 'OND': 0.0, '<|da_3|>': 0.0}\tmicrosecond second -> millisecond\n",
      "* Saturday 0.999 {' Saturday': 0.999, 'Saturday': 0.0, ' Monday': 0.0, ' Thursday': 0.0, ' Wednesday': 0.0}\tSunday Friday -> Saturday\n",
      "* m 0.838 {' m': 0.838, ' k': 0.117, ' o': 0.03, ' n': 0.003, ' km': 0.003}\tn l -> m\n",
      "* r 0.89 {' r': 0.89, ' t': 0.096, ' p': 0.007, ' s': 0.002, ' u': 0.001}\tq s -> r\n",
      "* Tuesday 0.747 {' Tuesday': 0.747, ' Thursday': 0.251, 'Thursday': 0.001, 'Tuesday': 0.0, ' Friday': 0.0}\tMonday Wednesday -> Tuesday\n",
      "  young 0.101 {' child': 0.443, ' youth': 0.196, ' young': 0.101, ' adult': 0.095, ' adolescent': 0.065}\tadult teenager -> young\n",
      "  teenager 0.246 {' adult': 0.475, ' teenager': 0.246, ' adolescent': 0.142, ' infant': 0.018, ' kid': 0.018}\tchild young -> teenager\n",
      "* young 0.628 {' young': 0.628, ' child': 0.216, ' teenager': 0.064, ' youth': 0.017, ' adult': 0.017}\tadult teenager -> young\n",
      "  day 0.433 {' minute': 0.54, ' day': 0.433, ' minutes': 0.006, ' min': 0.004, ' hour': 0.004}\tweek hour -> day\n",
      "  modern 0.031 {' medieval': 0.672, ' bar': 0.219, ' modern': 0.031, ' post': 0.026, ' classical': 0.008}\tcontemporary renaissance -> modern\n",
      "  kilomet 0.336 {' yard': 0.421, ' kilomet': 0.336, ' foot': 0.168, ' inch': 0.017, ' mile': 0.014}\n",
      "*er 1.0 {'er': 1.0, 're': 0.0, '<|endoftext|>': 0.0, 'e': 0.0, 'ER': 0.0}\tmeter mile -> kilometer\n",
      "* Tuesday 0.997 {' Tuesday': 0.997, ' Thursday': 0.001, 'Tuesday': 0.001, ' Sunday': 0.0, ' Tues': 0.0}\tMonday Wednesday -> Tuesday\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6658827949207646, False)"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model_name, (model, tokenizer) in models.items():\n",
    "    with Timer(model_name): o = model(**inputs)\n",
    "    show_predictions(text, examples, tokenizer, o.logits, bos_indices, eos_indices, answers, labels,\n",
    "                    sep='\\t', loss_reduction='mean', show_range=range(k_shot, len(examples)))\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950456a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "6f135452",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = seq(choice(posets))\n",
    "p = times_of_day\n",
    "r = p2r(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "28fd5077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p2r(p): p = seq(p); return p.zip(p.inits().zip(p.tails()))#.slice(1, p.len() - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "f13deacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.zip(p.inits().zip(p.tails())).dom().init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "60151283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wednesday'"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = r.dom().a(choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "bc90b0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "relational_functions = [pred(), succ()]\n",
    "rel_fns = [prevs, nexts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "e66d2631",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_fn = choice(relational_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "1cbe83ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wednesday'"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['Thursday', 'Friday', 'Saturday', 'Sunday']"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e\n",
    "nexts(r.image(e)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "6f8aba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "e1, e2 = r.dom().a(sample, 2)\n",
    "e1, e2 = 'morning', 'afternoon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "08c4b476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['noon']"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.image(e1).map(nexts)[0].intersection(r.image(e2).map(prevs)[0]).union(\n",
    "    r.image(e1).map(prevs)[0].intersection(r.image(e2).map(nexts)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "e9673b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.image(e1).map(seq(rel_fns).find(lambda f: e2 in r.image(e1).map(f)[0]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "3c6cab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbour(direction, k=1): return lambda x: x[direction][k]\n",
    "def prev(k=1): return neighbour(0, k)\n",
    "def next(k=1): return neighbour(1, k)\n",
    "prevs, nexts = _[0][1:], _[1][1:]\n",
    "beside = lambda x: (x[0][1], x[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2bbcf3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'C'\n",
    "l.zip(l.reverse().tails().reverse().tail().zip(l.tails())).filter(_[0] == query).map(_[1]).map(succ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "e4848490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: select same as. For example:\n",
      "A L L A. A -> A A\n",
      "W B R W. R -> R\n",
      "J J J C. C -> C\n",
      "F F F F. F -> F F F F\n",
      "I M W W. W -> W W\n",
      "X X X X. X -> X X X X\n",
      "P P P P. P -> P P P P\n",
      "H G L L. H -> H\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(make_input_str(tasks[-4], nrows=8, ncols=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "17373019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: replace with the other. For example:\n",
      "G H G G G -> H G H H H\n",
      "I I I I M -> M M M M I\n",
      "A A F A A -> F F A F F\n",
      "9 9 9 I I -> I I I 9 9\n",
      "\n",
      "Instruction: replace with the other. For example:\n",
      "V Q Q V V -> Q V V Q Q\n",
      "G L L G L -> L G G L G\n",
      "G 2 2 2 G -> 2 G G G 2\n",
      "I I Z Z Z -> Z Z I I I\n",
      "\n",
      "Instruction: replace with the other. For example:\n",
      "R H H H R -> H R R R H\n",
      "B 9 9 B B -> 9 B B 9 9\n",
      "D 2 2 2 D -> 2 D D D 2\n",
      "A A A A W -> W W W W A\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_total, n_valid = 192, 64\n",
    "n_train = n_total - n_valid\n",
    "\n",
    "input_strs = [make_input_str(tasks[4], nrows=4, ncols=5) for __ in range(n_total)]\n",
    "for s in sample(input_strs, 3): print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "f7d6edbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(s.count('Yes') for s in input_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "e2f80b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CHILDDataset(input_strs[:-n_valid], tokenizer)\n",
    "eval_dataset = CHILDDataset(input_strs[-n_valid:], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3185653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_total == 1:\n",
    "    inputs = tokenizer.encode_plus(text, return_tensors='pt')\n",
    "    inputs = prepare_inputs(inputs, model.device)\n",
    "    outputs = model(**inputs, output_attentions=False)\n",
    "\n",
    "    # assert inputs.input_ids.size(0) == 1\n",
    "    input_ids = inputs.input_ids\n",
    "    logits = outputs.logits\n",
    "\n",
    "    bsz = input_ids.size(0); assert bsz == 1\n",
    "    labels = torch.ones_like(input_ids) * (-100)\n",
    "    for bi in range(bsz):\n",
    "        bos_indices = (input_ids[bi] == bos_id).nonzero().squeeze(1)\n",
    "        eos_indices = (input_ids[bi] == eos_id).nonzero()[-nrows:].squeeze(1)\n",
    "        for i, (example, bos_i, eos_i) in enumerate(zip(examples, bos_indices.tolist(), eos_indices.tolist())):\n",
    "            print(' ' + make_example_str(example))\n",
    "            ans_ids = input_ids[bi, bos_i + 1: eos_i]\n",
    "            if i >= 2: labels[bi, bos_i: eos_i - 1] = ans_ids\n",
    "            ans_prob_dist = logits[bi, bos_i: eos_i - 1].softmax(-1)\n",
    "            ans_probs = ans_prob_dist[torch.arange(ans_prob_dist.size(0)), ans_ids]\n",
    "            ans_tokens = tokenizer.convert_ids_to_tokens(ans_ids)\n",
    "            for ans_id, ans_token, ans_prob, dist in zip(ans_ids, ans_tokens, numpy(ans_probs, decimals=3), ans_prob_dist):\n",
    "                top1_correct = (dist.argmax() == ans_id).item()\n",
    "                print(('*' if top1_correct else ' ') + ans_token, ans_prob, \n",
    "                      show_topk(*dist.topk(5), indices_fn=tokenizer.convert_ids_to_tokens)) \n",
    "    loss = nn.CrossEntropyLoss()(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "    loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "6ebf074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"./models/model_name\", \n",
    "    overwrite_output_dir=True, do_train=True, do_eval=True,\n",
    "    per_device_train_batch_size=16, per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01, adam_beta2=0.98, adam_epsilon=1e-6,\n",
    "    lr_scheduler_type='constant', learning_rate=5e-3, num_train_epochs=4,\n",
    "    logging_strategy ='epoch', evaluation_strategy ='epoch', save_steps=0,\n",
    "    no_cuda=True, report_to='none',  # to avoid report to wandb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "d89c7d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, training_args, train_dataset=train_dataset, eval_dataset=eval_dataset,\n",
    "                  optimizers=(create_optimizer(model, training_args), None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "b37a9874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.place_model_on_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4b3eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prev(elem):\n",
    "    i, v = elem\n",
    "    return _l[i - 1] if i > 0 else None\n",
    "\n",
    "false = lambda *_: False\n",
    "true  = lambda *_: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721cb66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Element = namedtuple('Element', 'index value')\n",
    "_l = 'A B C B'.split()\n",
    "n = len(_l)\n",
    "# l = [Element._make(e) for e in enumerate(l)]\n",
    "l = seq(_l)\n",
    "l = l.enumerate().map(Element._make)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f22f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "l.map(lambda x: {'B': 'D'}.get(x, x))\n",
    "\n",
    "l.filter(lambda x: get_prev(x) == 'B').select(_.value)\n",
    "\n",
    "find_fn = _.index == 1\n",
    "l.filter(find_fn).select(_.value).map(lower)\n",
    "\n",
    "find_fn = _.value == 'C'\n",
    "l.filter(find_fn).select(_.index)\n",
    "\n",
    "# move x to first\n",
    "update_filter = _.value == 'C'\n",
    "get_new = lambda x: -1\n",
    "l.map(lambda x: Element(update_fn(x, 'index'), x.value)).order_by(_.index).select(_.value)\n",
    "\n",
    "# swap first and last\n",
    "update_filter = true\n",
    "get_new = lambda x: {0: n - 1, n - 1: 0}.get(x.index, x.index)\n",
    "l.map(lambda x: Element(update_fn(x, 'index'), x.value)).order_by(_.index).select(_.value)\n",
    "\n",
    "# get inbetween == drop_while + take_while?\n",
    "\n",
    "# update by index to its prev\n",
    "update_filter = _.index == 1\n",
    "get_new = lambda x: get_prev(x)\n",
    "def update_fn(x, update_field): return get_new(x) if update_filter(x) else getattr(x, update_field)\n",
    "l.map(lambda x: Element(x.index, update_fn(x, 'value')))\n",
    "\n",
    "# if two adjacent elements by indices are equal\n",
    "l.filter(lambda x: x.index in [0, 1]).select(_.value).distinct().len() == 1\n",
    "\n",
    "seq('A B C B C'.split()).group_by(_).select(_[1]).flatten()\n",
    "\n",
    "# count occurance till current\n",
    "seq('A B A C B A'.split()).inits().reverse().tail().map(lambda x: x.filter(_ == x.last()).len())\n",
    "\n",
    "# find special\n",
    "seq('A B A A'.split()).count_by_value().filter(_[1] == 1).select(_[0])\n",
    "\n",
    "# generalized find special\n",
    "seq('A A B C C D D'.split()).group_by(_).map(lambda x: (x[0], len(x[1]))).filter(_[1] == 1).select(_[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
