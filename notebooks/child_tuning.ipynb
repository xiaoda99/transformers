{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7292808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'  #'last', 'last_expr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d03e56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In file_utils.py: default_cache_path = /raid3/xd/.cache/torch/hub\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/nas/xd/projects/transformers/src')\n",
    "import os\n",
    "os.environ['HF_HOME'] = '/raid3/xd/.cache/torch'  # deliberately set this wrong path to avoid migrating cache\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"8,7\"\n",
    "\n",
    "from types import MethodType\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, OrderedDict, Counter\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "from dataclasses import dataclass, fields, asdict\n",
    "import itertools\n",
    "from itertools import chain, product\n",
    "import math\n",
    "from functools import reduce, partial\n",
    "from collections.abc import Iterable\n",
    "from collections import namedtuple \n",
    "import traceback\n",
    "import pickle, gzip\n",
    "\n",
    "# from multiprocessing import Pool\n",
    "# from torch.multiprocessing import Pool\n",
    "# torch.multiprocessing.set_start_method('spawn', force=True)\n",
    "from multiprocessing.dummy import Pool\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data.sampler import RandomSampler, Sampler, SequentialSampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "# from transformers.data.data_collator import DataCollator, default_data_collator\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, GPT2Tokenizer#, pipeline\n",
    "# from transformers import RobertaForMaskedLM, RobertaTokenizer, GPT2LMHeadModel, GPT2Tokenizer, GPTNeoForCausalLM\n",
    "# from transformers import T5Tokenizer, T5TokenizerFast, T5ForConditionalGeneration\n",
    "# from transformers import HfArgumentParser, Trainer, TrainingArguments, set_seed, AdamW\n",
    "torch.set_grad_enabled(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49c8f3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/nas/xd/projects/PyFunctional')\n",
    "from functional import seq\n",
    "from functional.pipeline import Sequence\n",
    "from fn import _ as __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58cba5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common_utils ... done 0:00:00.000057\n",
      "utils ... done 0:00:00.004480\n",
      "child_utils ... Loading tokenizer ... done 0:00:08.703494\n",
      "done 0:00:19.618518\n",
      "tasks ... done 0:00:00.001589\n",
      "model_utils ... done 0:00:02.392556\n",
      "weight_analysis ... done 0:00:00.000031\n"
     ]
    }
   ],
   "source": [
    "from common_utils import Timer\n",
    "with Timer('common_utils'): from common_utils import *\n",
    "with Timer('utils'): from utils import *\n",
    "with Timer('child_utils'): from child_utils import *\n",
    "from child_utils import _cxt2str, _item2str, _s, _be\n",
    "from child_frames import *\n",
    "with Timer('tasks'): from tasks import *\n",
    "with Timer('model_utils'): from model_utils import *\n",
    "with Timer('weight_analysis'): from weight_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90f62ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "cache_dir = '/nas/xd/.cache/torch/transformers/'  # for models besides t5-3b/11b\n",
    "# cache_dir = '/mnt/nvme1/xd/.cache/torch/transformers/'  # for gpt-neox-20b on elderberry\n",
    "proxies = {'http': '192.168.50.1:1081'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4ab655d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EleutherAI/gpt-neox-20b/cpu ... In huggingface_hub.file_download.cached_download: url = https://huggingface.co/EleutherAI/gpt-neox-20b/resolve/main/config.json\n",
      "done 0:11:22.757894\n"
     ]
    }
   ],
   "source": [
    "# curl -x http://192.168.50.1:1081 -L -O [-C -] https://huggingface.co/google/ul2/resolve/main/pytorch_model.bin  # -C for 断点续传\n",
    "s2s_model_names = ['google/t5-xl-lm-adapt', 'google/t5-xxl-lm-adapt', 'bigscience/T0p', 'bigscience/T0_3B', \n",
    "    'allenai/tk-instruct-3b-pos', 'allenai/tk-instruct-3b-def-pos', 'google/ul2']\n",
    "gpt_model_names = ['EleutherAI/gpt-j-6B/cpu', #'EleutherAI/gpt-j-6B',\n",
    "                   'EleutherAI/gpt-neox-20b/cpu', #'EleutherAI/gpt-neox-20b'\n",
    "                  ]#, 'gpt2-xl', 'gpt2']\n",
    "#                    'KoboldAI/fairseq-dense-6.7B', 'KoboldAI/fairseq-dense-13B']\n",
    "for model_name in s2s_model_names[:0] + gpt_model_names[1:]:#, 'gpt2-xl', 'EleutherAI/gpt-neo-1.3B', 'KoboldAI/fairseq-dense-6.7B']:\n",
    "    if model_name in models: continue\n",
    "    with Timer(model_name):\n",
    "        model_cls = AutoModelForCausalLM if any(s in model_name for s in ['gpt', 'fairseq-dense']) else T5ForConditionalGeneration\n",
    "        # _cache_dir = cache_dir.replace('/nas/', '/nas2/') if 'gpt' not in model_name else cache_dir\n",
    "        kwargs = dict(cache_dir=cache_dir, proxies=proxies, low_cpu_mem_usage=True)\n",
    "        if '/cpu' in model_name or 'gpt-j' not in model_name and 'gpt-neox' not in model_name:\n",
    "            model = model_cls.from_pretrained(model_name.replace('/cpu', ''), cache_dir=cache_dir, proxies=proxies)\n",
    "        elif 'gpt-j' in model_name:\n",
    "            device = 0\n",
    "            model = model_cls.from_pretrained(model_name, revision=\"float16\", torch_dtype=torch.float16, **kwargs).to(device)\n",
    "        elif 'gpt-neox' in model_name:\n",
    "            device = 8; device_map = {'gpt_neox': device, 'embed_out': device}\n",
    "            model = model_cls.from_pretrained(model_name, device_map=device_map, load_in_8bit=True, **kwargs)\n",
    "        if hasattr(model.config, 'use_cache'): model.config.use_cache = False  # save GPU mem\n",
    "        # if model_name in ['EleutherAI/gpt-neox-20b']: model = model.half()\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name.replace('/cpu', ''), cache_dir=cache_dir)\n",
    "        unify(model)\n",
    "        models[model_name] = model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "21c8cd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there was a little girl named Alice. She lived in a small village with her parents and siblings.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "openai.api_key = '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'\n",
    "proxy_key = \"brd-customer-hl_c1b0ccff-zone-openai2-ip-178.171.126.110:sf23ma3ozhu3@zproxy.lum-superproxy.io:22225\"\n",
    "openai.proxy = {\"http\": 'http://'+proxy_key, \"https\": 'https://' + proxy_key}\n",
    "#open('/nas/xd/projects/openai_api_keys.txt').readlines()[4].split()[0]\n",
    "response = openai.Completion.create(engine='text-davinci-003', prompt='Once upon a time',\n",
    "    max_tokens=20, temperature=0, echo=True, logprobs=5)\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c64283f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_model(engine):\n",
    "    def forward(input_ids):#, attention_mask=None):\n",
    "        text = tokenizer.decode(input_ids[0])\n",
    "        response = openai.Completion.create(engine=engine, prompt=text, max_tokens=0, echo=True, logprobs=5)\n",
    "        return Outputs(logits=response.choices[0].logprobs)\n",
    "    return forward\n",
    "    \n",
    "tokenizer0 = GPT2Tokenizer.from_pretrained('gpt2', cache_dir=cache_dir)\n",
    "engines = ['text-curie-001', 'davinci', 'text-davinci-001', 'text-davinci-002', 'text-davinci-003', 'code-davinci-002'] #+ \\\n",
    "#     ['curie', 'curie:2020-05-03', 'curie-instruct-beta', 'text-curie-001'] + \\\n",
    "#     ['davinci', 'davinci:2020-05-03', 'davinci-instruct-beta', 'davinci-instruct-beta:2.0.0', 'text-davinci-001', 'text-davinci-002']\n",
    "for engine in engines:\n",
    "    if engine not in models: models[engine] = get_openai_model(engine), tokenizer0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bc28755",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = gpt_model_names[1]  # engines[4]\n",
    "model, tokenizer = models[model_name]\n",
    "model_name_gpu = model_name.replace('/cpu', '')\n",
    "model_gpu = models[model_name_gpu][0] if model_name_gpu in models else model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b77b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = model.transformer.h\n",
    "for i, b in enumerate(blocks): b.layer = i\n",
    "ln_f = model.transformer.ln_f\n",
    "L, H, embed_dim = len(blocks), blocks[0].attn.num_heads, blocks[0].attn.embed_dim\n",
    "\n",
    "# we = model.transformer.wte.weight.data\n",
    "# wu = model.lm_head.weight.data\n",
    "\n",
    "# es = [we]\n",
    "# for b in blocks[:1]: es.append(es[-1] + mlp_forward(b, es[-1]))\n",
    "# model.es = es\n",
    "# weBTAs = [es[i].T @ es[i] for i in range(2)]\n",
    "# model.weBTAs = weBTAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f9e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:7')\n",
    "_ = clone_model_to(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801a667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediary_heads = [(8, 1), (12, 10), (13, 13)]\n",
    "circuit_ends = {\n",
    "    'thing->type': ([(15, 8), (21, 5)], [(5, 12), (7, 2)]),\n",
    "    'thing->capability': ([(13, 15)], [(6, 5), (3, 7), (5, 12)]),\n",
    "    'capital->country': ([(19, 12)], [(5, 12)]), # inverse 3-7 by nrk \n",
    "    'opposite': ([(16, 14)], [(7, 9)]),\n",
    "    'fr->en': ([(16, 15), (21, 14)], [(5, 12)]),\n",
    "    'copy': ([(16, 7)], [(8, 7), (6, 2)]), # (1, 7), (3, 12), (6, 10)\n",
    "    # did->does 6-2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6eb024",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicting_heads, relating_heads = defaultdict(list), defaultdict(list)\n",
    "for taskname, (pred_heads, rel_heads) in circuit_ends.items():\n",
    "    for pred_head in pred_heads: predicting_heads[pred_head].append(taskname)\n",
    "    for rel_head in rel_heads: relating_heads[rel_head].append(taskname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df73ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for block in blocks: remove_composed_heads(block.attn)\n",
    "# blocks[4].attn.composed_heads = [((4, 8), (4, 6))]; blocks[4].attn.ranges_i = ['ans]->*']  # opposite\n",
    "blocks[6].attn.composed_heads = [('ans]->ans0]', (6, 2))]; blocks[6].attn.ranges_i = ['ans]->*']  # opposite\n",
    "blocks[1].attn.composed_heads = [('ans]->ans0]', (1, 7))]; blocks[1].attn.ranges_i = ['ans]->*']  # opposite\n",
    "blocks[8].attn.composed_heads = [('ans]->ans0]', (8, 7))]; blocks[8].attn.ranges_i = ['ans]->*']  # opposite\n",
    "# blocks[6].attn.composed_heads = [((4, 8), (6, 10))]; blocks[6].attn.ranges_i = ['ans]->*']  # opposite\n",
    "# blocks[8].attn.composed_heads = [((7, 2), (8, 7))]\n",
    "# blocks[6].attn.composed_heads = [((7, 2), (6, 2))]\n",
    "# blocks[4].attn.composed_heads = [((3, 12), (4, 8))]\n",
    "# blocks[3].attn.composed_heads = [((3, 12), (3, 6))]\n",
    "blocks[11].attn.composed_heads = [('bos->query]', (11, 12))]; blocks[11].attn.ranges_i = ['bos->*']\n",
    "for block in blocks:\n",
    "    if getattr(block.attn, 'composed_heads', None) is not None:\n",
    "        compose_heads(model, block.attn, block.attn.composed_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fb0fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "relating_heads = [(6, 2), (8, 7), (7, 2), (5, 12)]#(7, 9)]\n",
    "intermediary_heads = [(8, 1), (12, 10), (13, 13)]\n",
    "predicting_heads = [(13, 7), (16, 7), (15, 8), (21, 5)]#, (16, 14)]\n",
    "for circuit in product(relating_heads, intermediary_heads, predicting_heads):\n",
    "    eigv_pos = plot_eigv(weightprod(model, list(circuit), 'e vo vo qk e', weBTA=model.weBTAs[0]), plot=False)[0]\n",
    "    print(circuit, eigv_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fb34c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with gzip.open(f'results/results-genders_of_persons-types_of_things.pkl.gz', 'wb') as f:\n",
    "#     pickle.dump({k: result2dict(r) for k, r in results.items()}, f)\n",
    "# with gzip.open(f'results.pkl.gz', 'rb') as f: results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fa6edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_key = keys[0]; res_key\n",
    "fpath = f'results/{res_key}_attn_attrs.npz'\n",
    "np.savez_compressed(fpath, *dump_attn_attrs_to_arrays(root, result.data_tuples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04901ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "_root = deepcopy(root)\n",
    "def fn(node): node.data = asdict(node.data)\n",
    "traverse_tree(_root, fn, include_dummy=True)\n",
    "pickle.dump(_root, gzip.open(f'results/{res_key}_tree.pkl.gz', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "706055f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\n",
    "    (lambda: [TreeSet(genders_of_persons).use('equal'), TreeSet(types_of_things).use('equal')], MlM_gen,\n",
    "     partial(_cxt2str, item2str=lambda i, _: [f\"{i[0]} has {wrap_noun(i[1])}\", f\"The {i[1]} is {i[0]}'s\"]), lambda q, _: f'{q}', \" likes\"\n",
    "    ),\n",
    "#     (lambda: [TreeSet(types_of_characters).use('child'), TreeSet(types_of_things).use('child')], partial(MlM_gen, cxt_sample_fn=enumerate_sample, query=1),\n",
    "#      partial(_cxt2str, item2str=lambda i, _: [f\"{i[0]} has {i[1]}\", f\"{the_(i[1])} is {i[0]}'s\"]), lambda q, _: f\"{q}\", \" likes\"\n",
    "#     ),\n",
    "    (lambda: [TreeSet(genders_of_persons).use(['equal', 'child', 'sibling']), TreeSet(types_of_things).use(['equal', 'child', 'sibling'])], MlM_gen,\n",
    "     partial(_cxt2str, item2str=lambda i, _: [f\"{i[0]} has {a_(i[1])}\", f\"{_be(the_(i[1]))} {i[0]}'s\"]), lambda q, _: f\"{the_(q)}\", \" likes\"\n",
    "    ), # t: 21-5, 15-8, 19. p: 16-7, 18-5, [3-12, 13-7]. p+: 16-7, 16-0. 13-7:induction head qk, thing->type ov\n",
    "    (lambda: [TreeSet(genders_of_persons).use('equal'), TreeSet(countries_of_cities).use('equal')], MlM_gen,\n",
    "     partial(_cxt2str, item2str=lambda i, _: [f'{i[0]} likes {i[1]}', f'{i[1]} attracts {i[0]}']), lambda q, _: f'{q} wants to go', ' to'\n",
    "    ), # t: 19-12 >> 16-10 = 12-7\n",
    "    (lambda: [TreeSet(genders_of_persons).use('equal'), TreeSet(countries_of_cities).use('child')], MlM_gen,\n",
    "     partial(_cxt2str, item2str=lambda i, _: [f'{i[0]} likes {i[1]}', f'{i[1]} attracts {i[0]}']), lambda q, _: f'{q} wants to go', ' to'\n",
    "    ), # t: 19-12 >> 16-10 = 12-7\n",
    "#     (lambda: [TreeSet(genders_of_persons).use('equal'), TreeSet(capabilities_of_things).use('equal')], MlM_gen,\n",
    "#      partial(_cxt2str, item2str=lambda i, _: [f\"{i[0]} has {wrap_noun(i[1])}\", f\"The {i[1]} is {i[0]}'s\"]), lambda q, _: f'{q} likes', ' the'\n",
    "#     ),\n",
    "#     (lambda: [TreeSet(genders_of_persons).use('equal'), TreeSet(capabilities_of_things).use('child')], MlM_gen,\n",
    "#      partial(_cxt2str, item2str=lambda i, _: [f\"{i[0]} has {wrap_noun(i[1])}\", f\"The {i[1]} is {i[0]}'s\"]), lambda q, _: f'{q}', ' can'\n",
    "#     ),\n",
    "#     (lambda: [TreeSet(genders_of_persons).use('equal'), SymSet(person_adjs).use('equal')], MlM_gen,\n",
    "#      partial(_cxt2str, item2str=lambda i, _: [f\"{i[0]} is {i[1]}\", f\"{i[1].capitalize()} is {i[0]}\"]), lambda q, _: f\"Yes, {q} looks\", \" like\"\n",
    "#     ),\n",
    "#     (lambda: [TreeSet(genders_of_persons).use('equal'), SymSet(person_adjs).use('opposite')], MlM_gen,\n",
    "#      partial(_cxt2str, item2str=lambda i, _: [f\"{i[0]} is {i[1]}\", f\"{i[1].capitalize()} is {i[0]}\"]), lambda q, _: f\"Um, {q} looks\", \" like\"\n",
    "#     ), # t: 16-14, somewhat 14-7 # verbose acc: gpj-j > curie-001 > davinci-001 > gpt-neox!? abstract acc: gpt-neox > gpt-j. all poor (inc. davinci-002!)\n",
    "#     (lambda: [TreeSet(genders_of_persons).use('equal'), PoSet(temporal_posets).use('equal')], MlM_gen,\n",
    "#      partial(_cxt2str, item2str=lambda i, _: [f'{i[0]} arrived {wrap_noun2(i[1])}', f'{wrap_noun2(i[1]).capitalize()} arrived {i[0]}']), lambda q, _: f\"So {q}'s arrival time\", ' is'\n",
    "#     ),\n",
    "#     (lambda: [TreeSet(genders_of_persons).use('equal'), PoSet(temporal_posets).use('prev')], MlM_gen,\n",
    "#      partial(_cxt2str, item2str=lambda i, _: [f'{i[0]} arrived {wrap_noun2(i[1])}', f'{wrap_noun2(i[1]).capitalize()} arrived {i[0]}']), lambda q, _: f'So {q} arrived just', ' after'\n",
    "#     ),\n",
    "#     (lambda: [TreeSet(genders_of_persons).use('equal'), PoSet(temporal_posets).use('next')], MlM_gen,\n",
    "#      partial(_cxt2str, item2str=lambda i, _: [f'{i[0]} arrived {wrap_noun2(i[1])}', f'{wrap_noun2(i[1]).capitalize()} arrived {i[0]}']), lambda q, _: f'So {q} arrived just', ' before'\n",
    "#     ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "20e45b55",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.equal][cxt_len=3,rev_item2str]\n",
      " ┌@[0,1,2,6,8,9,10,11,12,14,15] 9-m,10-m,41-m,33-m,25-m,40-m,34-m,38-m,24-m,21-m,26-m B->B 54\n",
      " ├@[3,4,5,13,16,17,18] 35-62,22-40,30-34,19-21,29-5,21-49,24-37 B->A0 26\n",
      " ├@[7,19] 42-7,42-37 unk 0\n",
      " ├@0 9-m 100\n",
      " ├@1 10-m 65\n",
      " ├@2 41-m 62\n",
      " ├@6 33-m 48\n",
      " ├@8 25-m 45\n",
      " ├@9 40-m 45\n",
      " ├@10 34-m 44\n",
      " ├@11 38-m 44\n",
      " ├@12 24-m 43\n",
      " ├@14 21-m 42\n",
      " ├@15 26-m 42\n",
      " ├@3 35-62 56 B->A0 5/2/-9.2 attn/ans0s\n",
      " │                                       ┌@[1,4,6,7] 19-53,12-44,17-61,14-39 B->A0 36\n",
      " │                                       ├@[3,5,9] 19-29,21-60,12-m B->B 24\n",
      " │                                       ├@[0] 15-38 B->Q 10\n",
      " │                                       ├@[2,8] 12-35,16-45 B->T 8\n",
      " │                                       ├@1 19-53 98 B->A0 95/43/-5.9\n",
      " │                                       ├@4 12-44 79 B->A0 94/40/-4.4\n",
      " │                                       ├@6 17-61 67 B->A0 81/23/-3.7\n",
      " │                                       ├@7 14-39 61 B->A0 56/22/-3.9\n",
      " │                                       ├@3 19-29 85 B->B 62/58/-5.8\n",
      " │                                       ├@5 21-60 77 B->B 74/78/-7.4\n",
      " │                                       ├@9 12-m 46\n",
      " ├@4 22-40 52 B->A0 96/54/-6.3 attn/ans0s┤\n",
      " │                                       │                            ┌@[4,6] 10-54 31,9-m Q->Q 19\n",
      " │                                       │                            ├@[0,1,2,3,5] 12-35 100,12-63 45,8-55 33,10-6 32,9-12 31 unk 0\n",
      " │                                       │                            ├@4 10-54 31 Q->Q 39/46/-5.4\n",
      " │                                       │                            ├@0 12-35 100 Q->T 64/43/-5.8\n",
      " │                                       ├@0 15-38 100 B->Q 60/61/-4.3┤\n",
      " │                                       │                            ├@1 12-63 45 Q->A0 0/0/-7.7\n",
      " │                                       │                            ├@2 8-55 33 Q->T 0/0/-6.5\n",
      " │                                       │                            ├@3 10-6 32 Q->T 3/5/-5.7\n",
      " │                                       │                            └@5 9-12 31 Q->T+ -1/1/-4.5\n",
      " │                                       │                           ┌@:5 11-5 100,7-7 81,7-57 78,7-31,6-38 T->A0 31\n",
      " │                                       │                           ├@0 11-5 100 T->A0 22/17/-2.7\n",
      " │                                       ├@2 12-35 87 B->T 58/28/-4.8┤\n",
      " │                                       │                           ├@1 7-7 81 T->A0 45/58/-2.2\n",
      " │                                       │                           └@2 7-57 78 T->A0 50/55/-1.9\n",
      " │                                       │                           ┌@[1,2,3,6] 12-m 35,9-m 32,10-m,8-m T->T 57\n",
      " │                                       │                           ├@[0,4,5] 14-39 100,11-35,12-52 unk 0\n",
      " │                                       └@8 16-45 57 B->T 26/13/-4.8┤\n",
      " │                                                                   ├@1 12-m 35\n",
      " │                                                                   ├@2 9-m 32\n",
      " │                                                                   └@0 14-39 100 T->A0 13/56/-3.4\n",
      " ├@5 30-34 51 B->A0 92/33/-6.3 attn/ans0s\n",
      " ┤\n",
      " │                                        ┌@[3,5] 18-23,0-m B->B 21\n",
      " │                                        ├@[0,2,8] 14-39,12-52,10-52 B->A0 20\n",
      " │                                        ├@[6,7] 15-38,15-0 B->Q 19\n",
      " │                                        ├@[1,4] 16-45,12-35 B->T 10\n",
      " │                                        ├@3 18-23 54 B->B 69/84/-7.9\n",
      " │                                        ├@5 0-m 46\n",
      " │                                        ├@0 14-39 100 B->A0 56/22/-3.6\n",
      " │                                        ├@2 12-52 54 B->A0 70/24/-4.1\n",
      " │                                        ├@8 10-52 31 B->A0 46/16/-3.3\n",
      " │                                        │                           ┌@[1,2,3] 9-12 62,0-m,8-m Q->Q 30\n",
      " │                                        │                           ├@[0,4,5,6] 12-35 100,10-0,10-6,10-12 Q->T 12\n",
      " │                                        ├@6 15-38 43 B->Q 62/61/-4.9┤\n",
      " │                                        │                           ├@1 9-12 62 Q->Q 0/1/-4.7\n",
      " │                                        │                           └@0 12-35 100 Q->T 71/43/-5.8\n",
      " ├@13 19-21 42 B->A0 94/43/-5.1 attn/ans0s┤\n",
      " │                                        │                          ┌@[0,1,2,3,4,6] 8-m 100,8-43 79,7-m 73,10-m 64,9-17 64,0-m 54 Q->Q 57\n",
      " │                                        │                          ├@[5] 10-19 56 unk 0\n",
      " │                                        │                          ├@0 8-m 100\n",
      " │                                        │                          ├@1 8-43 79 Q->Q 0/0/-4.3\n",
      " │                                        ├@7 15-0 34 B->Q 45/34/-4.5┤\n",
      " │                                        │                          ├@2 7-m 73\n",
      " │                                        │                          ├@3 10-m 64\n",
      " │                                        │                          ├@4 9-17 64 Q->Q 0/2/-5.1\n",
      " │                                        │                          ├@6 0-m 54\n",
      " │                                        │                          └@5 10-19 56 Q->T+ 0/1/-4.2\n",
      " │                                        │                           ┌@[1,2,3,4] 13-m 36,10-m 31,12-m,9-m T->T 57\n",
      " │                                        │                           ├@[0,5,6] 14-39 100,12-52,11-35 T->A0 6\n",
      " │                                        ├@1 16-45 64 B->T 26/13/-4.8┤\n",
      " │                                        │                           ├@1 13-m 36\n",
      " │                                        │                           ├@2 10-m 31\n",
      " │                                        │                           └@0 14-39 100 T->A0 20/56/-2.5\n",
      " │                                        │                           ┌@[1,3] 6-m 81,8-m 46 T->T 39\n",
      " │                                        │                           ├@[0,2,4] 11-35 100,10-52 48,8-15 41 T->A0 13\n",
      " │                                        │                           ├@1 6-m 81\n",
      " │                                        └@4 12-35 47 B->T 64/28/-4.8┤\n",
      " │                                                                    ├@3 8-m 46\n",
      " │                                                                    ├@0 11-35 100 T->A0 33/24/-2.4\n",
      " │                                                                    ├@2 10-52 48 T->A0 33/30/-2.5\n",
      " │                                                                    └@4 8-15 41 T->A0 0/1/-6.7\n",
      " ├@16 29-5 39 B->A0 47/11/-9.3 attn/ans0s\n",
      " │                                        ┌@[0,3,5,6,9] 19-29,18-m,0-m,17-m,18-23 B->B 45\n",
      " │                                        ├@[2,4] 12-44,14-39 B->A0 19\n",
      " │                                        ├@[8] 15-38 B->Q 9\n",
      " │                                        ├@[1,7] 12-35,16-45 B->T 9\n",
      " │                                        ├@0 19-29 100 B->B 60/58/-5.5\n",
      " │                                        ├@3 18-m 88\n",
      " │                                        ├@5 0-m 75\n",
      " │                                        ├@6 17-m 72\n",
      " │                                        ├@9 18-23 50 B->B 81/84/-7.4\n",
      " │                                        ├@2 12-44 95 B->A0 92/40/-4.2\n",
      " │                                        ├@4 14-39 85 B->A0 59/22/-3.6\n",
      " ├@17 21-49 38 B->A0 98/58/-6.7 attn/ans0s┤\n",
      " │                                        │                           ┌@[3,4,5] 8-m,7-m,9-1 Q->Q 28\n",
      " │                                        ├@8 15-38 66 B->Q 60/61/-4.7┤\n",
      " │                                        │                           ├@[0,1,2,6] 12-35 100,9-12,10-6,12-63 unk 0\n",
      " │                                        │                           └@0 12-35 100 Q->T 69/43/-5.9\n",
      " │                                        │                           ┌@[0,1,2,4] 11-35 100,11-5 99,7-7 86,7-57 74 T->A0 33\n",
      " │                                        │                           ├@[3] 8-m 84 T->T 20\n",
      " │                                        │                           ├@0 11-35 100 T->A0 34/24/-2.7\n",
      " │                                        ├@1 12-35 98 B->T 62/28/-4.7┤\n",
      " │                                        │                           ├@1 11-5 99 T->A0 25/17/-2.9\n",
      " │                                        │                           ├@2 7-7 86 T->A0 50/58/-2.1\n",
      " │                                        │                           ├@4 7-57 74 T->A0 57/55/-1.8\n",
      " │                                        │                           └@3 8-m 84\n",
      " │                                        │                           ┌@[3,5] 10-m,8-20 T->T 14\n",
      " │                                        └@7 16-45 71 B->T 28/13/-5.0┤\n",
      " │                                                                    ├@[0,1,2,4,6] 14-39 100,15-23,10-52,12-52,14-7 T->A0 8\n",
      " │                                                                    └@0 14-39 100 T->A0 20/56/-2.4\n",
      " ├@18 24-37 38 B->A0 91/33/-7.5 attn/ans0s\n",
      " │                                 ┌@[2,5,8] 15-m,18-23,8-m B->B 26\n",
      " │                                 ├@[0,6,7] 15-38,11-35,10-54 B->Q 21\n",
      " │                                 ├@[1,4] 12-35,16-45 B->T 8\n",
      " │                                 ├@[3] 14-39 B->A0 6\n",
      " │                                 ├@2 15-m 56\n",
      " │                                 ├@5 18-23 35 B->B 29/84/-7.9\n",
      " ├@125 19-54 11 B->A0/58 attn/ans0s┤\n",
      " │                                 ├@8 8-m 30\n",
      " │                                 ├@0 15-38 100 B->Q 50/61/-4.6\n",
      " │                                 ├@6 11-35 34 B->Q 69/76/-6.1\n",
      " │                                 ├@7 10-54 34 B->Q 55/76/-6.9\n",
      " │                                 ├@1 12-35 60 B->T 53/28/-4.9\n",
      " │                                 ├@4 16-45 45 B->T 17/13/-4.9\n",
      " │                                 └@3 14-39 54 B->A0 43/22/-4.0\n",
      " │                                ┌@[2,3] 12-m,9-m B->B 25\n",
      " │                                ├@[0,7] 15-38,10-54 B->Q 14\n",
      " │                                ├@[1,5] 12-35,16-45 B->T 9\n",
      " │                                ├@[4] 14-39 B->A0 5\n",
      " │                                ├@[6] 12-17 unk 0\n",
      " │                                ├@2 12-m 66\n",
      " ├@196 17-28 6 B->A0/55 attn/ans0s┤\n",
      " │                                ├@3 9-m 53\n",
      " │                                ├@0 15-38 100 B->Q 50/61/-4.7\n",
      " │                                ├@7 10-54 35 B->Q 47/76/-6.5\n",
      " │                                ├@1 12-35 70 B->T 56/28/-4.9\n",
      " │                                ├@5 16-45 47 B->T 20/13/-4.8\n",
      " │                                ├@4 14-39 50 B->A0 44/22/-4.1\n",
      " │                                └@6 12-17 39 B->A] 1/5\n",
      " ├@2650 19-1 -2 B->A0/55 attn/ans0s\n",
      " ├@7 42-7 47 B->A] 0/0 attn\n",
      " └@19 42-37 37 B->Q 55/90/-10.5 attn\n"
     ]
    }
   ],
   "source": [
    "print(key); print_tree(r.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c23b7bda",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.equal][cxt_len=3,rev_item2str]\n",
      " ┌@[0,3,9,10,11,13,14,17,18] 35-62,25-m,11-m,28-m,9-m,24-m,30-m,26-m,29-m B->B 42\n",
      " ├@[1,2,4,5,7,8,12,15,16,19] 22-19,27-6,24-41,26-19,22-40,33-49,29-39,33-63,25-27,21-14 B->A0 41\n",
      " ├@[6] 42-7 unk 0\n",
      " ├@0 35-62 100 B->B 15/70/-9.3\n",
      " ├@3 25-m 82\n",
      " ├@9 11-m 64\n",
      " ├@10 28-m 63\n",
      " ├@11 9-m 63\n",
      " ├@13 24-m 61\n",
      " ├@14 30-m 61\n",
      " ├@17 26-m 56\n",
      " ├@18 29-m 54\n",
      " ├@1 22-19 92 B->A0 94/35/-7.3 attn/ans0s\n",
      " ├@2 27-6 90 B->A0 89/32/-7.6 attn/ans0s\n",
      " │                                       ┌@[0,4,5,6,10] 20-m,21-60,17-m,19-29,21-m 23 B->B 38\n",
      " │                                       ├@[2,3,7,9] 12-44,19-53,11-49,14-39 30 B->A0 25\n",
      " │                                       ├@[8] 15-38 B->Q 7\n",
      " │                                       ├@[1] 12-35 B->T 4\n",
      " │                                       ├@0 20-m 100\n",
      " │                                       ├@4 21-60 56 B->B 60/76/-7.2\n",
      " ├@4 24-41 79 B->A0 95/43/-6.4 attn/ans0s┤\n",
      " │                                       ├@5 17-m 51\n",
      " │                                       ├@6 19-29 50 B->B 47/59/-6.0\n",
      " │                                       ├@2 12-44 66 B->A0 97/35/-4.9\n",
      " │                                       ├@3 19-53 56 B->A0 94/43/-6.8\n",
      " │                                       ├@7 11-49 35 B->A0 91/28/-4.7\n",
      " │                                       ├@8 15-38 32 B->Q 28/57/-4.4\n",
      " │                                       └@1 12-35 73 B->T 59/22/-4.9\n",
      " ├@5 26-19 69 B->A0 77/35/-5.5 attn/ans0s\n",
      " ┤\n",
      " │                                       ┌@[1,4,6] 17-m,19-29,21-60 B->B 20\n",
      " │                                       ├@[0,5,7,9] 12-44,19-53,11-49,17-61 B->A0 16\n",
      " │                                       ├@[2] 15-38 B->Q 7\n",
      " │                                       ├@[3] 12-35 B->T 5\n",
      " │                                       ├@[8] 19-60 unk 0\n",
      " │                                       ├@1 17-m 98\n",
      " │                                       ├@4 19-29 78 B->B 48/59/-6.3\n",
      " ├@7 22-40 68 B->A0 93/45/-6.6 attn/ans0s┤\n",
      " │                                       ├@6 21-60 67 B->B 46/76/-7.4\n",
      " │                                       ├@0 12-44 100 B->A0 89/35/-4.7\n",
      " │                                       ├@5 19-53 78 B->A0 96/43/-6.4\n",
      " │                                       ├@7 11-49 57 B->A0 89/28/-4.5\n",
      " │                                       ├@9 17-61 52 B->A0 78/24/-3.7\n",
      " │                                       ├@2 15-38 93 B->Q 64/57/-4.4\n",
      " │                                       ├@3 12-35 92 B->T 54/22/-4.8\n",
      " │                                       └@8 19-60 56 B->S 8/1/-6.6\n",
      " ├@8 33-49 66 B->A0 31/14/-10.5 attn/ans0s\n",
      " ├@12 29-39 62 B->A0 84/30/-7.9 attn/ans0s\n",
      " ├@15 33-63 61 B->A0 64/21/-9.4 attn/ans0s\n",
      " │                                        ┌@[3,4,6,8,9] 12-44,19-53,11-49,15-38,14-39 B->A0 27\n",
      " │                                        ├@[0,1,5,7] 21-60,19-29,22-m,20-m B->B 12\n",
      " │                                        ├@[2] 12-35 B->T 3\n",
      " │                                        ├@[10] 18-23 unk 0\n",
      " │                                        ├@3 12-44 92 B->A0 86/35/-4.9\n",
      " │                                        ├@4 19-53 85 B->A0 77/43/-6.3\n",
      " │                                        ├@6 11-49 60 B->A0 85/28/-4.3\n",
      " ├@16 25-27 60 B->A0 91/43/-6.5 attn/ans0s┤\n",
      " │                                        ├@8 15-38 54 B->A0 18/9/-4.8\n",
      " │                                        ├@9 14-39 44 B->A0 50/23/-4.0\n",
      " │                                        ├@0 21-60 100 B->B 51/76/-6.9\n",
      " │                                        ├@1 19-29 95 B->B 66/59/-5.9\n",
      " │                                        ├@5 22-m 62\n",
      " │                                        ├@7 20-m 56\n",
      " │                                        ├@2 12-35 94 B->T 35/22/-4.9\n",
      " │                                        └@10 18-23 40 B->Q- 4/0/-8.1\n",
      " │                                        ┌@[4,5,8] 19-29,18-m,17-m B->B 27\n",
      " │                                        ├@[0,2,3] 12-44,19-53,11-49 B->A0 16\n",
      " │                                        ├@[1] 12-35 B->T 6\n",
      " │                                        ├@[7] 15-38 B->Q 4\n",
      " │                                        ├@[6,9] 16-20,19-60 25 B->S 3\n",
      " │                                        ├@4 19-29 49 B->B 62/59/-6.2\n",
      " │                                        ├@5 18-m 47\n",
      " ├@19 21-14 54 B->A0 99/45/-7.1 attn/ans0s┤\n",
      " │                                        ├@8 17-m 33\n",
      " │                                        ├@0 12-44 100 B->A0 89/35/-4.6\n",
      " │                                        ├@2 19-53 64 B->A0 92/43/-5.9\n",
      " │                                        ├@3 11-49 50 B->A0 86/28/-4.5\n",
      " │                                        ├@1 12-35 92 B->T 52/22/-4.9\n",
      " │                                        ├@7 15-38 42 B->Q 42/57/-4.4\n",
      " │                                        └@6 16-20 43 B->S 24/11/-5.4\n",
      " └@6 42-7 68 B->S 0/0/-11.5 attn\n"
     ]
    }
   ],
   "source": [
    "print(key); print_tree(r.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "61d301bd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.equal][cxt_len=3,rev_item2str]\n",
      " ┌@[0,3,9,10,11,13,14,17,18] 35-62,25-m,11-m,28-m,9-m,24-m,30-m,26-m,29-m B->B 42\n",
      " ├@[1,2,4,5,7,8,12,15,16,19] 22-19,27-6,24-41,26-19,22-40,33-49,29-39,33-63,25-27,21-14 B->A0 41\n",
      " ├@[6] 42-7 unk 0\n",
      " ├@0 35-62 100 B->B 15/70/-9.3\n",
      " ├@3 25-m 82\n",
      " ├@9 11-m 64\n",
      " ├@10 28-m 63\n",
      " ├@11 9-m 63\n",
      " ├@13 24-m 61\n",
      " ├@14 30-m 61\n",
      " ├@17 26-m 56\n",
      " ├@18 29-m 54\n",
      " ├@1 22-19 92 B->A0 94/35/-7.3 attn/ans0s\n",
      " ├@2 27-6 90 B->A0 89/32/-7.6 attn/ans0s\n",
      " ├@4 24-41 79 B->A0 95/43/-6.4 attn/ans0s\n",
      " ├@5 26-19 69 B->A0 77/35/-5.5 attn/ans0s\n",
      " ├@7 22-40 68 B->A0 93/45/-6.6 attn/ans0s\n",
      " ├@8 33-49 66 B->A0 31/14/-10.5 attn/ans0s\n",
      " ├@12 29-39 62 B->A0 84/30/-7.9 attn/ans0s\n",
      " ├@15 33-63 61 B->A0 64/21/-9.4 attn/ans0s\n",
      " ├@16 25-27 60 B->A0 91/43/-6.5 attn/ans0s\n",
      " ├@19 21-14 54 B->A0 99/45/-7.1 attn/ans0s\n",
      " ├@6 42-7 68 B->S 0/0/-11.5 attn\n",
      " ┤\n",
      " │                                        ┌@[2,4,5,8] 20-m,19-29,21-60,17-m B->B 32\n",
      " │                                        ├@[0,3,7,9] 12-44,19-53,11-49,14-39 B->A0 31\n",
      " │                                        ├@[6] 15-38 B->Q 10\n",
      " │                                        ├@[1] 12-35 B->T 6\n",
      " │                                        ├@[10] 16-20 unk 0\n",
      " │                                        ├@2 20-m 96\n",
      " │                                        ├@4 19-29 75 B->B 70/59/-6.0\n",
      " │                                        ├@5 21-60 60 B->B 74/76/-7.0\n",
      " │                                        ├@8 17-m 49\n",
      " │                                        ├@0 12-44 100 B->A0 96/35/-4.5\n",
      " │                                        ├@3 19-53 78 B->A0 98/43/-6.2\n",
      " │                                        ├@7 11-49 56 B->A0 93/28/-4.3\n",
      " │                                        ├@9 14-39 38 B->A0 49/23/-3.9\n",
      " │                                        ├@6 15-38 60 B->Q 60/57/-4.3\n",
      " │                                        ├@1 12-35 97 B->T 57/22/-4.8\n",
      " └24-41,22-40,25-27,21-14 B->A0 attn/ans0s┤\n",
      "                                          ├@10 16-20 34 B->S 28/11/-5.3\n",
      "                                          │          ┌@[0,4] 12-35 100,8-55 Q->T 5\n",
      "                                          │          ├@[3,6] 9-12 32,10-54 Q->Q 4\n",
      "                                          │          ├@[5] 12-52 Q->A0 2\n",
      "                                          │          ├@[1,2] 12-63 38,9-39 38 unk 0\n",
      "                                          ├15-38 B->Q┤\n",
      "                                          │          ├@0 12-35 100 Q->T 58/43/-5.9\n",
      "                                          │          ├@3 9-12 32 Q->Q 0/1/-4.5\n",
      "                                          │          ├@1 12-63 38 Q->T+ 4/8/-7.2\n",
      "                                          │          ├@2 9-39 38 Q->T+ 0/0/-7.8\n",
      "                                          │          └12-35 Q->T\n",
      "                                          │          ┌@:5 11-5 100,7-57 31,11-35,10-52,7-7 T->A0 33\n",
      "                                          └12-35 B->T┤\n",
      "                                                     ├@0 11-5 100 T->A0 23/17/-2.8\n",
      "                                                     └@1 7-57 31 T->A0 48/58/-1.9\n"
     ]
    }
   ],
   "source": [
    "print(key); print_tree(r.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "722c0ef4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.equal][cxt_len=3,rev_item2str]\n",
      " ┌@[1,4,5,7,8,11,12,13,17,18] 26-19,27-6,22-40,29-39,25-27,17-61,23-29,33-63,34-47,22-2 B->A0 44\n",
      " ├@[0,2,3,6,14,15,16,19] 25-m,28-m,24-m,30-m,26-m,15-m,10-m,29-m B->B 40\n",
      " ├@[9,10] 35-38,42-7 unk 0\n",
      " ├@1 26-19 92 B->A0 85/37/-4.8 attn/ans0s\n",
      " ├@4 27-6 83 B->A0 95/38/-6.9 attn/ans0s\n",
      " │                                       ┌@[2,3,4,6,8] 18-m,19-29,21-60,16-m,17-m B->B 44\n",
      " │                                       ├@[0,5,7] 11-49,19-53,17-61 B->A0 32\n",
      " │                                       ├@[1,9] 15-38,14-39 B->Q 10\n",
      " │                                       ├@2 18-m 92\n",
      " │                                       ├@3 19-29 75 B->B 60/57/-5.9\n",
      " │                                       ├@4 21-60 72 B->B 81/83/-7.8\n",
      " ├@5 22-40 80 B->A0 97/56/-6.1 attn/ans0s┤\n",
      " │                                       ├@6 16-m 53\n",
      " │                                       ├@8 17-m 47\n",
      " │                                       ├@0 11-49 100 B->A0 92/42/-5.0\n",
      " │                                       ├@5 19-53 56 B->A0 90/38/-5.3\n",
      " │                                       ├@7 17-61 52 B->A0 74/23/-4.6\n",
      " │                                       ├@1 15-38 93 B->Q 54/45/-4.1\n",
      " │                                       └@9 14-39 44 B->Q 51/29/-4.2\n",
      " ├@7 29-39 73 B->A0 91/33/-7.5 attn/ans0s\n",
      " │                                       ┌@[1,3,4,6,9] 21-60,19-29,20-m,18-m,22-m B->B 41\n",
      " │                                       ├@[0,2,7,10] 11-49,19-53,9-5,16-20 B->A0 27\n",
      " │                                       ├@[5,8] 15-38,15-0 B->Q 9\n",
      " │                                       ├@1 21-60 94 B->B 79/83/-7.2\n",
      " │                                       ├@3 19-29 75 B->B 50/57/-5.7\n",
      " │                                       ├@4 20-m 73\n",
      " │                                       ├@6 18-m 62\n",
      " ├@8 25-27 72 B->A0 98/51/-5.8 attn/ans0s┤\n",
      " │                                       ├@9 22-m 41\n",
      " │                                       ├@0 11-49 100 B->A0 88/42/-4.8\n",
      " │                                       ├@2 19-53 80 B->A0 92/38/-5.2\n",
      " │                                       ├@7 9-5 50 B->A0 23/5/-6.3\n",
      " │                                       ├@10 16-20 41 B->A0 43/11/-4.6\n",
      " │                                       ├@5 15-38 67 B->Q 50/45/-4.4\n",
      " │                                       └@8 15-0 41 B->Q 47/48/-4.4\n",
      " ┤\n",
      " ├@11 17-61 68 B->A0 81/23/-4.0 attn/ans0s\n",
      " │                                        ┌@[3,4,5,9] 15-38,11-35,15-0,14-30 B->Q 31\n",
      " │                                        ├@[2,6,8] 14-39,11-49,12-52 B->A0 27\n",
      " │                                        ├@:2 21-60,19-29 B->B 17\n",
      " │                                        ├@[7] 11-50 B->T 10\n",
      " │                                        ├@3 15-38 89 B->Q 41/45/-4.3\n",
      " │                                        ├@4 11-35 62 B->Q 83/64/-5.0\n",
      " │                                        ├@5 15-0 61 B->Q 47/48/-4.2\n",
      " ├@12 23-29 68 B->A0 94/48/-5.1 attn/ans0s┤\n",
      " │                                        ├@9 14-30 42 B->Q 85/66/-5.1\n",
      " │                                        ├@2 14-39 89 B->A0 40/13/-3.9\n",
      " │                                        ├@6 11-49 53 B->A0 87/42/-5.0\n",
      " │                                        ├@8 12-52 43 B->A0 68/22/-3.9\n",
      " │                                        ├@0 21-60 100 B->B 81/83/-7.4\n",
      " │                                        ├@1 19-29 90 B->B 58/57/-5.3\n",
      " │                                        └@7 11-50 49 B->T 64/63/-4.7\n",
      " ├@13 33-63 66 B->A0 70/19/-9.3 attn/ans0s\n",
      " ├@17 34-47 58 B->A0 70/19/-8.0 attn/ans0s\n",
      " ├@18 22-2 56 B->A0 92/33/-6.5 attn/ans0s\n",
      " ├@113 17-28 15 B->A0/61 attn/ans0s\n",
      " ├@139 19-1 12 B->A0/57 attn/ans0s\n",
      " ├@165 19-54 10 B->A0/59 attn/ans0s\n",
      " ├@2806 26-57 -20 B->A0/59 attn/ans0s\n",
      " ├@2853 23-54 -78 B->A0/60 attn/ans0s\n",
      " ├@0 25-m 100\n",
      " ├@2 28-m 90\n",
      " ├@3 24-m 88\n",
      " ├@6 30-m 80\n",
      " ├@14 26-m 64\n",
      " ├@15 15-m 60\n",
      " ├@16 10-m 59\n",
      " ├@19 29-m 55\n",
      " ├@9 35-38 69 B->Q- 0/1/-8.3 attn\n",
      " ├@10 42-7 69 B->A0+ 0/0/-11.5 attn/ans0s\n",
      " └@[5,8,12,113,139,165]  B->A0 attn/ans0s\n"
     ]
    }
   ],
   "source": [
    "print(key); print_tree(r.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e7bc57d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.equal][cxt_len=3]\n",
      " ┌@[1,4,5,7,8,11,12,13,17,18] 26-19,27-6,22-40,29-39,25-27,17-61,23-29,33-63,34-47,22-2 B->A0 44\n",
      " ├@[0,2,3,6,14,15,16,19] 25-m,28-m,24-m,30-m,26-m,15-m,10-m,29-m B->B 40\n",
      " ├@[9,10] 35-38,42-7 unk 0\n",
      " ├@1 26-19 92 B->A0 85/37/6/-4.8 attn/ans0s\n",
      " ├@4 27-6 83 B->A0 95/38/23/-6.9 attn/ans0s\n",
      " ├@5 22-40 80 B->A0 97/56/62/-6.1 attn/ans0s\n",
      " ├@7 29-39 73 B->A0 91/33/16/-7.5 attn/ans0s\n",
      " ├@8 25-27 72 B->A0 98/51/23/-5.8 attn/ans0s\n",
      " ├@11 17-61 68 B->A0 81/23/3/-4.0 attn/ans0s\n",
      " ├@12 23-29 68 B->A0 94/48/50/-5.1 attn/ans0s\n",
      " ├@13 33-63 66 B->A0 70/19/1/-9.3 attn/ans0s\n",
      " ├@17 34-47 58 B->A0 70/19/-22/-8.0 attn/ans0s\n",
      " ├@18 22-2 56 B->A0 92/33/-5/-6.5 attn/ans0s\n",
      " ├@113 17-28 15 B->A0/61/78 attn/ans0s\n",
      " ├@139 19-1 12 B->A0/57/60 attn/ans0s\n",
      " ├@165 19-54 10 B->A0/59/56 attn/ans0s\n",
      " ├@2806 26-57 -20 B->A0/59/14 attn/ans0s\n",
      " ├@2853 23-54 -78 B->A0/60/52 attn/ans0s\n",
      " ├@0 25-m 100\n",
      " ├@2 28-m 90\n",
      " ├@3 24-m 88\n",
      " ├@6 30-m 80\n",
      " ├@14 26-m 64\n",
      " ├@15 15-m 60\n",
      " ├@16 10-m 59\n",
      " ├@19 29-m 55\n",
      " ├@9 35-38 69 B->Q- 0/1/-31/-8.3 attn\n",
      " ├@10 42-7 69 B->A0+ 0/0/0/-11.5 attn/ans0s\n",
      " ┤\n",
      " │                            ┌@[1,2,4,5,9] 21-60,19-29,20-m,18-m,17-m B->B 47\n",
      " │                            ├@[3,8] 11-49,17-61 B->A0 27\n",
      " │                            ├@[0,6,7] 15-38,14-39,15-0 B->Q 14\n",
      " │                            ├@1 21-60 92 B->B 87/83/53/-7.5\n",
      " │                            ├@2 19-29 90 B->B 60/57/23/-5.5\n",
      " │                            ├@4 20-m 82\n",
      " │                            ├@5 18-m 72\n",
      " │                            ├@9 17-m 40\n",
      " │                            ├@3 11-49 87 B->A0 93/42/19/-4.9\n",
      " │                            ├@8 17-61 41 B->A0 75/23/3/-4.5\n",
      " │                            ├@0 15-38 100 B->Q 49/45/30/-4.2\n",
      " │                            ├@6 14-39 70 B->Q 41/29/26/-4.0\n",
      " │                            ├@7 15-0 47 B->Q 50/48/39/-4.3\n",
      " ├22-40,23-29 B->A0 attn/ans0s┤\n",
      " │                            │                ┌@[0,6,8] 11-49 100,17-61 48,17-19 42 B->A0 25\n",
      " │                            │                ├@[3,5,9] 18-m 62,19-29 53,12-63 41 B->B 16\n",
      " │                            │                ├@[1,2,7] 15-38 81,14-39 75,15-0 42 B->Q 10\n",
      " │                            │                ├@[4] 9-5 57 unk 0\n",
      " │                            │                ├@0 11-49 100 B->A0 80/42/19/-5.3\n",
      " │                            │                ├@6 17-61 48 B->A0 61/23/3/-4.5\n",
      " │                            │                ├@8 17-19 42 B->A0 4/1/3/-7.9\n",
      " │                            ├21-60,19-29 B->B┤\n",
      " │                            │                ├@3 18-m 62\n",
      " │                            │                ├@5 19-29 53 B->B 41/57/23/-5.8\n",
      " │                            │                ├@9 12-63 41 B->B 4/4/0/-6.3\n",
      " │                            │                ├@1 15-38 81 B->Q 37/45/30/-4.4\n",
      " │                            │                ├@2 14-39 75 B->Q 30/29/26/-4.2\n",
      " │                            │                ├@7 15-0 42 B->Q 35/48/39/-4.5\n",
      " │                            │                └@4 9-5 57 B->A] 19/63/43\n",
      " │                            │          ┌@[1,2,4,6] 9-33 75,10-61 60,12-35 41,11-38 40 Q->A0 12\n",
      " │                            │          ├@[3] 11-50 56 Q->T 6\n",
      " │                            │          ├@[5] 10-54 41 Q->Q 5\n",
      " │                            │          ├@[0] 12-63 100 Q->T+ 1\n",
      " │                            │          ├@1 9-33 75 Q->A0 43/50/13/-5.6\n",
      " │                            └15-38 B->Q┤\n",
      " │                                       ├@2 10-61 60 Q->A0 34/31/9/-5.1\n",
      " │                                       ├@4 12-35 41 Q->A0 1/1/2/-5.5\n",
      " │                                       ├@6 11-38 40 Q->A0 7/10/-14/-5.9\n",
      " │                                       ├@3 11-50 56 Q->T 42/94/21/-6.6\n",
      " │                                       ├@5 10-54 41 Q->Q 35/32/-2/-5.1\n",
      " │                                       └@0 12-63 100 Q->T+ 6/7/-13/-5.0\n",
      " │                                 ┌@[1,4] 11-m,9-m B->B 25\n",
      " │                                 ├@[0,2,3,7] 15-38,14-39,15-0,11-35 25 B->Q 17\n",
      " │                                 ├@[8] 17-61 24 B->A0 12\n",
      " │                                 ├@[6] 11-50 B->T 9\n",
      " │                                 ├@[5] 9-5 unk 0\n",
      " │                                 ├@1 11-m 62\n",
      " └17-28,19-1,19-54 B->A0 attn/ans0s┤\n",
      "                                   ├@4 9-m 40\n",
      "                                   ├@0 15-38 100 B->Q 29/45/30/-4.2\n",
      "                                   ├@2 14-39 58 B->Q 30/29/26/-4.1\n",
      "                                   ├@3 15-0 46 B->Q 37/48/39/-4.4\n",
      "                                   ├@6 11-50 33 B->T 44/63/19/-4.7\n",
      "                                   └@5 9-5 35 B->A] 19/63/43\n"
     ]
    }
   ],
   "source": [
    "print(key); print_tree(r.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19f62b01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.equal][cxt_len=3]\n",
      " ┌@[1,4,5,7,8,11,12,13,17,18] 26-19,27-6,22-40,29-39,25-27,17-61,23-29,33-63,34-47,22-2 B->A0 44\n",
      " ├@[0,2,3,6,14,15,16,19] 25-m,28-m,24-m,30-m,26-m,15-m,10-m,29-m B->B 40\n",
      " ├@[9,10] 35-38,42-7 unk 0\n",
      " ├@1 26-19 92 B->A0 85/37/45/-4.8 attn/ans0s\n",
      " ├@4 27-6 83 B->A0 95/38/32/-6.9 attn/ans0s\n",
      " ├@5 22-40 80 B->A0 97/56/74/-6.1 attn/ans0s\n",
      " ├@5 22-40 80 B->A0 97/56/74/-6.1 attn:B->~<s>\n",
      " ├@7 29-39 73 B->A0 91/33/71/-7.5 attn/ans0s\n",
      " ├@7 29-39 73 B->A0 91/33/71/-7.5 attn:B->~<s>\n",
      " ├@8 25-27 72 B->A0 98/51/31/-5.8 attn/ans0s\n",
      " ├@11 17-61 68 B->A0 81/23/-19/-4.0 attn/ans0s\n",
      " ├@12 23-29 68 B->A0 94/48/75/-5.1 attn/ans0s\n",
      " ├@12 23-29 68 B->A0 94/48/75/-5.1 attn:B->~<s>\n",
      " ├@13 33-63 66 B->A0 70/19/6/-9.3 attn/ans0s\n",
      " ├@17 34-47 58 B->A0 70/19/-66/-8.0 attn/ans0s\n",
      " ├@18 22-2 56 B->A0 92/33/15/-6.5 attn/ans0s\n",
      " ├@113 17-28 15 B->A0/61/100 attn/ans0s\n",
      " ├@139 19-1 12 B->A0/57/75 attn/ans0s\n",
      " ├@165 19-54 10 B->A0/59/88 attn/ans0s\n",
      " ├@2806 26-57 -20 B->A0/59/19 attn/ans0s\n",
      " ├@2853 23-54 -78 B->A0/60/80 attn/ans0s\n",
      " ├@0 25-m 100\n",
      " ├@2 28-m 90\n",
      " ├@3 24-m 88\n",
      " ├@6 30-m 80\n",
      " ├@14 26-m 64\n",
      " ├@15 15-m 60\n",
      " ├@16 10-m 59\n",
      " ├@19 29-m 55\n",
      " ├@9 35-38 69 B->Q- 0/1/-3072/-8.3 attn/example\n",
      " ├@10 42-7 69 B->A0+ 0/0/-759039/-11.5 attn/ans0s\n",
      " ┤\n",
      " │                                  ┌@[1,7,9,10] 11-49,19-53,9-5,17-61 B->A0 35\n",
      " │                                  ├@[0,3,4,5] 21-60,19-29,20-m,18-m B->B 34\n",
      " │                                  ├@[2,6,8] 15-38,14-39,15-0 B->Q 14\n",
      " │                                  ├@1 11-49 99 B->A0 92/42/62/-4.8\n",
      " │                                  ├@1 11-49 99 B->A0 92/42/62/-4.8 attn:B->~<s>\n",
      " │                                  ├@1 11-49 99 B->A0 92/42/62/-4.8 attn/ans0s\n",
      " │                                  ├@7 19-53 58 B->A0 93/38/14/-5.2\n",
      " │                                  ├@9 9-5 45 B->A0 25/5/35/-6.1\n",
      " │                                  ├@10 17-61 43 B->A0 76/23/-19/-4.4\n",
      " │                                  ├@0 21-60 100 B->B 91/83/83/-7.4\n",
      " │                                  ├@0 21-60 100 B->B 91/83/83/-7.4 attn:B->~<s>\n",
      " │                                  ├@3 19-29 90 B->B 62/57/12/-5.6\n",
      " │                                  ├@4 20-m 84\n",
      " │                                  ├@5 18-m 73\n",
      " │                                  ├@2 15-38 93 B->Q 50/45/30/-4.2\n",
      " │                                  ├@6 14-39 59 B->Q 42/29/88/-4.1\n",
      " │                                  ├@6 14-39 59 B->Q 42/29/88/-4.1 attn:B->~<s>\n",
      " │                                  ├@6 14-39 59 B->Q 42/29/88/-4.1 attn/example\n",
      " │                                  ├@8 15-0 48 B->Q 53/48/65/-4.3\n",
      " │                                  ├@8 15-0 48 B->Q 53/48/65/-4.3 attn:B->~<s>\n",
      " │                                  ├@8 15-0 48 B->Q 53/48/65/-4.3 attn/example\n",
      " │                                  │           ┌@:5 0-m 100,5-m,7-m,9-39,6-m A0->A0 84\n",
      " │                                  ├11-49 B->A0┤\n",
      " │                                  │           └@0 0-m 100\n",
      " │                                  │                      ┌@[0,1,3,4] 7-10 100,10-52 85,10-55 71,10-54 61 B->Q 43\n",
      " │                                  │                      ├@[2] 9-21 75 unk 0\n",
      " │                                  │                      ├@0 7-10 100 B->Q 87/92/-5/-5.9\n",
      " │                                  ├11-49 B->A0 attn/ans0s┤\n",
      " │                                  │                      ├@1 10-52 85 B->Q 39/14/47/-3.3\n",
      " │                                  │                      ├@3 10-55 71 B->Q 58/88/-10/-7.3\n",
      " │                                  │                      ├@4 10-54 61 B->Q 32/58/-33/-6.6\n",
      " │                                  │                      └@2 9-21 75 B->A] 21/83\n",
      " │                                  │                        ┌@[0,1,2,4] 10-16 100,9-42 89,9-21 55,9-23 47 B->A] 50\n",
      " │                                  │                        ├@[3] 10-52 49 B->Q 6\n",
      " │                                  │                        ├@0 10-16 100 B->A] 80/78\n",
      " │                                  ├11-49 B->A0 attn:B->~<s>┤\n",
      " │                                  │                        ├@1 9-42 89 B->A] 83/74\n",
      " │                                  │                        ├@2 9-21 55 B->A] 87/83\n",
      " │                                  │                        ├@4 9-23 47 B->A] 0/0\n",
      " │                                  │                        └@3 10-52 49 B->Q 26/14/47/-3.4\n",
      " ├22-40,25-27,23-29 B->A0 attn/ans0s┤\n",
      " │                                  │          ┌@[2,4,6,7,9] 11-49 84,12-52 53,9-5 39,17-61 38,16-21 38 B->A0 36\n",
      " │                                  │          ├@[0,8] 19-29 100,0-m 38 B->B 16\n",
      " │                                  │          ├@[1,3,5] 15-38 96,14-39 69,15-0 40 B->Q 12\n",
      " │                                  │          ├@2 11-49 84 B->A0 81/42/62/-5.5\n",
      " │                                  │          ├@4 12-52 53 B->A0 54/22/68/-4.1\n",
      " │                                  │          ├@4 12-52 53 B->A0 54/22/68/-4.1 attn:B->~<s>\n",
      " │                                  │          ├@4 12-52 53 B->A0 54/22/68/-4.1 attn/ans0s\n",
      " │                                  │          ├@6 9-5 39 B->A0 17/5/35/-6.4\n",
      " │                                  ├21-60 B->B┤\n",
      " │                                  │          ├@7 17-61 38 B->A0 61/23/-19/-4.6\n",
      " │                                  │          ├@9 16-21 38 B->A0 51/27/76/-5.4\n",
      " │                                  │          ├@9 16-21 38 B->A0 51/27/76/-5.4 attn:B->~<s>\n",
      " │                                  │          ├@9 16-21 38 B->A0 51/27/76/-5.4 attn/ans0s\n",
      " │                                  │          ├@0 19-29 100 B->B 41/57/12/-5.8\n",
      " │                                  │          ├@8 0-m 38\n",
      " │                                  │          ├@1 15-38 96 B->Q 40/45/30/-4.4\n",
      " │                                  │          ├@3 14-39 69 B->Q 32/29/88/-4.2\n",
      " │                                  │          └@5 15-0 40 B->Q 41/48/65/-4.5\n",
      " │                                  │                       ┌@[0,2,3,5] 18-23 100,0-m 57,13-9 54,17-m 44 B->B 37\n",
      " │                                  │                       ├@[1,6,8] 15-0 63,10-40 38,19-44 B->Q 23\n",
      " │                                  │                       ├@[4,7] 12-4 46,9-15 30 B->A] 9\n",
      " │                                  │                       ├@[9] 11-49 B->A0 4\n",
      " │                                  │                       ├@0 18-23 100 B->B 84/84/26/-5.9\n",
      " │                                  │                       ├@2 0-m 57\n",
      " │                                  ├21-60 B->B attn:B->~<s>┤\n",
      " │                                  │                       ├@3 13-9 54 B->B 53/40/50/-5.4\n",
      " │                                  │                       ├@5 17-m 44\n",
      " │                                  │                       ├@1 15-0 63 B->Q 60/48/65/-3.6\n",
      " │                                  │                       ├@6 10-40 38 B->Q 43/45/11/-5.4\n",
      " │                                  │                       ├@4 12-4 46 B->A] 84/90\n",
      " │                                  │                       └@7 9-15 30 B->A] 1/1\n",
      " │                                  │                     ┌@[0,2,6] 9-33 100,10-61 68,12-52 43 Q->A0 17\n",
      " │                                  │                     ├@[1,3] 12-63 95,11-50 63 Q->T 8\n",
      " │                                  │                     ├@[5] 11-35 45 Q->Q 4\n",
      " │                                  │                     ├@[4] 9-39 45 unk 0\n",
      " │                                  │                     ├@0 9-33 100 Q->A0 48/50/23/-5.4\n",
      " │                                  ├15-38,14-39,15-0 B->Q┤\n",
      " │                                  │                     ├@2 10-61 68 Q->A0 40/31/9/-4.8\n",
      " │                                  │                     ├@6 12-52 43 Q->A0 29/17/60/-4.5\n",
      " │                                  │                     ├@1 12-63 95 Q->T 25/78/42/-5.2\n",
      " │                                  │                     ├@3 11-50 63 Q->T 41/94/24/-7.0\n",
      " │                                  │                     ├@5 11-35 45 Q->Q 31/33/49/-4.9\n",
      " │                                  │                     └@4 9-39 45 Q->T+ 0/0/-5349/-8.1\n",
      " │                                  │                            ┌@:5 0-m 100,12-m 62,11-m 51,8-m 32,5-m B->B 71\n",
      " │                                  │                            ├@[5] 9-10 B->A] 10\n",
      " │                                  │                            ├@[6] 12-55 B->A0 8\n",
      " │                                  ├14-39,15-0 B->Q attn/example┤\n",
      " │                                  │                            ├@0 0-m 100\n",
      " │                                  │                            ├@1 12-m 62\n",
      " │                                  │                            ├@2 11-m 51\n",
      " │                                  │                            └@3 8-m 32\n",
      " │                                  │                            ┌@[0,1,3,5] 0-m 100,5-m,13-9,12-m B->B 52\n",
      " │                                  │                            ├@[6] 10-40 B->Q 13\n",
      " │                                  └14-39,15-0 B->Q attn:B->~<s>┤\n",
      " │                                                               ├@[2] 9-10 B->A] 11\n",
      " │                                                               ├@[4] 9-0 unk 0\n",
      " │                                                               └@0 0-m 100\n",
      " │                              ┌@[0,1,3,5,7,8] 20-m,18-23,21-60,17-m,14-m,19-m B->B 58\n",
      " │                              ├@[2,4,6] 12-4,9-5,9-42 B->A] 23\n",
      " │                              ├@[9] 15-0 B->Q 7\n",
      " │                              ├@0 20-m 100\n",
      " │                              ├@1 18-23 99 B->B 83/84/26/-5.8\n",
      " │                              ├@3 21-60 79 B->B 78/83/83/-5.9\n",
      " │                              ├@5 17-m 62\n",
      " │                              ├@7 14-m 55\n",
      " │                              ├@8 19-m 50\n",
      " │                              ├@2 12-4 88 B->A] 81/90\n",
      " │                              ├@4 9-5 62 B->A] 65/63\n",
      " │                              ├@6 9-42 61 B->A] 84/74\n",
      " │                              ├@9 15-0 46 B->Q 54/48/65/-4.1\n",
      " │                              │                   ┌@[2,4] 4-53 81,9-39 60 A]->A0] 31\n",
      " │                              │                   ├@[0,1,3] 8-21 100,8-46 82,8-47 64 A]->A0+ 30\n",
      " │                              │                   ├@2 4-53 81 A]->A0] 77/87/0/-8.5\n",
      " │                              ├12-4,9-5,9-42 B->A]┤\n",
      " │                              │                   ├@4 9-39 60 A]->A0] 77/90/0/-7.5\n",
      " │                              │                   ├@0 8-21 100 A]->A0+ 78/80/0/-8.9\n",
      " │                              │                   ├@1 8-46 82 A]->A0+ 72/80/0/-6.8\n",
      " │                              │                   └@3 8-47 64 A]->A0+ 1/2/0/-9.7\n",
      " └22-40,23-29 B->A0 attn:B->~<s>┤\n",
      "                                │                ┌@[0,2,3,5,6,7,8] 12-4 100,15-42 59,9-42 59,17-19 49,9-5 43,8-47 42,9-23 40 B->A] 40\n",
      "                                │                ├@[1,4] 16-20 72,11-49 52 B->A0 6\n",
      "                                │                ├@[9] 10-40 38 unk 0\n",
      "                                │                ├@0 12-4 100 B->A] 67/90\n",
      "                                │                ├@2 15-42 59 B->A] 79/87\n",
      "                                │                ├@3 9-42 59 B->A] 73/74\n",
      "                                ├18-23,21-60 B->B┤\n",
      "                                │                ├@5 17-19 49 B->A] 58/59\n",
      "                                │                ├@6 9-5 43 B->A] 64/63\n",
      "                                │                ├@7 8-47 42 B->A] 64/70\n",
      "                                │                ├@8 9-23 40 B->A] 0/0\n",
      "                                │                ├@1 16-20 72 B->A0 13/11/-141/-3.8\n",
      "                                │                ├@4 11-49 52 B->A0 40/42/62/-3.6\n",
      "                                │                └@9 10-40 38 B->Q- 37/44/9/-4.0\n",
      "                                │         ┌@[1,2,5] 12-4 87,0-m 63,10-40 59 Q->Q 15\n",
      "                                │         ├@[0,4,6] 9-39 100,12-63 62,10-0 59 Q->T 12\n",
      "                                │         ├@[3] 8-55 63 Q->T+ 6\n",
      "                                │         ├@1 12-4 87 Q->Q 0/0/-18315/-10.9\n",
      "                                │         ├@2 0-m 63\n",
      "                                └15-0 B->Q┤\n",
      "                                          ├@5 10-40 59 Q->Q 2/4/-160/-6.9\n",
      "                                          ├@0 9-39 100 Q->T 43/72/14/-8.4\n",
      "                                          ├@4 12-63 62 Q->T 38/78/42/-6.8\n",
      "                                          ├@6 10-0 59 Q->T 4/9/-122/-4.8\n",
      "                                          └@3 8-55 63 Q->T+ 38/68/5/-7.0\n"
     ]
    }
   ],
   "source": [
    "print(key); print_tree(r.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "514194bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['', '9-m', '10-m', '41-m', '33-m', '25-m', '40-m', '34-m', '38-m', '24-m', '21-m', '26-m', '35-62 attn/ans0s', '22-40 attn/ans0s', '22-40 attn/ans0s > 17-61', '22-40 attn/ans0s > 19-53', '22-40 attn/ans0s > 14-39', '22-40 attn/ans0s > 16-22', '22-40 attn/ans0s > 20-60', '22-40 attn/ans0s > 12-44', '22-40 attn/ans0s > 12-m', '22-40 attn/ans0s > 17-m', '22-40 attn/ans0s > 13-m', '22-40 attn/ans0s > 17-19', '22-40 attn/ans0s > 19-29', '22-40 attn/ans0s > 21-60', '22-40 attn/ans0s > 15-38', '22-40 attn/ans0s > 12-35', '22-40 attn/ans0s > 16-45', '22-40 attn/ans0s > 16-20', '30-34 attn/ans0s', '19-21 attn/ans0s', '29-5 attn/ans0s', '21-49 attn/ans0s', '24-37 attn/ans0s', '19-54 attn/ans0s', '17-28 attn/ans0s', '19-1 attn/ans0s', '42-7 attn', '42-37 attn'])\n"
     ]
    }
   ],
   "source": [
    "nodes = {}\n",
    "def fn(node): nodes[node2key(node)] = node\n",
    "traverse_tree(r.root, fn)\n",
    "print(nodes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fe39a194",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = nodes['22-40 attn/ans0s']\n",
    "node.children = []\n",
    "node.data.attr = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0f089be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = r.root.children[-1]\n",
    "plot_attn_attrs(r.data_tuples[:3], model, tokenizer, node, topi=[6], attn_patterns=['B->Q'], k_shot=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b113734",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}; key = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "064e94d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = 'MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.equal][cxt_len=3,rev_item2str]' # 18-5  11-4,13-11 B->A0+ 10-11?\n",
    "# key = 'MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.equal][cxt_len=3]'\n",
    "key = 'rm_query[MlM_gen][genders_of_persons.TreeSet.neg_equal,genders_of_persons.TreeSet.equal][cxt_len=3]'\n",
    "# key = 'MlM_gen[cxt_sample_fn=enumerate_sample,query=1][types_of_characters.TreeSet.equal,types_of_characters.TreeSet.equal][cxt_len=3,abstract]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d83c85cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "del results[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38c1bccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dt in r.data_tuples: dt[-1].attn_attr.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f13e0c0d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "transform_task failed: invalid rel for rm_query['equal', 'equal'] (rel1_kwargs=(),do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['equal', 'equal'] (rel1_kwargs=(),do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['equal', 'equal'] (rel1_kwargs=(),do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['equal', 'equal'] (rel1_kwargs=(),do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'equal'] (rel1_kwargs=(),do_rm_local_hop)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'equal'] (rel1_kwargs=(),do_rm_local_hop,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'equal'] (rel1_kwargs=(),do_rm_local_hop)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'equal'] (rel1_kwargs=(),do_rm_local_hop,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'equal'] (rel1_kwargs=(),do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'equal'] (rel1_kwargs=(),do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'equal'] (rel1_kwargs=(),do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'equal'] (rel1_kwargs=(),do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "== rm_query[MlM_gen][genders_of_persons.TreeSet.neg_equal,genders_of_persons.TreeSet.equal][cxt_len=3] == rel1_kwargs=(),do_negate,do_rm_local_hop,do_rm_query\n",
      "There are Laura, Daniel, Laura. Who is different? Daniel\n",
      "There are Edward, Linda, Linda. Who is different? Edward\n",
      "There are Susan, Paul, Susan. Who is different? Paul\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:06,  6.85s/it]\u001b[A\n",
      "2it [00:13,  6.83s/it]\u001b[A\n",
      "3it [00:20,  6.91s/it]\u001b[A\n",
      "4it [00:27,  6.94s/it]\u001b[A\n",
      "5it [00:34,  6.90s/it]\u001b[A\n",
      "6it [00:41,  6.91s/it]\u001b[A\n",
      "7it [00:48,  6.93s/it]\u001b[A\n",
      "8it [00:55,  6.90s/it]\u001b[A\n",
      "9it [01:02,  6.93s/it]\u001b[A\n",
      "10it [01:09,  6.91s/it]\u001b[A\n",
      "11it [01:15,  6.89s/it]\u001b[A\n",
      "12it [01:22,  6.88s/it]\u001b[A\n",
      "13it [01:29,  6.98s/it]\u001b[A\n",
      "14it [01:36,  6.96s/it]\u001b[A\n",
      "15it [01:43,  6.94s/it]\u001b[A\n",
      "16it [01:50,  6.91s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0956543050706387 0.4722222222222222\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['equal', 'equal'] (rel1_kwargs=(),do_swap_qa,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['equal', 'equal'] (rel1_kwargs=(),do_swap_qa,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['equal', 'equal'] (rel1_kwargs=(),do_swap_qa,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['equal', 'equal'] (rel1_kwargs=(),do_swap_qa,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'equal'] (rel1_kwargs=(),do_swap_qa,do_rm_local_hop)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'equal'] (rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'equal'] (rel1_kwargs=(),do_swap_qa,do_rm_local_hop)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'equal'] (rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'equal'] (rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'equal'] (rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'equal'] (rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'equal'] (rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['equal', 'child'] (rel1_i=1,rel1_kwargs=(),do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['equal', 'child'] (rel1_i=1,rel1_kwargs=(),do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['equal', 'child'] (rel1_i=1,rel1_kwargs=(),do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['equal', 'child'] (rel1_i=1,rel1_kwargs=(),do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'child'] (rel1_i=1,rel1_kwargs=(),do_rm_local_hop)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'child'] (rel1_i=1,rel1_kwargs=(),do_rm_local_hop,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'child'] (rel1_i=1,rel1_kwargs=(),do_rm_local_hop)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'child'] (rel1_i=1,rel1_kwargs=(),do_rm_local_hop,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'child'] (rel1_i=1,rel1_kwargs=(),do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'child'] (rel1_i=1,rel1_kwargs=(),do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'child'] (rel1_i=1,rel1_kwargs=(),do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'child'] (rel1_i=1,rel1_kwargs=(),do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "== rm_query[MlM_gen][genders_of_persons.TreeSet.neg_equal,genders_of_persons.TreeSet.equal][cxt_len=3] == rel1_i=1,rel1_kwargs=(),do_negate,do_rm_local_hop,do_rm_query\n",
      "There are Laura, Daniel, Laura. Who is different? Daniel\n",
      "There are Edward, Linda, Linda. Who is different? Edward\n",
      "There are Susan, Paul, Susan. Who is different? Paul\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:06,  6.70s/it]\u001b[A\n",
      "2it [00:13,  6.81s/it]\u001b[A\n",
      "3it [00:20,  7.00s/it]\u001b[A\n",
      "4it [00:28,  7.09s/it]\u001b[A\n",
      "5it [00:35,  7.22s/it]\u001b[A\n",
      "6it [00:43,  7.35s/it]\u001b[A\n",
      "7it [00:49,  7.17s/it]\u001b[A\n",
      "8it [00:56,  7.05s/it]\u001b[A\n",
      "9it [01:04,  7.25s/it]\u001b[A\n",
      "10it [01:11,  7.21s/it]\u001b[A\n",
      "11it [01:18,  7.13s/it]\u001b[A\n",
      "12it [01:25,  7.05s/it]\u001b[A\n",
      "13it [01:32,  7.07s/it]\u001b[A\n",
      "14it [01:39,  6.96s/it]\u001b[A\n",
      "15it [01:46,  6.98s/it]\u001b[A\n",
      "16it [01:53,  7.10s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0956543050706387 0.4722222222222222\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel1_i=1,rel1_kwargs=(),do_swap_qa,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel1_i=1,rel1_kwargs=(),do_swap_qa,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel1_i=1,rel1_kwargs=(),do_swap_qa,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel1_i=1,rel1_kwargs=(),do_swap_qa,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel1_i=1,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel1_i=1,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel1_i=1,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel1_i=1,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['equal', 'sibling'] (rel1_i=2,rel1_kwargs=(),do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['equal', 'sibling'] (rel1_i=2,rel1_kwargs=(),do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['equal', 'sibling'] (rel1_i=2,rel1_kwargs=(),do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['equal', 'sibling'] (rel1_i=2,rel1_kwargs=(),do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'sibling'] (rel1_i=2,rel1_kwargs=(),do_rm_local_hop)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'sibling'] (rel1_i=2,rel1_kwargs=(),do_rm_local_hop,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'sibling'] (rel1_i=2,rel1_kwargs=(),do_rm_local_hop)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'sibling'] (rel1_i=2,rel1_kwargs=(),do_rm_local_hop,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'sibling'] (rel1_i=2,rel1_kwargs=(),do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'sibling'] (rel1_i=2,rel1_kwargs=(),do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'sibling'] (rel1_i=2,rel1_kwargs=(),do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'sibling'] (rel1_i=2,rel1_kwargs=(),do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "== rm_query[MlM_gen][genders_of_persons.TreeSet.neg_equal,genders_of_persons.TreeSet.equal][cxt_len=3] == rel1_i=2,rel1_kwargs=(),do_negate,do_rm_local_hop,do_rm_query\n",
      "There are Laura, Daniel, Laura. Who is different? Daniel\n",
      "There are Edward, Linda, Linda. Who is different? Edward\n",
      "There are Susan, Paul, Susan. Who is different? Paul\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:06,  6.74s/it]\u001b[A\n",
      "2it [00:13,  6.77s/it]\u001b[A\n",
      "3it [00:20,  6.82s/it]\u001b[A\n",
      "4it [00:27,  6.88s/it]\u001b[A\n",
      "5it [00:33,  6.78s/it]\u001b[A\n",
      "6it [00:40,  6.74s/it]\u001b[A\n",
      "7it [00:47,  6.80s/it]\u001b[A\n",
      "8it [00:54,  6.84s/it]\u001b[A\n",
      "9it [01:04,  7.86s/it]\u001b[A\n",
      "10it [01:11,  7.45s/it]\u001b[A\n",
      "11it [01:17,  7.23s/it]\u001b[A\n",
      "12it [01:24,  7.03s/it]\u001b[A\n",
      "13it [01:34,  8.10s/it]\u001b[A\n",
      "14it [01:41,  7.73s/it]\u001b[A\n",
      "15it [01:48,  7.37s/it]\u001b[A\n",
      "16it [01:54,  7.19s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0956543050706387 0.4722222222222222\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel1_i=2,rel1_kwargs=(),do_swap_qa,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel1_i=2,rel1_kwargs=(),do_swap_qa,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel1_i=2,rel1_kwargs=(),do_swap_qa,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel1_i=2,rel1_kwargs=(),do_swap_qa,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel1_i=2,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel1_i=2,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel1_i=2,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel1_i=2,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel0_i=1,rel1_kwargs=(),do_rm_query)\n",
      "task is None! skip."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [06:44, 134.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel0_i=1,rel1_kwargs=(),do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel0_i=1,rel1_kwargs=(),do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel0_i=1,rel1_kwargs=(),do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel0_i=1,rel1_kwargs=(),do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel0_i=1,rel1_kwargs=(),do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel0_i=1,rel1_kwargs=(),do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel0_i=1,rel1_kwargs=(),do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['equal', 'child'] (rel0_i=1,rel1_kwargs=(),do_swap_qa,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['equal', 'child'] (rel0_i=1,rel1_kwargs=(),do_swap_qa,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['equal', 'child'] (rel0_i=1,rel1_kwargs=(),do_swap_qa,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['equal', 'child'] (rel0_i=1,rel1_kwargs=(),do_swap_qa,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'child'] (rel0_i=1,rel1_kwargs=(),do_swap_qa,do_rm_local_hop)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'child'] (rel0_i=1,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'child'] (rel0_i=1,rel1_kwargs=(),do_swap_qa,do_rm_local_hop)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'child'] (rel0_i=1,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'child'] (rel0_i=1,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'child'] (rel0_i=1,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'child'] (rel0_i=1,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'child'] (rel0_i=1,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'child'] (rel0_i=1,rel1_i=1,rel1_kwargs=(),do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'child'] (rel0_i=1,rel1_i=1,rel1_kwargs=(),do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'child'] (rel0_i=1,rel1_i=1,rel1_kwargs=(),do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'child'] (rel0_i=1,rel1_i=1,rel1_kwargs=(),do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel0_i=1,rel1_i=1,rel1_kwargs=(),do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel0_i=1,rel1_i=1,rel1_kwargs=(),do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel0_i=1,rel1_i=1,rel1_kwargs=(),do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel0_i=1,rel1_i=1,rel1_kwargs=(),do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'child'] (rel0_i=1,rel1_i=1,rel1_kwargs=(),do_swap_qa,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'child'] (rel0_i=1,rel1_i=1,rel1_kwargs=(),do_swap_qa,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'child'] (rel0_i=1,rel1_i=1,rel1_kwargs=(),do_swap_qa,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'child'] (rel0_i=1,rel1_i=1,rel1_kwargs=(),do_swap_qa,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel0_i=1,rel1_i=1,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel0_i=1,rel1_i=1,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel0_i=1,rel1_i=1,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel0_i=1,rel1_i=1,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'sibling'] (rel0_i=1,rel1_i=2,rel1_kwargs=(),do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'sibling'] (rel0_i=1,rel1_i=2,rel1_kwargs=(),do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'sibling'] (rel0_i=1,rel1_i=2,rel1_kwargs=(),do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'sibling'] (rel0_i=1,rel1_i=2,rel1_kwargs=(),do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel0_i=1,rel1_i=2,rel1_kwargs=(),do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel0_i=1,rel1_i=2,rel1_kwargs=(),do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel0_i=1,rel1_i=2,rel1_kwargs=(),do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel0_i=1,rel1_i=2,rel1_kwargs=(),do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'child'] (rel0_i=1,rel1_i=2,rel1_kwargs=(),do_swap_qa,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'child'] (rel0_i=1,rel1_i=2,rel1_kwargs=(),do_swap_qa,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'child'] (rel0_i=1,rel1_i=2,rel1_kwargs=(),do_swap_qa,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'child'] (rel0_i=1,rel1_i=2,rel1_kwargs=(),do_swap_qa,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel0_i=1,rel1_i=2,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel0_i=1,rel1_i=2,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel0_i=1,rel1_i=2,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel0_i=1,rel1_i=2,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel0_i=2,rel1_kwargs=(),do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel0_i=2,rel1_kwargs=(),do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel0_i=2,rel1_kwargs=(),do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel0_i=2,rel1_kwargs=(),do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel0_i=2,rel1_kwargs=(),do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel0_i=2,rel1_kwargs=(),do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel0_i=2,rel1_kwargs=(),do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel0_i=2,rel1_kwargs=(),do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['equal', 'sibling'] (rel0_i=2,rel1_kwargs=(),do_swap_qa,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['equal', 'sibling'] (rel0_i=2,rel1_kwargs=(),do_swap_qa,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['equal', 'sibling'] (rel0_i=2,rel1_kwargs=(),do_swap_qa,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['equal', 'sibling'] (rel0_i=2,rel1_kwargs=(),do_swap_qa,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'sibling'] (rel0_i=2,rel1_kwargs=(),do_swap_qa,do_rm_local_hop)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'sibling'] (rel0_i=2,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'sibling'] (rel0_i=2,rel1_kwargs=(),do_swap_qa,do_rm_local_hop)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'sibling'] (rel0_i=2,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'sibling'] (rel0_i=2,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'sibling'] (rel0_i=2,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'sibling'] (rel0_i=2,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_local_hop: ['equal', 'sibling'] (rel0_i=2,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'child'] (rel0_i=2,rel1_i=1,rel1_kwargs=(),do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'child'] (rel0_i=2,rel1_i=1,rel1_kwargs=(),do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'child'] (rel0_i=2,rel1_i=1,rel1_kwargs=(),do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'child'] (rel0_i=2,rel1_i=1,rel1_kwargs=(),do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel0_i=2,rel1_i=1,rel1_kwargs=(),do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel0_i=2,rel1_i=1,rel1_kwargs=(),do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel0_i=2,rel1_i=1,rel1_kwargs=(),do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel0_i=2,rel1_i=1,rel1_kwargs=(),do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'sibling'] (rel0_i=2,rel1_i=1,rel1_kwargs=(),do_swap_qa,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'sibling'] (rel0_i=2,rel1_i=1,rel1_kwargs=(),do_swap_qa,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'sibling'] (rel0_i=2,rel1_i=1,rel1_kwargs=(),do_swap_qa,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'sibling'] (rel0_i=2,rel1_i=1,rel1_kwargs=(),do_swap_qa,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel0_i=2,rel1_i=1,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel0_i=2,rel1_i=1,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel0_i=2,rel1_i=1,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['child', 'equal'] (rel0_i=2,rel1_i=1,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'sibling'] (rel0_i=2,rel1_i=2,rel1_kwargs=(),do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'sibling'] (rel0_i=2,rel1_i=2,rel1_kwargs=(),do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'sibling'] (rel0_i=2,rel1_i=2,rel1_kwargs=(),do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'sibling'] (rel0_i=2,rel1_i=2,rel1_kwargs=(),do_rm_query,do_g2c)\n",
      "task is None! skip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel0_i=2,rel1_i=2,rel1_kwargs=(),do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel0_i=2,rel1_i=2,rel1_kwargs=(),do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel0_i=2,rel1_i=2,rel1_kwargs=(),do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel0_i=2,rel1_i=2,rel1_kwargs=(),do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'sibling'] (rel0_i=2,rel1_i=2,rel1_kwargs=(),do_swap_qa,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'sibling'] (rel0_i=2,rel1_i=2,rel1_kwargs=(),do_swap_qa,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'sibling'] (rel0_i=2,rel1_i=2,rel1_kwargs=(),do_swap_qa,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'sibling'] (rel0_i=2,rel1_i=2,rel1_kwargs=(),do_swap_qa,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel0_i=2,rel1_i=2,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel0_i=2,rel1_i=2,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel0_i=2,rel1_i=2,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query)\n",
      "task is None! skip.\n",
      "\n",
      "transform_task failed: invalid rel for rm_query['sibling', 'equal'] (rel0_i=2,rel1_i=2,rel1_kwargs=(),do_swap_qa,do_rm_local_hop,do_rm_query,do_g2c)\n",
      "task is None! skip.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrows, k_shot = 12, 3; cxt_len = 3; save_results = False\n",
    "batch_size = 16; verbose = False #not save_results or batch_size <= 8\n",
    "rel1_kwargs = {'x_f': None}  # {'x_f': _s, 'y_f': a_, 'skip_inv_f':False}\n",
    "for task,        rel0_i, rel1_i, do_swap_qa, do_negate, do_rm_local_hop, do_rm_query, rev_item2str, do_g2c in product(\n",
    "#     tasks[1:2],rel0_kwargs_list,rel1_kwargs_list,[False,], [False,],  [True,],        [False,],    [False,]):\n",
    "#     tasks[1:2],[2],[0],[True, ],   [False, ],[False,],[False, ],[False],[True,]):\n",
    "    tasks[1:2],range(3),range(3),[False, True],[False, True],[False, True],[False, True],[False, True],[False, True]):\n",
    "    seed(42)\n",
    "    args = dict(cxt_len=cxt_len, rev_item2str=rev_item2str, abstract=False)\n",
    "    trans_args = dict(rel0_i=rel0_i, rel1_i=rel1_i, rel1_kwargs=rel1_kwargs, do_swap_qa=do_swap_qa, do_negate=do_negate,\n",
    "                      do_rm_local_hop=do_rm_local_hop, do_rm_query=do_rm_query, do_g2c=do_g2c)\n",
    "    task = transform_task(task, **trans_args)\n",
    "    if task is None: print('task is None! skip.'); continue\n",
    "    res_key = f'{task2str(task)}[{args2str(args)}]'# + composed_heads2str(model)\n",
    "    if key is not None and res_key != key: continue\n",
    "    if not validate_args(task, args, trans_args): print(f'invalid args {res_key}! skip.'); continue\n",
    "#     if has_attribution_results(res_key): continue\n",
    "    print(f'\\n== {res_key} == {args2str(trans_args)}')\n",
    "    r = results[res_key] if save_results and res_key in results else None\n",
    "    r = generate_and_predict_batch(model if save_results else model_gpu, tokenizer, task, nrows, k_shot, batch_size,\n",
    "            custom_forward=save_results, result=r, verbose=verbose, **args)\n",
    "    break\n",
    "    if save_results: results[res_key] = r\n",
    "    if not save_results or getattr(r, 'mean_acc', 0) < 0.45: continue\n",
    "\n",
    "    if True or r.root is None: r.root = add_node(None, layer=L, label_type='labels')\n",
    "    r.root = attribute_tree_on(r.data_tuples, model, r.root, -1, topk=20, k_shot=k_shot, mix=True, device=device, verbose=True)\n",
    "#     with Timer('save_attribution_results'): save_attribution_results(r, res_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ea4871",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.7977414910208334 0.7430555555555556  # davinci\n",
    "0.6401057616613541 0.7638888888888888  # 001 slowest\n",
    "0.11072069162819444 0.9722222222222222  # 002\n",
    "0.012047627688270834 1.0                # 003 fastest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6e25a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(3+9)*16 equal\n",
    "1.369818564504385 0.4861111111111111 # cpu\n",
    "1.1842011790722609 0.5555555555555556  # gpu\n",
    "\n",
    "(7+9)*8 equal\n",
    "0.8679518327116966 0.6388888888888888 # cpu\n",
    "0.7969751581549644 0.6805555555555556 # gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c869c156",
   "metadata": {},
   "outputs": [],
   "source": [
    "(7+9)*8 child+skip_inv_f\n",
    "In generate_and_predict_batch: predict ... done 0:01:31.341952  # cpu\n",
    "0.7979045361280441 0.7361111111111112\n",
    "In generate_and_predict_batch: predict ... done 0:02:14.901858  # cpu custom\n",
    "0.7978888042271137 0.7361111111111112\n",
    "In generate_and_predict_batch: predict ... done 0:00:03.989033  # gpu\n",
    "0.626735083758831 0.7777777777777778\n",
    "In generate_and_predict_batch: predict ... done 0:00:26.205185  # gpu  custom\n",
    "0.6506555993109941 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e835a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(genders_of_persons.TreeSet.child(skip_inv_f), types_of_things.TreeSet.child(skip_inv_f)) (cxt_len=3)'\n",
    "result = results[key]; print_tree(result.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed64bbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36787b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(types_of_things.TreeSet.child, genders_of_persons.TreeSet.child) (cxt_len=3)'\n",
    "result = results[key]; show_predictions_by_result(tokenizer, result, k_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557c1baf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nrows, k_shot = 16, 7; cxt_len=3; save_results = True\n",
    "batch_size = 8; verbose = not save_results or batch_size <= 8\n",
    "for task, replace_rel0, replace_rel1, do_swap_qa, do_negate, do_rm_local_hop, do_rm_query, rev_item2str in product(\n",
    "    tasks[2:3], [0,  ], [0,     ],   [False,],[False,],[False,],[False,],[False,]):\n",
    "    seed(42)\n",
    "    args = dict(cxt_len=cxt_len, rev_item2str=rev_item2str, abstract=False)\n",
    "    trans_args = dict(replace_rel0=replace_rel0, replace_rel1=replace_rel1, do_swap_qa=do_swap_qa, do_negate=do_negate,\n",
    "                      do_rm_local_hop=do_rm_local_hop, do_rm_query=do_rm_query)\n",
    "    task = transform_task(task, **trans_args)\n",
    "    if task is None: continue\n",
    "    res_key = f\"{task2str(task)} ({args2str(args)})\" + composed_heads2str(model)\n",
    "#     if not validate_args(task, args, trans_args): print('invalid args! skip.'); continue\n",
    "#     if save_results and key is not None and res_key != key: continue\n",
    "    if verbose: print(f'\\n== {res_key} == {args2str(trans_args)}')\n",
    "    if save_results and res_key in results:\n",
    "        assert results[res_key].trans_args == trans_args, f'{res_key} {args2str(results[res_key].trans_args)} != {args2str(trans_args)}'\n",
    "        result = results[res_key]; data_tuples = result.data_tuples\n",
    "    else:\n",
    "        all_examples, texts, all_bos_tokens = zip(*[generate(task, verbose=False, plot=False, nrows=nrows, **args)\n",
    "                                                for i in range(batch_size)])\n",
    "        result = Result(task, trans_args, args, all_examples, texts)\n",
    "        for text in texts: print('\\n'.join(text.split('\\n')[:3]))\n",
    "\n",
    "        data_tuples, eval_results = zip(*[predict(model, tokenizer, text, examples,\n",
    "            k_shot=k_shot, bos_token=bos_tokens, verbose=verbose)\n",
    "            for text, examples, bos_tokens in zip(texts, all_examples, all_bos_tokens)\n",
    "            if True or any(s in text[24:] for s in ['dangerous'])])\n",
    "        result.data_tuples = data_tuples\n",
    "        loss, acc, *_ = zip(*eval_results)\n",
    "        result.mean_loss, result.mean_acc = np.array(loss).mean(), np.array(join_lists(acc)).mean()\n",
    "        if verbose: print(result.mean_loss, result.mean_acc)\n",
    "        if save_results: results[res_key] = result\n",
    "    if not save_results: continue\n",
    "\n",
    "#     for node_name in ['node']:\n",
    "#         node = getattr(result, node_name, None)\n",
    "#         if node is None: node = result.node = result.root = add_node(node, label_type=node_name.replace('node', 'labels'))\n",
    "#         node.data.attr = mr(attribute_step)(data_tuples[:], model, node)\n",
    "#     node.data.scores = {ap: mr(get_head_matching_scores)(data_tuples, ap, k_shot=k_shot)\n",
    "#         for ap in attn_patterns_by_step.get(node.data.step, [])} if 'g2c' not in res_key else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1418741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\") # codex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b2e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "_ = clone_model_to(model, device)\n",
    "data_tuples_gpu = data_tuples_to(data_tuples, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba71533",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tree(root)  # cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbb0675",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(genders_of_persons.TreeSet.child, types_of_things.TreeSet.equal) (cxt_len=3)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e7f37f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:3], model, tokenizer, node, topi=[0,1,2], k_shot=k_shot, mix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435f910b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for data_tuple in data_tuples[:3]:\n",
    "    plot_attn_attr(data_tuple, model, tokenizer, node, 13, 7, attn_patterns=['bos->ans0]'], k_shot=0, plot_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835266e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = node.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce14dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); print('\\n'.join(result.texts[-1].split('\\n')[:1]))\n",
    "node = result.node = add_node(node, topi=[0,1,2,3,4])#layer=11, head=12, attn_pattern='bos->query]', label_type='argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f4dd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(genders_of_persons.TreeSet.equal, types_of_things.TreeSet.child) (cxt_len=3)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aebe41",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for data_tuple in data_tuples[:3]:\n",
    "    plot_attn_attr(data_tuple, model, tokenizer, node, 13, 7, attn_patterns=['bos->ans0]'], k_shot=0, plot_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0701ae6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:3], model, tokenizer, node, topi=[0,1,2], k_shot=k_shot, mix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409bc0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = result.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d23ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); print('\\n'.join(result.texts[-1].split('\\n')[:1]))\n",
    "node = result.node = add_node(node, topi=[0,1,2])#, attn_pattern='bos->query]', label_type='argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e179ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0,1,2,3,4,5])#attn_pattern='bos->ans0]', label_type='argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badcf5b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "key = 'MlM_gen(genders_of_persons.TreeSet.equal, types_of_things.TreeSet.equal) (cxt_len=3)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363fbf25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for data_tuple in data_tuples[:]:\n",
    "    plot_attn_attr(data_tuple, model, tokenizer, node, 11, 12, attn_patterns=['bos->query]'], k_shot=0, plot_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91db824e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:3], model, tokenizer, node, topi=[0,1], k_shot=k_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f897ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = result.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07867280",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); print('\\n'.join(result.texts[-1].split('\\n')[:1]))\n",
    "node = result.node = add_node(node, topi=[0,1,2,3,4,5])#, label_type='argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20113f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0])#, attn_pattern='bos->query]', label_type='argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568fca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for head_chain in product([(8, 7), (6, 2)], [(13, 13), (9, 14), (12, 10)], [(16, 7)]):\n",
    "    print(head_chain, plot_eigv(weightprod(model, list(head_chain), 'e vo vo qk e', weBTA=model.weBTAs[0]), plot=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e0b598",
   "metadata": {},
   "source": [
    "### person_adjs.opposite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b7d463",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cbe1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=3, abstract=0)_4-6/6-10->4-8_1-7/6-2/8-7->7-9'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd48aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:3], model, tokenizer, node, topi=[0,1,2], k_shot=k_shot, mix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8a9671",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = result.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41bbb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0,1])#, label_type='argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485bccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=3, abstract=0)_4-6qk->4-8_6-2qk->7-9'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5d093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = node.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e64a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0,1,2,3], head_attr_fn=get_head_mlp_attr, k_shot=k_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4ed844",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0,1,2,3]) #label_type='argmax_attn_labels', attn_pattern='bos->query]') # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa60022",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=3, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f031a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = node.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50dc477",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0], head_attr_fn=get_head_mlp_attr, k_shot=k_shot)  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f131da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0,1], head_attr_fn=get_head_mlp_attr)#label_type='argmax_attn_labels', attn_pattern='bos->query]') # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64dce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.equal) (cxt_len=3, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9ba16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0,1,4,5], k_shot=k_shot)  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807a0cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "forked_node_k.k_node = q_node; forked_node_k.model = model\n",
    "del forked_node_k.k_node; del forked_node_k.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd81ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forked_node.k_node = k_node; forked_node.model = model\n",
    "del forked_node.k_node; del forked_node.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75612c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = node.parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30875b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0,1,2,3]) #label_type='attn_labels', attn_pattern='bos->query]', step=0, attribute_k=True) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a6332",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.equal) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cd8143",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0,1,2], head_attr_fn=get_head_mlp_attr, k_shot=k_shot)  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ed26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdf2869",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0], k_shot=k_shot)  # head_attr_fn=get_head_mlp_attr, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e03775",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0,2], head_attr_fn=get_head_mlp_attr, k_shot=k_shot, mix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86219f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0,1,2,3], head_attr_fn=get_head_mlp_attr, k_shot=k_shot, mix=True)  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65baa7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_tuple in data_tuples[:4]: plot_attn_attr(data_tuple, model, tokenizer, node, 7, 9, attn_patterns=['bos->ans0]'], k_shot=k_shot, plot_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3713a89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = node.children[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17929199",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0,1,2], head_attr_fn=get_head_mlp_attr)# label_type='attn_labels')  # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079866a0",
   "metadata": {},
   "source": [
    "### thing->type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342b97df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691139e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.equal) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155c3d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0,1], head_attr_fn=get_head_mlp_attr, k_shot=k_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e1fc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "node.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f94d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0,2,4], head_attr_fn=get_head_mlp_attr)#, label_type='argmax_attn_labels')  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03ffba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.parent) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95222719",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_tuple in data_tuples[:4]: plot_attn_attr(data_tuple, model, tokenizer, node, 16, 7, attn_patterns=['bos->ans0]'], k_shot=k_shot, plot_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014caa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0,1,2,3], head_attr_fn=get_head_mlp_attr, k_shot=k_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae8689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = node.parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9476640",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = result.node = add_node(node, layer=16, head=7, topi=[0], head_attr_fn=get_head_mlp_attr)#, label_type=f'argmax_attn_labels')  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f07fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0], head_attr_fn=get_head_mlp_attr)#, label_type=f'argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb4e419",
   "metadata": {},
   "source": [
    "### fr->en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0101f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d156659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, en2fr.TreeSet.parent) (cxt_len=1, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result, topk=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c870a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0,1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07ef9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_head_chains(model, get_head2scores(node));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b752617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, en2fr.TreeSet.parent) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result, topk=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e9bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples, model, tokenizer, node, topi=[0,1,2], k_shot=k_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697be2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,1,2], label_type='argmax_attn_labels')  # head_attr_fn=get_head_mlp_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b8bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_head_chains(model, get_head2scores(result.root.children[1].children[0].children[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68713987",
   "metadata": {},
   "source": [
    "### did->does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83926d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38f701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, does2did.TreeSet.parent) (cxt_len=1, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result, topk=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b511c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node.parent.parent.parent, topi=[0,1], head_attr_fn=get_head_mlp_attr, mix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb9f0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text, input_ids, labels, ranges, *args, o in data_tuples:\n",
    "    show_predictions(tokenizer, *args, logits=o.logits, labels=labels, k_shot=k_shot, topk=3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9790bcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.node = result.node.parent.parent.parent\n",
    "result.node = result.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657592c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[1,0,2,7], head_attr_fn=get_head_mlp_attr, label_type='attn_labels')  # head_attr_fn=get_head_mlp_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb091b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_tuple in data_tuples:\n",
    "    plot_attn_attr(data_tuple, model, tokenizer, node, 17, 16, attn_patterns=None, k_shot=0, plot_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0c3bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_circuit(model, tokenizer, result.task, node.parent, topi=[0,1,6,7,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27296b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0, 1, 2], k_shot=k_shot)  # head_attr_fn=get_head_mlp_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0185b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, does2did.TreeSet.equal) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result, topk=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e7c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0, 7], head_attr_fn=get_head_mlp_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6460cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3de5818",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_head_chains(model, get_head2scores(node));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01df267",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, does2did.TreeSet.parent) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result, topk=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b619a4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,1,2,3], label_type='attn_labels')  # head_attr_fn=get_head_mlp_attr, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a102409",
   "metadata": {},
   "source": [
    "### thing->capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb25f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d207a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, capabilities_of_things.TreeSet.parent) (cxt_len=1, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689b07c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_circuit(model, tokenizer, result.task, node, topi=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8d310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_circuit(model, tokenizer, result.task, node, topi=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0541f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759696a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, capabilities_of_things.TreeSet.equal) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc85adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[2,1,3,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd405a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_head_chains(model, get_head2scores(node));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8615ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, capabilities_of_things.TreeSet.parent) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f2e785",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text, input_ids, labels, ranges, *args, o in data_tuples:\n",
    "    loss, top1_corrects, answer_probs, candidate_probs = show_predictions(\n",
    "        tokenizer, *args, logits=o.logits, labels=labels, loss_reduction='mean',\n",
    "        candidates=None, k_shot=k_shot, topk=3, verbose=True)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854622df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node.parent.parent.parent, topi=[0], k_shot=k_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4126b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0, 1, 2, 3], k_shot=k_shot, plot_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d60291",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[1,2,0], label_type='argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04c9c89",
   "metadata": {},
   "source": [
    "### capital->country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f5c5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb37da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, country2capital.TreeSet.parent) (cxt_len=1, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ffef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_circuit(model, tokenizer, result.task, node, topi=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd05881",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28882636",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, country2capital.TreeSet.equal) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63db07d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060f0c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, country2capital.TreeSet.parent) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0cebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,1,2])#, label_type='argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8261a178",
   "metadata": {},
   "source": [
    "### person_adjs.opposite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d291a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423b3633",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=1, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ebe210",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542c29d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.equal) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a0c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66abd13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a226df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,])#, label_type='attn_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d8dd04",
   "metadata": {},
   "source": [
    "### thing->type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d50e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\")  # old full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45e7be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.parent) (cxt_len=1, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe516f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94799e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.equal) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b745c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0, 1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414c7caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.parent) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819f6256",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,1,2])#, label_type='attn_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e68100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed(1234); torch.cuda.empty_cache()\n",
    "model_names = ['EleutherAI/gpt-j-6B/cpu', 'EleutherAI/gpt-neox-20b', #'EleutherAI/gpt-neox-20b/cpu', \n",
    "               'text-curie-001', 'text-davinci-001', 'text-davinci-002'][:1]\n",
    "metrics = dict(losses=defaultdict(list), accuracies=defaultdict(list))\n",
    "\n",
    "def batch_predict(model, tokenizer):\n",
    "    return [predict(model, tokenizer, text, examples, k_shot=k_shot, custom_forward=False, # avoid computing head_inputs\n",
    "                    bos_token=bos_token, eos_token=eos_token, verbose=len(model_names) == 1)[1]\n",
    "            for text, examples in zip(texts, all_examples)]\n",
    "    \n",
    "with Timer('pmapped batch_predict'):\n",
    "    parallel = len(model_names) > 1\n",
    "    pool = Pool(len(model_names)) if parallel else itertools  # with Pool(len(model_names)) as pool:\n",
    "    results = pool.starmap(batch_predict, [models[model_name] for model_name in model_names])\n",
    "    if parallel: pool.close(); pool.join()\n",
    "            \n",
    "# query2acc, query2loss = defaultdict(list), defaultdict(list)\n",
    "for model_name, r in zip(model_names, results):\n",
    "    _, tokenizer = models[model_name]\n",
    "    for i, (loss, top1_corrects, answer_indices, answer_probs, candidate_probs) in enumerate(r):#.get()\n",
    "        acc = top1_corrects[k_shot:] # np.array(top1_corrects[k_shot:]).mean()\n",
    "        metrics['losses'][model_name].append(loss); metrics['accuracies'][model_name].append(acc)\n",
    "        if batch_size == 1: print(model_name, loss, acc)\n",
    "#         queries = [e[1] for e in _examples_list[i]][k_shot:]\n",
    "#         for q, a, l in zip(queries, acc, loss): query2acc[q].append(float(a)); query2loss[q].append(l)\n",
    "# print(sorted([(q, np.array(v).mean()) for q, v in query2acc.items()], key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89581697",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in ['accuracies', 'losses']:\n",
    "    for model_name in model_names[:]:\n",
    "        print(metric, model_name, np.array(metrics[metric][model_name]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf1f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp(a, b):\n",
    "    print(a.dtype, a.size(), b.dtype, b.size())\n",
    "    print('allclose:', torch.allclose(a, b), 'equal:', torch.equal(a, b))\n",
    "    print((a == b).float().mean())\n",
    "    print((a - b).float().abs().mean(), a.float().abs().mean(), b.float().abs().mean())\n",
    "#     print((a - b).max(), (a - b).min())\n",
    "#     print(a[a - b == (a - b).max()])\n",
    "#     print(a[a - b == (a - b).min()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc4497",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# text, _examples = texts[0], _examples_list[0]\n",
    "torch.cuda.empty_cache()\n",
    "if True: #def predict2(model, tokenizer, text, _examples):\n",
    "    examples, input_ids, tokens, bos_indices, eos_indices, answers, labels = make_data_tuple(\n",
    "        text, tokenizer, k_shot=k_shot, bos_token=bos_token, eos_token=eos_token)\n",
    "    candidates = [[tokenizer.encode(' ' + token)[0] for token in cands[0]] for _, _, cands, _ in _examples]\n",
    "    with torch.no_grad():\n",
    "        with Timer(): o0 = model(input_ids.to(model.device), output_attentions=True, output_hidden_states=True)\n",
    "        with Timer(): o1 = forward0(model, input_ids.to(model.device), labels=labels.to(model.device),\n",
    "                by_head=['head_input0', 'head_output0'], attn_weights=None, output_hidden_states=True)\n",
    "        for o in [o0, o1]:\n",
    "            logits = o.logits\n",
    "            if isinstance(logits, torch.Tensor): logits = logits.to('cpu').float()# softmax on cpu needs float32\n",
    "            loss, top1_corrects, answer_probs, candidate_probs = show_predictions(\n",
    "                examples, tokenizer, logits, bos_indices, eos_indices, answers, labels, loss_reduction='none',\n",
    "                candidates=candidates, k_shot=k_shot, topk=3, verbose=True)\n",
    "            print('\\n')\n",
    "#     return loss, top1_corrects, answer_probs, candidate_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a74c135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a661b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in ['accuracies', 'losses']:\n",
    "    for model_name in model_names[:]:\n",
    "        print(metric, model_name, np.array(metrics[metric][model_name]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aaa1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in ['accuracies', 'losses']:\n",
    "    for model_name in model_names[:]:\n",
    "        print(metric, model_name, np.array(metrics[metric][model_name])[:,:27].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cba876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in ['accuracies', 'losses']:\n",
    "    _ = plt.figure(figsize=(10, 3));\n",
    "    for model_name in model_names[:2]:\n",
    "        plt.plot(np.array(metrics[metric][model_name])[:].mean(0), label=f'{model_name}');\n",
    "    _ = plt.legend();  _ = plt.title(metric); _ = plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60515185",
   "metadata": {},
   "outputs": [],
   "source": [
    "time2prep = {tuple(clock_of_day): 'at', tuple(days_of_week): 'on', tuple(months): 'in'}\n",
    "def lookup_item2str(item, vocab=None):\n",
    "    if vocab[0] in [clock_of_day, days_of_week, months]:\n",
    "        prep = time2prep[tuple(vocab[0])]\n",
    "        return f'{item[1]} came {prep} {item[0]}'\n",
    "    elif vocab[0] == digits:\n",
    "        return f'{item[1]} is {item[0]}'\n",
    "def lookup_query2str(query, vocab=None, rel_name=None):\n",
    "    if vocab[0] in [clock_of_day, days_of_week, months]:\n",
    "        prep = time2prep[tuple(vocab[0])]\n",
    "        prep = {'prev': 'just before', 'next': 'just after', 'same': prep}[rel_name]\n",
    "        return f'Who came {prep} {query}?'\n",
    "    elif vocab[0] == digits:\n",
    "        prep = {'prev': 'a year younger than', 'next': 'a year younger than', 'same': ''}[rel_name]\n",
    "        return f'Who is {prep} {query}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed9c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Aaren is a boy. Harlow is a girl.\n",
    "Harlow called Aaren.\n",
    "Harlow: \"Are you a girl?\"\n",
    "Aaren: \"'''\n",
    "model_name = 'EleutherAI/gpt-j-6B'\n",
    "model, tokenizer = models[model_name]\n",
    "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "logits = model(input_ids.to(getattr(model, 'device', 'cpu'))).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e43fb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_topk(*logits[0][-1].softmax(-1).topk(5), indices_fn=tokenizer.convert_ids_to_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3d4809",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prob_dist(logits.top_logprobs[-1], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5780be",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'The capital of Canada is'\n",
    "input_ids = tokenizer(text, return_tensors='pt').input_ids\n",
    "list(zip(tokenizer.convert_ids_to_tokens(input_ids[0]), input_ids[0].numpy()))\n",
    "outputs = model.generate(input_ids, max_length=10)\n",
    "tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9c689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nrows = 5; k_shot = nrows // 2 + 1\n",
    "# for pairs in [drop_first_and_last, ]:\n",
    "nrows = 6;  k_shot = 3\n",
    "for pairs in reversible_transformations + irreversible_transformations:\n",
    "    seps = [' -> ', '->'] if random.random() < 0.5 else ['->', ' -> ']\n",
    "    # seps = [' -> ', ' -> ']\n",
    "    samples = ['\\n' + '\\n'.join(a + seps[0] + b for a, b in sample(pairs, nrows)) + '\\n']\n",
    "    for s in samples: data_tuples.append(list(make_data_tuple(s, tokenizer, k_shot=k_shot, bos_token=tokenizer.tokenize(seps[0])[0])))\n",
    "    samples = ['\\n' + '\\n'.join(b + seps[1] + a for a, b in sample(pairs, nrows)) + '\\n' if pairs in reversible_transformations else \n",
    "                '\\n' + '\\n'.join(a + seps[1] + b for a, b in sample(pairs, nrows)) + '\\n']\n",
    "    for s in samples: data_tuples.append(list(make_data_tuple(s, tokenizer, k_shot=k_shot, bos_token=tokenizer.tokenize(seps[1])[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2f807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sys.path.insert(0, '/nas/xd/projects/ec')\n",
    "# from child_utils import loadPBETasks, retrieveJSONTasks\n",
    "# challenge, challengeCheating = loadPBETasks('/nas/xd/projects/ec/PBE_Strings_Track')\n",
    "# challenge2, challengeCheating2 = loadPBETasks('/nas/xd/projects/ec/data/sygus')\n",
    "# tasks = retrieveJSONTasks(\"/nas/xd/projects/ec/data/list_tasks.json\")\n",
    "# tasks2 = retrieveJSONTasks(\"/nas/xd/projects/ec/data/list_tasks2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ff8618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxy_utils import get_examples_behind, get_examples_before, get_examples_query_before, \\\n",
    "    get_examples_query_behid, get_examples_query_repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432fcd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reversible_transformations = [list(digit2cardinal.items()), noun2adj, lxy, verb_form, country2capital, en2fr, antonyms]\n",
    "irreversible_transformations = [capabilities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59cbab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc67151",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for model_name, (model, tokenizer) in models.items():\n",
    "    if any(model_name.startswith(s) for s in ['gpt2-', 'KoboldAI/fairseq-dense', 'text-davinci-001', ]): continue\n",
    "    if not model_name == 'EleutherAI/gpt-j-6B': continue\n",
    "    if not isinstance(model, types.FunctionType): _ = model.eval()\n",
    "    with Timer(model_name): outputs = model(**inputs)\n",
    "    options_ids_list = [[tokenizer.encode(' ' + option)[0] for option in options] for cxt, query, options, ans in _examples]\n",
    "    mask_logits_fn = partial(mask_logits, indices=bos_indices, kept_ids=options_ids_list)\n",
    "    loss, all_top1_correct = show_predictions(text, examples, tokenizer, outputs.logits, bos_indices, eos_indices, answers, labels,\n",
    "                    mask_logits_fn=None, topk=3, loss_reduction='mean', show_range=range(k_shot, len(examples)), sep='\\t')\n",
    "    print(loss, all_top1_correct, '\\n')\n",
    "    losses.append(loss.item() if hasattr(loss, 'item') else loss)\n",
    "    if model_name == 'EleutherAI/gpt-j-6B': break\n",
    "print(sum(losses) / len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc90b0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "relational_functions = [prev(), next()]\n",
    "rel_fns = [prevs, nexts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92834550",
   "metadata": {},
   "source": [
    "**TODO: read children books for more posets**  \n",
    "**TODO: Prompt gpt3 to elicit the posets it knows**  \n",
    "$x \\to f(x)$ where $f \\in \\{\\text{prev/next in posets of numbers/letters/months/days, antonym, hypernym, hyponym, ...}\\}$  \n",
    "$x \\to f^2(x)$  \n",
    "one poset or mixed posets  \n",
    "$x, f(x).~y \\to Ff^{[-1]}(y)$ one poset or mixed posets  \n",
    "$x, f^k(x).~y \\to Ff^{[-1]}(y)~/Ff^{[-]k}(y)$  \n",
    "$x, f(f(x))~/f(f(x)), x \\to f(x)$ in between, the simplest form of sequence completion  \n",
    "$x, f(x) \\to Gf$ where $Gf \\in \\{<, >\\}$  \n",
    "$x, f(x); y, g(y) \\to Ff \\stackrel{?}{=} g^{[-1]}$ where $\\text{output} \\in \\{\\text{True}, \\text{False}\\}$  \n",
    "sort\n",
    "\n",
    "There is a *natural* monotone map/functor $F$ between posets/sets $A$ and $B$.  Compose the computation (set operations, sorting etc.) between $A$ and $B$ with $F$ to make harder tasks.  \n",
    "$P(A) ,P(B) \\to F(P(A)) \\setminus ~/ \\cap ~/ \\triangle P(B)$. Harder form of set difference/intersection.  \n",
    "$P(A) \\to F(\\text{sorted}(P(A)))$. Harder form of sorting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504ae9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17373019",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total, n_valid = 192, 64\n",
    "n_train = n_total - n_valid\n",
    "\n",
    "input_strs = [make_input_str(tasks[4], nrows=4, ncols=5) for __ in range(n_total)]\n",
    "for s in sample(input_strs, 3): print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d6edbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(s.count('Yes') for s in input_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f80b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CHILDDataset(input_strs[:-n_valid], tokenizer)\n",
    "eval_dataset = CHILDDataset(input_strs[-n_valid:], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3185653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_total == 1:\n",
    "    inputs = tokenizer.encode_plus(text, return_tensors='pt')\n",
    "    inputs = prepare_inputs(inputs, model.device)\n",
    "    outputs = model(**inputs, output_attentions=False)\n",
    "\n",
    "    # assert inputs.input_ids.size(0) == 1\n",
    "    input_ids = inputs.input_ids\n",
    "    logits = outputs.logits\n",
    "\n",
    "    bsz = input_ids.size(0); assert bsz == 1\n",
    "    labels = torch.ones_like(input_ids) * (-100)\n",
    "    for bi in range(bsz):\n",
    "        bos_indices = (input_ids[bi] == bos_id).nonzero().squeeze(1)\n",
    "        eos_indices = (input_ids[bi] == eos_id).nonzero()[-nrows:].squeeze(1)\n",
    "        for i, (example, bos_i, eos_i) in enumerate(zip(examples, bos_indices.tolist(), eos_indices.tolist())):\n",
    "            print(' ' + make_example_str(example))\n",
    "            ans_ids = input_ids[bi, bos_i + 1: eos_i]\n",
    "            if i >= 2: labels[bi, bos_i: eos_i - 1] = ans_ids\n",
    "            ans_prob_dist = logits[bi, bos_i: eos_i - 1].softmax(-1)\n",
    "            ans_probs = ans_prob_dist[torch.arange(ans_prob_dist.size(0)), ans_ids]\n",
    "            ans_tokens = tokenizer.convert_ids_to_tokens(ans_ids)\n",
    "            for ans_id, ans_token, ans_prob, dist in zip(ans_ids, ans_tokens, numpy(ans_probs, decimals=3), ans_prob_dist):\n",
    "                top1_correct = (dist.argmax() == ans_id).item()\n",
    "                print(('*' if top1_correct else ' ') + ans_token, ans_prob, \n",
    "                      show_topk(*dist.topk(5), indices_fn=tokenizer.convert_ids_to_tokens)) \n",
    "    loss = nn.CrossEntropyLoss()(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "    loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"./models/model_name\", \n",
    "    overwrite_output_dir=True, do_train=True, do_eval=True,\n",
    "    per_device_train_batch_size=16, per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01, adam_beta2=0.98, adam_epsilon=1e-6,\n",
    "    lr_scheduler_type='constant', learning_rate=5e-3, num_train_epochs=4,\n",
    "    logging_strategy ='epoch', evaluation_strategy ='epoch', save_steps=0,\n",
    "    no_cuda=True, report_to='none',  # to avoid report to wandb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c7d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, training_args, train_dataset=train_dataset, eval_dataset=eval_dataset,\n",
    "                  optimizers=(create_optimizer(model, training_args), None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37a9874",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.place_model_on_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4b3eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prev(elem):\n",
    "    i, v = elem\n",
    "    return _l[i - 1] if i > 0 else None\n",
    "\n",
    "false = lambda *_: False\n",
    "true  = lambda *_: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721cb66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Element = namedtuple('Element', 'index value')\n",
    "_l = 'A B C B'.split()\n",
    "n = len(_l)\n",
    "# l = [Element._make(e) for e in enumerate(l)]\n",
    "l = seq(_l)\n",
    "l = l.enumerate().map(Element._make)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f22f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "l.map(lambda x: {'B': 'D'}.get(x, x))\n",
    "\n",
    "l.filter(lambda x: get_prev(x) == 'B').select(_.value)\n",
    "\n",
    "find_fn = _.index == 1\n",
    "l.filter(find_fn).select(_.value).map(lower)\n",
    "\n",
    "find_fn = _.value == 'C'\n",
    "l.filter(find_fn).select(_.index)\n",
    "\n",
    "# move x to first\n",
    "update_filter = _.value == 'C'\n",
    "get_new = lambda x: -1\n",
    "l.map(lambda x: Element(update_fn(x, 'index'), x.value)).order_by(_.index).select(_.value)\n",
    "\n",
    "# swap first and last\n",
    "update_filter = true\n",
    "get_new = lambda x: {0: n - 1, n - 1: 0}.get(x.index, x.index)\n",
    "l.map(lambda x: Element(update_fn(x, 'index'), x.value)).order_by(_.index).select(_.value)\n",
    "\n",
    "# get inbetween == drop_while + take_while?\n",
    "\n",
    "# update by index to its prev\n",
    "update_filter = _.index == 1\n",
    "get_new = lambda x: get_prev(x)\n",
    "def update_fn(x, update_field): return get_new(x) if update_filter(x) else getattr(x, update_field)\n",
    "l.map(lambda x: Element(x.index, update_fn(x, 'value')))\n",
    "\n",
    "# if two adjacent elements by indices are equal\n",
    "l.filter(lambda x: x.index in [0, 1]).select(_.value).distinct().len() == 1\n",
    "\n",
    "seq('A B C B C'.split()).group_by(_).select(_[1]).flatten()\n",
    "\n",
    "# count occurance till current\n",
    "seq('A B A C B A'.split()).inits().reverse().tail().map(lambda x: x.filter(_ == x.last()).len())\n",
    "\n",
    "# find special\n",
    "seq('A B A A'.split()).count_by_value().filter(_[1] == 1).select(_[0])\n",
    "\n",
    "# generalized find special\n",
    "seq('A A B C C D D'.split()).group_by(_).map(lambda x: (x[0], len(x[1]))).filter(_[1] == 1).select(_[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
