{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7292808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'  #'last', 'last_expr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d03e56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In file_utils.py: default_cache_path = /raid3/xd/.cache/torch/hub\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/nas/xd/projects/transformers/src')\n",
    "import os\n",
    "os.environ['HF_HOME'] = '/raid3/xd/.cache/torch'  # deliberately set this wrong path to avoid migrating cache\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"8,7\"\n",
    "\n",
    "from types import MethodType\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, OrderedDict, Counter\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "from dataclasses import dataclass, fields, asdict\n",
    "import itertools\n",
    "from itertools import chain, product\n",
    "import math\n",
    "from functools import reduce, partial\n",
    "from collections.abc import Iterable\n",
    "from collections import namedtuple \n",
    "import traceback\n",
    "import pickle, gzip\n",
    "\n",
    "# from multiprocessing import Pool\n",
    "# from torch.multiprocessing import Pool\n",
    "# torch.multiprocessing.set_start_method('spawn', force=True)\n",
    "from multiprocessing.dummy import Pool\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data.sampler import RandomSampler, Sampler, SequentialSampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "# from transformers.data.data_collator import DataCollator, default_data_collator\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, GPT2Tokenizer#, pipeline\n",
    "# from transformers import RobertaForMaskedLM, RobertaTokenizer, GPT2LMHeadModel, GPT2Tokenizer, GPTNeoForCausalLM\n",
    "# from transformers import T5Tokenizer, T5TokenizerFast, T5ForConditionalGeneration\n",
    "# from transformers import HfArgumentParser, Trainer, TrainingArguments, set_seed, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49c8f3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/nas/xd/projects/PyFunctional')\n",
    "from functional import seq\n",
    "from functional.pipeline import Sequence\n",
    "from fn import _ as __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58cba5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common_utils ... done 0:00:00.000076\n",
      "utils ... done 0:00:00.122799\n",
      "child_utils ... Loading tokenizer ... done 0:00:09.708236\n",
      "done 0:00:41.837122\n",
      "tasks ... done 0:00:00.018930\n",
      "model_utils ... done 0:01:06.416629\n",
      "weight_analysis ... done 0:00:00.000045\n"
     ]
    }
   ],
   "source": [
    "from common_utils import Timer\n",
    "with Timer('common_utils'): from common_utils import *\n",
    "with Timer('utils'): from utils import *\n",
    "with Timer('child_utils'): from child_utils import *\n",
    "from child_utils import _cxt2str, _item2str, _s\n",
    "from child_frames import *\n",
    "with Timer('tasks'): from tasks import *\n",
    "with Timer('model_utils'): from model_utils import *\n",
    "with Timer('weight_analysis'): from weight_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29bd23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90f62ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "cache_dir = '/nas/xd/.cache/torch/transformers/'  # for models besides t5-3b/11b\n",
    "# cache_dir = '/mnt/nvme1/xd/.cache/torch/transformers/'  # for gpt-j-6B on elderberry\n",
    "proxies = {'http': '192.168.50.1:1081'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4ab655d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EleutherAI/gpt-neox-20b/cpu ... In huggingface_hub.file_download.cached_download: url = https://huggingface.co/EleutherAI/gpt-neox-20b/resolve/main/config.json\n",
      "done 0:26:20.492653\n"
     ]
    }
   ],
   "source": [
    "# curl -x http://192.168.50.1:1081 -L -O [-C -] https://huggingface.co/google/ul2/resolve/main/pytorch_model.bin  # -C for 断点续传\n",
    "s2s_model_names = ['google/t5-xl-lm-adapt', 'google/t5-xxl-lm-adapt', 'bigscience/T0p', 'bigscience/T0_3B', \n",
    "    'allenai/tk-instruct-3b-pos', 'allenai/tk-instruct-3b-def-pos', 'google/ul2']\n",
    "gpt_model_names = ['EleutherAI/gpt-j-6B/cpu', #'EleutherAI/gpt-j-6B',\n",
    "                   'EleutherAI/gpt-neox-20b/cpu', #'EleutherAI/gpt-neox-20b'\n",
    "                  ]#, 'gpt2-xl', 'gpt2']\n",
    "#                    'KoboldAI/fairseq-dense-6.7B', 'KoboldAI/fairseq-dense-13B']\n",
    "for model_name in s2s_model_names[:0] + gpt_model_names[1:]:#, 'gpt2-xl', 'EleutherAI/gpt-neo-1.3B', 'KoboldAI/fairseq-dense-6.7B']:\n",
    "    if model_name in models: continue\n",
    "    with Timer(model_name):\n",
    "        model_cls = AutoModelForCausalLM if any(s in model_name for s in ['gpt', 'fairseq-dense']) else T5ForConditionalGeneration\n",
    "        # _cache_dir = cache_dir.replace('/nas/', '/nas2/') if 'gpt' not in model_name else cache_dir\n",
    "        kwargs = dict(cache_dir=cache_dir, proxies=proxies, low_cpu_mem_usage=True)\n",
    "        if '/cpu' in model_name or 'gpt-j' not in model_name and 'gpt-neox' not in model_name:\n",
    "            model = model_cls.from_pretrained(model_name.replace('/cpu', ''), cache_dir=cache_dir, proxies=proxies)\n",
    "        elif 'gpt-j' in model_name:\n",
    "            device = 0\n",
    "            model = model_cls.from_pretrained(model_name, revision=\"float16\", torch_dtype=torch.float16, **kwargs).to(device)\n",
    "        elif 'gpt-neox' in model_name:\n",
    "            device = 7; device_map = {'gpt_neox': device, 'embed_out': device}\n",
    "            model = model_cls.from_pretrained(model_name, device_map=device_map, load_in_8bit=True, **kwargs)\n",
    "        if hasattr(model.config, 'use_cache'): model.config.use_cache = False  # save GPU mem\n",
    "        # if model_name in ['EleutherAI/gpt-neox-20b']: model = model.half()\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name.replace('/cpu', ''), cache_dir=cache_dir)\n",
    "        unify(model)\n",
    "        models[model_name] = model, tokenizer#, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c64283f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a little girl who loved to read.\n",
      "\n",
      "She loved to read so much that\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "openai.api_key = open('/nas/xd/projects/openai_api_keys.txt').readlines()[4].split()[0]\n",
    "response = openai.Completion.create(engine='text-davinci-002', prompt='Once upon a time',\n",
    "    max_tokens=20, echo=True, logprobs=5)\n",
    "print(response.choices[0].text)\n",
    "\n",
    "def get_openai_model(engine):\n",
    "    def forward(input_ids):#, attention_mask=None):\n",
    "        text = tokenizer.decode(input_ids[0])\n",
    "        response = openai.Completion.create(engine=engine, prompt=text, max_tokens=0, echo=True, logprobs=5)\n",
    "        return Outputs(logits=response.choices[0].logprobs)\n",
    "    return forward\n",
    "    \n",
    "tokenizer0 = GPT2Tokenizer.from_pretrained('gpt2', cache_dir=cache_dir)\n",
    "engines = ['text-curie-001', 'text-davinci-001', 'text-davinci-002', 'text-davinci-003', 'code-davinci-002'] #+ \\\n",
    "#     ['curie', 'curie:2020-05-03', 'curie-instruct-beta', 'text-curie-001'] + \\\n",
    "#     ['davinci', 'davinci:2020-05-03', 'davinci-instruct-beta', 'davinci-instruct-beta:2.0.0', 'text-davinci-001', 'text-davinci-002']\n",
    "for engine in engines:\n",
    "    if engine not in models: models[engine] = get_openai_model(engine), tokenizer0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bc28755",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = gpt_model_names[1]\n",
    "# model_name = engines[-1]\n",
    "model, tokenizer = models[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b77b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = model.transformer.h\n",
    "for i, b in enumerate(blocks): b.layer = i\n",
    "ln_f = model.transformer.ln_f\n",
    "L, H, embed_dim = len(blocks), blocks[0].attn.num_heads, blocks[0].attn.embed_dim\n",
    "\n",
    "# we = model.transformer.wte.weight.data\n",
    "# wu = model.lm_head.weight.data\n",
    "\n",
    "# es = [we]\n",
    "# for b in blocks[:1]: es.append(es[-1] + mlp_forward(b, es[-1]))\n",
    "# model.es = es\n",
    "# weBTAs = [es[i].T @ es[i] for i in range(2)]\n",
    "# model.weBTAs = weBTAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f9e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:7')\n",
    "_ = clone_model_to(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "801a667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediary_heads = [(8, 1), (12, 10), (13, 13)]\n",
    "circuit_ends = {\n",
    "    'thing->type': ([(15, 8), (21, 5)], [(5, 12), (7, 2)]),\n",
    "    'thing->capability': ([(13, 15)], [(6, 5), (3, 7), (5, 12)]),\n",
    "    'capital->country': ([(19, 12)], [(5, 12)]), # inverse 3-7 by nrk \n",
    "    'opposite': ([(16, 14)], [(7, 9)]),\n",
    "    'fr->en': ([(16, 15), (21, 14)], [(5, 12)]),\n",
    "    'copy': ([(16, 7)], [(8, 7), (6, 2)]), # (1, 7), (3, 12), (6, 10)\n",
    "    # did->does 6-2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "8a6eb024",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicting_heads, relating_heads = defaultdict(list), defaultdict(list)\n",
    "for taskname, (pred_heads, rel_heads) in circuit_ends.items():\n",
    "    for pred_head in pred_heads: predicting_heads[pred_head].append(taskname)\n",
    "    for rel_head in rel_heads: relating_heads[rel_head].append(taskname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "0df73ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for block in blocks: remove_composed_heads(block.attn)\n",
    "# blocks[4].attn.composed_heads = [((4, 8), (4, 6))]; blocks[4].attn.ranges_i = ['ans]->*']  # opposite\n",
    "blocks[6].attn.composed_heads = [('ans]->ans0]', (6, 2))]; blocks[6].attn.ranges_i = ['ans]->*']  # opposite\n",
    "blocks[1].attn.composed_heads = [('ans]->ans0]', (1, 7))]; blocks[1].attn.ranges_i = ['ans]->*']  # opposite\n",
    "blocks[8].attn.composed_heads = [('ans]->ans0]', (8, 7))]; blocks[8].attn.ranges_i = ['ans]->*']  # opposite\n",
    "# blocks[6].attn.composed_heads = [((4, 8), (6, 10))]; blocks[6].attn.ranges_i = ['ans]->*']  # opposite\n",
    "# blocks[8].attn.composed_heads = [((7, 2), (8, 7))]\n",
    "# blocks[6].attn.composed_heads = [((7, 2), (6, 2))]\n",
    "# blocks[4].attn.composed_heads = [((3, 12), (4, 8))]\n",
    "# blocks[3].attn.composed_heads = [((3, 12), (3, 6))]\n",
    "blocks[11].attn.composed_heads = [('bos->query]', (11, 12))]; blocks[11].attn.ranges_i = ['bos->*']\n",
    "for block in blocks:\n",
    "    if getattr(block.attn, 'composed_heads', None) is not None:\n",
    "        compose_heads(model, block.attn, block.attn.composed_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fb0fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "relating_heads = [(6, 2), (8, 7), (7, 2), (5, 12)]#(7, 9)]\n",
    "intermediary_heads = [(8, 1), (12, 10), (13, 13)]\n",
    "predicting_heads = [(13, 7), (16, 7), (15, 8), (21, 5)]#, (16, 14)]\n",
    "for circuit in product(relating_heads, intermediary_heads, predicting_heads):\n",
    "    eigv_pos = plot_eigv(weightprod(model, list(circuit), 'e vo vo qk e', weBTA=model.weBTAs[0]), plot=False)[0]\n",
    "    print(circuit, eigv_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb34c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result2dict(result): return {k: v for k, v in result.__dict__.items() if k not in ['task', 'data_tuples']}  # \n",
    "with gzip.open(f'results/results-genders_of_persons-types_of_things.pkl.gz', 'wb') as f:\n",
    "    pickle.dump({k: result2dict(r) for k, r in results.items()}, f)\n",
    "# with gzip.open(f'results.pkl.gz', 'rb') as f: results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "f1fa6edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.equal][cxt_len=3]'"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_key = keys[0]; res_key\n",
    "fpath = f'results/{res_key}_attn_attrs.npz'\n",
    "np.savez_compressed(fpath, *dump_attn_attrs_to_arrays(root, result.data_tuples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "d04901ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "_root = deepcopy(root)\n",
    "def fn(node): node.data = asdict(node.data)\n",
    "traverse_tree(_root, fn, include_dummy=True)\n",
    "pickle.dump(_root, gzip.open(f'results/{res_key}_tree.pkl.gz', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "706055f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\n",
    "    (lambda: [TreeSet(genders_of_persons).use('equal'), TreeSet(types_of_things).use('equal')], MlM_gen,\n",
    "     partial(_cxt2str, item2str=lambda i, _: [f\"{i[0]} has {wrap_noun(i[1])}\", f\"The {i[1]} is {i[0]}'s\"]), lambda q, _: f'{q}', \" likes\"\n",
    "    ),\n",
    "#     (lambda: [TreeSet(types_of_characters).use('child'), TreeSet(types_of_things).use('child')], partial(MlM_gen, cxt_sample_fn=enumerate_sample, query=1),\n",
    "#      partial(_cxt2str, item2str=lambda i, _: [f\"{i[0]} has {i[1]}\", f\"{the_(i[1])} is {i[0]}'s\"]), lambda q, _: f\"{q}\", \" likes\"\n",
    "#     ),\n",
    "    (lambda: [TreeSet(genders_of_persons).use('child'), TreeSet(types_of_things).use('child')], MlM_gen,\n",
    "     partial(_cxt2str, item2str=lambda i, _: [f\"{i[0]} has {i[1]}\", f\"{the_(i[1])} is {i[0]}'s\"]), lambda q, _: f\"{q}\", \" likes\"\n",
    "    ), # t: 21-5, 15-8, 19. p: 16-7, 18-5, [3-12, 13-7]. p+: 16-7, 16-0. 13-7:induction head qk, thing->type ov\n",
    "    (lambda: [TreeSet(genders_of_persons).use('equal'), TreeSet(countries_of_cities).use('equal')], MlM_gen,\n",
    "     partial(_cxt2str, item2str=lambda i, _: [f'{i[0]} likes {i[1]}', f'{i[1]} attracts {i[0]}']), lambda q, _: f'{q} wants to go', ' to'\n",
    "    ), # t: 19-12 >> 16-10 = 12-7\n",
    "    (lambda: [TreeSet(genders_of_persons).use('equal'), TreeSet(countries_of_cities).use('child')], MlM_gen,\n",
    "     partial(_cxt2str, item2str=lambda i, _: [f'{i[0]} likes {i[1]}', f'{i[1]} attracts {i[0]}']), lambda q, _: f'{q} wants to go', ' to'\n",
    "    ), # t: 19-12 >> 16-10 = 12-7\n",
    "#     (lambda: [TreeSet(genders_of_persons).use('equal'), TreeSet(capabilities_of_things).use('equal')], MlM_gen,\n",
    "#      partial(_cxt2str, item2str=lambda i, _: [f\"{i[0]} has {wrap_noun(i[1])}\", f\"The {i[1]} is {i[0]}'s\"]), lambda q, _: f'{q} likes', ' the'\n",
    "#     ),\n",
    "#     (lambda: [TreeSet(genders_of_persons).use('equal'), TreeSet(capabilities_of_things).use('child')], MlM_gen,\n",
    "#      partial(_cxt2str, item2str=lambda i, _: [f\"{i[0]} has {wrap_noun(i[1])}\", f\"The {i[1]} is {i[0]}'s\"]), lambda q, _: f'{q}', ' can'\n",
    "#     ),\n",
    "#     (lambda: [TreeSet(genders_of_persons).use('equal'), SymSet(person_adjs).use('equal')], MlM_gen,\n",
    "#      partial(_cxt2str, item2str=lambda i, _: [f\"{i[0]} is {i[1]}\", f\"{i[1].capitalize()} is {i[0]}\"]), lambda q, _: f\"Yes, {q} looks\", \" like\"\n",
    "#     ),\n",
    "#     (lambda: [TreeSet(genders_of_persons).use('equal'), SymSet(person_adjs).use('opposite')], MlM_gen,\n",
    "#      partial(_cxt2str, item2str=lambda i, _: [f\"{i[0]} is {i[1]}\", f\"{i[1].capitalize()} is {i[0]}\"]), lambda q, _: f\"Um, {q} looks\", \" like\"\n",
    "#     ), # t: 16-14, somewhat 14-7 # verbose acc: gpj-j > curie-001 > davinci-001 > gpt-neox!? abstract acc: gpt-neox > gpt-j. all poor (inc. davinci-002!)\n",
    "#     (lambda: [TreeSet(genders_of_persons).use('equal'), PoSet(temporal_posets).use('equal')], MlM_gen,\n",
    "#      partial(_cxt2str, item2str=lambda i, _: [f'{i[0]} arrived {wrap_noun2(i[1])}', f'{wrap_noun2(i[1]).capitalize()} arrived {i[0]}']), lambda q, _: f\"So {q}'s arrival time\", ' is'\n",
    "#     ),\n",
    "#     (lambda: [TreeSet(genders_of_persons).use('equal'), PoSet(temporal_posets).use('prev')], MlM_gen,\n",
    "#      partial(_cxt2str, item2str=lambda i, _: [f'{i[0]} arrived {wrap_noun2(i[1])}', f'{wrap_noun2(i[1]).capitalize()} arrived {i[0]}']), lambda q, _: f'So {q} arrived just', ' after'\n",
    "#     ),\n",
    "#     (lambda: [TreeSet(genders_of_persons).use('equal'), PoSet(temporal_posets).use('next')], MlM_gen,\n",
    "#      partial(_cxt2str, item2str=lambda i, _: [f'{i[0]} arrived {wrap_noun2(i[1])}', f'{wrap_noun2(i[1]).capitalize()} arrived {i[0]}']), lambda q, _: f'So {q} arrived just', ' before'\n",
    "#     ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "435a097d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ┌@[0,2,6,7,9] 9-m,28-m,15-m,39-m,35-62 B->B 44\n",
      " ├@[1,3,4,5,8] 30-34,29-39,25-43,22-40,33-63 B->A0 42\n",
      " ├@0 9-m 100\n",
      " ├@2 28-m 73\n",
      " ├@6 15-m 66\n",
      " ├@7 39-m 66\n",
      " ├@9 35-62 57 B->B 39/61\n",
      " ├@1 30-34 84 B->A0 95/45 attn\n",
      " ├@3 29-39 70 B->A0 82/32 attn\n",
      " ├@4 25-43 70 B->A0 57/8 attn\n",
      " │                            ┌@[0,1,2,5,7,9] 18-23,17-m,21-60,19-m,14-m,19-29 50 B->B 48\n",
      " │                            ├@[3,4,6] 12-4,9-42,9-5 B->A 17\n",
      " │                            ├@[8] 11-49 B->A0 10\n",
      " │                            │                       ┌@[0,1,7] 0-m 100,11-m 56,14-m B->B 30\n",
      " │                            │                       ├@[2,5,8] 12-52 52,16-21,11-49 B->A0 18\n",
      " │                            ├@0 18-23 100 B->B 60/89┤\n",
      " │                            │                       ├@[4,9] 14-39,15-38 B->Q 9\n",
      " │                            │                       └@[3,6] 9-23,9-42 unk 0\n",
      " │                            │          ┌@[0,1,2,3,4,6,8] 11-m 100,12-m 68,9-m 52,8-m,10-m,7-m,14-m B->B 71\n",
      " │                            ├@1 17-m 80┤\n",
      " │                            │          └@[5,7,9] 9-0,9-34,11-27 unk 0\n",
      " │                            │                      ┌@[1,3,4] 19-29 99,18-m 83,13-m 81 B->B 26\n",
      " │                            │                      ├@[0,2,5] 11-49 100,12-52 87,16-20 75 B->A0 20\n",
      " │                            ├@2 21-60 78 B->B 66/90┤\n",
      " │                            │                      ├@[6,7] 17-19 73,9-5 71 B->A 9\n",
      " │                            │                      └@[8,9] 14-39 65,18-11 63 B->Q 7\n",
      " │                            │          ┌@[2,4,6,7,8] 16-46,13-28,15-57,7-m,12-42 B->B 26\n",
      " │                            ├@5 19-m 69┤\n",
      " │                            │          └@[0,1,3,5,9] 9-0 100,17-49 51,10-36,11-39,8-52 unk 0\n",
      " ├@5 22-40 69 B->A0 99/78 attn┤\n",
      " │                            │          ┌@[5,7,8] 11-27,10-9,10-54 B->Q 16\n",
      " │                            │          ├@[1,9] 1-m 53,13-28 B->B 12\n",
      " │                            ├@7 14-m 64┤\n",
      " │                            │          ├@[4,6] 11-24,8-52 B->A 2\n",
      " │                            │          ├@[3] 10-36 B->A0+ 2\n",
      " │                            │          └@[0,2] 9-0 100,11-39 unk 0\n",
      " │                            │                      ┌@[1,2,3,4,5] 15-m 82,14-m 79,11-m 78,16-m 75,9-m 73 B->B 50\n",
      " │                            │                      ├@[0,8] 11-49 100,12-52 54 B->A0 15\n",
      " │                            ├@9 19-29 50 B->B 59/63┤\n",
      " │                            │                      ├@[6,9] 9-5 73,8-55 53 B->A 8\n",
      " │                            │                      └@[7] 14-39 66 unk 0\n",
      " │                            │                     ┌@[3,4,5,7] 5-m 53,6-m 52,6-38,10-54 A->A 30\n",
      " │                            ├@3 12-4 75 B->A 62/99┤\n",
      " │                            │                     ├@[2,6,8] 9-39 80,4-53,3-36 A->A0 19\n",
      " │                            │                     └@[0,1,9] 8-46 100,8-21 95,9-5 A->A0+ 16\n",
      " │                            │                     ┌@[0,2,6,9] 8-55 100,8-21 75,6-45,4-26 A->A0+ 15\n",
      " │                            ├@4 9-42 70 B->A 55/81┤\n",
      " │                            │                     ├@[4,5,7,8] 6-13,4-53,3-31,4-61 A->A0 15\n",
      " │                            │                     └@[1,3] 0-m 77,8-47 55 A->A 10\n",
      " │                            │                    ┌@[0,2,4,5,6,7,8] 8-61 100,7-4 66,5-60,2-19,6-42,8-55,8-45 A->A0+ 5\n",
      " │                            ├@6 9-5 68 B->A 54/86┤\n",
      " │                            │                    └@[1,3,9] 8-59 70,6-39 63,6-32 unk 0\n",
      " │                            │                       ┌@[0,1,2,3,4,5,6,8] 0-m 100,5-m,4-m,7-m,8-m,6-m,2-m,5-13 A0->A0 70\n",
      " │                            └@8 11-49 60 B->A0 81/47┤\n",
      " │                                                    └@[7,9] 9-17,10-19 unk 0\n",
      " ├@8 33-63 59 B->A0 66/18 attn\n",
      " ┤\n",
      " │                          ┌@[0,1,3,5,7] 9-5,12-4,9-42,8-47,15-42 B->A 48\n",
      " │                          ├@[4,8,9] 15-0,10-40 45,16-54 44 B->Q 19\n",
      " │                          ├@[2,6] 11-49,16-20 B->A0 10\n",
      " │                          │                     ┌@[0,3,4,5,8] 8-15 100,7-26,8-45,8-35,6-37 A->A 3\n",
      " │                          ├@0 9-5 100 B->A 88/86┤\n",
      " │                          │                     ├@[1,2,6,7] 7-51 73,8-61 54,6-2,8-19 A->A0+ 2\n",
      " │                          │                     └@[9] 5-10 A->A0 1\n",
      " │                          │                      ┌@[0,2,5,7,8,9] 8-46 100,8-55 60,8-21 51,8-47,9-1,9-5 A->A0+ 19\n",
      " │                          ├@1 12-4 86 B->A 100/99┤\n",
      " │                          │                      └@[1,3,4,6] 9-39 90,11-50 52,10-6 52,3-36 A->A0 16\n",
      " │                          │                     ┌@[0,1,6,7,8] 8-55 100,8-21 53,6-37,6-45,5-34 A->A0+ 16\n",
      " │                          ├@3 9-42 70 B->A 97/81┤\n",
      " │                          │                     ├@[9] 0-m A->A 11\n",
      " │                          │                     └@[2,3,4,5] 6-13,8-47,8-14,4-61 A->A0 10\n",
      " │                          │                     ┌@[0,1,2,3,4,6,7,9] 3-36 100,6-13 100,4-21 88,2-62 67,4-55 62,5-60,7-51,6-54 A->A0 31\n",
      " │                          ├@5 8-47 63 B->A 96/93┤\n",
      " │                          │                     └@[5,8] 6-38 51,6-19 A->A 5\n",
      " ├@95 17-28 16 B->A0/78 attn┤\n",
      " │                          │                      ┌@[0,1,2,3,4,6,8] 9-m 100,10-m 94,12-m 61,11-m,6-m,8-m,5-m A->A 70\n",
      " │                          ├@7 15-42 53 B->A 99/88┤\n",
      " │                          │                      └@[5,7,9] 8-46,9-17,11-7 unk 0\n",
      " │                          │                     ┌@[0,1,3,5,6] 9-m 100,11-m 77,8-m,8-15,9-15 Q->Q 30\n",
      " │                          ├@4 15-0 64 B->Q 61/49┤\n",
      " │                          │                     ├@[7,9] 10-61,12-52 Q->A0 7\n",
      " │                          │                     └@[2,4,8] 9-12 72,9-42,7-35 unk 0\n",
      " │                          │                      ┌@[1,2,4,5,7,8] 6-m 95,5-m 78,9-15 65,4-m 58,3-m,2-m Q->Q 50\n",
      " │                          ├@8 10-40 45 B->Q 46/45┤\n",
      " │                          │                      ├@[3] 9-33 75 Q->A0 5\n",
      " │                          │                      └@[0,6,9] 9-17 100,8-21 52,9-1 unk 0\n",
      " │                          │                      ┌@[0,1,2,3,4,6] 12-m 100,13-m 73,0-m 65,9-m 59,11-m,5-m Q->Q 60\n",
      " │                          ├@9 16-54 44 B->Q 86/84┤\n",
      " │                          │                      ├@[5,7,9] 12-52,9-33,11-7 Q->A0 12\n",
      " │                          │                      └@[8] 14-54 unk 0\n",
      " │                          │                       ┌@[0,1,2,8,9] 0-m 100,6-m,5-m,9-39,8-21 A0->A0 30\n",
      " │                          ├@2 11-49 85 B->A0 72/47┤\n",
      " │                          │                       └@[3,4,5,6,7] 10-51,9-17,10-19,8-43,8-42 unk 0\n",
      " │                          │                       ┌@[0,1,2,6,9] 12-m 100,7-m 81,8-m 74,14-23,12-42 A0->A0 30\n",
      " │                          └@6 16-20 62 B->A0 20/10┤\n",
      " │                                                  └@[3,4,5,7,8] 13-31,15-57,10-9,8-42,8-43 unk 0\n",
      " │                          ┌@[1,4,5,8] 9-42,9-28 47,12-4 43,8-47 40 B->A 39\n",
      " │                          ├@[3,6,9] 15-0,18-11 42,16-54 40 B->Q 23\n",
      " │                          ├@[0] 18-23 B->B 15\n",
      " │                          ├@[2] 11-49 B->A0 9\n",
      " │                          ├@[7] 10-40 41 B->Q- 9\n",
      " │                          │                     ┌@[0,1,7,8] 8-46 100,8-55 98,6-45,8-21 A->A0+ 15\n",
      " │                          ├@1 9-42 89 B->A 97/81┤\n",
      " │                          │                     ├@[3,4,5,6,9] 8-47 61,4-53 60,6-13 54,3-31,8-14 A->A0 15\n",
      " │                          │                     └@[2] 0-m 70 A->A 11\n",
      " │                          │                     ┌@[1,2,5,7,8] 4-53 66,3-36 59,6-13,3-31,3-63 A->A0 35\n",
      " │                          ├@4 9-28 47 B->A 99/96┤\n",
      " │                          │                     ├@[0,3,9] 8-46 100,8-21,8-55 A->A0+ 17\n",
      " │                          │                     └@[4,6] 5-m,8-47 A->A 10\n",
      " │                          │                     ┌@[1,3,4,6,7,9] 9-39 69,3-36,11-50,10-0,4-61,10-6 A->A0 22\n",
      " │                          ├@5 12-4 43 B->A 97/99┤\n",
      " │                          │                     ├@[5,8] 6-m,5-m A->A 21\n",
      " │                          │                     └@[0,2] 8-46 100,8-55 65 A->A0+ 10\n",
      " ├@135 19-1 12 B->A0/79 attn┤\n",
      " │                          │                     ┌@[0,1,5,7,8] 8-m 100,9-m 95,10-m,7-m,9-15 Q->Q 40\n",
      " │                          ├@3 15-0 52 B->Q 63/49┤\n",
      " │                          │                     ├@[3,6] 9-42 51,10-61 Q->A0 5\n",
      " │                          │                     └@[2,4,9] 13-31 56,9-12 50,7-35 unk 0\n",
      " │                          │                      ┌@[0,1,2,5,7,9] 0-m 100,14-m 57,7-m,6-m,11-m,9-42 Q->Q 50\n",
      " │                          ├@6 18-11 42 B->Q 35/27┤\n",
      " │                          │                      └@[3,4,6,8] 9-17,3-31,13-31,9-29 unk 0\n",
      " │                          │                       ┌@[1,2,3,4] 12-52 75,11-49,16-21,14-39 B->A0 23\n",
      " │                          │                       ├@[6,7,9] 8-47,4-26,9-28 B->A 23\n",
      " │                          ├@0 18-23 100 B->B 94/89┤\n",
      " │                          │                       ├@[0,8] 0-m 100,11-m B->B 20\n",
      " │                          │                       └@[5] 15-38 B->Q 7\n",
      " │                          │                       ┌@[0,2,5,6,7] 0-m 100,9-39 87,8-47 72,10-53 64,8-34 54 A0->A0 10\n",
      " │                          ├@2 11-49 65 B->A0 83/47┤\n",
      " │                          │                       ├@[1,3,8,9] 10-40 91,10-51 80,7-40 50,5-4 A0->T+ 3\n",
      " │                          │                       └@[4] 8-55 79 unk 0\n",
      " │                          └@7 10-40 41 B->Q- 45/46┐\n",
      " │                                                  └@:10 5-m 100,9-15 81,9-33 77,9-17 62,0-m 55,8-21 52,6-m 51,4-m 50,3-m,9-20 Q-->Q- 50\n",
      " │                             ┌@[0,1,2,3,4,6,7,8,9] 23-m,22-m,17-m,19-m,18-m,14-m 43,19-29 41,20-m 41,21-m 36 B->B 88\n",
      " │                             ├@[5] 11-49 B->A0 10\n",
      " │                             ├@0 23-m 100\n",
      " │                             ├@1 22-m 83\n",
      " │                             ├@2 17-m 81\n",
      " ├@2806 26-57 -19 B->A0/81 attn┤\n",
      " │                             ├@3 19-m 67\n",
      " │                             ├@4 18-m 64\n",
      " │                             ├@6 14-m 43\n",
      " │                             ├@7 19-29 41 B->B 75/63\n",
      " │                             ├@8 20-m 41\n",
      " │                             └@5 11-49 53 B->A0 81/47\n",
      " │                             ┌@[1,2,3,6,7,8,9] 18-m,20-m,17-m,19-29,12-m,10-m,11-m B->B 69\n",
      " │                             ├@[0,4,5] 11-49,12-44,22-40 B->A0 26\n",
      " │                             ├@1 18-m 99\n",
      " │                             ├@2 20-m 89\n",
      " │                             ├@3 17-m 88\n",
      " │                             ├@6 19-29 68 B->B 88/63\n",
      " └@2854 23-54 -57 B->A0/80 attn┤\n",
      "                               ├@7 12-m 65\n",
      "                               ├@8 10-m 64\n",
      "                               ├@9 11-m 51\n",
      "                               ├@0 11-49 100 B->A0 77/47\n",
      "                               ├@4 12-44 78 B->A0 80/48\n",
      "                               └@5 22-40 72 B->A0 90/78\n"
     ]
    }
   ],
   "source": [
    "print_tree(r.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d140cd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['', '22-40 attn/candidates', '17-28 attn/candidates', '19-1 attn/candidates', '26-57 attn/candidates', '23-54 attn/candidates', '22-40 attn/candidates > 15-38', '22-40 attn/candidates > 14-39', '22-40 attn/candidates > 10-52', '17-28 attn/candidates > 15-38', '17-28 attn/candidates > 14-39', '17-28 attn/candidates > 11-50', '17-28 attn/candidates > 11-35', '17-28 attn/candidates > 14-30', '17-28 attn/candidates > 15-0', '19-1 attn/candidates > 14-39', '19-1 attn/candidates > 15-0', '22-40 attn/candidates > 19-29', '22-40 attn/candidates > 11-m', '22-40 attn/candidates > 21-60'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.data_tuples[0][-1].attn_attr.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d9380fe6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ┌@[0,2,6,7,9] 9-m,28-m,15-m,39-m,35-62 B->B 44\n",
      " ├@[1,3,4,5,8] 30-34,29-39,25-43,22-40,33-63 B->A0 42\n",
      " ├@0 9-m 100\n",
      " ├@2 28-m 73\n",
      " ├@6 15-m 66\n",
      " ├@7 39-m 66\n",
      " ├@9 35-62 57 B->B 39/61\n",
      " ├@1 30-34 84 B->A0 95/45 attn/candidates\n",
      " ├@3 29-39 70 B->A0 82/32 attn/candidates\n",
      " ├@4 25-43 70 B->A0 57/8 attn/candidates\n",
      " │                                       ┌@[2,4,5,8] 19-29,11-m,21-60,0-m B->B 31\n",
      " │                                       ├@[3,7] 11-49,16-21 B->A0 22\n",
      " │                                       ├@[0,1,9] 15-38,14-39,10-52 B->Q 15\n",
      " │                                       ├@[6] 12-17 unk 0\n",
      " │                                       │                      ┌@[1,8,9] 11-49 100,12-52 46,17-61 43 B->A0 19\n",
      " │                                       │                      ├@[5] 13-m 52 B->B 10\n",
      " │                                       ├@2 19-29 84 B->B 59/63┤\n",
      " │                                       │                      ├@[0,2,4] 15-38 100,14-39 85,11-50 60 B->Q 9\n",
      " │                                       │                      └@[3,6,7] 12-17 79,9-17 49,8-43 47 unk 0\n",
      " │                                       │          ┌@[0,1,2,3,4,6,8] 8-m 100,6-m 55,7-m 53,10-53,4-m,10-0,6-39 B->B 41\n",
      " │                                       ├@4 11-m 64┤\n",
      " │                                       │          ├@[7] 10-51 B->Q 5\n",
      " │                                       │          └@[5,9] 8-19,9-5 unk 0\n",
      " │                                       │                      ┌@[0,1,7,8,9] 15-38 100,14-39 93,11-50,11-35,14-30 B->Q 27\n",
      " │                                       │                      ├@[3,4,5] 16-21 48,12-52 47,11-49 40 B->A0 25\n",
      " │                                       ├@5 21-60 55 B->B 44/90┤\n",
      " │                                       │                      ├@[6] 19-29 B->B 6\n",
      " │                                       │                      └@[2] 12-17 50 unk 0\n",
      " │                                       ├@8 0-m 46\n",
      " │                                       ├@3 11-49 74 B->A0 85/47\n",
      " │                                       ├@7 16-21 47 B->A0 57/38\n",
      " ├@5 22-40 69 B->A0 99/78 attn/candidates┤\n",
      " │                                       │                       ┌@[6,7] 5-m,9-29 Q->Q 10\n",
      " │                                       ├@0 15-38 100 B->Q 52/43┤\n",
      " │                                       │                       ├@[0,1,3,5,8] 9-12 100,10-6 59,11-50 46,9-17 43,8-29 Q->T 5\n",
      " │                                       │                       └@[2,4,9] 9-1 50,8-43 44,10-19 unk 0\n",
      " │                                       │                            ┌@[0,6] 0-m 100,5-m 64 B->B 25\n",
      " │                                       │                            ├@[2,3,8] 11-35 82,13-9 79,10-40 59 B->Q 19\n",
      " │                                       ├@0 15-38 100 B->Q 52/43 attn┤\n",
      " │                                       │                            ├@[1,7] 9-10 95,10-6 60 B->A 12\n",
      " │                                       │                            └@[4,5,9] 9-1 72,11-53 65,14-54 58 B->A0 8\n",
      " │                                       │                      ┌@[1,2] 11-50 81,12-63 73 Q->T 8\n",
      " │                                       │                      ├@[6,8] 12-52 47,9-33 Q->A0 5\n",
      " │                                       ├@1 14-39 94 B->Q 56/34┤\n",
      " │                                       │                      ├@[3,5,7,9] 10-19 69,9-17 48,12-17,9-29 Q->T+ 1\n",
      " │                                       │                      └@[0,4] 9-12 100,8-43 52 unk 0\n",
      " │                                       │                           ┌@[0,1,3,6] 0-m 100,11-m,8-m,5-m B->B 40\n",
      " │                                       ├@1 14-39 94 B->Q 56/34 attn┤\n",
      " │                                       │                           ├@[2,4,8] 9-10,12-4,10-0 B->A 18\n",
      " │                                       │                           └@[5,7,9] 9-0,9-1,12-55 B->A0 4\n",
      " │                                       │                      ┌@[6] 9-33 Q->A0 3\n",
      " │                                       ├@9 10-52 44 B->Q 40/23┤\n",
      " │                                       │                      ├@[0,1,2,3,8,9] 9-17 100,8-43 96,9-12 94,9-29 42,8-29,3-63 Q->T 1\n",
      " │                                       │                      └@[4,5,7] 9-1,8-15,8-42 unk 0\n",
      " │                                       │                           ┌@[1,3,4,5,6,7,8,9] 9-10 86,8-19 48,9-21,8-30,8-47,9-23,7-3,9-3 B->A 38\n",
      " │                                       ├@9 10-52 44 B->Q 40/23 attn┤\n",
      " │                                       │                           ├@[0] 0-m 100 B->B 10\n",
      " │                                       │                           └@[2] 9-1 61 unk 0\n",
      " │                                       └@6 12-17 48 B->A 9/12\n",
      " ├@8 33-63 59 B->A0 66/18 attn/candidates\n",
      " ┤\n",
      " │                                     ┌@[0,1,2,5,6,7,8] 15-38,14-39,11-50,11-35,14-30,15-0,10-52 36 B->Q 17\n",
      " │                                     ├@[4] 11-49 B->A0 11\n",
      " │                                     ├@[9] 12-63 35 B->B 2\n",
      " │                                     ├@[3] 9-5 B->A 2\n",
      " │                                     │                       ┌@[8,9] 5-m,9-m Q->Q 20\n",
      " │                                     │                       ├@[4,5,7] 9-33,10-61,12-52 Q->A0 7\n",
      " │                                     ├@0 15-38 100 B->Q 18/43┤\n",
      " │                                     │                       ├@[0,2,3] 9-12 100,10-6 57,11-50 51 Q->T 3\n",
      " │                                     │                       └@[1,6] 9-1 70,8-43 unk 0\n",
      " │                                     │                            ┌@[0] 0-m 100 B->B 15\n",
      " │                                     │                            ├@[1,2,6] 11-35 98,13-9 78,10-40 57 B->Q 12\n",
      " │                                     ├@0 15-38 100 B->Q 18/43 attn┤\n",
      " │                                     │                            ├@[3,7] 9-10 78,10-6 56 B->A 9\n",
      " │                                     │                            ├@[8] 11-7 50 B->Q- 6\n",
      " │                                     │                            └@[4,5,9] 9-1 67,11-53 66,13-40 45 B->A0 5\n",
      " │                                     │                      ┌@[0,2,7,8] 9-12 100,0-m 50,8-43,8-m Q->Q 20\n",
      " │                                     │                      ├@[3,9] 9-33 50,10-61 Q->A0 4\n",
      " │                                     ├@1 14-39 66 B->Q 26/34┤\n",
      " │                                     │                      ├@[1,5,6] 11-50 90,12-61,12-63 Q->T 4\n",
      " │                                     │                      └@[4] 9-17 48 unk 0\n",
      " │                                     │                           ┌@[0,2,3,4,7] 0-m 100,8-m,5-m,11-m,13-9 B->B 43\n",
      " │                                     ├@1 14-39 66 B->Q 26/34 attn┤\n",
      " │                                     │                           ├@[1,5,9] 9-10,12-4,10-0 B->A 13\n",
      " │                                     │                           └@[6,8] 9-1,9-0 unk 0\n",
      " │                                     │                    ┌@[0,1,5,7] 0-m 100,5-m 74,8-m 60,4-m Q->Q 40\n",
      " │                                     ├@2 11-50 61 B->Q 4/7┤\n",
      " │                                     │                    └@[2,3,4,6,8,9] 9-39 72,6-59 71,10-0 65,10-19 45,8-55,9-5 unk 0\n",
      " ├@95 17-28 16 B->A0/78 attn/candidates┤\n",
      " │                                     │                         ┌@[0,1,2,3,6,8,9] 7-10 100,10-55 98,10-35 59,8-60 57,5-41 43,7-7 42,6-1 41 B->Q 32\n",
      " │                                     ├@2 11-50 61 B->Q 4/7 attn┤\n",
      " │                                     │                         ├@[7] 9-42 43 B->A 6\n",
      " │                                     │                         └@[4,5] 9-14 56,10-40 51 B->Q- 6\n",
      " │                                     │                      ┌@[4,5,6,7] 0-m 43,6-59,10-55,5-m Q->Q 26\n",
      " │                                     │                      ├@[0,1,8] 9-39 100,10-0 81,10-20 Q->T 8\n",
      " │                                     ├@5 11-35 43 B->Q 41/63┤\n",
      " │                                     │                      ├@[2,3] 8-55 81,9-5 60 Q->T+ 7\n",
      " │                                     │                      └@[9] 9-55 unk 0\n",
      " │                                     │                           ┌@[0,1,7] 0-m 100,5-m,3-m B->B 31\n",
      " │                                     │                           ├@[4,5,6,9] 8-30,9-42,7-3,9-28 B->A 18\n",
      " │                                     ├@5 11-35 43 B->Q 41/63 attn┤\n",
      " │                                     │                           ├@[8] 9-26 B->Q 8\n",
      " │                                     │                           ├@[2] 10-40 B->Q- 3\n",
      " │                                     │                           └@[3] 9-0 unk 0\n",
      " │                                     │                      ┌@[4,5,6,7] 10-55,11-35,0-m,13-63 Q->Q 17\n",
      " │                                     ├@6 14-30 42 B->Q 43/63┤\n",
      " │                                     │                      ├@[0,1,2,3,8] 11-50 100,12-61 63,12-63 54,9-39 43,10-0 Q->T 13\n",
      " │                                     │                      └@[9] 8-55 Q->T+ 4\n",
      " │                                     │                           ┌@[0,1,4,7,8] 0-m 100,9-39,5-m,3-63,13-12 B->B 25\n",
      " │                                     ├@6 14-30 42 B->Q 43/63 attn┤\n",
      " │                                     │                           ├@[2,3,6] 13-9,9-26,10-40 B->Q 16\n",
      " │                                     │                           └@[5,9] 9-42,9-23 B->A 6\n",
      " │                                     │                     ┌@[0,1,2,6,7,8,9] 7-m 100,8-m 99,9-m 97,10-m 53,9-12 53,12-17 47,6-m 47 Q->Q 50\n",
      " │                                     ├@7 15-0 41 B->Q 20/49┤\n",
      " │                                     │                     └@[3,4,5] 9-17 70,13-31 68,8-43 66 unk 0\n",
      " │                                     │                          ┌@:5 0-m 100,12-m 68,5-m,11-m,4-53 B->B 42\n",
      " │                                     │                          ├@[5,9] 9-21,9-10 B->A 10\n",
      " │                                     ├@7 15-0 41 B->Q 20/49 attn┤\n",
      " │                                     │                          ├@[7,8] 9-26,13-9 B->Q 7\n",
      " │                                     │                          └@[6] 11-53 unk 0\n",
      " │                                     ├@4 11-49 48 B->A0 53/47\n",
      " │                                     └@3 9-5 55 B->A 19/86\n",
      " │                                     ┌@[3,4,5,7] 9-m,11-m,10-m,18-23 B->B 36\n",
      " │                                     ├@[0,2,6,9] 15-38,16-21,10-52,17-61 B->A0 15\n",
      " │                                     ├@[1,8] 14-39,15-0 B->Q 10\n",
      " │                                     ├@3 9-m 52\n",
      " │                                     ├@4 11-m 46\n",
      " │                                     ├@5 10-m 46\n",
      " │                                     ├@7 18-23 43 B->B 46/89\n",
      " │                                     ├@0 15-38 100 B->A0 20/15\n",
      " │                                     ├@2 16-21 65 B->A0 44/38\n",
      " │                                     ├@6 10-52 44 B->A0 22/13\n",
      " │                                     ├@9 17-61 43 B->A0 31/16\n",
      " ├@135 19-1 12 B->A0/79 attn/candidates┤\n",
      " │                                     │                      ┌@[3,7,8] 9-12 85,12-17 54,0-m 46 Q->Q 10\n",
      " │                                     │                      ├@[0,2] 10-61 100,9-33 92 Q->A0 5\n",
      " │                                     ├@1 14-39 89 B->Q 25/34┤\n",
      " │                                     │                      ├@[4,6,9] 8-43 83,13-31 77,11-50 42 Q->T 1\n",
      " │                                     │                      └@[1,5] 10-19 93,9-17 78 unk 0\n",
      " │                                     │                           ┌@[0,1,4,6] 0-m 100,11-m,5-m,8-m B->B 43\n",
      " │                                     ├@1 14-39 89 B->Q 25/34 attn┤\n",
      " │                                     │                           ├@[2,7,8] 9-10,12-4,10-0 B->A 14\n",
      " │                                     │                           └@[3,5,9] 13-9,9-14,9-1 unk 0\n",
      " │                                     │                     ┌@[0,1,2,3,7,9] 8-m 100,10-m 84,7-m 74,9-m 73,12-m 44,12-17 Q->Q 50\n",
      " │                                     ├@8 15-0 43 B->Q 23/49┤\n",
      " │                                     │                     └@[4,5,6,8] 9-17 60,8-43 52,13-31 51,10-19 unk 0\n",
      " │                                     │                          ┌@:5 0-m 100,12-m 72,11-m,5-m,4-53 B->B 41\n",
      " │                                     │                          ├@[5,8] 9-21,9-10 B->A 10\n",
      " │                                     └@8 15-0 43 B->Q 23/49 attn┤\n",
      " │                                                                ├@[7,9] 9-26,10-40 B->Q 8\n",
      " │                                                                └@[6] 11-53 unk 0\n",
      " │                                        ┌@:8 8-m,10-m,19-29,14-m,13-m,21-60,21-m,9-m B->B 70\n",
      " │                                        ├@[8,9] 11-49,17-61 B->A0 10\n",
      " │                                        ├@0 8-m 100\n",
      " │                                        ├@1 10-m 96\n",
      " │                                        ├@2 19-29 94 B->B 42/63\n",
      " │                                        ├@3 14-m 84\n",
      " ├@2806 26-57 -19 B->A0/81 attn/candidates┤\n",
      " │                                        ├@4 13-m 82\n",
      " │                                        ├@5 21-60 81 B->B 53/90\n",
      " │                                        ├@6 21-m 80\n",
      " │                                        ├@7 9-m 77\n",
      " │                                        ├@8 11-49 73 B->A0 52/47\n",
      " │                                        └@9 17-61 69 B->A0 33/16\n",
      " │                                        ┌@[0,1,3,4,5,7,9] 15-m,0-m,19-m,14-m,19-29,13-m,12-m 37 B->B 63\n",
      " │                                        ├@[2,8] 17-61,15-38 B->A0 7\n",
      " │                                        ├@[6] 9-5 unk 0\n",
      " │                                        ├@0 15-m 100\n",
      " │                                        ├@1 0-m 96\n",
      " │                                        ├@3 19-m 51\n",
      " └@2854 23-54 -57 B->A0/80 attn/candidates┤\n",
      "                                          ├@4 14-m 49\n",
      "                                          ├@5 19-29 47 B->B 28/63\n",
      "                                          ├@7 13-m 43\n",
      "                                          ├@2 17-61 78 B->A0 29/16\n",
      "                                          ├@8 15-38 41 B->A0 23/15\n",
      "                                          └@6 9-5 47 B->A 11/86\n"
     ]
    }
   ],
   "source": [
    "print_tree(r.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96bb3aa6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ┌@[0,2,6,7,9] 9-m,28-m,15-m,39-m,35-62 B->B 44\n",
      " ├@[1,3,4,5,8] 30-34,29-39,25-43,22-40,33-63 B->A0 42\n",
      " ├@0 9-m 100\n",
      " ├@2 28-m 73\n",
      " ├@6 15-m 66\n",
      " ├@7 39-m 66\n",
      " ├@9 35-62 57 B->B 39/61\n",
      " ├@1 30-34 84 B->A0 95/45 attn/ans0s\n",
      " ├@3 29-39 70 B->A0 82/32 attn/ans0s\n",
      " ├@4 25-43 70 B->A0 57/8 attn/ans0s\n",
      " │                                  ┌@[2,4,5,8] 19-29,11-m,21-60,0-m B->B 31\n",
      " │                                  ├@[3,7] 11-49,16-21 B->A0 22\n",
      " │                                  ├@[0,1,9] 15-38,14-39,10-52 B->Q 15\n",
      " │                                  ├@[6] 12-17 unk 0\n",
      " │                                  │                      ┌@[1,8,9] 11-49 100,12-52 46,17-61 43 B->A0 19\n",
      " │                                  │                      ├@[5] 13-m 52 B->B 10\n",
      " │                                  ├@2 19-29 84 B->B 59/63┤\n",
      " │                                  │                      ├@[0,2,4] 15-38 100,14-39 85,11-50 60 B->Q 9\n",
      " │                                  │                      └@[3,6,7] 12-17 79,9-17 49,8-43 47 unk 0\n",
      " │                                  ├@4 11-m 64\n",
      " │                                  │                      ┌@[0,1,7,8,9] 15-38 100,14-39 93,11-50,11-35,14-30 B->Q 27\n",
      " │                                  │                      ├@[3,4,5] 16-21 48,12-52 47,11-49 40 B->A0 25\n",
      " │                                  ├@5 21-60 55 B->B 44/90┤\n",
      " │                                  │                      ├@[6] 19-29 B->B 6\n",
      " │                                  │                      └@[2] 12-17 50 unk 0\n",
      " │                                  ├@8 0-m 46\n",
      " │                                  ├@3 11-49 74 B->A0 85/47\n",
      " │                                  ├@7 16-21 47 B->A0 57/38\n",
      " │                                  │                       ┌@[6,7] 5-m,9-29 Q->Q 10\n",
      " │                                  ├@0 15-38 100 B->Q 52/43┤\n",
      " │                                  │                       ├@[0,1,3,5,8] 9-12 100,10-6 59,11-50 46,9-17 43,8-29 Q->T 5\n",
      " │                                  │                       └@[2,4,9] 9-1 50,8-43 44,10-19 unk 0\n",
      " ├@5 22-40 69 B->A0 99/78 attn/ans0s┤\n",
      " │                                  │                            ┌@[0,6] 0-m 100,5-m 64 B->B 25\n",
      " │                                  │                            ├@[2,3,8] 11-35 82,13-9 79,10-40 59 B->Q 19\n",
      " │                                  │                            ├@[1,7] 9-10 95,10-6 60 B->A 12\n",
      " │                                  │                            ├@[4,5,9] 9-1 72,11-53 65,14-54 58 B->A0 8\n",
      " │                                  │                            ├@0 0-m 100\n",
      " │                                  │                            ├@6 5-m 64\n",
      " │                                  │                            ├@2 11-35 82 B->Q 85/63\n",
      " │                                  │                            ├@3 13-9 79 B->Q 50/59\n",
      " │                                  │                            ├@8 10-40 59 B->Q 51/45\n",
      " │                                  ├@0 15-38 100 B->Q 52/43 attn┤\n",
      " │                                  │                            │                     ┌@[0,1,2,4,6,7,8] 6-m 100,5-7 54,7-62 47,8-55,6-31,8-29,8-42 A->A 11\n",
      " │                                  │                            ├@1 9-10 95 B->A 89/92┤\n",
      " │                                  │                            │                     └@[3,5,9] 6-45,7-40,8-33 unk 0\n",
      " │                                  │                            │                     ┌@[0,6,8] 7-37 100,5-15 51,3-3 45 A->A0 1\n",
      " │                                  │                            ├@7 10-6 60 B->A 34/51┤\n",
      " │                                  │                            │                     ├@[3,7,9] 9-29 57,5-4 47,9-8 43 A->A 1\n",
      " │                                  │                            │                     └@[1,2,4,5] 8-17 72,7-4 64,8-34 56,9-26 52 A->A0+ 0\n",
      " │                                  │                            ├@4 9-1 72 B->A0 1/2\n",
      " │                                  │                            ├@5 11-53 65 B->A0 15/14\n",
      " │                                  │                            └@9 14-54 58 B->A0 54/46\n",
      " │                                  │                      ┌@[1,2] 11-50 81,12-63 73 Q->T 8\n",
      " │                                  │                      ├@[6,8] 12-52 47,9-33 Q->A0 5\n",
      " │                                  ├@1 14-39 94 B->Q 56/34┤\n",
      " │                                  │                      ├@[3,5,7,9] 10-19 69,9-17 48,12-17,9-29 Q->T+ 1\n",
      " │                                  │                      └@[0,4] 9-12 100,8-43 52 unk 0\n",
      " │                                  │                           ┌@[0,1,3,6] 0-m 100,11-m,8-m,5-m B->B 40\n",
      " │                                  │                           ├@[2,4,8] 9-10,12-4,10-0 B->A 18\n",
      " │                                  ├@1 14-39 94 B->Q 56/34 attn┤\n",
      " │                                  │                           ├@[5,7,9] 9-0,9-1,12-55 B->A0 4\n",
      " │                                  │                           └@0 0-m 100\n",
      " │                                  │                      ┌@[6] 9-33 Q->A0 3\n",
      " │                                  ├@9 10-52 44 B->Q 40/23┤\n",
      " │                                  │                      ├@[0,1,2,3,8,9] 9-17 100,8-43 96,9-12 94,9-29 42,8-29,3-63 Q->T 1\n",
      " │                                  │                      └@[4,5,7] 9-1,8-15,8-42 unk 0\n",
      " │                                  │                           ┌@[1,3,4,5,6,7,8,9] 9-10 86,8-19 48,9-21,8-30,8-47,9-23,7-3,9-3 B->A 38\n",
      " │                                  │                           ├@[0] 0-m 100 B->B 10\n",
      " │                                  │                           ├@[2] 9-1 61 unk 0\n",
      " │                                  ├@9 10-52 44 B->Q 40/23 attn┤\n",
      " │                                  │                           │                     ┌@[1,4,6,7,9] 8-43 90,5-m 81,6-45 57,3-m 54,2-m 44 A->A 29\n",
      " │                                  │                           ├@1 9-10 86 B->A 67/92┤\n",
      " │                                  │                           │                     └@[0,2,3,5,8] 8-18 100,8-47 84,8-30 84,8-46 60,5-7 49 unk 0\n",
      " │                                  │                           │                     ┌@[1,2] 0-m 43,6-45 A->A 10\n",
      " │                                  │                           ├@3 8-19 48 B->A 64/81┤\n",
      " │                                  │                           │                     └@[0,3,4,5,6,7,8,9] 5-7 100,6-13,3-63,4-26,6-46,4-53,5-20,3-36 unk 0\n",
      " │                                  │                           ├@0 0-m 100\n",
      " │                                  │                           └@2 9-1 61 B->Q- 0/0\n",
      " │                                  └@6 12-17 48 B->A 9/12\n",
      " ├@8 33-63 59 B->A0 66/18 attn/ans0s\n",
      " ┤\n",
      " │                                ┌@[0,1,2,5,6,7,8] 15-38,14-39,11-50,11-35,14-30,15-0,10-52 36 B->Q 17\n",
      " │                                ├@[4] 11-49 B->A0 11\n",
      " │                                ├@[9] 12-63 35 B->B 2\n",
      " │                                ├@[3] 9-5 B->A 2\n",
      " │                                │                       ┌@[8,9] 5-m,9-m Q->Q 20\n",
      " │                                │                       ├@[4,5,7] 9-33,10-61,12-52 Q->A0 7\n",
      " │                                ├@0 15-38 100 B->Q 18/43┤\n",
      " │                                │                       ├@[0,2,3] 9-12 100,10-6 57,11-50 51 Q->T 3\n",
      " │                                │                       └@[1,6] 9-1 70,8-43 unk 0\n",
      " │                                │                            ┌@[0] 0-m 100 B->B 15\n",
      " │                                │                            ├@[1,2,6] 11-35 98,13-9 78,10-40 57 B->Q 12\n",
      " │                                │                            ├@[3,7] 9-10 78,10-6 56 B->A 9\n",
      " │                                │                            ├@[8] 11-7 50 B->Q- 6\n",
      " │                                │                            ├@[4,5,9] 9-1 67,11-53 66,13-40 45 B->A0 5\n",
      " │                                │                            ├@0 0-m 100\n",
      " │                                │                            ├@1 11-35 98 B->Q 48/63\n",
      " │                                │                            ├@2 13-9 78 B->Q 37/59\n",
      " │                                │                            ├@6 10-40 57 B->Q 33/45\n",
      " │                                ├@0 15-38 100 B->Q 18/43 attn┤\n",
      " │                                │                            │                     ┌@[0,1,2,6,8] 6-m 100,7-62 62,0-m 52,5-7 42,6-31 A->A 21\n",
      " │                                │                            ├@3 9-10 78 B->A 62/92┤\n",
      " │                                │                            │                     ├@[3,4,5] 6-45 49,8-55 46,6-37 46 A->A0+ 3\n",
      " │                                │                            │                     └@[7,9] 7-21 41,8-21 unk 0\n",
      " │                                │                            │                     ┌@[0,7,8] 7-37 100,5-15 47,3-3 43 A->A0 2\n",
      " │                                │                            ├@7 10-6 56 B->A 30/51┤\n",
      " │                                │                            │                     ├@[5,6,9] 9-29 49,5-4 48,9-4 42 A->A 1\n",
      " │                                │                            │                     └@[1,2,3,4] 8-34 79,8-17 74,7-4 61,9-26 58 A->A0+ 1\n",
      " │                                │                            ├@8 11-7 50 B->Q- 32/25\n",
      " │                                │                            ├@4 9-1 67 B->A0 1/2\n",
      " │                                │                            ├@5 11-53 66 B->A0 10/14\n",
      " │                                │                            └@9 13-40 45 B->A0 30/57\n",
      " │                                │                      ┌@[0,2,7,8] 9-12 100,0-m 50,8-43,8-m Q->Q 20\n",
      " │                                │                      ├@[3,9] 9-33 50,10-61 Q->A0 4\n",
      " │                                ├@1 14-39 66 B->Q 26/34┤\n",
      " │                                │                      ├@[1,5,6] 11-50 90,12-61,12-63 Q->T 4\n",
      " │                                │                      └@[4] 9-17 48 unk 0\n",
      " │                                │                           ┌@[0,2,3,4,7] 0-m 100,8-m,5-m,11-m,13-9 B->B 43\n",
      " │                                │                           ├@[1,5,9] 9-10,12-4,10-0 B->A 13\n",
      " │                                ├@1 14-39 66 B->Q 26/34 attn┤\n",
      " │                                │                           ├@[6,8] 9-1,9-0 unk 0\n",
      " │                                │                           └@0 0-m 100\n",
      " │                                │                    ┌@[0,1,5,7] 0-m 100,5-m 74,8-m 60,4-m Q->Q 40\n",
      " │                                ├@2 11-50 61 B->Q 4/7┤\n",
      " │                                │                    └@[2,3,4,6,8,9] 9-39 72,6-59 71,10-0 65,10-19 45,8-55,9-5 unk 0\n",
      " ├@95 17-28 16 B->A0/78 attn/ans0s┤\n",
      " │                                │                         ┌@[0,1,2,3,6,8,9] 7-10 100,10-55 98,10-35 59,8-60 57,5-41 43,7-7 42,6-1 41 B->Q 32\n",
      " │                                │                         ├@[7] 9-42 43 B->A 6\n",
      " │                                │                         ├@[4,5] 9-14 56,10-40 51 B->Q- 6\n",
      " │                                │                         ├@0 7-10 100 B->Q 44/92\n",
      " │                                │                         ├@1 10-55 98 B->Q 39/85\n",
      " │                                │                         ├@2 10-35 59 B->Q 41/33\n",
      " │                                │                         ├@3 8-60 57 B->Q 35/48\n",
      " │                                │                         ├@6 5-41 43 B->Q 48/63\n",
      " │                                ├@2 11-50 61 B->Q 4/7 attn┤\n",
      " │                                │                         ├@8 7-7 42 B->Q 48/94\n",
      " │                                │                         ├@9 6-1 41 B->Q 44/51\n",
      " │                                │                         │                     ┌@[0,1,5,6,7] 6-m 100,5-m 96,4-m,7-38,6-38 A->A 35\n",
      " │                                │                         ├@7 9-42 43 B->A 65/81┤\n",
      " │                                │                         │                     ├@[2,4,9] 3-36 77,2-62,8-29 A->A0 12\n",
      " │                                │                         │                     └@[3,8] 8-47 62,8-59 unk 0\n",
      " │                                │                         ├@4 9-14 56 B->Q- 28/33\n",
      " │                                │                         └@5 10-40 51 B->Q- 29/46\n",
      " │                                │                      ┌@[4,5,6,7] 0-m 43,6-59,10-55,5-m Q->Q 26\n",
      " │                                │                      ├@[0,1,8] 9-39 100,10-0 81,10-20 Q->T 8\n",
      " │                                ├@5 11-35 43 B->Q 41/63┤\n",
      " │                                │                      ├@[2,3] 8-55 81,9-5 60 Q->T+ 7\n",
      " │                                │                      └@[9] 9-55 unk 0\n",
      " │                                │                           ┌@[0,1,7] 0-m 100,5-m,3-m B->B 31\n",
      " │                                │                           ├@[4,5,6,9] 8-30,9-42,7-3,9-28 B->A 18\n",
      " │                                │                           ├@[8] 9-26 B->Q 8\n",
      " │                                ├@5 11-35 43 B->Q 41/63 attn┤\n",
      " │                                │                           ├@[2] 10-40 B->Q- 3\n",
      " │                                │                           ├@[3] 9-0 unk 0\n",
      " │                                │                           └@0 0-m 100\n",
      " │                                │                      ┌@[4,5,6,7] 10-55,11-35,0-m,13-63 Q->Q 17\n",
      " │                                ├@6 14-30 42 B->Q 43/63┤\n",
      " │                                │                      ├@[0,1,2,3,8] 11-50 100,12-61 63,12-63 54,9-39 43,10-0 Q->T 13\n",
      " │                                │                      └@[9] 8-55 Q->T+ 4\n",
      " │                                │                           ┌@[0,1,4,7,8] 0-m 100,9-39,5-m,3-63,13-12 B->B 25\n",
      " │                                │                           ├@[2,3,6] 13-9,9-26,10-40 B->Q 16\n",
      " │                                ├@6 14-30 42 B->Q 43/63 attn┤\n",
      " │                                │                           ├@[5,9] 9-42,9-23 B->A 6\n",
      " │                                │                           └@0 0-m 100\n",
      " │                                │                     ┌@[0,1,2,6,7,8,9] 7-m 100,8-m 99,9-m 97,10-m 53,9-12 53,12-17 47,6-m 47 Q->Q 50\n",
      " │                                ├@7 15-0 41 B->Q 20/49┤\n",
      " │                                │                     └@[3,4,5] 9-17 70,13-31 68,8-43 66 unk 0\n",
      " │                                │                          ┌@:5 0-m 100,12-m 68,5-m,11-m,4-53 B->B 42\n",
      " │                                │                          ├@[5,9] 9-21,9-10 B->A 10\n",
      " │                                │                          ├@[7,8] 9-26,13-9 B->Q 7\n",
      " │                                ├@7 15-0 41 B->Q 20/49 attn┤\n",
      " │                                │                          ├@[6] 11-53 unk 0\n",
      " │                                │                          ├@0 0-m 100\n",
      " │                                │                          └@1 12-m 68\n",
      " │                                ├@4 11-49 48 B->A0 53/47\n",
      " │                                └@3 9-5 55 B->A 19/86\n",
      " │                                ┌@[3,4,5,7] 9-m,11-m,10-m,18-23 B->B 36\n",
      " │                                ├@[0,2,6,9] 15-38,16-21,10-52,17-61 B->A0 15\n",
      " │                                ├@[1,8] 14-39,15-0 B->Q 10\n",
      " │                                ├@3 9-m 52\n",
      " │                                ├@4 11-m 46\n",
      " │                                ├@5 10-m 46\n",
      " │                                │                      ┌@:7 9-m 100,15-m 78,10-m 74,11-m 73,12-m 67,14-m 63,8-m 56 B->B 70\n",
      " │                                ├@7 18-23 43 B->B 46/89┤\n",
      " │                                │                      └@[7,8,9] 14-39 50,15-38 44,16-21 42 unk 0\n",
      " │                                ├@0 15-38 100 B->A0 20/15\n",
      " │                                ├@2 16-21 65 B->A0 44/38\n",
      " │                                ├@6 10-52 44 B->A0 22/13\n",
      " │                                ├@9 17-61 43 B->A0 31/16\n",
      " ├@135 19-1 12 B->A0/79 attn/ans0s┤\n",
      " │                                │                      ┌@[3,7,8] 9-12 85,12-17 54,0-m 46 Q->Q 10\n",
      " │                                │                      ├@[0,2] 10-61 100,9-33 92 Q->A0 5\n",
      " │                                ├@1 14-39 89 B->Q 25/34┤\n",
      " │                                │                      ├@[4,6,9] 8-43 83,13-31 77,11-50 42 Q->T 1\n",
      " │                                │                      └@[1,5] 10-19 93,9-17 78 unk 0\n",
      " │                                │                           ┌@[0,1,4,6] 0-m 100,11-m,5-m,8-m B->B 43\n",
      " │                                │                           ├@[2,7,8] 9-10,12-4,10-0 B->A 14\n",
      " │                                ├@1 14-39 89 B->Q 25/34 attn┤\n",
      " │                                │                           ├@[3,5,9] 13-9,9-14,9-1 unk 0\n",
      " │                                │                           └@0 0-m 100\n",
      " │                                │                     ┌@[0,1,2,3,7,9] 8-m 100,10-m 84,7-m 74,9-m 73,12-m 44,12-17 Q->Q 50\n",
      " │                                ├@8 15-0 43 B->Q 23/49┤\n",
      " │                                │                     └@[4,5,6,8] 9-17 60,8-43 52,13-31 51,10-19 unk 0\n",
      " │                                │                          ┌@:5 0-m 100,12-m 72,11-m,5-m,4-53 B->B 41\n",
      " │                                │                          ├@[5,8] 9-21,9-10 B->A 10\n",
      " │                                │                          ├@[7,9] 9-26,10-40 B->Q 8\n",
      " │                                └@8 15-0 43 B->Q 23/49 attn┤\n",
      " │                                                           ├@[6] 11-53 unk 0\n",
      " │                                                           ├@0 0-m 100\n",
      " │                                                           └@1 12-m 72\n",
      " ├@2806 26-57 -19 B->A0/81 attn/ans0s\n",
      " └@2854 23-54 -57 B->A0/80 attn/ans0s\n"
     ]
    }
   ],
   "source": [
    "print_tree(r.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b9233a9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ┌@[0,2,6,7,9] 9-m,28-m,15-m,39-m,35-62 B->B 44\n",
      " ├@[1,3,4,5,8] 30-34,29-39,25-43,22-40,33-63 B->A0 42\n",
      " ├@0 9-m 100\n",
      " ├@2 28-m 73\n",
      " ├@6 15-m 66\n",
      " ├@7 39-m 66\n",
      " ├@9 35-62 57 B->B 39/61\n",
      " ├@1 30-34 84 B->A0 95/45 attn/~<s>\n",
      " ├@3 29-39 70 B->A0 82/32 attn/~<s>\n",
      " ├@4 25-43 70 B->A0 57/8 attn/~<s>\n",
      " │                                 ┌@[0,3,4,5,6] 18-23,17-m,21-60,14-m,19-m B->B 42\n",
      " │                                 ├@[1,2,7,9] 12-4,9-42,9-5,15-42 B->A 24\n",
      " │                                 ├@[8] 11-49 B->A0 8\n",
      " │                                 ├@0 18-23 100 B->B 58/89\n",
      " │                                 ├@3 17-m 74\n",
      " │                                 ├@4 21-60 73 B->B 61/90\n",
      " ├@5 22-40 69 B->A0 99/78 attn/~<s>┤\n",
      " │                                 ├@5 14-m 72\n",
      " │                                 ├@6 19-m 68\n",
      " │                                 ├@1 12-4 81 B->A 65/99\n",
      " │                                 ├@2 9-42 74 B->A 60/81\n",
      " │                                 ├@7 9-5 68 B->A 51/86\n",
      " │                                 ├@9 15-42 48 B->A 60/88\n",
      " │                                 └@8 11-49 49 B->A0 78/47\n",
      " ├@8 33-63 59 B->A0 66/18 attn/~<s>\n",
      " │                               ┌@[0,1,4,6,7] 9-5,12-4,8-47,9-42,15-42 B->A 31\n",
      " │                               ├@[5,8] 15-0,16-54 B->Q 9\n",
      " │                               ├@[2,3] 11-49,16-20 B->A0 6\n",
      " │                               ├@[9] 9-23 unk 0\n",
      " │                               ├@0 9-5 100 B->A 56/86\n",
      " │                               ├@1 12-4 96 B->A 58/99\n",
      " │                               ├@4 8-47 67 B->A 58/93\n",
      " ├@95 17-28 16 B->A0/78 attn/~<s>┤\n",
      " │                               ├@6 9-42 63 B->A 69/81\n",
      " │                               ├@7 15-42 50 B->A 68/88\n",
      " │                               ├@5 15-0 66 B->Q 38/49\n",
      " │                               ├@8 16-54 42 B->Q 56/84\n",
      " │                               ├@2 11-49 85 B->A0 43/47\n",
      " │                               ├@3 16-20 70 B->A0 10/10\n",
      " │                               └@9 9-23 42 B->Q- 0/0\n",
      " ┤\n",
      " │                               ┌@[1,2,6,9] 9-42,12-4,9-23,9-5 B->A 18\n",
      " │                               ├@[3,4] 15-0,18-11 B->Q 9\n",
      " │                               ├@[0] 18-23 B->B 9\n",
      " │                               ├@[5,8] 11-49,16-20 B->A0 7\n",
      " │                               ├@[7] 10-40 B->Q- 6\n",
      " │                               ├@1 9-42 87 B->A 69/81\n",
      " │                               ├@2 12-4 71 B->A 57/99\n",
      " ├@135 19-1 12 B->A0/79 attn/~<s>┤\n",
      " │                               ├@6 9-23 50 B->A 0/0\n",
      " │                               ├@9 9-5 45 B->A 53/86\n",
      " │                               ├@3 15-0 57 B->Q 40/49\n",
      " │                               ├@4 18-11 55 B->Q 18/27\n",
      " │                               ├@0 18-23 100 B->B 61/89\n",
      " │                               ├@5 11-49 52 B->A0 50/47\n",
      " │                               ├@8 16-20 45 B->A0 12/10\n",
      " │                               └@7 10-40 47 B->Q- 33/46\n",
      " │                                  ┌@[0,1,2,3,4,6,7,8,9] 23-m,22-m,17-m,18-m,19-m,20-m,14-m,19-29 35,21-m 32 B->B 85\n",
      " │                                  ├@[5] 11-49 unk 0\n",
      " │                                  ├@0 23-m 100\n",
      " │                                  ├@1 22-m 83\n",
      " │                                  ├@2 17-m 82\n",
      " ├@2806 26-57 -19 B->A0/81 attn/~<s>┤\n",
      " │                                  ├@3 18-m 72\n",
      " │                                  ├@4 19-m 69\n",
      " │                                  ├@6 20-m 43\n",
      " │                                  ├@7 14-m 42\n",
      " │                                  └@5 11-49 51 B->A0 48/47\n",
      " │                                  ┌@[0,1,4,6,7,8,9] 17-m,18-m,20-m,12-m,19-29,10-m,8-m B->B 66\n",
      " │                                  ├@[2,3,5] 11-49,12-44,22-40 B->A0 15\n",
      " │                                  ├@0 17-m 100\n",
      " │                                  ├@1 18-m 98\n",
      " │                                  ├@4 20-m 73\n",
      " │                                  ├@6 12-m 68\n",
      " └@2854 23-54 -57 B->A0/80 attn/~<s>┤\n",
      "                                    ├@7 19-29 64 B->B 61/63\n",
      "                                    ├@8 10-m 59\n",
      "                                    ├@9 8-m 52\n",
      "                                    ├@2 11-49 98 B->A0 47/47\n",
      "                                    ├@3 12-44 87 B->A0 47/48\n",
      "                                    └@5 22-40 70 B->A0 55/78\n"
     ]
    }
   ],
   "source": [
    "print_tree(r.root)  # bos->~<s> as attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ca2c3726",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ┌@[0,2,6,7,9] 9-m,28-m,15-m,39-m,35-62 B->B 44\n",
      " ├@[1,3,4,5,8] 30-34,29-39,25-43,22-40,33-63 B->A0 42\n",
      " ├@0 9-m 100\n",
      " ├@2 28-m 73\n",
      " ├@6 15-m 66\n",
      " ├@7 39-m 66\n",
      " ├@9 35-62 57 B->B 39/61\n",
      " ├@1 30-34 84 B->A0 95/45 attn:B->~<s>\n",
      " ├@3 29-39 70 B->A0 82/32 attn:B->~<s>\n",
      " ├@4 25-43 70 B->A0 57/8 attn:B->~<s>\n",
      " │                                    ┌@[0,2,3,6,7,9] 18-23,19-m,14-m,21-60,17-m,13-m B->B 59\n",
      " │                                    ├@[1,4,5,8] 12-4,9-42,9-5,15-42 B->A 39\n",
      " │                                    │                       ┌@[0,1,2,4,5,9] 12-4 100,9-42 79,15-42 77,9-23 52,9-5 50,8-47 44 B->A 45\n",
      " │                                    │                       ├@[7,8] 0-m 48,13-m 47 B->B 21\n",
      " │                                    ├@0 18-23 100 B->B 94/89┤\n",
      " │                                    │                       ├@[6] 10-40 48 B->Q- 5\n",
      " │                                    │                       └@[3] 16-20 73 unk 0\n",
      " │                                    ├@2 19-m 76\n",
      " │                                    ├@3 14-m 76\n",
      " │                                    │                      ┌@[0,5,6,8,9] 12-4 100,9-42 69,15-42 65,9-5 60,8-47 55 B->A 45\n",
      " │                                    ├@6 21-60 66 B->B 92/90┤\n",
      " │                                    │                      ├@[1,4,7] 13-m 95,19-29 70,18-23 61 B->B 26\n",
      " │                                    │                      └@[2,3] 16-20 81,11-49 72 B->A0 8\n",
      " │                                    ├@7 17-m 56\n",
      " │                                    ├@9 13-m 45\n",
      " ├@5 22-40 69 B->A0 99/78 attn:B->~<s>┤\n",
      " │                                    │                      ┌@[2,4,9] 9-39 64,10-6 50,4-53 A->A0 14\n",
      " │                                    ├@1 12-4 77 B->A 100/99┤\n",
      " │                                    │                      ├@:2 8-21 100,9-5 73 A->A0+ 11\n",
      " │                                    │                      └@[3,5,6,7,8] 10-54 61,10-9 48,5-7,10-36,8-47 A->A 6\n",
      " │                                    │                     ┌@[3,5,6,8,9] 5-7 54,6-m 47,5-m 41,4-m,6-38 A->A 34\n",
      " │                                    ├@4 9-42 75 B->A 97/81┤\n",
      " │                                    │                     ├@[0,2,7] 8-21 100,8-46 64,8-47 A->A0+ 11\n",
      " │                                    │                     └@[1,4] 4-53 65,3-31 51 A->A0 11\n",
      " │                                    │                    ┌@[2,4,5,9] 0-m 81,1-m 72,8-37 68,6-m 56 A->A 31\n",
      " │                                    ├@5 9-5 70 B->A 90/86┤\n",
      " │                                    │                    ├@[0,1,3,6,8] 8-55 100,8-20 92,8-46 73,7-4 66,7-42 61 A->A0+ 15\n",
      " │                                    │                    └@[7] 4-21 62 A->A0 8\n",
      " │                                    │                      ┌@[4,6,8,9] 8-21 41,9-1,9-5,8-46 A->A0+ 17\n",
      " │                                    └@8 15-42 46 B->A 99/88┤\n",
      " │                                                           ├@[7] 13-49 A->A 6\n",
      " │                                                           └@[0,1,2,3,5] 10-6 100,9-12 59,8-29 43,9-43 42,13-63 A->A0 4\n",
      " ├@8 33-63 59 B->A0 66/18 attn:B->~<s>\n",
      " ┤\n",
      " │                                  ┌@[0,1,3,4,7] 9-5,12-4,9-42,8-47,15-42 B->A 48\n",
      " │                                  ├@[5,9] 15-0,16-54 B->Q 20\n",
      " │                                  ├@[2,6] 11-49,16-20 B->A0 9\n",
      " │                                  ├@[8] 10-40 B->Q- 6\n",
      " │                                  │                     ┌@[0,1,3,4,5,8] 8-55 100,8-20 84,8-47 62,7-4 62,8-21 58,7-42 47 A->A0+ 16\n",
      " │                                  ├@0 9-5 100 B->A 88/86┤\n",
      " │                                  │                     ├@[2,6,9] 1-m 67,8-37 51,5-7 45 A->A 12\n",
      " │                                  │                     └@[7] 7-21 51 A->A0 3\n",
      " │                                  │                      ┌@[1,2,6,8] 8-21 72,9-5 62,8-55,8-46 A->A0+ 23\n",
      " │                                  ├@1 12-4 98 B->A 100/99┤\n",
      " │                                  │                      ├@[0,3,5,9] 9-39 100,10-6 57,4-53,3-63 A->A0 21\n",
      " │                                  │                      └@[4,7] 10-54,6-38 A->A 9\n",
      " ├@95 17-28 16 B->A0/78 attn:B->~<s>┤\n",
      " │                                  │                     ┌@[2,4,9] 4-53 67,3-31,6-13 A->A0 16\n",
      " │                                  ├@3 9-42 78 B->A 97/81┤\n",
      " │                                  │                     ├@[0,1,3,5] 8-46 100,8-21 68,8-47 43,8-55 A->A0+ 16\n",
      " │                                  │                     └@[6,7,8] 5-7,6-38,6-m A->A 15\n",
      " │                                  │                     ┌@[1,2,3,5,6,7,8] 4-53,6-13,3-36,3-31,3-63,5-20,4-21 A->A0 41\n",
      " │                                  ├@4 8-47 68 B->A 96/93┤\n",
      " │                                  │                     └@[0,4,9] 0-m 100,6-38,3-49 A->A 17\n",
      " │                                  │                      ┌@[4,6,8] 8-21,9-1,9-5 A->A0+ 11\n",
      " │                                  ├@7 15-42 58 B->A 99/88┤\n",
      " │                                  │                      ├@[0,1,2,3,5,7] 10-6 100,9-12 54,8-29 45,9-43 41,13-63,9-39 A->A0 9\n",
      " │                                  │                      └@[9] 13-49 A->A 7\n",
      " │                                  ├@5 15-0 64 B->Q 64/49\n",
      " │                                  ├@9 16-54 47 B->Q 88/84\n",
      " │                                  ├@2 11-49 83 B->A0 65/47\n",
      " │                                  ├@6 16-20 62 B->A0 16/10\n",
      " │                                  └@8 10-40 47 B->Q- 45/46\n",
      " │                                  ┌@[0,2,5,7,8,9] 9-42,12-4,9-23,15-42,9-5,8-30 B->A 48\n",
      " │                                  ├@[1,3] 18-23,14-m B->B 22\n",
      " │                                  ├@[6] 15-0 B->Q 12\n",
      " │                                  ├@[4] 10-40 B->Q- 5\n",
      " │                                  │                      ┌@[1,3,8,9] 4-53 67,3-31,3-36,6-13 A->A0 22\n",
      " │                                  ├@0 9-42 100 B->A 97/81┤\n",
      " │                                  │                      ├@[4,5,6,7] 5-m,5-7,6-38,8-47 A->A 15\n",
      " │                                  │                      └@[0,2] 8-46 100,8-21 60 A->A0+ 11\n",
      " │                                  │                      ┌@[2,3,8,9] 4-53 93,9-39 92,10-6 46,3-63 41 A->A0 19\n",
      " │                                  ├@2 12-4 82 B->A 100/99┤\n",
      " │                                  │                      ├@[0,1,4] 8-46 100,8-21 98,9-5 75 A->A0+ 17\n",
      " │                                  │                      └@[5,6,7] 10-54 68,6-38 66,8-47 62 A->A 9\n",
      " │                                  │                   ┌@:9 7-7 100,7-2 78,6-38 70,6-62 69,7-36 56,6-31 56,5-41 46,8-47 43,5-m 43 A->A 10\n",
      " │                                  ├@5 9-23 55 B->A 0/0┤\n",
      " │                                  │                   └@[9] 6-18 unk 0\n",
      " ├@135 19-1 12 B->A0/79 attn:B->~<s>┤\n",
      " │                                  │                      ┌@[4,6,7,8] 8-21 47,8-46 43,9-1,8-47 A->A0+ 12\n",
      " │                                  ├@7 15-42 49 B->A 99/88┤\n",
      " │                                  │                      ├@[5] 13-49 46 A->A 6\n",
      " │                                  │                      └@[0,1,2,3,9] 10-6 100,9-12 72,8-29 52,9-43 51,13-63 A->A0 4\n",
      " │                                  │                    ┌@[0,4,5,8,9] 0-m 100,6-m,5-m,8-45,8-37 A->A 34\n",
      " │                                  ├@8 9-5 43 B->A 87/86┤\n",
      " │                                  │                    ├@[1,2,3,7] 8-55 51,8-47,8-20,8-33 A->A0+ 10\n",
      " │                                  │                    └@[6] 7-21 unk 0\n",
      " │                                  │                     ┌@[4,6,7,9] 5-m,6-38,7-9,4-m A->A 25\n",
      " │                                  ├@9 8-30 41 B->A 92/65┤\n",
      " │                                  │                     ├@[0,1,2,3,5] 4-53 100,3-36 46,6-13 45,3-31 42,3-63 A->A0 24\n",
      " │                                  │                     └@[8] 5-50 A->A0+ 3\n",
      " │                                  │                      ┌@[0,1,2,4,6,7,9] 12-4 100,9-42 92,15-42 79,9-23 70,9-5 54,8-47 53,17-19 50 B->A 52\n",
      " │                                  ├@1 18-23 96 B->B 93/89┤\n",
      " │                                  │                      ├@[8] 0-m 50 B->B 11\n",
      " │                                  │                      └@[3,5] 16-20 76,10-40 60 unk 0\n",
      " │                                  ├@3 14-m 68\n",
      " │                                  ├@6 15-0 54 B->Q 68/49\n",
      " │                                  └@4 10-40 56 B->Q- 51/46\n",
      " ├@2806 26-57 -19 B->A0/81 attn:B->~<s>\n",
      " └@2854 23-54 -57 B->A0/80 attn:B->~<s>\n"
     ]
    }
   ],
   "source": [
    "print_tree(r.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c01978f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dt in r.data_tuples: dt[-1].attn_attr.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fe39a194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@5 22-40 69 B->A0 99/78 attn'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node = r.root.children[10]#.children[1]\n",
    "node.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911c2df7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_attn_attrs(r.data_tuples[:], model, tokenizer, node, topi=[3,4,6], attn_patterns=['B->B'], k_shot=k_shot, mix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7dc50c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 (0.5464575067162514, 0.8194444444444444)\n",
      "36 (0.45821835473179817, 0.8333333333333334)\n",
      "37 (0.3822524305433035, 0.8888888888888888)\n",
      "38 (0.3553805500268936, 0.8888888888888888)\n",
      "39 (0.3521486185491085, 0.9027777777777778)\n",
      "40 (0.3169629741460085, 0.875)\n",
      "41 (0.327828467823565, 0.8472222222222222)\n",
      "42 (0.33170338813215494, 0.875)\n",
      "43 (0.34491169452667236, 0.8888888888888888)\n"
     ]
    }
   ],
   "source": [
    "for l in range(35, L): print(l, show_predictions_by_data_tuples(model, tokenizer, r.data_tuples, k_shot, to_layer=l, verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b113734",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "064e94d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = 'MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.equal][cxt_len=3,rev_item2str]' # 18-5  11-4,13-11 B->A0+ 10-11?\n",
    "key = 'MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.equal][cxt_len=3]'\n",
    "# key = 'MlM_gen[cxt_sample_fn=enumerate_sample,query=1][types_of_characters.TreeSet.equal,types_of_characters.TreeSet.equal][cxt_len=3,abstract]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5c1c58a6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rotary_emb\n",
      "query_key_value\n",
      "dense\n",
      "attn_dropout\n",
      "resid_dropout\n",
      "q_proj\n",
      "k_proj\n",
      "v_proj\n",
      "out_proj_cuda7\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.transformer.h[30].attn.named_children(): print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c71b5fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del results[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "501165b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.equal][cxt_len=3] == rel0_kwargs=(skip_inv_f),rel1_kwargs=(skip_inv_f)\n",
      "Sharon has fox. Donna has piano. James has meat. James likes meat\n",
      "James has purple. Christopher has jeans. Jennifer has meat. Jennifer likes meat\n",
      "Nancy has gun. Edward has phone. Kevin has mouse. Nancy likes gun\n",
      "attribute_tree ... In attribute_tree: attribute_step  ... done 0:00:11.694551\n",
      "In attribute_tree: attribute_step stage2  ... done 0:00:05.529612\n",
      "get ap_scores ... done 0:00:02.500766\n",
      "get attr_ap_scores ... done 0:00:00.439238\n",
      "In _add_node: add @0 9-m 100\n",
      "In _add_node: add @2 28-m 73\n",
      "In _add_node: add @6 15-m 66\n",
      "In _add_node: add @7 39-m 66\n",
      "In _add_node: add @9 35-62 57 B->B 39/61\n",
      "In _add_node: add @1 30-34 84 B->A0 95/45 attn:B->~<s>\n",
      "In _add_node: add @3 29-39 70 B->A0 82/32 attn:B->~<s>\n",
      "In _add_node: add @4 25-43 70 B->A0 57/8 attn:B->~<s>\n",
      "In _add_node: add @5 22-40 69 B->A0 99/78 attn:B->~<s>\n",
      "In _add_node: add @8 33-63 59 B->A0 66/18 attn:B->~<s>\n",
      "In _add_node: add @2806 26-57 -19 B->A0/81 attn:B->~<s>\n",
      "In _add_node: add @2854 23-54 -57 B->A0/80 attn:B->~<s>\n",
      "In _add_node: add @135 19-1 12 B->A0/79 attn:B->~<s>\n",
      "In _add_node: add @95 17-28 16 B->A0/78 attn:B->~<s>\n",
      "In _add_node: add @[0,2,6,7,9] 9-m,28-m,15-m,39-m,35-62 B->B 44\n",
      "In _add_node: add @[1,3,4,5,8] 30-34,29-39,25-43,22-40,33-63 B->A0 42\n",
      "In attribute_tree: attribute_step @5 22-40 69 B->A0 99/78 attn:B->~<s> ... done 0:00:05.859749\n",
      "In attribute_tree: attribute_step stage2 @5 22-40 69 B->A0 99/78 attn:B->~<s> ... done 0:00:03.695288\n",
      "get ap_scores ... done 0:00:02.167912\n",
      "get attr_ap_scores ... done 0:00:00.477285\n",
      "In _add_node: add @0 18-23 100 B->B 94/89\n",
      "In _add_node: add @2 19-m 76\n",
      "In _add_node: add @3 14-m 76\n",
      "In _add_node: add @6 21-60 66 B->B 92/90\n",
      "In _add_node: add @7 17-m 56\n",
      "In _add_node: add @9 13-m 45\n",
      "In _add_node: add @1 12-4 77 B->A 100/99\n",
      "In _add_node: add @4 9-42 75 B->A 97/81\n",
      "In _add_node: add @5 9-5 70 B->A 90/86\n",
      "In _add_node: add @8 15-42 46 B->A 99/88\n",
      "In _add_node: add @[0,2,3,6,7,9] 18-23,19-m,14-m,21-60,17-m,13-m B->B 59\n",
      "In _add_node: add @[1,4,5,8] 12-4,9-42,9-5,15-42 B->A 39\n",
      "In attribute_tree: attribute_step @0 18-23 100 B->B 94/89 ... done 0:00:04.565010\n",
      "In attribute_tree: attribute_step stage2 @0 18-23 100 B->B 94/89 ... done 0:00:04.479785\n",
      "get ap_scores ... done 0:00:02.254064\n",
      "get attr_ap_scores ... done 0:00:00.526242\n",
      "In _add_node: add @[0,1,2,4,5,9] 12-4 100,9-42 79,15-42 77,9-23 52,9-5 50,8-47 44 B->A 45\n",
      "In _add_node: add @[7,8] 0-m 48,13-m 47 B->B 21\n",
      "In _add_node: add @[6] 10-40 48 B->Q- 5\n",
      "In _add_node: add @[3] 16-20 73 unk 0\n",
      "In attribute_tree: attribute_step @6 21-60 66 B->B 92/90 ... done 0:00:05.088222\n",
      "In attribute_tree: attribute_step stage2 @6 21-60 66 B->B 92/90 ... done 0:00:04.769171\n",
      "get ap_scores ... done 0:00:02.226642\n",
      "get attr_ap_scores ... done 0:00:00.417965\n",
      "In _add_node: add @[0,5,6,8,9] 12-4 100,9-42 69,15-42 65,9-5 60,8-47 55 B->A 45\n",
      "In _add_node: add @[1,4,7] 13-m 95,19-29 70,18-23 61 B->B 26\n",
      "In _add_node: add @[2,3] 16-20 81,11-49 72 B->A0 8\n",
      "In attribute_tree: attribute_step @1 12-4 77 B->A 100/99 ... done 0:00:02.308282\n",
      "In attribute_tree: attribute_step stage2 @1 12-4 77 B->A 100/99 ... done 0:00:04.122455\n",
      "get ap_scores ... done 0:00:02.420821\n",
      "get attr_ap_scores ... done 0:00:00.166504\n",
      "In _add_node: add @[2,4,9] 9-39 64,10-6 50,4-53 A->A0 14\n",
      "In _add_node: add @:2 8-21 100,9-5 73 A->A0+ 11\n",
      "In _add_node: add @[3,5,6,7,8] 10-54 61,10-9 48,5-7,10-36,8-47 A->A 6\n",
      "In attribute_tree: attribute_step @4 9-42 75 B->A 97/81 ... done 0:00:01.820947\n",
      "In attribute_tree: attribute_step stage2 @4 9-42 75 B->A 97/81 ... done 0:00:03.969633\n",
      "get ap_scores ... done 0:00:02.145350\n",
      "get attr_ap_scores ... done 0:00:00.164422\n",
      "In _add_node: add @[3,5,6,8,9] 5-7 54,6-m 47,5-m 41,4-m,6-38 A->A 34\n",
      "In _add_node: add @[0,2,7] 8-21 100,8-46 64,8-47 A->A0+ 11\n",
      "In _add_node: add @[1,4] 4-53 65,3-31 51 A->A0 11\n",
      "In attribute_tree: attribute_step @5 9-5 70 B->A 90/86 ... done 0:00:01.791639\n",
      "In attribute_tree: attribute_step stage2 @5 9-5 70 B->A 90/86 ... done 0:00:04.552337\n",
      "get ap_scores ... done 0:00:02.084190\n",
      "get attr_ap_scores ... done 0:00:00.160681\n",
      "In _add_node: add @[2,4,5,9] 0-m 81,1-m 72,8-37 68,6-m 56 A->A 31\n",
      "In _add_node: add @[0,1,3,6,8] 8-55 100,8-20 92,8-46 73,7-4 66,7-42 61 A->A0+ 15\n",
      "In _add_node: add @[7] 4-21 62 A->A0 8\n",
      "In attribute_tree: attribute_step @8 15-42 46 B->A 99/88 ... done 0:00:02.855331\n",
      "In attribute_tree: attribute_step stage2 @8 15-42 46 B->A 99/88 ... done 0:00:04.118327\n",
      "get ap_scores ... done 0:00:02.312475\n",
      "get attr_ap_scores ... done 0:00:00.161831\n",
      "In _add_node: add @[4,6,8,9] 8-21 41,9-1,9-5,8-46 A->A0+ 17\n",
      "In _add_node: add @[7] 13-49 A->A 6\n",
      "In _add_node: add @[0,1,2,3,5] 10-6 100,9-12 59,8-29 43,9-43 42,13-63 A->A0 4\n",
      "In attribute_tree: attribute_step @95 17-28 16 B->A0/78 attn:B->~<s> ... done 0:00:04.315276\n",
      "In attribute_tree: attribute_step stage2 @95 17-28 16 B->A0/78 attn:B->~<s> ... done 0:00:03.119071\n",
      "get ap_scores ... done 0:00:02.071790\n",
      "get attr_ap_scores ... done 0:00:00.442401\n",
      "In _add_node: add @0 9-5 100 B->A 88/86\n",
      "In _add_node: add @1 12-4 98 B->A 100/99\n",
      "In _add_node: add @3 9-42 78 B->A 97/81\n",
      "In _add_node: add @4 8-47 68 B->A 96/93\n",
      "In _add_node: add @7 15-42 58 B->A 99/88\n",
      "In _add_node: add @5 15-0 64 B->Q 64/49\n",
      "In _add_node: add @9 16-54 47 B->Q 88/84\n",
      "In _add_node: add @2 11-49 83 B->A0 65/47\n",
      "In _add_node: add @6 16-20 62 B->A0 16/10\n",
      "In _add_node: add @8 10-40 47 B->Q- 45/46\n",
      "In _add_node: add @[0,1,3,4,7] 9-5,12-4,9-42,8-47,15-42 B->A 48\n",
      "In _add_node: add @[5,9] 15-0,16-54 B->Q 20\n",
      "In _add_node: add @[2,6] 11-49,16-20 B->A0 9\n",
      "In _add_node: add @[8] 10-40 B->Q- 6\n",
      "In attribute_tree: attribute_step @0 9-5 100 B->A 88/86 ... done 0:00:01.797780\n",
      "In attribute_tree: attribute_step stage2 @0 9-5 100 B->A 88/86 ... done 0:00:04.150763\n",
      "get ap_scores ... done 0:00:02.021602\n",
      "get attr_ap_scores ... done 0:00:00.136741\n",
      "In _add_node: add @[0,1,3,4,5,8] 8-55 100,8-20 84,8-47 62,7-4 62,8-21 58,7-42 47 A->A0+ 16\n",
      "In _add_node: add @[2,6,9] 1-m 67,8-37 51,5-7 45 A->A 12\n",
      "In _add_node: add @[7] 7-21 51 A->A0 3\n",
      "In attribute_tree: attribute_step @1 12-4 98 B->A 100/99 ... done 0:00:02.301455\n",
      "In attribute_tree: attribute_step stage2 @1 12-4 98 B->A 100/99 ... done 0:00:03.830358\n",
      "get ap_scores ... done 0:00:02.033962\n",
      "get attr_ap_scores ... done 0:00:00.136092\n",
      "In _add_node: add @[1,2,6,8] 8-21 72,9-5 62,8-55,8-46 A->A0+ 23\n",
      "In _add_node: add @[0,3,5,9] 9-39 100,10-6 57,4-53,3-63 A->A0 21\n",
      "In _add_node: add @[4,7] 10-54,6-38 A->A 9\n",
      "In attribute_tree: attribute_step @3 9-42 78 B->A 97/81 ... done 0:00:01.776847\n",
      "In attribute_tree: attribute_step stage2 @3 9-42 78 B->A 97/81 ... done 0:00:04.158895\n",
      "get ap_scores ... done 0:00:02.098975\n",
      "get attr_ap_scores ... done 0:00:00.140438\n",
      "In _add_node: add @[2,4,9] 4-53 67,3-31,6-13 A->A0 16\n",
      "In _add_node: add @[0,1,3,5] 8-46 100,8-21 68,8-47 43,8-55 A->A0+ 16\n",
      "In _add_node: add @[6,7,8] 5-7,6-38,6-m A->A 15\n",
      "In attribute_tree: attribute_step @4 8-47 68 B->A 96/93 ... done 0:00:01.614373\n",
      "In attribute_tree: attribute_step stage2 @4 8-47 68 B->A 96/93 ... done 0:00:04.485276\n",
      "get ap_scores ... done 0:00:02.396588\n",
      "get attr_ap_scores ... done 0:00:00.143029\n",
      "In _add_node: add @[1,2,3,5,6,7,8] 4-53,6-13,3-36,3-31,3-63,5-20,4-21 A->A0 41\n",
      "In _add_node: add @[0,4,9] 0-m 100,6-38,3-49 A->A 17\n",
      "In attribute_tree: attribute_step @7 15-42 58 B->A 99/88 ... done 0:00:02.828140\n",
      "In attribute_tree: attribute_step stage2 @7 15-42 58 B->A 99/88 ... done 0:00:04.385443\n",
      "get ap_scores ... done 0:00:02.196372\n",
      "get attr_ap_scores ... done 0:00:00.164521\n",
      "In _add_node: add @[4,6,8] 8-21,9-1,9-5 A->A0+ 11\n",
      "In _add_node: add @[0,1,2,3,5,7] 10-6 100,9-12 54,8-29 45,9-43 41,13-63,9-39 A->A0 9\n",
      "In _add_node: add @[9] 13-49 A->A 7\n",
      "In attribute_tree: attribute_step @135 19-1 12 B->A0/79 attn:B->~<s> ... done 0:00:04.648179\n",
      "In attribute_tree: attribute_step stage2 @135 19-1 12 B->A0/79 attn:B->~<s> ... done 0:00:03.148721\n",
      "get ap_scores ... done 0:00:02.115464\n",
      "get attr_ap_scores ... done 0:00:00.403679\n",
      "In _add_node: add @0 9-42 100 B->A 97/81\n",
      "In _add_node: add @2 12-4 82 B->A 100/99\n",
      "In _add_node: add @5 9-23 55 B->A 0/0\n",
      "In _add_node: add @7 15-42 49 B->A 99/88\n",
      "In _add_node: add @8 9-5 43 B->A 87/86\n",
      "In _add_node: add @9 8-30 41 B->A 92/65\n",
      "In _add_node: add @1 18-23 96 B->B 93/89\n",
      "In _add_node: add @3 14-m 68\n",
      "In _add_node: add @6 15-0 54 B->Q 68/49\n",
      "In _add_node: add @4 10-40 56 B->Q- 51/46\n",
      "In _add_node: add @[0,2,5,7,8,9] 9-42,12-4,9-23,15-42,9-5,8-30 B->A 48\n",
      "In _add_node: add @[1,3] 18-23,14-m B->B 22\n",
      "In _add_node: add @[6] 15-0 B->Q 12\n",
      "In _add_node: add @[4] 10-40 B->Q- 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In attribute_tree: attribute_step @0 9-42 100 B->A 97/81 ... done 0:00:01.805843\n",
      "In attribute_tree: attribute_step stage2 @0 9-42 100 B->A 97/81 ... done 0:00:04.277287\n",
      "get ap_scores ... done 0:00:02.267850\n",
      "get attr_ap_scores ... done 0:00:00.176750\n",
      "In _add_node: add @[1,3,8,9] 4-53 67,3-31,3-36,6-13 A->A0 22\n",
      "In _add_node: add @[4,5,6,7] 5-m,5-7,6-38,8-47 A->A 15\n",
      "In _add_node: add @[0,2] 8-46 100,8-21 60 A->A0+ 11\n",
      "In attribute_tree: attribute_step @2 12-4 82 B->A 100/99 ... done 0:00:02.267427\n",
      "In attribute_tree: attribute_step stage2 @2 12-4 82 B->A 100/99 ... done 0:00:04.060522\n",
      "get ap_scores ... done 0:00:02.116073\n",
      "get attr_ap_scores ... done 0:00:00.151664\n",
      "In _add_node: add @[2,3,8,9] 4-53 93,9-39 92,10-6 46,3-63 41 A->A0 19\n",
      "In _add_node: add @[0,1,4] 8-46 100,8-21 98,9-5 75 A->A0+ 17\n",
      "In _add_node: add @[5,6,7] 10-54 68,6-38 66,8-47 62 A->A 9\n",
      "In attribute_tree: attribute_step @5 9-23 55 B->A 0/0 ... done 0:00:01.908831\n",
      "In attribute_tree: attribute_step stage2 @5 9-23 55 B->A 0/0 ... done 0:00:04.175985\n",
      "get ap_scores ... done 0:00:02.366087\n",
      "get attr_ap_scores ... done 0:00:00.158427\n",
      "In _add_node: add @:9 7-7 100,7-2 78,6-38 70,6-62 69,7-36 56,6-31 56,5-41 46,8-47 43,5-m 43 A->A 10\n",
      "In _add_node: add @[9] 6-18 unk 0\n",
      "In attribute_tree: attribute_step @7 15-42 49 B->A 99/88 ... done 0:00:02.870500\n",
      "In attribute_tree: attribute_step stage2 @7 15-42 49 B->A 99/88 ... done 0:00:04.358408\n",
      "get ap_scores ... done 0:00:02.230115\n",
      "get attr_ap_scores ... done 0:00:00.152105\n",
      "In _add_node: add @[4,6,7,8] 8-21 47,8-46 43,9-1,8-47 A->A0+ 12\n",
      "In _add_node: add @[5] 13-49 46 A->A 6\n",
      "In _add_node: add @[0,1,2,3,9] 10-6 100,9-12 72,8-29 52,9-43 51,13-63 A->A0 4\n",
      "In attribute_tree: attribute_step @8 9-5 43 B->A 87/86 ... done 0:00:01.806401\n",
      "In attribute_tree: attribute_step stage2 @8 9-5 43 B->A 87/86 ... done 0:00:04.247397\n",
      "get ap_scores ... done 0:00:02.335030\n",
      "get attr_ap_scores ... done 0:00:00.205267\n",
      "In _add_node: add @[0,4,5,8,9] 0-m 100,6-m,5-m,8-45,8-37 A->A 34\n",
      "In _add_node: add @[1,2,3,7] 8-55 51,8-47,8-20,8-33 A->A0+ 10\n",
      "In _add_node: add @[6] 7-21 unk 0\n",
      "In attribute_tree: attribute_step @9 8-30 41 B->A 92/65 ... done 0:00:01.664992\n",
      "In attribute_tree: attribute_step stage2 @9 8-30 41 B->A 92/65 ... done 0:00:04.219344\n",
      "get ap_scores ... done 0:00:02.442274\n",
      "get attr_ap_scores ... done 0:00:00.188603\n",
      "In _add_node: add @[4,6,7,9] 5-m,6-38,7-9,4-m A->A 25\n",
      "In _add_node: add @[0,1,2,3,5] 4-53 100,3-36 46,6-13 45,3-31 42,3-63 A->A0 24\n",
      "In _add_node: add @[8] 5-50 A->A0+ 3\n",
      "In attribute_tree: attribute_step @1 18-23 96 B->B 93/89 ... done 0:00:04.613101\n",
      "In attribute_tree: attribute_step stage2 @1 18-23 96 B->B 93/89 ... done 0:00:04.447632\n",
      "get ap_scores ... done 0:00:02.419456\n",
      "get attr_ap_scores ... done 0:00:00.468146\n",
      "In _add_node: add @[0,1,2,4,6,7,9] 12-4 100,9-42 92,15-42 79,9-23 70,9-5 54,8-47 53,17-19 50 B->A 52\n",
      "In _add_node: add @[8] 0-m 50 B->B 11\n",
      "In _add_node: add @[3,5] 16-20 76,10-40 60 unk 0\n",
      "done 0:03:39.767415\n"
     ]
    }
   ],
   "source": [
    "nrows, k_shot = 16, 7; cxt_len = 3; save_results = True\n",
    "batch_size = 8; verbose = False #not save_results or batch_size <= 8\n",
    "rel0_kwargs_list = [{'skip_inv_f': True},{'skip_inv_f': False}]#[:1]\n",
    "rel1_kwargs_list = [{'x_f': None, 'y_f': None, 'skip_inv_f': True}, {'x_f': _s, 'y_f': a_, 'skip_inv_f': True},\n",
    "                    {'x_f': _s, 'y_f': a_, 'skip_inv_f':False}]#[:1]\n",
    "for task,        rel0_kwargs,     rel1_kwargs, do_swap_qa, do_negate, do_rm_local_hop, do_rm_query, rev_item2str in product(\n",
    "#     tasks[1:2],rel0_kwargs_list,rel1_kwargs_list,[False,], [False,],  [True,],        [False,],    [False,]):\n",
    "    tasks[1:2],rel0_kwargs_list,rel1_kwargs_list,[False,True],[False,], [False,],     [False,],   [False,True]):\n",
    "    seed(42)\n",
    "    args = dict(cxt_len=cxt_len, rev_item2str=rev_item2str, abstract=False)\n",
    "    trans_args = dict(rel0_kwargs=rel0_kwargs, rel1_kwargs=rel1_kwargs, do_swap_qa=do_swap_qa, do_negate=do_negate,\n",
    "                      do_rm_local_hop=do_rm_local_hop, do_rm_query=do_rm_query)\n",
    "    task = transform_task(task, **trans_args)\n",
    "    if task is None: print('task is None! skip.'); continue\n",
    "    res_key = f'{task2str(task)}[{args2str(args)}]'# + composed_heads2str(model)\n",
    "    if key is not None and res_key != key: continue\n",
    "    if not validate_args(task, args, trans_args): print('invalid args! skip.'); continue\n",
    "#     if has_attribution_results(res_key): continue\n",
    "    print(f'\\n== {res_key} == {args2str(trans_args)}')\n",
    "    r = results[res_key] if save_results and res_key in results else None\n",
    "    r = generate_and_predict_batch(model, tokenizer, task, nrows, k_shot, batch_size,\n",
    "                                        trim=False, result=r, verbose=verbose, **args)\n",
    "    if save_results: results[res_key] = r\n",
    "    if not save_results or getattr(r, 'mean_acc', 0) < 0.45: continue\n",
    "        \n",
    "# #     load_attribution_results(r, res_key)\n",
    "    if True or r.root is None: r.root = add_node(None, layer=L, label_type='labels')\n",
    "    r.root = attribute_tree_on(r.data_tuples, model, r.root, 1, topk=10, k_shot=k_shot, device=device, verbose=True)\n",
    "#     with Timer('save_attribution_results'): save_attribution_results(r, res_key)\n",
    "#     r.data_tuples = [dt[:-1] + [trim_outputs(dt[-1])] for dt in r.data_tuples] # to save mem. data_tuple is list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e835a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(genders_of_persons.TreeSet.child(skip_inv_f), types_of_things.TreeSet.child(skip_inv_f)) (cxt_len=3)'\n",
    "result = results[key]; print_tree(result.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed64bbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.equal][cxt_len=3]: 0.296, 0.917\n",
      "MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.equal][cxt_len=3,rev_item2str]: 1.237, 0.569\n",
      "MlM_gen[types_of_things.TreeSet.equal,genders_of_persons.TreeSet.equal][cxt_len=3]: 1.466, 0.458\n",
      "MlM_gen[types_of_things.TreeSet.equal,genders_of_persons.TreeSet.equal][cxt_len=3,rev_item2str]: 0.671, 0.722\n",
      "MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.equal[x_f=_s,y_f=a_]][cxt_len=3]: 0.650, 0.833\n",
      "MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.equal[x_f=_s,y_f=a_]][cxt_len=3,rev_item2str]: 1.830, 0.486\n",
      "MlM_gen[types_of_things.TreeSet.equal[x_f=_s,y_f=a_],genders_of_persons.TreeSet.equal][cxt_len=3]: 1.263, 0.569\n",
      "MlM_gen[types_of_things.TreeSet.equal[x_f=_s,y_f=a_],genders_of_persons.TreeSet.equal][cxt_len=3,rev_item2str]: 0.731, 0.708\n",
      "MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.child[x_f=_s,y_f=a_]][cxt_len=3]: 2.357, 0.458\n",
      "MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.child[x_f=_s,y_f=a_]][cxt_len=3,rev_item2str]: 3.075, 0.333\n",
      "MlM_gen[types_of_things.TreeSet.child[x_f=_s,y_f=a_],genders_of_persons.TreeSet.equal][cxt_len=3]: 1.715, 0.333\n",
      "MlM_gen[types_of_things.TreeSet.child[x_f=_s,y_f=a_],genders_of_persons.TreeSet.equal][cxt_len=3,rev_item2str]: 1.379, 0.458\n",
      "MlM_gen[genders_of_persons.TreeSet.child,types_of_things.TreeSet.equal][cxt_len=3]: 1.541, 0.486\n",
      "MlM_gen[genders_of_persons.TreeSet.child,types_of_things.TreeSet.equal][cxt_len=3,rev_item2str]: 1.845, 0.333\n",
      "MlM_gen[types_of_things.TreeSet.equal,genders_of_persons.TreeSet.child][cxt_len=3]: 0.007, 1.000\n",
      "MlM_gen[types_of_things.TreeSet.equal,genders_of_persons.TreeSet.child][cxt_len=3,rev_item2str]: 0.007, 1.000\n",
      "MlM_gen[genders_of_persons.TreeSet.child,types_of_things.TreeSet.equal[x_f=_s,y_f=a_]][cxt_len=3]: 2.263, 0.472\n",
      "MlM_gen[genders_of_persons.TreeSet.child,types_of_things.TreeSet.equal[x_f=_s,y_f=a_]][cxt_len=3,rev_item2str]: 2.919, 0.347\n",
      "MlM_gen[types_of_things.TreeSet.equal[x_f=_s,y_f=a_],genders_of_persons.TreeSet.child][cxt_len=3]: 0.011, 1.000\n",
      "MlM_gen[types_of_things.TreeSet.equal[x_f=_s,y_f=a_],genders_of_persons.TreeSet.child][cxt_len=3,rev_item2str]: 0.009, 1.000\n",
      "MlM_gen[genders_of_persons.TreeSet.child,types_of_things.TreeSet.child[x_f=_s,y_f=a_]][cxt_len=3]: 3.361, 0.264\n",
      "MlM_gen[genders_of_persons.TreeSet.child,types_of_things.TreeSet.child[x_f=_s,y_f=a_]][cxt_len=3,rev_item2str]: 3.834, 0.153\n",
      "MlM_gen[types_of_things.TreeSet.child[x_f=_s,y_f=a_],genders_of_persons.TreeSet.child][cxt_len=3]: 0.011, 1.000\n",
      "MlM_gen[types_of_things.TreeSet.child[x_f=_s,y_f=a_],genders_of_persons.TreeSet.child][cxt_len=3,rev_item2str]: 0.008, 1.000\n"
     ]
    }
   ],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36787b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(types_of_things.TreeSet.child, genders_of_persons.TreeSet.child) (cxt_len=3)'\n",
    "result = results[key]; show_predictions_by_result(tokenizer, result, k_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557c1baf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nrows, k_shot = 16, 7; cxt_len=3; save_results = True\n",
    "batch_size = 8; verbose = not save_results or batch_size <= 8\n",
    "for task, replace_rel0, replace_rel1, do_swap_qa, do_negate, do_rm_local_hop, do_rm_query, rev_item2str in product(\n",
    "    tasks[2:3], [0,  ], [0,     ],   [False,],[False,],[False,],[False,],[False,]):\n",
    "    seed(42)\n",
    "    args = dict(cxt_len=cxt_len, rev_item2str=rev_item2str, abstract=False)\n",
    "    trans_args = dict(replace_rel0=replace_rel0, replace_rel1=replace_rel1, do_swap_qa=do_swap_qa, do_negate=do_negate,\n",
    "                      do_rm_local_hop=do_rm_local_hop, do_rm_query=do_rm_query)\n",
    "    task = transform_task(task, **trans_args)\n",
    "    if task is None: continue\n",
    "    res_key = f\"{task2str(task)} ({args2str(args)})\" + composed_heads2str(model)\n",
    "#     if not validate_args(task, args, trans_args): print('invalid args! skip.'); continue\n",
    "#     if save_results and key is not None and res_key != key: continue\n",
    "    if verbose: print(f'\\n== {res_key} == {args2str(trans_args)}')\n",
    "    if save_results and res_key in results:\n",
    "        assert results[res_key].trans_args == trans_args, f'{res_key} {args2str(results[res_key].trans_args)} != {args2str(trans_args)}'\n",
    "        result = results[res_key]; data_tuples = result.data_tuples\n",
    "    else:\n",
    "        all_examples, texts, all_bos_tokens = zip(*[generate(task, verbose=False, plot=False, nrows=nrows, **args)\n",
    "                                                for i in range(batch_size)])\n",
    "        result = Result(task, trans_args, args, all_examples, texts)\n",
    "        for text in texts: print('\\n'.join(text.split('\\n')[:3]))\n",
    "\n",
    "        data_tuples, eval_results = zip(*[predict(model, tokenizer, text, examples,\n",
    "            k_shot=k_shot, bos_token=bos_tokens, verbose=verbose)\n",
    "            for text, examples, bos_tokens in zip(texts, all_examples, all_bos_tokens)\n",
    "            if True or any(s in text[24:] for s in ['dangerous'])])\n",
    "        result.data_tuples = data_tuples\n",
    "        loss, acc, *_ = zip(*eval_results)\n",
    "        result.mean_loss, result.mean_acc = np.array(loss).mean(), np.array(join_lists(acc)).mean()\n",
    "        if verbose: print(result.mean_loss, result.mean_acc)\n",
    "        if save_results: results[res_key] = result\n",
    "    if not save_results: continue\n",
    "\n",
    "#     for node_name in ['node']:\n",
    "#         node = getattr(result, node_name, None)\n",
    "#         if node is None: node = result.node = result.root = add_node(node, label_type=node_name.replace('node', 'labels'))\n",
    "#         node.data.attr = mr(attribute_step)(data_tuples[:], model, node)\n",
    "#     node.data.scores = {ap: mr(get_head_matching_scores)(data_tuples, ap, k_shot=k_shot)\n",
    "#         for ap in attn_patterns_by_step.get(node.data.step, [])} if 'g2c' not in res_key else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1418741f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(genders_of_persons.TreeSet.child, types_of_things.TreeSet.equal) (cxt_len=3): 1.395, 0.5277777777777778\n",
      "MlM_gen(genders_of_persons.TreeSet.child, nouns.things.wrap_noun.TreeSet.child) (cxt_len=3): 2.519, 0.4027777777777778\n",
      "MlM_gen(genders_of_persons.TreeSet.child, things.TreeSet.equal) (cxt_len=3): 1.395, 0.5277777777777778\n",
      "MlM_gen(genders_of_persons.TreeSet.child, things.TreeSet.child) (cxt_len=3): 1.395, 0.5277777777777778\n"
     ]
    }
   ],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\") # codex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac9b2e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "_ = clone_model_to(model, device)\n",
    "data_tuples_gpu = data_tuples_to(data_tuples, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ba71533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ┌[0] @:6 24-10,21-13,22-5,19-15,21-14,19-m\n",
      "          ├[0] 11-12 B->Q] argmax_attn┐\n",
      "          │                           └[1] 8-1 B->A]\n",
      "          │                           ┌[1] 11-12 B->Q]\n",
      "          ├[0] 13-7 B->A0] argmax_attn┤\n",
      "          │                           └[1] 12-10 B->A]\n",
      " [-1] root┤\n",
      "          │                                  ┌[1] 11-12 B->Q]\n",
      "          ├[0] @7 16-7 32% B->A0] argmax_attn┤\n",
      "          │                                  ├[1] 12-10 B->A]\n",
      "          │                                  └[1] 13-13 B->A]\n",
      "          ├[0] @0 24-10 100% B->B argmax_attn\n",
      "          └[0] @1 21-13 68% B->A0] argmax_attn\n"
     ]
    }
   ],
   "source": [
    "print_tree(root)  # cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbb0675",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(genders_of_persons.TreeSet.child, types_of_things.TreeSet.equal) (cxt_len=3)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e7f37f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:3], model, tokenizer, node, topi=[0,1,2], k_shot=k_shot, mix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435f910b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for data_tuple in data_tuples[:3]:\n",
    "    plot_attn_attr(data_tuple, model, tokenizer, node, 13, 7, attn_patterns=['bos->ans0]'], k_shot=0, plot_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "835266e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = node.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5ce14dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(genders_of_persons.TreeSet.child, types_of_things.TreeSet.equal) (cxt_len=3)\n",
      "Maria has gray. Dorothy has a cat. Christopher has a revolver. The boy likes revolver\n",
      "                 ┌[0] 13-2 argmax_attn_labels┐\n",
      "                 │                           └[1] top[0, 1] 12-10,8-1┐\n",
      "                 │                                                   └[2] top[0] 1-7\n",
      " [-1] root labels┤\n",
      "                 │                           ┌[1] top[0, 1, 2, 3] 11-12,12-10,9-14,9-5\n",
      "                 ├[0] 13-7 argmax_attn_labels┤\n",
      "                 │                           ├[1] top[2] 9-14┐\n",
      "                 │                           │               └[2] top[0, 1] 8-7,6-2\n",
      "                 │                           └[1] top[1] 12-10┐\n",
      "                 │                                            └[2] top[0, 1] 8-7,0-mlp\n",
      "                 │                            ┌[1] top[0, 1, 2] 0-mlp,9-14,8-1\n",
      "                 └[0] 11-12 argmax_attn_labels┤\n",
      "                                              └[1] top[1, 2] 9-14,8-1┐\n",
      "                                                                     └*[2] top[0, 1, 2, 3, 4] 0-mlp,4-1,7-10,8-7,7-mlp...\n"
     ]
    }
   ],
   "source": [
    "print(key); print('\\n'.join(result.texts[-1].split('\\n')[:1]))\n",
    "node = result.node = add_node(node, topi=[0,1,2,3,4])#layer=11, head=12, attn_pattern='bos->query]', label_type='argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f4dd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(genders_of_persons.TreeSet.equal, types_of_things.TreeSet.child) (cxt_len=3)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aebe41",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for data_tuple in data_tuples[:3]:\n",
    "    plot_attn_attr(data_tuple, model, tokenizer, node, 13, 7, attn_patterns=['bos->ans0]'], k_shot=0, plot_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0701ae6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:3], model, tokenizer, node, topi=[0,1,2], k_shot=k_shot, mix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "409bc0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = result.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f9d23ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(genders_of_persons.TreeSet.equal, types_of_things.TreeSet.child) (cxt_len=3)\n",
      "Nancy has blueberries. Mary has a wolf. Jennifer has wine. Mary likes animal\n",
      "                 ┌[0] 11-12 argmax_attn_labels┐\n",
      "                 │                            └*[1] top[0, 1, 2] 0-mlp,9-5,10-8...\n",
      "                 │                                  ┌[1] top[0, 1, 2, 3, 4, 5, 6] 19-mlp,14-9,16-mlp,8-1,13-13,17-mlp,12-10\n",
      "                 ├[0] top[2] 21-5 argmax_attn_labels┤\n",
      "                 │                                  └[1] top[3, 4, 6] 8-1,13-13,12-10┐\n",
      "                 │                                                                   └[2] top[0, 1] 3-12,5-12\n",
      " [-1] root labels┤\n",
      "                 │                                  ┌[1] top[0, 1, 2, 3, 4, 5] 14-9,0-mlp,8-1,13-13,12-10,9-14\n",
      "                 ├[0] top[3] 15-8 argmax_attn_labels┤\n",
      "                 │                                  ├[1] top[2, 3, 4, 5] 8-1,13-13,12-10,9-14┐\n",
      "                 │                                  │                                        └[2] top[0, 1, 2, 3, 4] 5-12,3-12,8-3,4-mlp,0-mlp\n",
      "                 │                                  └[1] top[0] 14-9┐\n",
      "                 │                                                  └[2] top[0, 1, 2, 3] 13-mlp,11-4,13-13,9-14\n",
      "                 │                                  ┌[1] top[0, 1, 2, 3, 4, 5] 19-mlp,16-mlp,14-9,18-9,17-mlp,8-1\n",
      "                 └[0] top[6] 20-5 argmax_attn_labels┤\n",
      "                                                    └[1] top[5, 7] 8-1,12-10┐\n",
      "                                                                            └[2] top[0, 1, 2] 3-12,7-2,5-12\n"
     ]
    }
   ],
   "source": [
    "print(key); print('\\n'.join(result.texts[-1].split('\\n')[:1]))\n",
    "node = result.node = add_node(node, topi=[0,1,2])#, attn_pattern='bos->query]', label_type='argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "d9e179ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(genders_of_persons.TreeSet.equal, types_of_things.TreeSet.child) (cxt_len=3)\n",
      "                 ┌[0] 11-12 argmax_attn_labels\n",
      " [-1] root labels┤\n",
      "                 ├[0] 16-7 argmax_attn_labels┐\n",
      "                 │                           └[1] top[0, 1] 13-13,12-10┐\n",
      "                 │                                                     └*[2] top[0, 1, 2, 3, 4, 5] 0-mlp,10-4,12-mlp,6-2,7-9,10-mlp...\n",
      "                 └[0] top[5] 13-7 argmax_attn_labels┐\n",
      "                                                    └[1] top[1, 3] 12-10,8-1┐\n",
      "                                                                            └[2] top[0] 3-12\n"
     ]
    }
   ],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0,1,2,3,4,5])#attn_pattern='bos->ans0]', label_type='argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badcf5b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "key = 'MlM_gen(genders_of_persons.TreeSet.equal, types_of_things.TreeSet.equal) (cxt_len=3)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363fbf25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for data_tuple in data_tuples[:]:\n",
    "    plot_attn_attr(data_tuple, model, tokenizer, node, 11, 12, attn_patterns=['bos->query]'], k_shot=0, plot_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91db824e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:3], model, tokenizer, node, topi=[0,1], k_shot=k_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2f897ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = result.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "07867280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(genders_of_persons.TreeSet.equal, types_of_things.TreeSet.equal) (cxt_len=3)\n",
      "Kimberly has a rabbit. Charles has white. Jason has a taxi. Kimberly likes rabbit\n",
      "                 ┌[0] 11-12 argmax_attn_labels attr_k┐\n",
      "                 │                                   └[1] top[0] 0-mlp\n",
      "                 ├[0] 9-5 argmax_attn_labels┐\n",
      "                 │                          └[1] top[0] 0-mlp\n",
      "                 ├[0] 13-7 argmax_attn_labels┐\n",
      "                 │                           └*[1] top[0, 1, 2, 3, 4, 5] 11-12,9-5,12-14,9-14,11-4,12-10...\n",
      " [-1] root labels┤\n",
      "                 │                            ┌[1] top[0, 1, 2, 3] 8-1,0-mlp,9-14,9-5\n",
      "                 ├[0] 11-12 argmax_attn_labels┤\n",
      "                 │                            │              ┌[2] top[0, 1, 2, 3] 6-mlp,4-6,4-12,7-mlp\n",
      "                 │                            └[1] top[0] 8-1┤\n",
      "                 │                                           └[2] top[1] 4-6┐\n",
      "                 │                                                          └[3] top[0] 0-mlp\n",
      "                 │                                  ┌[1] top[0, 1, 2, 3, 4, 5] 11-12,14-9,13-13,9-14,15-5,12-10\n",
      "                 └[0] top[1] 16-7 argmax_attn_labels┤\n",
      "                                                    └[1] top[2, 3, 5] 13-13,9-14,12-10\n"
     ]
    }
   ],
   "source": [
    "print(key); print('\\n'.join(result.texts[-1].split('\\n')[:1]))\n",
    "node = result.node = add_node(node, topi=[0,1,2,3,4,5])#, label_type='argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "20113f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(genders_of_persons.TreeSet.equal, types_of_things.TreeSet.equal) (cxt_len=3)\n",
      "                 ┌[0] top[3] 16-7 argmax_attn_labels┐\n",
      "                 │                                  └[1] top[0, 3, 4] 13-13,9-14,12-10┐\n",
      "                 │                                                                    └[2] top[0, 1, 2] 8-7,6-2,1-7\n",
      "                 ├[0] top[2] 16-0 argmax_attn_labels┐\n",
      "                 │                                  └[1] top[0, 1, 2] 13-13,12-10,8-1┐\n",
      "                 │                                                                   └[2] top[0, 1, 2, 3] 1-7,0-mlp,8-7,6-2\n",
      " [-1] root labels┤\n",
      "                 ├[0] 11-12 argmax_attn_labels┐\n",
      "                 │                            └[1] top[0, 2] 8-1,9-14┐\n",
      "                 │                                                   └*[2] top[0] 4-6...\n",
      "                 └[0] top[9] 13-7 argmax_attn_labels┐\n",
      "                                                    └[1] top[1, 2] 12-10,9-14┐\n",
      "                                                                             └[2] top[0] 8-7\n"
     ]
    }
   ],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0])#, attn_pattern='bos->query]', label_type='argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "568fca95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((8, 7), (13, 13), (16, 7)) (0.9622409343719482, 0.9821789860725403)\n",
      "((8, 7), (9, 14), (16, 7)) (0.9469795227050781, 0.9725989699363708)\n",
      "((8, 7), (12, 10), (16, 7)) (0.9750146865844727, 0.9863405823707581)\n",
      "((6, 2), (13, 13), (16, 7)) (0.9623928070068359, 0.9801956415176392)\n",
      "((6, 2), (9, 14), (16, 7)) (0.9362690448760986, 0.9594190120697021)\n",
      "((6, 2), (12, 10), (16, 7)) (0.954227864742279, 0.9754131436347961)\n"
     ]
    }
   ],
   "source": [
    "for head_chain in product([(8, 7), (6, 2)], [(13, 13), (9, 14), (12, 10)], [(16, 7)]):\n",
    "    print(head_chain, plot_eigv(weightprod(model, list(head_chain), 'e vo vo qk e', weBTA=model.weBTAs[0]), plot=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e0b598",
   "metadata": {},
   "source": [
    "### person_adjs.opposite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "id": "89b7d463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.equal) (cxt_len=3, abstract=0): 0.892, 0.7142857142857143\n",
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=3, abstract=0): 3.309, 0.2857142857142857\n",
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=3, abstract=0)_4-6qk->4-8: 3.436, 0.21428571428571427\n",
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=3, abstract=0)_4-6qk->4-8_6-2qk->7-9: 3.461, 0.23809523809523808\n"
     ]
    }
   ],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cbe1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=3, abstract=0)_4-6/6-10->4-8_1-7/6-2/8-7->7-9'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd48aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:3], model, tokenizer, node, topi=[0,1,2], k_shot=k_shot, mix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1155,
   "id": "1d8a9671",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = result.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "id": "c41bbb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=3, abstract=0)_4-6/6-10->4-8_1-7/6-2/8-7->7-9\n",
      "                 ┌*[0] top[1] 16-14 argmax_attn_labels...\n",
      " [-1] root labels┤\n",
      "                 │                           ┌[1] top[4, 7] 9-14,12-10┐\n",
      "                 │                           │                        └[2] top[0] 7-9\n",
      "                 └[0] 16-7 argmax_attn_labels┤\n",
      "                                             ├[1] top[7] 12-10┐\n",
      "                                             │                └[2] top[0, 1] 1-7,11-mlp\n",
      "                                             └[1] top[4] 9-14┐\n",
      "                                                             └[2] top[0, 1] 6-2,7-9\n"
     ]
    }
   ],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0,1])#, label_type='argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485bccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=3, abstract=0)_4-6qk->4-8_6-2qk->7-9'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "id": "6f5d093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = node.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e64a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0,1,2,3], head_attr_fn=get_head_mlp_attr, k_shot=k_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "id": "9a4ed844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=3, abstract=0)_4-6qk->4-8_6-2qk->7-9\n",
      "                 ┌[0] top[0] 16-14 argmax_attn_labels\n",
      " [-1] root labels┤\n",
      "                 └[0] 11-12 argmax_attn_labels┐\n",
      "                                              └[1] top[3] 8-1┐\n",
      "                                                             └*[2] top[0, 1, 2, 3] 6-2,4-6,6-mlp,7-9...\n"
     ]
    }
   ],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0,1,2,3]) #label_type='argmax_attn_labels', attn_pattern='bos->query]') # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa60022",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=3, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "id": "f8f031a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = node.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50dc477",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0], head_attr_fn=get_head_mlp_attr, k_shot=k_shot)  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "id": "7f131da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=3, abstract=0)\n",
      "                 ┌[0] top[0] 16-14 argmax_attn_labels┐\n",
      "                 │                                   └[1] top[0] 8-1┐\n",
      "                 │                                                  └[2] top[0] 7-9\n",
      " [-1] root labels┤\n",
      "                 │                            ┌[1] top[0, 1, 2, 3, 4] 9-5,0-mlp,10-8,8-1,9-14\n",
      "                 └[0] 11-12 argmax_attn_labels┤\n",
      "                                              └[1] top[3] 8-1┐\n",
      "                                                             └*[2] top[0, 1] 4-6,6-mlp...\n"
     ]
    }
   ],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0,1], head_attr_fn=get_head_mlp_attr)#label_type='argmax_attn_labels', attn_pattern='bos->query]') # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64dce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.equal) (cxt_len=3, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9ba16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0,1,4,5], k_shot=k_shot)  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "id": "807a0cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "forked_node_k.k_node = q_node; forked_node_k.model = model\n",
    "del forked_node_k.k_node; del forked_node_k.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "id": "dd81ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forked_node.k_node = k_node; forked_node.model = model\n",
    "del forked_node.k_node; del forked_node.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "id": "75612c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = node.parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "id": "30875b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.equal) (cxt_len=3, abstract=0)\n",
      " [-1] root labels┐\n",
      "                 │                           ┌[0] top[0] 11-12 attn_labels attr_k┐\n",
      "                 │                           │                                   └[1] top[0] 0-mlp\n",
      "                 │                           ├[1] top[0] 9-14┐\n",
      "                 │                           │               └[2] top[0, 1, 2] 1-7,8-7,6-10\n",
      "                 │                           ├[1] top[5] 12-10┐\n",
      "                 │                           │                └[2] top[0, 1] 1-7,10-7\n",
      "                 └[0] top[1] 16-7 attn_labels┤\n",
      "                                             │                            ┌[1] top[1] 9-14┐\n",
      "                                             │                            │               └[2] top[0, 1, 2, 3] 7-6,4-6,8-7,6-2\n",
      "                                             ├[0] top[0] 11-12 attn_labels┤\n",
      "                                             │                            │              ┌[2] top[0, 1] 4-6,6-2\n",
      "                                             │                            └[1] top[0] 8-1┤\n",
      "                                             │                                           └[2] top[0] 4-6┐\n",
      "                                             │                                                          └[3] top[0] 0-mlp\n",
      "                                             └[1] top[0, 5] 9-14,12-10┐\n",
      "                                                                      └*[2] top[0, 1, 2, 3] 1-7,8-7,4-6,6-10...\n"
     ]
    }
   ],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0,1,2,3]) #label_type='attn_labels', attn_pattern='bos->query]', step=0, attribute_k=True) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a6332",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.equal) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cd8143",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0,1,2], head_attr_fn=get_head_mlp_attr, k_shot=k_shot)  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ed26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdf2869",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0], k_shot=k_shot)  # head_attr_fn=get_head_mlp_attr, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e03775",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0,2], head_attr_fn=get_head_mlp_attr, k_shot=k_shot, mix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86219f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0,1,2,3], head_attr_fn=get_head_mlp_attr, k_shot=k_shot, mix=True)  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65baa7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_tuple in data_tuples[:4]: plot_attn_attr(data_tuple, model, tokenizer, node, 7, 9, attn_patterns=['bos->ans0]'], k_shot=k_shot, plot_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "3713a89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = node.children[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "17929199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=2, abstract=0)\n",
      "                 ┌[0] top[1] 14-7 attn_labels┐\n",
      "                 │                           └*[1] top[0, 1, 2] 13-12,12-10,8-1...\n",
      "                 │                            ┌[1] top[0] 13-12\n",
      "                 ├[0] top[0] 16-14 attn_labels┤\n",
      "                 │                            └[1] top[2] 14-9\n",
      " [-1] root labels┤\n",
      "                 │                                    ┌[1] top[1, 2] 8-1,12-10┐\n",
      "                 │                                    │                       └[2] top[0, 1] 7-9,0-mlp\n",
      "                 └[0] top[0, 1] 16-14,14-7 attn_labels┤\n",
      "                                                      │                ┌[2] top[0] 12-16┐\n",
      "                                                      │                │                └[3] top[0, 1, 2, 3, 4, 5] 8-16,6-16,10-16,9-16,0-16,5-16\n",
      "                                                      └[1] top[0] 13-12┤\n",
      "                                                                       └[2] top[1] 8-1┐\n",
      "                                                                                      └[3] top[0] 7-9\n"
     ]
    }
   ],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0,1,2], head_attr_fn=get_head_mlp_attr)# label_type='attn_labels')  # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079866a0",
   "metadata": {},
   "source": [
    "### thing->type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "342b97df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.equal) (cxt_len=2, abstract=0): 0.376, 0.8333333333333334\n",
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=2, abstract=0): 3.889, 0.21428571428571427\n"
     ]
    }
   ],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691139e6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.equal) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155c3d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0,1], head_attr_fn=get_head_mlp_attr, k_shot=k_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "id": "77e1fc52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0] top[0] 11-12 attn_labels attr_k'"
      ]
     },
     "execution_count": 990,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "7f94d610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.equal) (cxt_len=2, abstract=0)\n",
      "                 ┌[0] top[0] 16-0 attn_labels┐\n",
      "                 │                           └[1] top[0, 1, 2, 3, 4] 13-2,12-10,11-12,13-13,8-1\n",
      "                 ├[0] top[2] 13-2 attn_labels:┐\n",
      "                 │                            └[1] top[0, 1] 8-1,12-10\n",
      " [-1] root labels┤\n",
      "                 │                                  ┌[1] top[0] 9-14\n",
      "                 ├[0] top[1] 16-7 argmax_attn_labels┤\n",
      "                 │                                  └*[1] top[0, 2, 4] 9-14,12-10,13-13...\n",
      "                 └[0] top[1] 16-7 attn_labels┐\n",
      "                                             └[1] top[2] 12-10\n"
     ]
    }
   ],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0,2,4], head_attr_fn=get_head_mlp_attr)#, label_type='argmax_attn_labels')  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03ffba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.parent) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95222719",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_tuple in data_tuples[:4]: plot_attn_attr(data_tuple, model, tokenizer, node, 16, 7, attn_patterns=['bos->ans0]'], k_shot=k_shot, plot_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014caa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0,1,2,3], head_attr_fn=get_head_mlp_attr, k_shot=k_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "9ae8689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = node.parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "f9476640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.parent) (cxt_len=2, abstract=0)\n",
      " [-1] root labels┐\n",
      "                 └[0] 16-7 argmax_attn_labels┐\n",
      "                                             └*[1] top[0] 12-10...\n"
     ]
    }
   ],
   "source": [
    "print(key); node = result.node = add_node(node, layer=16, head=7, topi=[0], head_attr_fn=get_head_mlp_attr)#, label_type=f'argmax_attn_labels')  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "22f07fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.parent) (cxt_len=2, abstract=0)\n",
      "                 ┌[0] 16-7 attn_labels:\n",
      " [-1] root labels┤\n",
      "                 └[0] 16-7 argmax_attn_labels┐\n",
      "                                             └[1] top[0] 12-10┐\n",
      "                                                              └*[2] top[0] 0-16...\n"
     ]
    }
   ],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0], head_attr_fn=get_head_mlp_attr)#, label_type=f'argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb4e419",
   "metadata": {},
   "source": [
    "### fr->en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7f0101f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, en2fr.TreeSet.parent) (cxt_len=1, abstract=0): 0.091, 0.84375\n",
      "MlM_gen(persons.EqSet.equal, en2fr.TreeSet.parent) (cxt_len=1, abstract=1): 0.109, 0.875\n",
      "MlM_gen(persons.EqSet.equal, en2fr.TreeSet.parent) (cxt_len=2, abstract=0): 2.069, 0.53125\n",
      "MlM_gen(persons.EqSet.equal, en2fr.TreeSet.parent) (cxt_len=2, abstract=1): 1.034, 0.59375\n"
     ]
    }
   ],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d156659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, en2fr.TreeSet.parent) (cxt_len=1, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result, topk=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e8c870a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, en2fr.TreeSet.parent) (cxt_len=1, abstract=0)\n",
      " [-1] root labels┐\n",
      "                 └[0] top[0, 1] 16-15,21-14 attn_labels┐\n",
      "                                                       └[1] top[0, 1, 2] 12-10,8-1,9-14┐\n",
      "                                                                                       └*[2] top[0, 1, 2, 3, 4, 5] 6-10,5-12,8-7,8-3,7-2,8-9...\n"
     ]
    }
   ],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0,1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c07ef9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(5, 12, -1.016), (8, 7, -0.743), (7, 2, -1.071)], [(12, 10, -2.065), (8, 1, -2.009), (9, 14, -2.1)], [(16, 15, -0.416), (21, 14, -0.719)]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyze_head_chains(model, get_head2scores(node));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b752617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, en2fr.TreeSet.parent) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result, topk=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e9bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples, model, tokenizer, node, topi=[0,1,2], k_shot=k_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "697be2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, en2fr.TreeSet.parent) (cxt_len=2, abstract=0)\n",
      "parent has not been attributed yet, replace it instead of adding to it.\n",
      "                 ┌[0] top[1, 2] 16-15,21-14 argmax_attn_labels┐\n",
      "                 │                                            └[1] top[0, 1] 8-1,12-10┐\n",
      "                 │                                                                    └*[2] top[0, 1, 2] 6-10,5-12,8-7...\n",
      " [-1] root labels┤\n",
      "                 └[0] top[0] 20-5 argmax_attn_labels┐\n",
      "                                                    └[1] top[0, 1] 12-10,8-1┐\n",
      "                                                                            └[2] top[0, 1, 2] 6-10,5-12,8-7\n"
     ]
    }
   ],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,1,2], label_type='argmax_attn_labels')  # head_attr_fn=get_head_mlp_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "b0b8bb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(5, 12, -1.402), (8, 7, -0.846)], [(12, 10, -2.067), (8, 1, -1.974)], [(20, 5, -1.164)]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAocAAAGdCAYAAABgsdmCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAzRklEQVR4nO3de1xVVf7/8fcB5EAhoCkXDfFWmmlSOCKloyYjlll+v31nDC3RIZ0aK4tpRqmUGqdQs6JvWpZjl/mW46XJHqZGP0OdpmSyECskbTRLU0GNPMdgBIX1+6Nc40nucgD19Xw89uMxrrPW2p+zxDnv1j574zDGGAEAAACSfJq7AAAAALQchEMAAABYhEMAAABYhEMAAABYhEMAAABYhEMAAABYhEMAAABYhEMAAABYfs1dQGOrrKzU/v371bp1azkcjuYuBwAA1IExRkePHlWHDh3k48PeVXM658Lh/v37FRUV1dxlAACABti7d68uvvji5i7jvHbOhcPWrVtL+uGHKzg4uJmrAQAAdeF2uxUVFWU/x9F8vBoO33vvPT3++OPKzc3VgQMHtHLlSo0ePbrGMRs3blRqaqq2bdumqKgoPfTQQ5owYUKdz3nyUnJwcDDhEACAswxfCWt+Xr2oX1JSor59+2rBggV16r97926NHDlSQ4cO1datW3Xvvffq9ttv1zvvvOPNMgEAAPAjr+4cXnfddbruuuvq3H/hwoXq0qWLnnjiCUnSZZddpvfff19PPfWUEhMTvVUmAAAAftSibgfKyclRQkKCR1tiYqJycnKqHVNWVia32+1xAAAAoGFaVDgsLCxUeHi4R1t4eLjcbrf+/e9/VzkmIyNDISEh9uBOZQAAgIZrUeGwIdLS0uRyueyxd+9er5+zoqJCM2bMUJcuXRQYGKhu3bpp1qxZMsZUO+arr76Sw+Go8lixYkW149544w0NHz5cF110kRwOh7Zu3erxenFxse6++2716NFDgYGB6tSpk+655x65XK4a38OxY8c0YcIE9enTR35+ftXeKLRx40ZdddVVcjqd6t69u15++eUa5924caNuuukmRUZG6sILL1RMTIxee+210/qtWLFCPXv2VEBAgPr06aO1a9fWOK8kDRky5LS1u+OOO2odBwAA6q5FhcOIiAgVFRV5tBUVFSk4OFiBgYFVjnE6nfbO5Ka6Q3nOnDl67rnnNH/+fH3++eeaM2eO5s6dq2eeeabaMVFRUTpw4IDH8cgjjygoKKjG72WWlJRo4MCBmjNnTpWv79+/X/v379e8efOUn5+vl19+WVlZWUpJSanxPVRUVCgwMFD33HPPaZfyT2rIDUKbNm3SFVdcob/97W/69NNPNXHiRI0fP16rV6/26JOUlKSUlBTl5eVp9OjRGj16tPLz82usWZImTZrksYZz586tdQwAAKg7h6lpu6sxT+Rw1Poom2nTpmnt2rX67LPPbNvYsWNVXFysrKysOp3H7XYrJCRELpfLa0HxhhtuUHh4uBYvXmzbbr75ZgUGBurVV1+t8zxXXnmlrrrqKo95qvPVV1+pS5cuysvLU0xMTI19V6xYoVtvvVUlJSXy86v9nqMJEyboyJEjevPNNz3ap02bpjVr1niEtltuuUVHjhyp89+HJI0cOVLh4eF68cUXJUljxoxRSUmJR2AcMGCAYmJitHDhwmrnGTJkiGJiYpSZmVnncwMAzg5N8fmNuvHqzuH333+vrVu32kuhu3fv1tatW7Vnzx5JP1wSHj9+vO1/xx136Msvv9Qf/vAHbd++Xc8++6yWL1+u++67z5tl1tvVV1+t7OxsffHFF5KkTz75RO+//3697szOzc3V1q1ba93ha4iT/7DqEgxr0pAbhKqrp23bto0y72uvvaZ27dqpd+/eSktLU2lpab1qAQAANfPqo2w+/vhjDR061P45NTVVkpScnKyXX35ZBw4csEFRkrp06aI1a9bovvvu09NPP62LL75Yf/7zn1vEY2wqKo027y7WwaPHNPiXk3TE5VLPnj3l6+uriooKPfrooxo3blyd51u8eLEuu+wyXX311Y1a5+HDhzVr1ixNnjz5jOeq7Qah6i71n2r58uX66KOP9Pzzz9c6b2FhYY1zjR07VtHR0erQoYM+/fRTTZs2TTt27NAbb7xRj3cFAABq4tVwOGTIkBpv0qjq5oYhQ4YoLy/Pi1XVX1b+AT3yVoEOuI5JkkoK/i73ey/rD3MWaNyIgfb7eB06dFBycrIee+wxPfbYY3Z8QUGBOnXqZP/873//W0uWLNGMGTMatU63262RI0eqV69eevjhh2375Zdfrq+//lqSNGjQIL399tuNet7qbNiwQRMnTtSiRYt0+eWX13lcdet3auDt06ePIiMjNWzYMO3atUvdunVr1NoBADhfnXO/W7mxZeUf0J2vbtGpEfe7jS8pZMD/aNm3nTTE0U633Xabvv76a2VkZCg5OVl33HGHfvWrX9n+HTp08Jjz9ddfV2lpqccl9TN19OhRjRgxQq1bt9bKlSvVqlUr+9ratWt1/PhxSarTbt9JDblB6KS///3vGjVqlJ566qnT3md180ZEREhSret3UlxcnCRp586dhEMAABoJ4bAGFZVGj7xVoJ/ufZrjZZLjh69rPvJWgX7RK0K+vr6qrKyUJLVt29bjO3Y/tXjxYt14441q3759o9TpdruVmJgop9OpVatWKSAgwOP16OjoBs0bHx9/2iNm1q1bp/j4+BrHbdy4UTfccIPmzJlT5eXt+Ph4ZWdn6957761y3trW76ST32WNjIystS8AAKgbwmENNu8utpeSTxXYvb9cm5bJN7i99rbrpMef/z89+eST+vWvf13rnDt37tR7771Xp+f6ST88x3DPnj3av3+/JGnHjh2Sfth9i4iIkNvt1vDhw1VaWqpXX33V47fEtG/fXr6+vtXOXVBQoPLychUXF+vo0aM2bJ28G/qOO+7Q/Pnz9Yc//EG//vWvtX79ei1fvlxr1qypds4NGzbohhtu0NSpU3XzzTfb7xH6+/vbwDd16lQNHjxYTzzxhEaOHKmlS5fq448/1gsvvFDtvLt27dKSJUt0/fXX66KLLtKnn36q++67Tz//+c91xRVX1GktAQBAHZhzjMvlMpKMy+U647nezPvGRE9bfdoRde9y0zr2RuMb3N44/PxN+MXR5sEHHzRlZWW1zpmWlmaioqJMRUVFnWp46aWXjKTTjvT0dGOMMRs2bKjydUlm9+7dNc4dHR1d5bhTbdiwwcTExBh/f3/TtWtX89JLL9U4Z3JycpVzDh482KPf8uXLzaWXXmr8/f3N5ZdfbtasWVPjvHv27DE///nPTdu2bY3T6TTdu3c3v//97xvl7xkA0Pwa8/MbZ6bJnnPYVBrzOUk5u75V0qJ/1trvr5MGKL7bRWd0LgAAzmc857DlaFG/IaWl6d+lrSJDAuSo5nWHpMiQAPXvUvv34wAAAM4GhMMa+Po4lD6qlySdFhBP/jl9VC/5+lQXHwEAAM4uhMNajOgdqeduvUoRIZ53AEeEBOi5W6/SiN7cKQsAAM4d3K1cByN6R+oXvSLsb0gJa/3DpWR2DAEAwLmGcFhHvj4ObjoBAADnPC4rAwAAwCIcAgAAwCIcAgAAwCIcAgAAwCIcAgAAwCIcAgAAwCIcAgAAwCIcAgAAwCIcAgAAwCIcAgAAwCIcAgAAwCIcAgAAwCIcAgAAwCIcAgAAwCIcAgAAwCIcAgAAwCIcAgAAwCIcAgAAwCIcAgAAwCIcAgAAwCIcAgAAwCIcAgAAwCIcAgAAwCIcAgAAwCIcAgAAwCIcAgAAwCIcAgAAwPJ6OFywYIE6d+6sgIAAxcXFafPmzTX2z8zMVI8ePRQYGKioqCjdd999OnbsmLfLBAAAgLwcDpctW6bU1FSlp6dry5Yt6tu3rxITE3Xw4MEq+y9ZskTTp09Xenq6Pv/8cy1evFjLli3TAw884M0yAQAA8COvhsMnn3xSkyZN0sSJE9WrVy8tXLhQF1xwgV588cUq+2/atEnXXHONxo4dq86dO2v48OFKSkqqdbcRAAAAjcNr4bC8vFy5ublKSEj4z8l8fJSQkKCcnJwqx1x99dXKzc21YfDLL7/U2rVrdf3111d7nrKyMrndbo8DAAAADePnrYkPHz6siooKhYeHe7SHh4dr+/btVY4ZO3asDh8+rIEDB8oYoxMnTuiOO+6o8bJyRkaGHnnkkUatHQAA4HzVou5W3rhxox577DE9++yz2rJli9544w2tWbNGs2bNqnZMWlqaXC6XPfbu3duEFQMAAJxbvLZz2K5dO/n6+qqoqMijvaioSBEREVWOmTFjhm677TbdfvvtkqQ+ffqopKREkydP1oMPPigfn9OzrNPplNPpbPw3AAAAcB7y2s6hv7+/YmNjlZ2dbdsqKyuVnZ2t+Pj4KseUlpaeFgB9fX0lScYYb5UKAACAH3lt51CSUlNTlZycrH79+ql///7KzMxUSUmJJk6cKEkaP368OnbsqIyMDEnSqFGj9OSTT+rKK69UXFycdu7cqRkzZmjUqFE2JAIAAMB7vBoOx4wZo0OHDmnmzJkqLCxUTEyMsrKy7E0qe/bs8dgpfOihh+RwOPTQQw9p3759at++vUaNGqVHH33Um2UCAADgRw5zjl2vdbvdCgkJkcvlUnBwcHOXAwAA6oDP75ajRd2tDAAAgOZFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIDl9XC4YMECde7cWQEBAYqLi9PmzZtr7H/kyBFNmTJFkZGRcjqduvTSS7V27VpvlwkAAABJft6cfNmyZUpNTdXChQsVFxenzMxMJSYmaseOHQoLCzutf3l5uX7xi18oLCxMr7/+ujp27Kivv/5aoaGh3iwTAAAAP3IYY4y3Jo+Li9PPfvYzzZ8/X5JUWVmpqKgo3X333Zo+ffpp/RcuXKjHH39c27dvV6tWrRp0TrfbrZCQELlcLgUHB59R/QAAoGnw+d1yeO2ycnl5uXJzc5WQkPCfk/n4KCEhQTk5OVWOWbVqleLj4zVlyhSFh4erd+/eeuyxx1RRUVHtecrKyuR2uz0OAAAANIzXwuHhw4dVUVGh8PBwj/bw8HAVFhZWOebLL7/U66+/roqKCq1du1YzZszQE088oT/96U/VnicjI0MhISH2iIqKatT3AQAAcD5pUXcrV1ZWKiwsTC+88IJiY2M1ZswYPfjgg1q4cGG1Y9LS0uRyueyxd+/eJqwYAADg3OK1G1LatWsnX19fFRUVebQXFRUpIiKiyjGRkZFq1aqVfH19bdtll12mwsJClZeXy9/f/7QxTqdTTqezcYsHAAA4T3lt59Df31+xsbHKzs62bZWVlcrOzlZ8fHyVY6655hrt3LlTlZWVtu2LL75QZGRklcEQAAAAjcurl5VTU1O1aNEivfLKK/r888915513qqSkRBMnTpQkjR8/Xmlpabb/nXfeqeLiYk2dOlVffPGF1qxZo8cee0xTpkzxZpkAAAD4kVefczhmzBgdOnRIM2fOVGFhoWJiYpSVlWVvUtmzZ498fP6TT6OiovTOO+/ovvvu0xVXXKGOHTtq6tSpmjZtmjfLBAAAwI+8+pzD5sBzkgAAOPvw+d1ytKi7lQEAANC8CIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwCIcAAACwmiQcLliwQJ07d1ZAQIDi4uK0efPmOo1bunSpHA6HRo8e7d0CAQAAIKkJwuGyZcuUmpqq9PR0bdmyRX379lViYqIOHjxY47ivvvpK999/vwYNGuTtEgEAAPAjr4fDJ598UpMmTdLEiRPVq1cvLVy4UBdccIFefPHFasdUVFRo3LhxeuSRR9S1a1dvlwgAAIAfeTUclpeXKzc3VwkJCf85oY+PEhISlJOTU+24P/7xjwoLC1NKSkqt5ygrK5Pb7fY4AAAA0DBeDYeHDx9WRUWFwsPDPdrDw8NVWFhY5Zj3339fixcv1qJFi+p0joyMDIWEhNgjKirqjOsGAAA4X7Wou5WPHj2q2267TYsWLVK7du3qNCYtLU0ul8see/fu9XKVAAAA5y4/b07erl07+fr6qqioyKO9qKhIERERp/XftWuXvvrqK40aNcq2VVZW/lCon5927Nihbt26eYxxOp1yOp1eqB4AAOD849WdQ39/f8XGxio7O9u2VVZWKjs7W/Hx8af179mzpz777DNt3brVHjfeeKOGDh2qrVu3cskYAADAy7y6cyhJqampSk5OVr9+/dS/f39lZmaqpKREEydOlCSNHz9eHTt2VEZGhgICAtS7d2+P8aGhoZJ0WjsAAAAan9fD4ZgxY3To0CHNnDlThYWFiomJUVZWlr1JZc+ePfLxaVFffQQAADhvOYwxprmLaExut1shISFyuVwKDg5u7nIAAEAd8PndcrBlBwAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAItwCAAAAKtJwuGCBQvUuXNnBQQEKC4uTps3b66276JFizRo0CC1adNGbdq0UUJCQo39AQAA0Hi8Hg6XLVum1NRUpaena8uWLerbt68SExN18ODBKvtv3LhRSUlJ2rBhg3JychQVFaXhw4dr37593i4VAADgvOcwxhhvniAuLk4/+9nPNH/+fElSZWWloqKidPfdd2v69Om1jq+oqFCbNm00f/58jR8/vtb+brdbISEhcrlcCg4OPuP6AQCA9/H53XJ4deewvLxcubm5SkhI+M8JfXyUkJCgnJycOs1RWlqq48ePq23btlW+XlZWJrfb7XEAAACgYbwaDg8fPqyKigqFh4d7tIeHh6uwsLBOc0ybNk0dOnTwCJinysjIUEhIiD2ioqLOuG4AAIDzVYu+W3n27NlaunSpVq5cqYCAgCr7pKWlyeVy2WPv3r1NXCUAAMC5w8+bk7dr106+vr4qKiryaC8qKlJERESNY+fNm6fZs2fr3Xff1RVXXFFtP6fTKafT2Sj1AgAAnO+8unPo7++v2NhYZWdn27bKykplZ2crPj6+2nFz587VrFmzlJWVpX79+nmzRAAAAJzCqzuHkpSamqrk5GT169dP/fv3V2ZmpkpKSjRx4kRJ0vjx49WxY0dlZGRIkubMmaOZM2dqyZIl6ty5s/1uYlBQkIKCgrxdLgAAwHnN6+FwzJgxOnTokGbOnKnCwkLFxMQoKyvL3qSyZ88e+fj8ZwPzueeeU3l5uf7nf/7HY5709HQ9/PDD3i4XAADgvOb15xw2NZ6TBADA2YfP75ajRd+tDAAAgKZFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIBFOAQAAIDVJOFwwYIF6ty5swICAhQXF6fNmzfX2H/FihXq2bOnAgIC1KdPH61du7YpygQAADjveT0cLlu2TKmpqUpPT9eWLVvUt29fJSYm6uDBg1X237Rpk5KSkpSSkqK8vDyNHj1ao0ePVn5+vrdLBQAAOO85jDHGmyeIi4vTz372M82fP1+SVFlZqaioKN19992aPn36af3HjBmjkpISrV692rYNGDBAMTExWrhwYa3nc7vdCgkJkcvlUnBwcOO9EQAA4DV8frccXt05LC8vV25urhISEv5zQh8fJSQkKCcnp8oxOTk5Hv0lKTExsdr+ZWVlcrvdHgcAAAAaxqvh8PDhw6qoqFB4eLhHe3h4uAoLC6scU1hYWK/+GRkZCgkJsUdUVFTjFA8AAHAeOuvvVk5LS5PL5bLH3r17m7skAACAs5afNydv166dfH19VVRU5NFeVFSkiIiIKsdERETUq7/T6ZTT6WycggEAAM5zXt059Pf3V2xsrLKzs21bZWWlsrOzFR8fX+WY+Ph4j/6StG7dumr7AwAAoPF4dedQklJTU5WcnKx+/fqpf//+yszMVElJiSZOnChJGj9+vDp27KiMjAxJ0tSpUzV48GA98cQTGjlypJYuXaqPP/5YL7zwgrdLBQAAOO95PRyOGTNGhw4d0syZM1VYWKiYmBhlZWXZm0727NkjH5//bGBeffXVWrJkiR566CE98MADuuSSS/Tmm2+qd+/e3i4VAADgvOf15xw2NZ6TBADA2YfP75bjrL9bGQAAAI2HcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAACLcAgAAADLa+GwuLhY48aNU3BwsEJDQ5WSkqLvv/++xv533323evToocDAQHXq1En33HOPXC6Xt0oEAADAT3gtHI4bN07btm3TunXrtHr1ar333nuaPHlytf3379+v/fv3a968ecrPz9fLL7+srKwspaSkeKtEAAAA/ITDGGMae9LPP/9cvXr10kcffaR+/fpJkrKysnT99dfrm2++UYcOHeo0z4oVK3TrrbeqpKREfn5+dRrjdrsVEhIil8ul4ODgBr8HAADQdPj8bjm8snOYk5Oj0NBQGwwlKSEhQT4+Pvrwww/rPM/JH5CagmFZWZncbrfHAQAAgIbxSjgsLCxUWFiYR5ufn5/atm2rwsLCOs1x+PBhzZo1q8ZL0ZKUkZGhkJAQe0RFRTW4bgAAgPNdvcLh9OnT5XA4ajy2b99+xkW53W6NHDlSvXr10sMPP1xj37S0NLlcLnvs3bv3jM8PAABwvqrbF/l+9Lvf/U4TJkyosU/Xrl0VERGhgwcPerSfOHFCxcXFioiIqHH80aNHNWLECLVu3VorV65Uq1atauzvdDrldDrrVD8AAABqVq9w2L59e7Vv377WfvHx8Tpy5Ihyc3MVGxsrSVq/fr0qKysVFxdX7Ti3263ExEQ5nU6tWrVKAQEB9SkPAAAAZ8gr3zm87LLLNGLECE2aNEmbN2/WBx98oLvuuku33HKLvVN537596tmzpzZv3izph2A4fPhwlZSUaPHixXK73SosLFRhYaEqKiq8USYAAAB+ol47h/Xx2muv6a677tKwYcPk4+Ojm2++Wf/7v/9rXz9+/Lh27Nih0tJSSdKWLVvsnczdu3f3mGv37t3q3Lmzt0oFAADAj7zynMPmxHOSAAA4+/D53XLwu5UBAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgEQ4BAABgeS0cFhcXa9y4cQoODlZoaKhSUlL0/fff12msMUbXXXedHA6H3nzzTW+VCAAAGujhhx+Ww+HwOHr27FnruEcffVRXX321LrjgAoWGhp72+meffaakpCRFRUUpMDBQl112mZ5++ula5/3iiy900003qV27dgoODtbAgQO1YcOGGsccO3ZMEyZMUJ8+feTn56fRo0fXep6vvvpKKSkp6tKliwIDA9WtWzelp6ervLzco9+nn36qQYMGKSAgQFFRUZo7d26tczd0TRubn7cmHjdunA4cOKB169bp+PHjmjhxoiZPnqwlS5bUOjYzM1MOh8NbpQEAgEZw+eWX691337V/9vOrPVaUl5frl7/8peLj47V48eLTXt+6davCwsL06quvKioqSps2bdLkyZPl6+uru+66q9p5b7jhBl1yySVav369AgMDlZmZqRtuuEG7du1SRERElWMqKioUGBioe+65R3/729/q8I6l7du3q7KyUs8//7y6d++u/Px8TZo0SSUlJZo3b54kye12a/jw4UpISNDChQv12Wef6de//rVCQ0M1efLkGudvyJo2OuMFBQUFRpL56KOPbNvbb79tHA6H2bdvX41j8/LyTMeOHc2BAweMJLNy5cp6ndvlchlJxuVyNaR0AABQB4MHDzaSPI4ePXrUOu5Pf/qTiY+PN61atTKnxpCTn9/vv/++ueWWW8zFF19sAgICTM+ePc3AgQPN0KFDq53z0KFDRpK5/PLLTWBgoAkJCTFut9tIMuvWrTPGGLN169bT5s3MzLRzJCcnm5tuuum0ufPz881///d/m+joaCPJPPXUU6f1mTt3rrnoootMdHS0cTqdJjo62gQHB5uysjLbZ9q0aR7r88ILL5iBAwea0NBQExoaaoYNG2Zuv/1207dvX9unsrLSzJgxw0RERJiAgAAzbNgw88UXX9S6xj/9e5Fk/vrXv9Y67iSvXFbOyclRaGio+vXrZ9sSEhLk4+OjDz/8sNpxpaWlGjt2rBYsWFBtyv+psrIyud1ujwMAAHifw+FQeHi4OnXqpP/6r//S0qVLax1zcufw2muvrfL1U3cOt23bpgcffFA5OTn67rvvqp3zoosu0kUXXaSgoCDdfvvtMsbo+eefV1hYmGJjYyVJubm5p82blpam+fPn11hvaWmpunbtqtmzZ1ebTXJyclRcXKz09HRt2bJFrVq1UmlpqY4cOWL7JCYmaseOHfZ9bNy4UUlJSdqwYYNycnIUFRWl//u//9MXX3yhDh06qGvXrrrqqquUmZmphQsX6sMPP9SFF16oxMREHTt2rMaaJemll17SgQMH7FGXS+ZWnWNkPTz66KPm0ksvPa29ffv25tlnn6123OTJk01KSor9s+qwc5ienl5lQmbnEACAxnWiotJs2nnYvJn3jfnFqJtNdHS0+eSTT0xWVpaJj483nTp1Mm63u05zpaSkVLlz+NPP7w8++MD4+Ph47KhVZe/evSY2NtY4HA4jyURGRpotW7bUOOa3v/2t3ZGsbufwVNHR0aftHP7rX/8yvr6+ZsiQIbYtISHBXHDBBSYjI8O2bdu2zUgyBQUFVc594sQJExgYaKZMmWI++eQT8/bbb5tWrVqZ0NBQu6ZHjhwxTqez1l3AuuSnmtRr53D69OmnfVHyp8f27dvrM6W1atUqrV+/XpmZmfUal5aWJpfLZY+9e/c26PwAAKB6WfkHNHDOeiUt+qemLt2qzcX+2ru/SEMThuvOO+9Ux44d9d1332n58uWSpDvuuENBQUH2aIj8/HzddNNN6t27t7p3715tP2OMpkyZorCwMKWlpSkoKEijR4/WqFGjdODAAUk/fJfvZC3XXXedJMnlcqlt27YNqk2S9u3bp8TERFVWVmrq1Km23eFwqGPHjsrJyaly3D/+8Q+PtXnttddUWloqY4xGjBihK664QpdeeqmOHz+uEydO2DUNCQlRXFxctfOeasqUKWrXrp369++vF198UT9kxrqp17ccf/e732nChAk19unatasiIiJ08OBBj/YTJ06ouLi42i3Z9evXa9euXafduXTzzTdr0KBB2rhxY5XjnE6nnE5nXd8CAACop6z8A7rz1S06NV44I3vI//p71aptR6XEXaQ1rzyjsrIyFRQUSJL++Mc/6v7772/wOQsKCjRs2DBdf/31WrJkiR5//PFq+65fv16rV6/Wd999pzfeeEO+vr569tlntW7dOr3yyiuaPn261q5dq+PHj0uSAgMDtWnTJi1btkxr1qxpUH379+/X0KFDdeWVV+rLL79UeHi4fS0iIkK7d+9WYWGhbSsqKrKvde7cWVu3brWvhYeHa9q0aerQoYMSEhIkyY7t1q2bdu7c6dH31Hmr8sc//lHXXnutLrjgAv2///f/9Nvf/lbff/+97rnnnjq9t3qFw/bt26t9+/a19ouPj9eRI0eUm5trr/WvX79elZWViouLq3LM9OnTdfvtt3u09enTR0899ZRGjRpVnzIBAEAjqag0euStAv103ymw23/uK1hdHKClS5epc3Qn7d+/X5I0c+ZMvfrqq7ZPXR9nJ0nbtm3Ttddeq5EjR+qtt95Senq6hg8fXm3/0tJSSZKPj+cFUR8fH1VWVkqSoqOjbfvJHclT5y0pKdHq1avtLucDDzygBx54oMrz7du3T0OHDlVsbKzmzp172p3O8fHxWrFihceG17p169SjRw+1adNGkjx2QmfPnq2lS5dq48aNCggI8Jjr66+/VmRkZJV1XHfddfrHP/5h39+2bdskSTNmzLB9rrzySpWUlOjxxx/3Tjisq8suu0wjRozQpEmTtHDhQh0/flx33XWXbrnlFnXo0EHSDws7bNgw/eUvf1H//v0VERFR5a5ip06d1KVLF2+UCQAAarF5d7EOuE6/AeK79YsV2L2//ELCtPubYv1y7Cz5+fkpLCxMUvU7h3v27FFxcbG+/fZbSbI7aCfHFRQU6MYbb9SAAQO0atUqjRs3TrfffrsOHTpU7QZVfHy82rRpo+TkZPXt21cVFRX6/e9/r927d2vkyJEefU/uSE6ePFkPPfSQCgoKVF5ermPHjqlfv342EA4cOLDKcx05ckRDhgxRdHS05s2bp4qKCvn4+Gj79u2Kj4+XJI0dO1apqakqLCzUtm3blJ+fr6efflpPPfXUafPNmzdPs2fP1rvvvqu//OUvGjVqlKKjo7Vv3z7bJykpyf7voqIixcTESJL+/Oc/69///rckqVWrVlXWK0lxcXGaNWuWysrK6na1tcHfVqzFt99+a5KSkkxQUJAJDg42EydONEePHrWv796920gyGzZsqHYO8SgbAACa1RtbvjHR01afdlzQc5DxDWpr5OtnfIMuMgOGXW+Cg4PN008/XeN8ycnJVd5Iunr1aiPJTJ8+vcrXo6Oja5z3o48+MsOHDzcXXnihkWQGDBhg1q5d69EnPz/fhIWFmd///ve27eQjan56VCU6OtokJSVV2f/UMRUVFSYsLMx07tzZOJ1O07FjRzN79uzT5pszZ44JDg42OTk5xhhjxowZYyIjI42/v7/p2LGjCQgIMNOnT7f9XS5XnW5I+ak//elPpk2bNnXu7zCmHt9QPAu43W6FhITI5XIpODi4ucsBAOCstvgfX2rWms9Paz915/DE0WK13fGmDn21QwUFBTV+Be3kzuGqVav0+OOP28uiYWFh9iaOG2+8UYmJiR7fM/T19W3QvN27d1dQUJDy8/N17bXX1nve8vJy+z3K66+/XuPGjdO4ceMUFBRkLw0vW7ZMycnJev7559W/f39lZmZq+fLl2r59u8d3EU81Z84czZw5U0uWLNE111xj20+9gWfOnDmaPXu2XnnlFXXp0kUzZszQp59+qoKCgtMuP5/01ltvqaioSAMGDFBAQIDWrVun+++/X/fff78eeeSRat+nh3pFz7MAO4cAADSeN3L31mnn8Jrho8zOnTtrnc9bO4fVzXvyCmV1j76rbd6TVzp/egwePNij3zPPPGM6depk/P39Tf/+/c0///nPGuetbscyPT3d9jn5EOzw8HDjdDrNsGHDzI4dO2qc9+233zYxMTEmKCjIXHjhhaZv375m4cKFpqKiosZxp2LnEAAAVCtn17dKWvTPWvv9ddIAxXe7qMHn4fO75fDKb0gBAADnhv5d2ioypOpLmCdFhgSof5eGPy8QLQvhEAAAVMvXx6H0Ub3kqOZ1h6T0Ub3k61NdD5xtCIcAAKBGI3pH6rlbrzptBzEyJEDP3XqVRvSu+jl8ODt55TmHAADg3DKid6R+0StCm3cX6+DRYwpr/cOlZHYMzz2EQwAAUCe+Po4zuukEZwcuKwMAAMAiHAIAAMAiHAIAAMAiHAIAAMAiHAIAAMAiHAIAAMAiHAIAAMAiHAIAAMAiHAIAAMA6535DijFGkuR2u5u5EgAAUFcnP7dPfo6j+Zxz4fDo0aOSpKioqGauBAAA1NfRo0cVEhLS3GWc1xzmHIvolZWV2r9/v1q3bi2Ho2X8MnC3262oqCjt3btXwcHBzV3OWYk1bBys45ljDc8ca3jmzsU1NMbo6NGj6tChg3x8+NZbczrndg59fHx08cUXN3cZVQoODj5n/hE3F9awcbCOZ441PHOs4Zk719aQHcOWgWgOAAAAi3AIAAAAi3DYBJxOp9LT0+V0Opu7lLMWa9g4WMczxxqeOdbwzLGG8KZz7oYUAAAANBw7hwAAALAIhwAAALAIhwAAALAIhwAAALAIh15SXFyscePGKTg4WKGhoUpJSdH3339f45jf/OY36tatmwIDA9W+fXvddNNN2r59exNV3PLUdw2Li4t19913q0ePHgoMDFSnTp10zz33yOVyNWHVLUtDfg5feOEFDRkyRMHBwXI4HDpy5EjTFNuCLFiwQJ07d1ZAQIDi4uK0efPmGvuvWLFCPXv2VEBAgPr06aO1a9c2UaUtV33WcNu2bbr55pvVuXNnORwOZWZmNl2hLVh91nDRokUaNGiQ2rRpozZt2ighIaHWn1ugOoRDLxk3bpy2bdumdevWafXq1Xrvvfc0efLkGsfExsbqpZde0ueff6533nlHxhgNHz5cFRUVTVR1y1LfNdy/f7/279+vefPmKT8/Xy+//LKysrKUkpLShFW3LA35OSwtLdWIESP0wAMPNFGVLcuyZcuUmpqq9PR0bdmyRX379lViYqIOHjxYZf9NmzYpKSlJKSkpysvL0+jRozV69Gjl5+c3ceUtR33XsLS0VF27dtXs2bMVERHRxNW2TPVdw40bNyopKUkbNmxQTk6OoqKiNHz4cO3bt6+JK8c5waDRFRQUGEnmo48+sm1vv/22cTgcZt++fXWe55NPPjGSzM6dO71RZovWWGu4fPly4+/vb44fP+6NMlu0M13DDRs2GEnmu+++82KVLU///v3NlClT7J8rKipMhw4dTEZGRpX9f/WrX5mRI0d6tMXFxZnf/OY3Xq2zJavvGp4qOjraPPXUU16s7uxwJmtojDEnTpwwrVu3Nq+88oq3SsQ5jJ1DL8jJyVFoaKj69etn2xISEuTj46MPP/ywTnOUlJTopZdeUpcuXRQVFeWtUlusxlhDSXK5XAoODpaf3zn3a8Rr1VhreD4pLy9Xbm6uEhISbJuPj48SEhKUk5NT5ZicnByP/pKUmJhYbf9zXUPWEJ4aYw1LS0t1/PhxtW3b1ltl4hxGOPSCwsJChYWFebT5+fmpbdu2KiwsrHHss88+q6CgIAUFBentt9/WunXr5O/v781yW6QzWcOTDh8+rFmzZtV6GfVc1RhreL45fPiwKioqFB4e7tEeHh5e7ZoVFhbWq/+5riFrCE+NsYbTpk1Thw4dTvsPF6AuCIf1MH36dDkcjhqPM72BZNy4ccrLy9Pf//53XXrppfrVr36lY8eONdI7aH5NsYaS5Ha7NXLkSPXq1UsPP/zwmRfegjTVGgI4O82ePVtLly7VypUrFRAQ0Nzl4Cx0/l1rOwO/+93vNGHChBr7dO3aVREREad9afjEiRMqLi6u9cvWISEhCgkJ0SWXXKIBAwaoTZs2WrlypZKSks60/BahKdbw6NGjGjFihFq3bq2VK1eqVatWZ1p2i9IUa3i+ateunXx9fVVUVOTRXlRUVO2aRURE1Kv/ua4hawhPZ7KG8+bN0+zZs/Xuu+/qiiuu8GaZOIcRDuuhffv2at++fa394uPjdeTIEeXm5io2NlaStH79elVWViouLq7O5zPGyBijsrKyBtfc0nh7Dd1utxITE+V0OrVq1apz8r+am/rn8Hzi7++v2NhYZWdna/To0ZKkyspKZWdn66677qpyTHx8vLKzs3XvvffatnXr1ik+Pr4JKm55GrKG8NTQNZw7d64effRRvfPOOx7fNQbqrbnviDlXjRgxwlx55ZXmww8/NO+//7655JJLTFJSkn39m2++MT169DAffvihMcaYXbt2mccee8x8/PHH5uuvvzYffPCBGTVqlGnbtq0pKipqrrfRrOq7hi6Xy8TFxZk+ffqYnTt3mgMHDtjjxIkTzfU2mlV919AYYw4cOGDy8vLMokWLjCTz3nvvmby8PPPtt982x1tockuXLjVOp9O8/PLLpqCgwEyePNmEhoaawsJCY4wxt912m5k+fbrt/8EHHxg/Pz8zb9488/nnn5v09HTTqlUr89lnnzXXW2h29V3DsrIyk5eXZ/Ly8kxkZKS5//77TV5envnXv/7VXG+h2dV3DWfPnm38/f3N66+/7vH/fUePHm2ut4CzGOHQS7799luTlJRkgoKCTHBwsJk4caLHP9Ldu3cbSWbDhg3GGGP27dtnrrvuOhMWFmZatWplLr74YjN27Fizffv2ZnoHza++a3jy0StVHbt3726eN9HM6ruGxhiTnp5e5Rq+9NJLTf8GmskzzzxjOnXqZPz9/U3//v3NP//5T/va4MGDTXJyskf/5cuXm0svvdT4+/ubyy+/3KxZs6aJK2556rOGJ38Of3oMHjy46QtvQeqzhtHR0VWuYXp6etMXjrOewxhjmmybEgAAAC0adysDAADAIhwCAADAIhwCAADAIhwCAADAIhwCAADAIhwCAADAIhwCAADAIhwCAADAIhwCAADAIhwCAADAIhwCAADAIhwCAADA+v/Ae1xrjx/n8AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(((5, 12), (12, 10), (20, 5)), -0.42940863966941833, 0.23799992),\n",
       " (((5, 12), (8, 1), (20, 5)), -0.4207330048084259, 0.23799992),\n",
       " (((8, 7), (12, 10), (20, 5)), 0.9564396142959595, -0.31800002)]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_head_chains(model, get_head2scores(result.root.children[1].children[0].children[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68713987",
   "metadata": {},
   "source": [
    "### did->does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a83926d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, does2did.TreeSet.equal) (cxt_len=2, abstract=0): 0.613, 0.65625\n",
      "MlM_gen(persons.EqSet.equal, does2did.TreeSet.equal) (cxt_len=2, abstract=1): 0.650, 0.53125\n",
      "MlM_gen(persons.EqSet.equal, does2did.TreeSet.parent) (cxt_len=1, abstract=0): 0.056, 0.8125\n",
      "MlM_gen(persons.EqSet.equal, does2did.TreeSet.parent) (cxt_len=1, abstract=1): 0.596, 0.5625\n",
      "MlM_gen(persons.EqSet.equal, does2did.TreeSet.parent) (cxt_len=2, abstract=0): 1.258, 0.53125\n",
      "MlM_gen(persons.EqSet.equal, does2did.TreeSet.parent) (cxt_len=2, abstract=1): 1.894, 0.5\n"
     ]
    }
   ],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38f701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, does2did.TreeSet.parent) (cxt_len=1, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result, topk=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b511c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node.parent.parent.parent, topi=[0,1], head_attr_fn=get_head_mlp_attr, mix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb9f0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text, input_ids, labels, ranges, *args, o in data_tuples:\n",
    "    show_predictions(tokenizer, *args, logits=o.logits, labels=labels, k_shot=k_shot, topk=3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9790bcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.node = result.node.parent.parent.parent\n",
    "result.node = result.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "657592c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, does2did.TreeSet.parent) (cxt_len=1, abstract=0)\n",
      "                 ┌[0] top3 21-16 labels┐\n",
      "                 │                     └[1] top[0, 1, 2, 3, 4, 5] 19-16,8-16,13-13,17-16,7-16,6-16\n",
      "                 ├[0] top[0] 17-9 attn_labels┐\n",
      "                 │                           └[1] top[0, 1, 2] 12-10,8-1,13-13┐\n",
      "                 │                                                            └[2] top[0] 6-10\n",
      " [-1] root labels┤\n",
      "                 │                     ┌[1] top[0, 1, 2, 3, 4, 5] 18-16,13-13,14-7,16-16,12-10,17-16\n",
      "                 ├[0] top0 19-16 labels┤\n",
      "                 │                     └[1] top0 18-16┐\n",
      "                 │                                    └[2] top0 17-16┐\n",
      "                 │                                                   └[3] top[0, 1] 16-16,15-16\n",
      "                 └[0] top[1] 14-7 attn_labels┐\n",
      "                                             └[1] top[0, 1] 8-1,12-10┐\n",
      "                                                                     └*[2] top[1, 0, 2, 7] 6-10,0-16,3-11,3-12...\n"
     ]
    }
   ],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[1,0,2,7], head_attr_fn=get_head_mlp_attr, label_type='attn_labels')  # head_attr_fn=get_head_mlp_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb091b94",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for data_tuple in data_tuples:\n",
    "    plot_attn_attr(data_tuple, model, tokenizer, node, 17, 16, attn_patterns=None, k_shot=0, plot_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0c3bcd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interpret_circuit(model, tokenizer, result.task, node.parent, topi=[0,1,6,7,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27296b00",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0, 1, 2], k_shot=k_shot)  # head_attr_fn=get_head_mlp_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0185b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, does2did.TreeSet.equal) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result, topk=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e7c66e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0, 7], head_attr_fn=get_head_mlp_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6460cf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, does2did.TreeSet.equal) (cxt_len=2, abstract=0)\n",
      " [-1] root labels┐\n",
      "                 └[0] top[0] 16-7 attn_labels┐\n",
      "                                             └[1] top[0, 1, 2, 3, 4] 9-14,13-13,15-5,8-1,12-10┐\n",
      "                                                                                              └*[2] top[0, 1, 2, 3] 6-10,1-7,3-12,6-2...\n"
     ]
    }
   ],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b3de5818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(6, 2, -0.6)], [(9, 14, -2.579), (13, 13, -2.123), (15, 5, -2.675), (8, 1, -1.939), (12, 10, -2.034)], [(16, 7, -1.086)]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyze_head_chains(model, get_head2scores(node));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01df267",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, does2did.TreeSet.parent) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result, topk=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b619a4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, does2did.TreeSet.parent) (cxt_len=2, abstract=0)\n",
      "                 ┌[0] top2 19-16 labels┐\n",
      "                 │                     └[1] top[0, 1, 2, 3, 4, 5, 6] 13-13,18-16,0-16,17-16,16-16,13-7,12-10\n",
      " [-1] root labels┤\n",
      "                 └[0] top[0] 16-7 attn_labels┐\n",
      "                                             └[1] top[0, 1, 2, 3, 4] 9-14,8-1,13-13,15-5,12-10┐\n",
      "                                                                                              └*[2] top[0, 1, 2, 3] 6-10,1-7,3-12,6-2...\n"
     ]
    }
   ],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,1,2,3], label_type='attn_labels')  # head_attr_fn=get_head_mlp_attr, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a102409",
   "metadata": {},
   "source": [
    "### thing->capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "id": "2eb25f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, capabilities_of_things.TreeSet.equal) (cxt_len=2, abstract=0): 0.536, 0.71875\n",
      "MlM_gen(persons.EqSet.equal, capabilities_of_things.TreeSet.equal) (cxt_len=2, abstract=1): 1.068, 0.375\n",
      "MlM_gen(persons.EqSet.equal, capabilities_of_things.TreeSet.parent) (cxt_len=1, abstract=0): 0.434, 0.9375\n",
      "MlM_gen(persons.EqSet.equal, capabilities_of_things.TreeSet.parent) (cxt_len=1, abstract=1): 0.939, 0.59375\n",
      "MlM_gen(persons.EqSet.equal, capabilities_of_things.TreeSet.parent) (cxt_len=2, abstract=0): 2.783, 0.375\n",
      "MlM_gen(persons.EqSet.equal, capabilities_of_things.TreeSet.parent) (cxt_len=2, abstract=1): 2.983, 0.3125\n"
     ]
    }
   ],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d207a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, capabilities_of_things.TreeSet.parent) (cxt_len=1, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689b07c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_circuit(model, tokenizer, result.task, node, topi=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8d310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_circuit(model, tokenizer, result.task, node, topi=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "id": "f0541f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, capabilities_of_things.TreeSet.parent) (cxt_len=1, abstract=0)\n",
      "                 ┌[0] top[0] 13-15 attn_labels┐\n",
      "                 │                            └[1] top[0, 1] 8-1,12-10┐\n",
      "                 │                                                    └[2] top[0, 1] 5-12,6-5\n",
      " [-1] root labels┤\n",
      "                 └[0] top[3] 21-14 attn_labels┐\n",
      "                                              └[1] top[0, 1] 8-1,12-10┐\n",
      "                                                                      └*[2] top[0, 1] 3-12,5-12...\n"
     ]
    }
   ],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759696a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, capabilities_of_things.TreeSet.equal) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "id": "6fc85adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, capabilities_of_things.TreeSet.equal) (cxt_len=2, abstract=0)\n",
      " [-1] root labels┐\n",
      "                 └[0] top[0] 16-7 attn_labels┐\n",
      "                                             └[1] top[0, 1] 9-14,12-10┐\n",
      "                                                                      └*[2] top[2, 1, 3, 0] 8-7,1-7,6-10,3-12...\n"
     ]
    }
   ],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[2,1,3,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "id": "bd405a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(8, 7, -0.282)], [(9, 14, -2.228), (12, 10, -2.236)], [(16, 7, -1.271)]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyze_head_chains(model, get_head2scores(node));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8615ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, capabilities_of_things.TreeSet.parent) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "id": "b4f2e785",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Ġplay 0.133 {'Ġplay': 0.133, 'Ġshoot': 0.058, 'âĢ': 0.057} \t Justice has a piano. Chance has a gun. Justice can play\n",
      "*Ġbake 0.241 {'Ġbake': 0.241, 'Ġfly': 0.136, 'Ġcook': 0.128} \t Tyler has an oven. London has a plane. Tyler can bake\n",
      " Ġfly 0.04 {'Ġprint': 0.727, 'Ġtype': 0.046, 'Ġfly': 0.04} \t India has a printer. Eva has a glider. Eva can fly\n",
      "*Ġwash 0.606 {'Ġwash': 0.606, 'Ġdry': 0.074, 'Ġclean': 0.062} \t Jamie has a phone. Dream has washing machine. Dream can wash\n",
      " Ġstab 0.219 {'Ġopen': 0.324, 'Ġstab': 0.219, 'Ġcut': 0.21} \t Angel has an opener. Laura has a dagger. Laura can stab\n",
      " Ġwatch 0.0 {'Ġstab': 0.975, 'Ġkill': 0.005, 'Ġcut': 0.002} \t Anna has a TV. Michael has a dagger. Anna can watch\n",
      " Ġcut 0.077 {'Ġcook': 0.286, 'Ġsaw': 0.119, 'Ġchop': 0.082} \t King has a saw. Amy has a pot. King can cut\n",
      " Ġcook 0.075 {'Ġdrive': 0.37, 'Ġcook': 0.075, 'Ġfix': 0.045} \t Georgia has a pot. Thomas has a car. Georgia can cook\n",
      "3.0769495964050293\n",
      " Ġchop 0.063 {\"'t\": 0.073, 'âĢ': 0.069, 'Ġchop': 0.063} \t Cash has an oven. Alexander has an axe. Alexander can chop\n",
      " Ġstab 0.007 {'Ġdig': 0.667, 'Ġchop': 0.045, 'Ġshovel': 0.039} \t Sky has a dagger. Jordan has a shovel. Sky can stab\n",
      "*Ġdig 0.331 {'Ġdig': 0.331, 'Ġstab': 0.294, 'Ġshovel': 0.076} \t Christopher has a lamp. Larry has a shovel. Larry can dig\n",
      " Ġadd 0.002 {'Ġshoot': 0.719, 'Ġkill': 0.031, 'Ġfire': 0.029} \t Eva has a calculator. Michael has a gun. Eva can add\n",
      "*Ġcall 0.45 {'Ġcall': 0.45, 'Ġdial': 0.244, 'Ġmake': 0.066} \t Ruby has a calculator. Paul has a phone. Paul can call\n",
      "*Ġdig 0.864 {'Ġdig': 0.864, 'Ġshovel': 0.022, 'Ġchop': 0.02} \t Anna has a pot. Hunter has a shovel. Hunter can dig\n",
      " Ġopen 0.003 {'Ġchop': 0.885, 'Ġcut': 0.036, 'Ġhack': 0.011} \t Bruce has an opener. Jessica has an axe. Bruce can open\n",
      "*Ġbake 0.818 {'Ġbake': 0.818, 'Ġcook': 0.13, 'Ġopen': 0.01} \t Jake has a saw. Sarah has an oven. Sarah can bake\n",
      "2.675234317779541\n",
      " Ġride 0.116 {\"'t\": 0.127, 'Ġride': 0.116, 'âĢ': 0.061} \t Lewis has a lamp. Elsa has a bicycle. Elsa can ride\n",
      "*Ġwash 0.533 {'Ġwash': 0.533, 'Ċ': 0.07, 'Ġuse': 0.068} \t Roger has a plane. Anne has washing machine. Anne can wash\n",
      "*Ġcook 0.456 {'Ġcook': 0.456, 'Ġboil': 0.165, 'Ġmake': 0.094} \t Rachel has washing machine. Dallas has a pot. Dallas can cook\n",
      " Ġadd 0.0 {'Ġfly': 0.821, 'Ġride': 0.051, 'Ġtake': 0.009} \t Angel has a calculator. Kate has a plane. Angel can add\n",
      " Ġwatch 0.027 {'Ġcook': 0.333, 'Ġboil': 0.112, 'Ġadd': 0.076} \t Amy has a TV. Anne has a pot. Amy can watch\n",
      " Ġstab 0.171 {'Ġcut': 0.216, 'Ġstab': 0.171, 'Ġkill': 0.11} \t Tony has washing machine. Gary has a dagger. Gary can stab\n",
      "*Ġdig 0.926 {'Ġdig': 0.926, 'Ġshovel': 0.031, 'Ġbury': 0.007} \t Ruby has a knife. Hunter has a shovel. Hunter can dig\n",
      "*Ġopen 0.488 {'Ġopen': 0.488, 'Ġwash': 0.182, 'Ġuse': 0.077} \t Sky has an opener. Victoria has washing machine. Sky can open\n",
      "3.071582078933716\n",
      " Ġfly 0.079 {\"'t\": 0.15, 'Ġfly': 0.079, 'âĢ': 0.046} \t Bo has a glider. Carl has an axe. Bo can fly\n",
      " Ġwrite 0.026 {'Ġfly': 0.588, \"'t\": 0.058, 'Ġdraw': 0.035} \t Christopher has a piano. Morgan has a pencil. Morgan can write\n",
      " Ġwatch 0.002 {'Ġwrite': 0.669, 'Ġdraw': 0.119, \"'t\": 0.039} \t August has a TV. Ruby has a pencil. August can watch\n",
      " Ġopen 0.009 {'Ġplay': 0.662, 'Ġlisten': 0.061, 'Ġhear': 0.047} \t Ryan has an opener. Robin has a violin. Ryan can open\n",
      " Ġprint 0.223 {'Ġopen': 0.437, 'Ġprint': 0.223, 'Ġwatch': 0.117} \t Collins has a printer. Winter has an opener. Collins can print\n",
      " Ġshoot 0.022 {'Ġopen': 0.696, 'Ġprint': 0.164, 'Ġwatch': 0.048} \t Maria has a gun. Ray has a printer. Maria can shoot\n",
      " Ġdrive 0.318 {'Ġwatch': 0.447, 'Ġdrive': 0.318, 'Ġopen': 0.023} \t Joy has a TV. Mary has a car. Mary can drive\n",
      "*Ġshoot 0.696 {'Ġshoot': 0.696, 'Ġopen': 0.072, 'Ġkill': 0.032} \t Warren has a gun. Alexander has an axe. Warren can shoot\n",
      "2.308245897293091\n"
     ]
    }
   ],
   "source": [
    "for text, input_ids, labels, ranges, *args, o in data_tuples:\n",
    "    loss, top1_corrects, answer_probs, candidate_probs = show_predictions(\n",
    "        tokenizer, *args, logits=o.logits, labels=labels, loss_reduction='mean',\n",
    "        candidates=None, k_shot=k_shot, topk=3, verbose=True)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854622df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node.parent.parent.parent, topi=[0], k_shot=k_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4126b548",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0, 1, 2, 3], k_shot=k_shot, plot_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "id": "99d60291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, capabilities_of_things.TreeSet.parent) (cxt_len=2, abstract=0)\n",
      "parent has not been attributed yet, replace it instead of adding to it.\n",
      "                 ┌[0] top[1] 21-14 argmax_attn_labels┐\n",
      "                 │                                   └[1] top[0, 1] 8-1,12-10┐\n",
      "                 │                                                           └*[2] top[1, 2, 0] 5-12,1-7,3-12...\n",
      " [-1] root labels┤\n",
      "                 └[0] top[0] 13-15 argmax_attn_labels┐\n",
      "                                                     └[1] top[0, 1] 8-1,12-10┐\n",
      "                                                                             └[2] top[2, 3, 1, 0] 6-5,3-7,5-12,3-12\n"
     ]
    }
   ],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[1,2,0], label_type='argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04c9c89",
   "metadata": {},
   "source": [
    "### capital->country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "87f5c5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, country2capital.TreeSet.equal) (cxt_len=1, abstract=0): 0.068, 0.8125\n",
      "MlM_gen(persons.EqSet.equal, country2capital.TreeSet.equal) (cxt_len=1, abstract=1): 0.111, 0.84375\n",
      "MlM_gen(persons.EqSet.equal, country2capital.TreeSet.equal) (cxt_len=2, abstract=0): 0.866, 0.65625\n",
      "MlM_gen(persons.EqSet.equal, country2capital.TreeSet.equal) (cxt_len=2, abstract=1): 1.251, 0.5\n",
      "MlM_gen(persons.EqSet.equal, country2capital.TreeSet.parent) (cxt_len=1, abstract=0): 0.093, 0.84375\n",
      "MlM_gen(persons.EqSet.equal, country2capital.TreeSet.parent) (cxt_len=1, abstract=1): 0.119, 0.8125\n",
      "MlM_gen(persons.EqSet.equal, country2capital.TreeSet.parent) (cxt_len=2, abstract=0): 1.386, 0.4375\n",
      "MlM_gen(persons.EqSet.equal, country2capital.TreeSet.parent) (cxt_len=2, abstract=1): 2.561, 0.4375\n"
     ]
    }
   ],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb37da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, country2capital.TreeSet.parent) (cxt_len=1, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "id": "55ffef5f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0\n",
      "(0.9464224576950073, 0.9693313837051392)\n",
      "Berlin->['Germany'] {'ĠBerlin': 34, 'ĠFriedrich': 22, 'ĠGermany': 19, 'ĠReich': 19, 'ĠGerman': 19}\n",
      "Cairo->['Egypt'] {'ĠCairo': 40, 'Egypt': 39, 'ĠEgypt': 39, 'ĠEgyptian': 38, 'ĠEgyptians': 37}\n",
      "Ankara->['Turkey'] {'ĠAnkara': 42, 'ĠTurkish': 38, 'ĠErdogan': 37, 'ĠTurkey': 36, 'Turkish': 35}\n",
      "Athens->['Greece'] {'ĠAthens': 42, 'ĠAthen': 33, 'ĠAthena': 30, 'ĠGreece': 30, 'ĠGreek': 29}\n",
      "London->['England'] {'ĠLondon': 26, 'London': 26, 'ĠNotting': 25, 'ĠThames': 24, 'ĠBarcl': 19}\n",
      "Manila->['the Philippines'] {'ĠManila': 34, 'ĠFilipino': 31, 'ĠPhilippines': 31, 'ĠPhilippine': 29, 'ĠFilip': 27}\n",
      "Ottawa->['Canada'] {'ĠOttawa': 36, 'Ott': 26, 'ĠCanadians': 24, 'ĠCanadian': 24, 'ĠQuebec': 22}\n",
      "Bern->['Switzerland'] {'Bern': 30, 'ĠBernstein': 30, 'ĠBern': 25, 'bern': 24, 'ĠBernard': 21}\n",
      "Seoul->['South Korea'] {'ĠSeoul': 39, 'ĠKoreans': 36, 'ĠKorean': 36, 'ĠKorea': 33, 'ĠYong': 29}\n",
      "Lisbon->['Portugal'] {'ĠLisbon': 40, 'ĠPortuguese': 38, 'ĠPortugal': 37, 'ĠPortug': 32, 'ĠLis': 20}\n",
      "Rome->['Italy'] {'ĠRome': 34, 'ĠRoma': 29, 'ĠRomans': 26, 'ĠItaly': 25, 'ĠItalian': 24}\n",
      "Canberra->['Australia'] {'ĠCanberra': 33, 'ĠACT': 22, 'ĠAustralian': 22, 'ĠAustralia': 22, 'ĠAustralians': 19}\n",
      "Bangkok->['Thailand'] {'ĠBangkok': 39, 'ĠThailand': 33, 'ĠThai': 30, 'Bang': 24, 'ĠBuddha': 21}\n",
      "Beijing->['China'] {'ĠBeijing': 35, 'ĠChinese': 29, 'ĠTian': 28, 'China': 28, 'ĠChina': 28}\n",
      "Tokyo->['Japan'] {'ĠTokyo': 35, 'Tok': 31, 'ĠJapanese': 30, 'ĠJapan': 30, 'Japan': 28}\n",
      "Paris->['France'] {'ĠParis': 33, 'Paris': 31, 'ĠFrance': 29, 'ĠFrench': 28, 'France': 26}\n",
      "Madrid->['Spain'] {'ĠMadrid': 38, 'ĠSpain': 31, 'ĠSpani': 30, 'ĠSpanish': 30, 'Spanish': 28}\n",
      "Moscow->['Russia'] {'ĠMoscow': 42, 'ĠRussians': 37, 'Moscow': 37, 'ĠKremlin': 37, 'ĠRussian': 36}\n",
      "12 7\n",
      "(0.9013831615447998, 0.9577867388725281)\n",
      "Berlin->['Germany'] {'ĠBerlin': 29, 'Germany': 22, 'German': 20, 'ĠGermany': 20, 'ĠGermans': 19}\n",
      "Cairo->['Egypt'] {'ĠEgypt': 35, 'ĠCairo': 34, 'ĠEgyptian': 34, 'Egypt': 33, 'ĠEgyptians': 31}\n",
      "Ankara->['Turkey'] {'ĠTurkish': 29, 'ĠAnkara': 29, 'Turkish': 27, 'ĠErdogan': 27, 'ĠIstanbul': 27}\n",
      "Athens->['Greece'] {'ĠAthens': 32, 'ĠAthen': 29, 'ĠGreece': 28, 'ĠGreeks': 27, 'ĠGreek': 26}\n",
      "London->['England'] {'London': 30, 'ĠLondon': 29, 'ĠBritain': 25, 'UK': 25, 'ĠÂ£': 25}\n",
      "Manila->['the Philippines'] {'ĠManila': 33, 'ĠFilipino': 32, 'ĠPhilippine': 31, 'ĠPhilippines': 30, 'ĠFilip': 28}\n",
      "Ottawa->['Canada'] {'ĠOttawa': 39, 'ĠCanadians': 36, 'ĠCanadian': 34, 'Canada': 34, 'ĠCanada': 34}\n",
      "Bern->['Switzerland'] {'ĠSwiss': 15, 'ĠSwitzerland': 15, 'Ġsignalling': 14, 'Ġlabou': 13, 'Ġneighbouring': 13}\n",
      "Seoul->['South Korea'] {'ĠKorea': 37, 'ĠKorean': 36, 'ĠSeoul': 36, 'ĠKoreans': 35, 'ĠYong': 28}\n",
      "Lisbon->['Portugal'] {'ĠLisbon': 35, 'ĠPortugal': 35, 'ĠPortuguese': 34, 'ĠPortug': 32, 'Brazil': 22}\n",
      "Rome->['Italy'] {'ĠRome': 27, 'ĠItaly': 24, 'ĠItalians': 23, 'Italy': 22, 'ĠItalian': 21}\n",
      "Canberra->['Australia'] {'ĠCanberra': 37, 'ĠAustralia': 35, 'ĠAustralian': 33, 'Australian': 32, 'ĠAustralians': 31}\n",
      "Bangkok->['Thailand'] {'ĠBangkok': 38, 'ĠThailand': 35, 'ĠThai': 33, 'Asia': 24, 'ĠCambodia': 23}\n",
      "Beijing->['China'] {'ĠBeijing': 34, 'ĠChinese': 30, 'China': 30, 'Chinese': 30, 'ĠChina': 29}\n",
      "Tokyo->['Japan'] {'Japan': 39, 'ĠJapan': 39, 'ĠJapanese': 37, 'Japanese': 37, 'ĠTokyo': 36}\n",
      "Paris->['France'] {'Paris': 31, 'ĠParis': 31, 'ĠFrance': 30, 'France': 29, 'ĠFranÃ§': 28}\n",
      "Madrid->['Spain'] {'ĠSpain': 35, 'ĠMadrid': 33, 'Spain': 32, 'Spanish': 31, 'ĠSpanish': 31}\n",
      "Moscow->['Russia'] {'ĠMoscow': 32, 'Moscow': 31, 'Russian': 29, 'ĠRussian': 29, 'ĠRussia': 29}\n",
      "19 12\n",
      "(0.935795247554779, 0.9572104811668396)\n",
      "Berlin->['Germany'] {'ĠGerman': 45, 'ĠBerlin': 45, 'ĠGermans': 44, 'German': 44, 'ĠGermany': 41}\n",
      "Cairo->['Egypt'] {'ĠCairo': 41, 'ĠEgyptian': 38, 'ĠEgypt': 38, 'Egypt': 37, 'ĠEgyptians': 34}\n",
      "Ankara->['Turkey'] {'ĠTurkish': 42, 'Turkish': 41, 'ĠTurkey': 40, 'Turkey': 39, 'ĠAnkara': 39}\n",
      "Athens->['Greece'] {'ĠAthens': 48, 'ĠGreek': 46, 'ĠGreece': 46, 'Greek': 45, 'ĠGreeks': 44}\n",
      "London->['England'] {'ĠLondon': 45, 'London': 42, 'ĠBritish': 40, 'ĠEngland': 38, 'ĠBritain': 37}\n",
      "Manila->['the Philippines'] {'ĠPhilippines': 38, 'ĠPhilippine': 36, 'ĠFilipino': 35, 'ĠManila': 35, 'ĠFilip': 33}\n",
      "Ottawa->['Canada'] {'ĠOttawa': 39, 'Ott': 34, 'ĠCanada': 33, 'Canada': 32, 'ĠCanadians': 32}\n",
      "Bern->['Switzerland'] {'ĠBern': 31, 'Bern': 31, 'ĠSwitzerland': 29, 'ĠBernard': 26, 'ĠSwiss': 26}\n",
      "Seoul->['South Korea'] {'ĠKorean': 45, 'ĠKoreans': 43, 'ĠKorea': 43, 'ĠSeoul': 43, 'South': 29}\n",
      "Lisbon->['Portugal'] {'ĠPortugal': 46, 'ĠPortuguese': 45, 'ĠLisbon': 43, 'ĠPortug': 37, 'ĠLis': 30}\n",
      "Rome->['Italy'] {'ĠRoman': 45, 'ĠRome': 44, 'Roman': 39, 'ĠRomans': 39, 'ĠRoma': 37}\n",
      "Canberra->['Australia'] {'ĠAustralia': 32, 'Australia': 30, 'ĠCanberra': 30, 'ĠAustralian': 29, 'ĠAustralians': 28}\n",
      "Bangkok->['Thailand'] {'ĠThailand': 44, 'ĠThai': 44, 'ĠBangkok': 42, 'ĠAsian': 27, 'ĠBuddhist': 25}\n",
      "Beijing->['China'] {'ĠChinese': 47, 'ĠBeijing': 44, 'ĠChina': 44, 'Chinese': 43, 'China': 42}\n",
      "Tokyo->['Japan'] {'ĠJapanese': 57, 'ĠJapan': 54, 'Japanese': 53, 'Japan': 52, 'ĠTokyo': 51}\n",
      "Paris->['France'] {'ĠFrench': 48, 'ĠFrance': 47, 'ĠParis': 47, 'Paris': 45, 'French': 45}\n",
      "Madrid->['Spain'] {'ĠSpain': 48, 'ĠMadrid': 47, 'Spain': 47, 'ĠSpanish': 46, 'Spanish': 44}\n",
      "Moscow->['Russia'] {'ĠRussian': 53, 'ĠRussians': 51, 'ĠMoscow': 50, 'Russian': 48, 'ĠRussia': 47}\n"
     ]
    }
   ],
   "source": [
    "interpret_circuit(model, tokenizer, result.task, node, topi=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "id": "3dd05881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, country2capital.TreeSet.parent) (cxt_len=1, abstract=0)\n",
      " [-1] root labels┐\n",
      "                 └[0] top[2] 19-12 attn_labels┐\n",
      "                                              └[1] top[0, 1, 2, 3] 13-13,8-1,12-10,11-0┐\n",
      "                                                                                       └*[2] top[0] 5-12...\n"
     ]
    }
   ],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28882636",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, country2capital.TreeSet.equal) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "id": "63db07d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, country2capital.TreeSet.equal) (cxt_len=2, abstract=0)\n",
      " [-1] root labels┐\n",
      "                 └[0] top[0, 1] 16-0,16-7 attn_labels┐\n",
      "                                                     └[1] top[0, 1, 2] 8-1,13-13,12-10┐\n",
      "                                                                                      └*[2] top[0, 1] 6-2,1-7...\n"
     ]
    }
   ],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060f0c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, country2capital.TreeSet.parent) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "7a0cebe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, country2capital.TreeSet.parent) (cxt_len=2, abstract=0)\n",
      "                 ┌[0] top[0, 1, 3] 16-0,12-7,19-12 attn_labels┐\n",
      "                 │                                            └[1] top[0, 1, 2, 3, 4] 8-1,11-0,13-13,9-14,12-10┐\n",
      "                 │                                                                                             └[2] top[0, 1, 3] 5-12,3-12,1-7\n",
      " [-1] root labels┤\n",
      "                 └[0] top[0, 1, 3] 16-0,12-7,19-12 argmax_attn_labels┐\n",
      "                                                                     └[1] top[0, 1, 2, 3, 4] 8-1,11-0,13-13,9-14,12-10┐\n",
      "                                                                                                                      └*[2] top[0, 1, 2] 5-12,1-7,3-12...\n"
     ]
    }
   ],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,1,2])#, label_type='argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8261a178",
   "metadata": {},
   "source": [
    "### person_adjs.opposite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "d291a627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.equal) (cxt_len=1, abstract=0): 0.027, 0.9375\n",
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.equal) (cxt_len=1, abstract=1): 0.102, 0.90625\n",
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.equal) (cxt_len=2, abstract=0): 1.261, 0.5625\n",
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.equal) (cxt_len=2, abstract=1): 1.538, 0.46875\n",
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=1, abstract=0): 0.451, 0.625\n",
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=1, abstract=1): 0.349, 0.75\n",
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=2, abstract=0): 3.566, 0.3125\n",
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=2, abstract=1): 3.773, 0.25\n"
     ]
    }
   ],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423b3633",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=1, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "c8ebe210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=1, abstract=0)\n",
      " [-1] root labels┐\n",
      "                 └[0] top[0] 16-14 attn_labels┐\n",
      "                                              └[1] top[0, 1] 8-1,12-10┐\n",
      "                                                                      └*[2] top[0] 7-9...\n"
     ]
    }
   ],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542c29d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.equal) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "34a0c127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.equal) (cxt_len=2, abstract=0)\n",
      " [-1] root labels┐\n",
      "                 └[0] top[0] 16-7 attn_labels┐\n",
      "                                             └[1] top[0, 1] 12-10,8-1┐\n",
      "                                                                     └*[2] top[0, 1, 2, 3, 4] 6-2,8-7,3-12,1-7,6-10...\n"
     ]
    }
   ],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66abd13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "b9a226df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=2, abstract=0)\n",
      "                 ┌[0] top[0] 16-14 argmax_attn_labels┐\n",
      "                 │                                   └[1] top[0, 1] 8-1,12-10┐\n",
      "                 │                                                           └[2] top[0] 7-9\n",
      " [-1] root labels┤\n",
      "                 └[0] top[0] 16-14 attn_labels┐\n",
      "                                              └[1] top[0, 1] 8-1,12-10┐\n",
      "                                                                      └*[2] top[0] 7-9...\n"
     ]
    }
   ],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,])#, label_type='attn_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d8dd04",
   "metadata": {},
   "source": [
    "### thing->type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "22d50e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.equal) (cxt_len=1, abstract=0): 0.032, 1.0\n",
      "MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.equal) (cxt_len=1, abstract=1): 0.117, 0.90625\n",
      "MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.equal) (cxt_len=2, abstract=0): 0.594, 0.65625\n",
      "MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.equal) (cxt_len=2, abstract=1): 1.354, 0.53125\n",
      "MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.parent) (cxt_len=1, abstract=0): 0.793, 0.625\n",
      "MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.parent) (cxt_len=1, abstract=1): 0.286, 0.8125\n",
      "MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.parent) (cxt_len=2, abstract=0): 2.174, 0.46875\n",
      "MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.parent) (cxt_len=2, abstract=1): 1.824, 0.46875\n",
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.equal) (cxt_len=1, abstract=0): 0.048, 0.875\n",
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.equal) (cxt_len=1, abstract=1): 0.191, 0.90625\n",
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.equal) (cxt_len=2, abstract=0): 1.170, 0.5\n",
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.equal) (cxt_len=2, abstract=1): 1.368, 0.59375\n",
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=1, abstract=0): 0.434, 0.71875\n",
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=1, abstract=1): 0.816, 0.65625\n",
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=2, abstract=0): 2.772, 0.3125\n",
      "MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=2, abstract=1): 2.973, 0.28125\n"
     ]
    }
   ],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\")  # old full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45e7be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.parent) (cxt_len=1, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe516f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94799e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.equal) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f4b745c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.equal) (cxt_len=2, abstract=0)\n",
      " [-1] root labels┐\n",
      "                 └[0] top[0] 16-7 attn_labels┐\n",
      "                                             └[1] top[0] 12-10┐\n",
      "                                                              └*[2] top[0, 1, 2, 3, 4] 8-7,6-2,6-10,3-12,1-7...\n"
     ]
    }
   ],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0, 1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414c7caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.parent) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "819f6256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.parent) (cxt_len=2, abstract=0)\n",
      "                 ┌[0] top[0, 1, 3] 20-5,21-5,15-8 argmax_attn_labels┐\n",
      "                 │                                                  └[1] top[0, 1] 8-1,12-10┐\n",
      "                 │                                                                          └[2] top[0, 1, 3] 5-12,3-12,7-2\n",
      " [-1] root labels┤\n",
      "                 ├[0] top[0, 1, 3] 20-5,21-5,15-8 attn_labels┐\n",
      "                 │                                           └[1] top[0, 1] 8-1,12-10┐\n",
      "                 │                                                                   └*[2] top[0, 1, 2] 5-12,3-12,7-2...\n",
      "                 └[0] 11-9 attn_labels┐\n",
      "                                      └[1] top[0] 8-1┐\n",
      "                                                     └[2] top[0, 1] 3-12,7-2\n"
     ]
    }
   ],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,1,2])#, label_type='attn_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e68100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed(1234); torch.cuda.empty_cache()\n",
    "model_names = ['EleutherAI/gpt-j-6B/cpu', 'EleutherAI/gpt-neox-20b', #'EleutherAI/gpt-neox-20b/cpu', \n",
    "               'text-curie-001', 'text-davinci-001', 'text-davinci-002'][:1]\n",
    "metrics = dict(losses=defaultdict(list), accuracies=defaultdict(list))\n",
    "\n",
    "def batch_predict(model, tokenizer):\n",
    "    return [predict(model, tokenizer, text, examples, k_shot=k_shot, custom_forward=False, # avoid computing head_inputs\n",
    "                    bos_token=bos_token, eos_token=eos_token, verbose=len(model_names) == 1)[1]\n",
    "            for text, examples in zip(texts, all_examples)]\n",
    "    \n",
    "with Timer('pmapped batch_predict'):\n",
    "    parallel = len(model_names) > 1\n",
    "    pool = Pool(len(model_names)) if parallel else itertools  # with Pool(len(model_names)) as pool:\n",
    "    results = pool.starmap(batch_predict, [models[model_name] for model_name in model_names])\n",
    "    if parallel: pool.close(); pool.join()\n",
    "            \n",
    "# query2acc, query2loss = defaultdict(list), defaultdict(list)\n",
    "for model_name, r in zip(model_names, results):\n",
    "    _, tokenizer = models[model_name]\n",
    "    for i, (loss, top1_corrects, answer_indices, answer_probs, candidate_probs) in enumerate(r):#.get()\n",
    "        acc = top1_corrects[k_shot:] # np.array(top1_corrects[k_shot:]).mean()\n",
    "        metrics['losses'][model_name].append(loss); metrics['accuracies'][model_name].append(acc)\n",
    "        if batch_size == 1: print(model_name, loss, acc)\n",
    "#         queries = [e[1] for e in _examples_list[i]][k_shot:]\n",
    "#         for q, a, l in zip(queries, acc, loss): query2acc[q].append(float(a)); query2loss[q].append(l)\n",
    "# print(sorted([(q, np.array(v).mean()) for q, v in query2acc.items()], key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "89581697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies EleutherAI/gpt-j-6B/cpu 0.4444444444444444\n",
      "accuracies EleutherAI/gpt-neox-20b 0.5555555555555556\n",
      "accuracies text-curie-001 0.3333333333333333\n",
      "losses EleutherAI/gpt-j-6B/cpu 3.0475401878356934\n",
      "losses EleutherAI/gpt-neox-20b 2.3752387364705405\n",
      "losses text-curie-001 5.4890399882962955\n"
     ]
    }
   ],
   "source": [
    "for metric in ['accuracies', 'losses']:\n",
    "    for model_name in model_names[:]:\n",
    "        print(metric, model_name, np.array(metrics[metric][model_name]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4cf1f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp(a, b):\n",
    "    print(a.dtype, a.size(), b.dtype, b.size())\n",
    "    print('allclose:', torch.allclose(a, b), 'equal:', torch.equal(a, b))\n",
    "    print((a == b).float().mean())\n",
    "    print((a - b).float().abs().mean(), a.float().abs().mean(), b.float().abs().mean())\n",
    "#     print((a - b).max(), (a - b).min())\n",
    "#     print(a[a - b == (a - b).max()])\n",
    "#     print(a[a - b == (a - b).min()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e9cc4497",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ... done 0:00:02.348918\n",
      " ... done 0:00:01.659792\n",
      " ĠJ 0.032 {'Ċ': 0.074, 'ĠS': 0.038, 'Ġ': 0.036} \t S J Y -> J\n",
      "*ĠN 0.429 {'ĠN': 0.429, 'ĠR': 0.223, 'ĠA': 0.074} \t A N R -> N\n",
      " ĠC 0.247 {'ĠV': 0.649, 'ĠC': 0.247, 'ĠB': 0.018} \t B C V -> C\n",
      "*ĠT 0.443 {'ĠT': 0.443, 'ĠK': 0.393, 'ĠS': 0.085} \t S T K -> T\n",
      "*ĠR 0.839 {'ĠR': 0.839, 'ĠT': 0.099, 'ĠA': 0.021} \t A R T -> R\n",
      "*ĠH 0.562 {'ĠH': 0.562, 'ĠQ': 0.278, 'ĠE': 0.112} \t E H Q -> H\n",
      "*ĠO 0.792 {'ĠO': 0.792, 'ĠF': 0.161, 'ĠN': 0.013} \t N O F -> O\n",
      "*ĠA 0.626 {'ĠA': 0.626, 'ĠI': 0.225, 'ĠY': 0.11} \t Y A I -> A\n",
      "\n",
      "\n",
      " ĠJ 0.032 {'Ċ': 0.074, 'ĠS': 0.038, 'Ġ': 0.036} \t S J Y -> J\n",
      "*ĠN 0.429 {'ĠN': 0.429, 'ĠR': 0.223, 'ĠA': 0.074} \t A N R -> N\n",
      " ĠC 0.247 {'ĠV': 0.649, 'ĠC': 0.247, 'ĠB': 0.018} \t B C V -> C\n",
      "*ĠT 0.443 {'ĠT': 0.443, 'ĠK': 0.393, 'ĠS': 0.085} \t S T K -> T\n",
      "*ĠR 0.839 {'ĠR': 0.839, 'ĠT': 0.099, 'ĠA': 0.021} \t A R T -> R\n",
      "*ĠH 0.562 {'ĠH': 0.562, 'ĠQ': 0.278, 'ĠE': 0.112} \t E H Q -> H\n",
      "*ĠO 0.792 {'ĠO': 0.792, 'ĠF': 0.161, 'ĠN': 0.013} \t N O F -> O\n",
      "*ĠA 0.626 {'ĠA': 0.626, 'ĠI': 0.225, 'ĠY': 0.11} \t Y A I -> A\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# text, _examples = texts[0], _examples_list[0]\n",
    "torch.cuda.empty_cache()\n",
    "if True: #def predict2(model, tokenizer, text, _examples):\n",
    "    examples, input_ids, tokens, bos_indices, eos_indices, answers, labels = make_data_tuple(\n",
    "        text, tokenizer, k_shot=k_shot, bos_token=bos_token, eos_token=eos_token)\n",
    "    candidates = [[tokenizer.encode(' ' + token)[0] for token in cands[0]] for _, _, cands, _ in _examples]\n",
    "    with torch.no_grad():\n",
    "        with Timer(): o0 = model(input_ids.to(model.device), output_attentions=True, output_hidden_states=True)\n",
    "        with Timer(): o1 = forward0(model, input_ids.to(model.device), labels=labels.to(model.device),\n",
    "                by_head=['head_input0', 'head_output0'], attn_weights=None, output_hidden_states=True)\n",
    "        for o in [o0, o1]:\n",
    "            logits = o.logits\n",
    "            if isinstance(logits, torch.Tensor): logits = logits.to('cpu').float()# softmax on cpu needs float32\n",
    "            loss, top1_corrects, answer_probs, candidate_probs = show_predictions(\n",
    "                examples, tokenizer, logits, bos_indices, eos_indices, answers, labels, loss_reduction='none',\n",
    "                candidates=candidates, k_shot=k_shot, topk=3, verbose=True)\n",
    "            print('\\n')\n",
    "#     return loss, top1_corrects, answer_probs, candidate_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9a74c135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "20a661b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies EleutherAI/gpt-j-6B 0.4976851851851852\n",
      "accuracies EleutherAI/gpt-neox-20b 0.5023148148148148\n",
      "accuracies text-davinci-001 0.48148148148148145\n",
      "accuracies text-davinci-002 0.9675925925925926\n",
      "losses EleutherAI/gpt-j-6B 1.3536101162543572\n",
      "losses EleutherAI/gpt-neox-20b 1.1634638377252957\n",
      "losses text-davinci-001 1.687816629922939\n",
      "losses text-davinci-002 0.1085046497381794\n"
     ]
    }
   ],
   "source": [
    "for metric in ['accuracies', 'losses']:\n",
    "    for model_name in model_names[:]:\n",
    "        print(metric, model_name, np.array(metrics[metric][model_name]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "26aaa1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies EleutherAI/gpt-j-6B 0.6203703703703703\n",
      "accuracies EleutherAI/gpt-neox-20b 0.7083333333333334\n",
      "accuracies text-curie-001 0.5879629629629629\n",
      "losses EleutherAI/gpt-j-6B 1.5619440356433054\n",
      "losses EleutherAI/gpt-neox-20b 1.0779137232247094\n",
      "losses text-curie-001 3.1073556870623844\n"
     ]
    }
   ],
   "source": [
    "for metric in ['accuracies', 'losses']:\n",
    "    for model_name in model_names[:]:\n",
    "        print(metric, model_name, np.array(metrics[metric][model_name])[:,:27].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cba876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in ['accuracies', 'losses']:\n",
    "    _ = plt.figure(figsize=(10, 3));\n",
    "    for model_name in model_names[:2]:\n",
    "        plt.plot(np.array(metrics[metric][model_name])[:].mean(0), label=f'{model_name}');\n",
    "    _ = plt.legend();  _ = plt.title(metric); _ = plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60515185",
   "metadata": {},
   "outputs": [],
   "source": [
    "time2prep = {tuple(clock_of_day): 'at', tuple(days_of_week): 'on', tuple(months): 'in'}\n",
    "def lookup_item2str(item, vocab=None):\n",
    "    if vocab[0] in [clock_of_day, days_of_week, months]:\n",
    "        prep = time2prep[tuple(vocab[0])]\n",
    "        return f'{item[1]} came {prep} {item[0]}'\n",
    "    elif vocab[0] == digits:\n",
    "        return f'{item[1]} is {item[0]}'\n",
    "def lookup_query2str(query, vocab=None, rel_name=None):\n",
    "    if vocab[0] in [clock_of_day, days_of_week, months]:\n",
    "        prep = time2prep[tuple(vocab[0])]\n",
    "        prep = {'prev': 'just before', 'next': 'just after', 'same': prep}[rel_name]\n",
    "        return f'Who came {prep} {query}?'\n",
    "    elif vocab[0] == digits:\n",
    "        prep = {'prev': 'a year younger than', 'next': 'a year younger than', 'same': ''}[rel_name]\n",
    "        return f'Who is {prep} {query}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1ed9c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Aaren is a boy. Harlow is a girl.\n",
    "Harlow called Aaren.\n",
    "Harlow: \"Are you a girl?\"\n",
    "Aaren: \"'''\n",
    "model_name = 'EleutherAI/gpt-j-6B'\n",
    "model, tokenizer = models[model_name]\n",
    "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "logits = model(input_ids.to(getattr(model, 'device', 'cpu'))).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6e43fb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Yes': 0.35, 'No': 0.226, 'Yeah': 0.078, 'I': 0.078, 'Y': 0.021}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_topk(*logits[0][-1].softmax(-1).topk(5), indices_fn=tokenizer.convert_ids_to_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6c3d4809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No': 0.824, 'Yes': 0.115, 'I': 0.04, 'What': 0.006, ' No': 0.003}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prob_dist(logits.top_logprobs[-1], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2e5780be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('▁The', 37),\n",
       " ('▁capital', 1784),\n",
       " ('▁of', 13),\n",
       " ('▁Canada', 1894),\n",
       " ('▁is', 19),\n",
       " ('</s>', 1)]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Ottawa. It is the largest city in Canada'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'The capital of Canada is'\n",
    "input_ids = tokenizer(text, return_tensors='pt').input_ids\n",
    "list(zip(tokenizer.convert_ids_to_tokens(input_ids[0]), input_ids[0].numpy()))\n",
    "outputs = model.generate(input_ids, max_length=10)\n",
    "tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "8c9c689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nrows = 5; k_shot = nrows // 2 + 1\n",
    "# for pairs in [drop_first_and_last, ]:\n",
    "nrows = 6;  k_shot = 3\n",
    "for pairs in reversible_transformations + irreversible_transformations:\n",
    "    seps = [' -> ', '->'] if random.random() < 0.5 else ['->', ' -> ']\n",
    "    # seps = [' -> ', ' -> ']\n",
    "    samples = ['\\n' + '\\n'.join(a + seps[0] + b for a, b in sample(pairs, nrows)) + '\\n']\n",
    "    for s in samples: data_tuples.append(list(make_data_tuple(s, tokenizer, k_shot=k_shot, bos_token=tokenizer.tokenize(seps[0])[0])))\n",
    "    samples = ['\\n' + '\\n'.join(b + seps[1] + a for a, b in sample(pairs, nrows)) + '\\n' if pairs in reversible_transformations else \n",
    "                '\\n' + '\\n'.join(a + seps[1] + b for a, b in sample(pairs, nrows)) + '\\n']\n",
    "    for s in samples: data_tuples.append(list(make_data_tuple(s, tokenizer, k_shot=k_shot, bos_token=tokenizer.tokenize(seps[1])[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2f807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sys.path.insert(0, '/nas/xd/projects/ec')\n",
    "# from child_utils import loadPBETasks, retrieveJSONTasks\n",
    "# challenge, challengeCheating = loadPBETasks('/nas/xd/projects/ec/PBE_Strings_Track')\n",
    "# challenge2, challengeCheating2 = loadPBETasks('/nas/xd/projects/ec/data/sygus')\n",
    "# tasks = retrieveJSONTasks(\"/nas/xd/projects/ec/data/list_tasks.json\")\n",
    "# tasks2 = retrieveJSONTasks(\"/nas/xd/projects/ec/data/list_tasks2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ff8618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxy_utils import get_examples_behind, get_examples_before, get_examples_query_before, \\\n",
    "    get_examples_query_behid, get_examples_query_repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432fcd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reversible_transformations = [list(digit2cardinal.items()), noun2adj, lxy, verb_form, country2capital, en2fr, antonyms]\n",
    "irreversible_transformations = [capabilities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59cbab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "fbc67151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EleutherAI/gpt-j-6B ... done 0:00:01\n",
      "* C 0.842 {' C': 0.842, ' A': 0.041, ' B': 0.04} \t D -> C\n",
      "* Thursday 0.778 {' Thursday': 0.778, ' Wednesday': 0.064, ' Friday': 0.063} \t Friday -> Thursday\n",
      "* a 0.742 {' a': 0.742, ' c': 0.051, ' A': 0.036} \t b -> a\n",
      "* four 0.472 {' four': 0.472, ' three': 0.246, ' one': 0.105} \t five -> four\n",
      "tensor(0.3677, grad_fn=<NllLossBackward>) True \n",
      "\n",
      "0.3677041530609131\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for model_name, (model, tokenizer) in models.items():\n",
    "    if any(model_name.startswith(s) for s in ['gpt2-', 'KoboldAI/fairseq-dense', 'text-davinci-001', ]): continue\n",
    "    if not model_name == 'EleutherAI/gpt-j-6B': continue\n",
    "    if not isinstance(model, types.FunctionType): _ = model.eval()\n",
    "    with Timer(model_name): outputs = model(**inputs)\n",
    "    options_ids_list = [[tokenizer.encode(' ' + option)[0] for option in options] for cxt, query, options, ans in _examples]\n",
    "    mask_logits_fn = partial(mask_logits, indices=bos_indices, kept_ids=options_ids_list)\n",
    "    loss, all_top1_correct = show_predictions(text, examples, tokenizer, outputs.logits, bos_indices, eos_indices, answers, labels,\n",
    "                    mask_logits_fn=None, topk=3, loss_reduction='mean', show_range=range(k_shot, len(examples)), sep='\\t')\n",
    "    print(loss, all_top1_correct, '\\n')\n",
    "    losses.append(loss.item() if hasattr(loss, 'item') else loss)\n",
    "    if model_name == 'EleutherAI/gpt-j-6B': break\n",
    "print(sum(losses) / len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc90b0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "relational_functions = [prev(), next()]\n",
    "rel_fns = [prevs, nexts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92834550",
   "metadata": {},
   "source": [
    "**TODO: read children books for more posets**  \n",
    "**TODO: Prompt gpt3 to elicit the posets it knows**  \n",
    "$x \\to f(x)$ where $f \\in \\{\\text{prev/next in posets of numbers/letters/months/days, antonym, hypernym, hyponym, ...}\\}$  \n",
    "$x \\to f^2(x)$  \n",
    "one poset or mixed posets  \n",
    "$x, f(x).~y \\to Ff^{[-1]}(y)$ one poset or mixed posets  \n",
    "$x, f^k(x).~y \\to Ff^{[-1]}(y)~/Ff^{[-]k}(y)$  \n",
    "$x, f(f(x))~/f(f(x)), x \\to f(x)$ in between, the simplest form of sequence completion  \n",
    "$x, f(x) \\to Gf$ where $Gf \\in \\{<, >\\}$  \n",
    "$x, f(x); y, g(y) \\to Ff \\stackrel{?}{=} g^{[-1]}$ where $\\text{output} \\in \\{\\text{True}, \\text{False}\\}$  \n",
    "sort\n",
    "\n",
    "There is a *natural* monotone map/functor $F$ between posets/sets $A$ and $B$.  Compose the computation (set operations, sorting etc.) between $A$ and $B$ with $F$ to make harder tasks.  \n",
    "$P(A) ,P(B) \\to F(P(A)) \\setminus ~/ \\cap ~/ \\triangle P(B)$. Harder form of set difference/intersection.  \n",
    "$P(A) \\to F(\\text{sorted}(P(A)))$. Harder form of sorting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504ae9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "17373019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: replace with the other. For example:\n",
      "G H G G G -> H G H H H\n",
      "I I I I M -> M M M M I\n",
      "A A F A A -> F F A F F\n",
      "9 9 9 I I -> I I I 9 9\n",
      "\n",
      "Instruction: replace with the other. For example:\n",
      "V Q Q V V -> Q V V Q Q\n",
      "G L L G L -> L G G L G\n",
      "G 2 2 2 G -> 2 G G G 2\n",
      "I I Z Z Z -> Z Z I I I\n",
      "\n",
      "Instruction: replace with the other. For example:\n",
      "R H H H R -> H R R R H\n",
      "B 9 9 B B -> 9 B B 9 9\n",
      "D 2 2 2 D -> 2 D D D 2\n",
      "A A A A W -> W W W W A\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_total, n_valid = 192, 64\n",
    "n_train = n_total - n_valid\n",
    "\n",
    "input_strs = [make_input_str(tasks[4], nrows=4, ncols=5) for __ in range(n_total)]\n",
    "for s in sample(input_strs, 3): print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "f7d6edbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(s.count('Yes') for s in input_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "e2f80b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CHILDDataset(input_strs[:-n_valid], tokenizer)\n",
    "eval_dataset = CHILDDataset(input_strs[-n_valid:], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3185653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_total == 1:\n",
    "    inputs = tokenizer.encode_plus(text, return_tensors='pt')\n",
    "    inputs = prepare_inputs(inputs, model.device)\n",
    "    outputs = model(**inputs, output_attentions=False)\n",
    "\n",
    "    # assert inputs.input_ids.size(0) == 1\n",
    "    input_ids = inputs.input_ids\n",
    "    logits = outputs.logits\n",
    "\n",
    "    bsz = input_ids.size(0); assert bsz == 1\n",
    "    labels = torch.ones_like(input_ids) * (-100)\n",
    "    for bi in range(bsz):\n",
    "        bos_indices = (input_ids[bi] == bos_id).nonzero().squeeze(1)\n",
    "        eos_indices = (input_ids[bi] == eos_id).nonzero()[-nrows:].squeeze(1)\n",
    "        for i, (example, bos_i, eos_i) in enumerate(zip(examples, bos_indices.tolist(), eos_indices.tolist())):\n",
    "            print(' ' + make_example_str(example))\n",
    "            ans_ids = input_ids[bi, bos_i + 1: eos_i]\n",
    "            if i >= 2: labels[bi, bos_i: eos_i - 1] = ans_ids\n",
    "            ans_prob_dist = logits[bi, bos_i: eos_i - 1].softmax(-1)\n",
    "            ans_probs = ans_prob_dist[torch.arange(ans_prob_dist.size(0)), ans_ids]\n",
    "            ans_tokens = tokenizer.convert_ids_to_tokens(ans_ids)\n",
    "            for ans_id, ans_token, ans_prob, dist in zip(ans_ids, ans_tokens, numpy(ans_probs, decimals=3), ans_prob_dist):\n",
    "                top1_correct = (dist.argmax() == ans_id).item()\n",
    "                print(('*' if top1_correct else ' ') + ans_token, ans_prob, \n",
    "                      show_topk(*dist.topk(5), indices_fn=tokenizer.convert_ids_to_tokens)) \n",
    "    loss = nn.CrossEntropyLoss()(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "    loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "6ebf074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"./models/model_name\", \n",
    "    overwrite_output_dir=True, do_train=True, do_eval=True,\n",
    "    per_device_train_batch_size=16, per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01, adam_beta2=0.98, adam_epsilon=1e-6,\n",
    "    lr_scheduler_type='constant', learning_rate=5e-3, num_train_epochs=4,\n",
    "    logging_strategy ='epoch', evaluation_strategy ='epoch', save_steps=0,\n",
    "    no_cuda=True, report_to='none',  # to avoid report to wandb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "d89c7d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, training_args, train_dataset=train_dataset, eval_dataset=eval_dataset,\n",
    "                  optimizers=(create_optimizer(model, training_args), None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "b37a9874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.place_model_on_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4b3eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prev(elem):\n",
    "    i, v = elem\n",
    "    return _l[i - 1] if i > 0 else None\n",
    "\n",
    "false = lambda *_: False\n",
    "true  = lambda *_: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721cb66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Element = namedtuple('Element', 'index value')\n",
    "_l = 'A B C B'.split()\n",
    "n = len(_l)\n",
    "# l = [Element._make(e) for e in enumerate(l)]\n",
    "l = seq(_l)\n",
    "l = l.enumerate().map(Element._make)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f22f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "l.map(lambda x: {'B': 'D'}.get(x, x))\n",
    "\n",
    "l.filter(lambda x: get_prev(x) == 'B').select(_.value)\n",
    "\n",
    "find_fn = _.index == 1\n",
    "l.filter(find_fn).select(_.value).map(lower)\n",
    "\n",
    "find_fn = _.value == 'C'\n",
    "l.filter(find_fn).select(_.index)\n",
    "\n",
    "# move x to first\n",
    "update_filter = _.value == 'C'\n",
    "get_new = lambda x: -1\n",
    "l.map(lambda x: Element(update_fn(x, 'index'), x.value)).order_by(_.index).select(_.value)\n",
    "\n",
    "# swap first and last\n",
    "update_filter = true\n",
    "get_new = lambda x: {0: n - 1, n - 1: 0}.get(x.index, x.index)\n",
    "l.map(lambda x: Element(update_fn(x, 'index'), x.value)).order_by(_.index).select(_.value)\n",
    "\n",
    "# get inbetween == drop_while + take_while?\n",
    "\n",
    "# update by index to its prev\n",
    "update_filter = _.index == 1\n",
    "get_new = lambda x: get_prev(x)\n",
    "def update_fn(x, update_field): return get_new(x) if update_filter(x) else getattr(x, update_field)\n",
    "l.map(lambda x: Element(x.index, update_fn(x, 'value')))\n",
    "\n",
    "# if two adjacent elements by indices are equal\n",
    "l.filter(lambda x: x.index in [0, 1]).select(_.value).distinct().len() == 1\n",
    "\n",
    "seq('A B C B C'.split()).group_by(_).select(_[1]).flatten()\n",
    "\n",
    "# count occurance till current\n",
    "seq('A B A C B A'.split()).inits().reverse().tail().map(lambda x: x.filter(_ == x.last()).len())\n",
    "\n",
    "# find special\n",
    "seq('A B A A'.split()).count_by_value().filter(_[1] == 1).select(_[0])\n",
    "\n",
    "# generalized find special\n",
    "seq('A A B C C D D'.split()).group_by(_).map(lambda x: (x[0], len(x[1]))).filter(_[1] == 1).select(_[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
