{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6ea7a72",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (4.17.0)\n",
      "Requirement already satisfied: sacremoses in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: filelock in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (2021.10.8)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/xd/.local/lib/python3.8/site-packages (from transformers) (4.60.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (0.11.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/xd/.local/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages/PyYAML-6.0-py3.8-linux-x86_64.egg (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (1.21.2)\n",
      "Requirement already satisfied: requests in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/xd/.local/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: six in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "0faf2697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.12 | packaged by conda-forge | (default, Jan 30 2022, 23:53:36) \\n[GCC 9.4.0]'"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e11bc1d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pyfunctional\n",
      "  Using cached PyFunctional-1.4.3-py3-none-any.whl (49 kB)\n",
      "Requirement already satisfied: dill>=0.2.5 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from pyfunctional) (0.3.4)\n",
      "Requirement already satisfied: tabulate<=1.0.0 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from pyfunctional) (0.8.9)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pyfunctional\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed pyfunctional-1.4.3\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pyfunctional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "367b7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run \"context_learning_nrk.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9398a888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Is this sentence correct. For example:\n",
      "A is more dangerous to look at than B because A is less luminous. Is that right? -> No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text1 = text\n",
    "print(text1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7292808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54a886cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In file_utils.py: default_cache_path = /raid/xd/.cache/torch/transformers\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ['HF_HOME'] = '/raid/xd/.cache/torch'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from types import MethodType\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, OrderedDict, Counter\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "from itertools import chain\n",
    "import math\n",
    "from functools import reduce\n",
    "import numpy as np \n",
    "# np.set_printoptions(threshold=np.inf)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data.sampler import RandomSampler, Sampler, SequentialSampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from transformers.data.data_collator import DataCollator, default_data_collator\n",
    "from transformers import AutoConfig, pipeline\n",
    "from transformers import RobertaForMaskedLM, RobertaTokenizer, GPT2LMHeadModel, GPT2Tokenizer, GPTNeoForCausalLM, AutoModelForCausalLM\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import HfArgumentParser, Trainer, TrainingArguments, set_seed, AdamW\n",
    "# from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "# from transformers.trainer_utils import EvaluationStrategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f54c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPTNeoForCausalLM, GPTJForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd287822",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/nas/xd/projects/PyFunctional')\n",
    "from functional import seq\n",
    "from functional.pipeline import Sequence\n",
    "from fn import _\n",
    "from collections import namedtuple \n",
    "import sys\n",
    "# sys.path.insert(0, '/nas/xd/projects/transformers/src/transformers')\n",
    "import os\n",
    "# device_mappings = {0: 1, 1: 5, 2: 6, 3: 7, 4: 2, 5: 3, 6: 0, 1: 4}\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(device_mappings[2])\n",
    "\n",
    "import random\n",
    "import string\n",
    "from collections import defaultdict, OrderedDict\n",
    "from itertools import product, chain\n",
    "import math\n",
    "import numpy as np\n",
    "from pattern.en import comparative\n",
    "import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2a577ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/nas/xd/projects/PyFunctional')\n",
    "from functional import seq\n",
    "from functional.pipeline import Sequence\n",
    "from fn import _\n",
    "from collections import namedtuple \n",
    "import sys\n",
    "# sys.path.insert(0, '/nas/xd/projects/transformers/src/transformers')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d5907ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "import openai\n",
    "openai.api_key = open('/nas/xd/projects/openai_api_keys.txt').readlines()[-1].split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "86a17aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Do all students choose courses in a department. For example:\n",
      "D: Chinese, U: Art, A: Art, U: Chinese, D: Art; Art: Chi, Chinese: Eng, Physics: Eng. A and U,Chi? -> Yes\n",
      "\n",
      "Instruction: Do all students choose courses in a department. For example:\n",
      "C: Sql, H: Physics, H: Sql, H: Chemistry, K: Sql; Sql: Chi, Physics: Chi, Chemistry: Eng. H and C,Eng? -> No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_total, n_valid =2,1\n",
    "n_train = n_total - n_valid\n",
    "# input_strs = [make_input_str(tasks[-7], nrows=1, ncols=(3,4,5)) for __ in range(n_total)]# Is the intersection of two sets empty.\n",
    "# input_strs = [make_input_str(tasks[-3], nrows=1, ncols=(4,4,3)) for __ in range(n_total)]# Are there any elements different from other elements\n",
    "# input_strs = [make_input_str(tasks[-4], nrows=1, ncols=(3,4,2,4)) for __ in range(n_total)]# Are_there_elements_belonging_to_the_same_class\n",
    "# input_strs = [make_input_str(tasks[-1], nrows=1, ncols=(5,2)) for __ in range(n_total)]#Is_the_number_of_first_elements_greater_than_the_second_one\n",
    "# input_strs = [make_input_str(tasks[-2], nrows=1, ncols=(3,1), ans_vocab=[0,1,2,3]) for __ in range(n_total)] #How_many_elements_are_similar_to_the_example\n",
    "# input_strs = [make_input_str(tasks[-5], nrows=1, ncols=(3,4,2,4)) for __ in range(n_total)] #Are_they_the_union_of_the_last_element\n",
    "# input_strs = [make_input_str(tasks[-6], nrows=1, ncols=(3,11,5)) for __ in range(n_total)]#Is the first set a subset of the second one\n",
    "input_strs = [make_input_str(tasks[-10], nrows=1, ncols=(3, 3, 2, 5)) for __ in range(n_total)]\n",
    "# input_strs = [make_input_str(tasks[-9], nrows=1, ncols=(4,2)) for __ in range(n_total)] #Compare the values of two sets.\n",
    "# input_strs = [make_input_str(tasks[-8], nrows=1, ncols=(4, 4, 4)) for __ in range(n_total)] #Relationship between two sets.\n",
    "\n",
    "for s in sample(input_strs, 2): print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "21465a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_fn(engine):  # XD\n",
    "    def fn(text):\n",
    "        return openai.Completion.create(engine=engine, prompt=text, max_tokens=1, echo=True, logprobs=5).choices[0]\n",
    "    return fn\n",
    "\n",
    "engines = ['davinci', 'curie']\n",
    "for engine in engines:\n",
    "    model_name = 'openai_api_' + engine\n",
    "#     model = lambda x: openai.Completion.create(engine=engine, prompt=x, max_tokens=0, echo=True, logprobs=5).choices[0]\n",
    "    model = get_model_fn(engine)\n",
    "    models[model_name] = model, tokenizer\n",
    "    \n",
    "# model_name = 'openai_api_davinci'\n",
    "model_name = 'openai_api_curie'\n",
    "model, tokenizer = models[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "bf3af01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['EleutherAI/gpt-j-6B'])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "693f563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_dist(d, topk=5): return {k: round(math.exp(v), 3) for k, v in sorted(d.items(), key=lambda x: x[1], reverse=True)[:topk]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "77d1817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ans_indices0(input_ids):\n",
    "    bos_id = tokenizer._convert_token_to_id('Ġ->')\n",
    "    eos_id = tokenizer._convert_token_to_id('Ċ')\n",
    "    bos_indices = (input_ids == bos_id).nonzero().squeeze(1).tolist()\n",
    "    eos_indices = (input_ids == eos_id).nonzero()[-len(bos_indices):].squeeze(1).tolist()\n",
    "    return bos_indices, eos_indices\n",
    "\n",
    "# def get_ans_indices1(input_ids):\n",
    "#     bos_id = tokenizer._convert_token_to_id('?')\n",
    "# #     print(\"bos_id\",bos_id)\n",
    "#     eos_id = tokenizer._convert_token_to_id('Ċ')\n",
    "#     period_ids = [tokenizer._convert_token_to_id('.'), tokenizer._convert_token_to_id('Ġ.')]\n",
    "# #     print(\"period_ids:\",period_ids)\n",
    "# #     l_bracket_id, r_bracket_id = tokenizer._convert_token_to_id('Ġ['), tokenizer._convert_token_to_id('Ġ]')\n",
    "# #     print(\"l_bracket_id\",l_bracket_id)\n",
    "# #     print(\"r_bracket_id:\",r_bracket_id)\n",
    "#     eos_indices = (input_ids == eos_id).nonzero().squeeze(1).tolist() #.nonezero()取非零元素坐标\n",
    "# #     print(\"eos_indices0:\",eos_indices)\n",
    "#     eos_indices = [i - 1 if input_ids[i - 1] in period_ids else i for i in eos_indices]\n",
    "# #     print(\"eos_indices1:\",eos_indices)\n",
    "# #     eos_indices = [i - 1 if input_ids[i - 1] == r_bracket_id else i for i in eos_indices]\n",
    "# #     print(\"eos_indices2:\",eos_indices)\n",
    "    \n",
    "#     def find_bos_index(start_i):\n",
    "#         for bos_i in range(start_i, start_i - 3, -1):\n",
    "# #             if input_ids[bos_i] == bos_id or input_ids[bos_i] == l_bracket_id and input_ids[bos_i - 1] == bos_id:\n",
    "#             if input_ids[bos_i] == bos_id:\n",
    "#                 if bos_i != start_i: print('subtokens:', tokenizer.convert_ids_to_tokens(input_ids[bos_i + 1: start_i + 2]))\n",
    "#                 return bos_i\n",
    "#         assert False\n",
    "#     bos_indices = [find_bos_index(i - 2) for i in eos_indices]\n",
    "# #     print(\"bos:\",bos_indices)\n",
    "# #     print(\"eos:\",eos_indices)\n",
    "#     return bos_indices, eos_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "bb474e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_num = 0\n",
    "def predict(model, text, ans_indices_fn, topk=5, return_reduced_loss=False, verbose=True):\n",
    "    use_openai_api = type(model) in [types.MethodType, types.FunctionType]  # openai.Completion.create\n",
    "    print(\"[]\",[types.MethodType, types.FunctionType])\n",
    "    print(\"type(model):\",type(model))\n",
    "    inputs = tokenizer.encode_plus(text, return_tensors='pt')\n",
    "    print(inputs)\n",
    "    input_ids = inputs.input_ids\n",
    "#     print(input_ids)\n",
    "    bsz = input_ids.size(0)\n",
    "#     print(\"bsz = \",bsz)\n",
    "    labels = torch.ones_like(input_ids) * (-100)\n",
    "    if use_openai_api:\n",
    "        assert bsz == 1\n",
    "#         outputs = model(engine=engine, prompt=text, max_tokens=0, echo=True, logprobs=5).choices[0].logprobs\n",
    "        outputs = model(text).logprobs  # XD\n",
    "        ans_nlls = []\n",
    "    else:\n",
    "        inputs = prepare_inputs(inputs, model.device)\n",
    "        outputs = model(**inputs, output_attentions=False)\n",
    "        logits = outputs.logits\n",
    "    for bi in range(bsz):\n",
    "\n",
    "        bos_indices, eos_indices = ans_indices_fn(input_ids[bi])\n",
    "#         print(\"input_ids :\",input_ids[bi])\n",
    "#         print(\"ans_indices_fn:\",ans_indices_fn(input_ids[bi]))\n",
    "#         print(\"bos_indices:\",bos_indices)\n",
    "#         print(\"eos_indices:\",eos_indices)\n",
    "        examples = text.strip().split('\\n')\n",
    "#         print(\"bos_indices:\",bos_indices)\n",
    "        print(\"examples:\",examples)\n",
    "        assert len(bos_indices) == len(examples)-1, '%d != %d' % (len(bos_indices), len(examples))\n",
    "        num = 0\n",
    "        for i, (example, bos_i, eos_i) in enumerate(zip(examples, bos_indices, eos_indices)):\n",
    "#             if verbose: print(' ' + example, end='\\t')\n",
    "            ans_ids = input_ids[bi, bos_i + 1: eos_i]\n",
    "            print(\"ans_ids:\",ans_ids)\n",
    "            labels[bi, bos_i: eos_i - 1] = ans_ids\n",
    "            if use_openai_api:\n",
    "                ans_prob_dist = [get_prob_dist(d, topk=topk) for d in outputs.top_logprobs[bos_i + 1: eos_i]]\n",
    "                ans_probs = [math.exp(lp) for lp in outputs.token_logprobs[bos_i + 1: eos_i]]\n",
    "                ans_nlls += [-lp for lp in outputs.token_logprobs[bos_i + 1: eos_i]]\n",
    "            else:\n",
    "                ans_prob_dist = logits[bi, bos_i: eos_i - 1].softmax(-1)\n",
    "                ans_probs = ans_prob_dist[torch.arange(ans_prob_dist.size(0)), ans_ids]\n",
    "            ans_tokens = tokenizer.convert_ids_to_tokens(ans_ids)\n",
    "            num += 1\n",
    "            for ans_id, ans_token, ans_prob, dist in zip(ans_ids, ans_tokens, numpy(ans_probs, decimals=3), ans_prob_dist):\n",
    "                top1_correct = max(dist.items(), key=lambda x: x[1])[0] == ans_token.replace('Ġ', ' ') \\\n",
    "                    if use_openai_api else (dist.argmax() == ans_id).item()  \n",
    "                \n",
    "                if verbose:\n",
    "                    if(num == 1 and top1_correct):\n",
    "                        global correct_num\n",
    "                        correct_num += 1\n",
    "                    if(len(ans_tokens) <= 1):\n",
    "#                         if(top1_correct):\n",
    "#                             dictlocation1[example] = 1\n",
    "                        print(('！！！' if top1_correct else ' ') + ans_token, ans_prob, \n",
    "                              dist if use_openai_api else show_topk(*dist.topk(topk), indices_fn=tokenizer.convert_ids_to_tokens)) \n",
    "                        \n",
    "                    else:\n",
    "                        pass\n",
    "    if use_openai_api:\n",
    "        loss = ans_nlls if return_reduced_loss else sum(ans_nlls) / len(ans_nlls)\n",
    "    else:\n",
    "        loss = nn.CrossEntropyLoss()(logits.view(-1, logits.size(-1)), labels.view(-1)) if return_reduced_loss \\\n",
    "            else nn.CrossEntropyLoss(reduction='none')(logits.view(-1, logits.size(-1)), labels.view(-1))[labels.view(-1)>=0].tolist()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "f49b21a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Instruction: Do all students choose courses in a department. For example:\n",
      "D: Chinese, U: Art, A: Art, U: Chinese, D: Art; Art: Chi, Chinese: Eng, Physics: Eng. A and U,Chi? -> Yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(input_strs))\n",
    "print(input_strs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "490ff768",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [<class 'method'>, <class 'function'>]\n",
      "type(model): <class 'function'>\n",
      "{'input_ids': tensor([[ 6310,  2762,    25,  2141,   477,  2444,  3853, 10902,   287,   257,\n",
      "          5011,    13,  1114,  1672,    25,   198,    35,    25,  3999,    11,\n",
      "           471,    25,  3683,    11,   317,    25,  3683,    11,   471,    25,\n",
      "          3999,    11,   360,    25,  3683,    26,  3683,    25, 21380,    11,\n",
      "          3999,    25,  1985,    11, 23123,    25,  1985,    13,   317,   290,\n",
      "           471,    11,  1925,    72,    30,  4613,  3363,   198]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'D: Chinese, U: Art, A: Art, U: Chinese, D: Art; Art: Chi, Chinese: Eng, Physics: Eng. A and U,Chi? -> Yes']\n",
      "ans_ids: tensor([3363])\n",
      " ĠYes 0.008 {' A': 0.086, ' U': 0.047, ' D': 0.037, ' Art': 0.031, ' Eng': 0.025}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.8359756"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [<class 'method'>, <class 'function'>]\n",
      "type(model): <class 'function'>\n",
      "{'input_ids': tensor([[ 6310,  2762,    25,  2141,   477,  2444,  3853, 10902,   287,   257,\n",
      "          5011,    13,  1114,  1672,    25,   198,    34,    25,   311, 13976,\n",
      "            11,   367,    25, 23123,    11,   367,    25,   311, 13976,    11,\n",
      "           367,    25, 27867,    11,   509,    25,   311, 13976,    26,   311,\n",
      "         13976,    25, 21380,    11, 23123,    25, 21380,    11, 27867,    25,\n",
      "          1985,    13,   367,   290,   327,    11,  7936,    30,  4613,  1400,\n",
      "           198]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'C: Sql, H: Physics, H: Sql, H: Chemistry, K: Sql; Sql: Chi, Physics: Chi, Chemistry: Eng. H and C,Eng? -> No']\n",
      "ans_ids: tensor([1400])\n",
      " ĠNo 0.018 {' H': 0.067, ' S': 0.056, ' Eng': 0.045, ' C': 0.03, ' K': 0.026}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.990212"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_num = 0\n",
    "for i in input_strs:\n",
    "# for i in text1:\n",
    "    text = i\n",
    "    predict(model, text, get_ans_indices0, verbose=True, topk=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c1fe66",
   "metadata": {},
   "source": [
    "# 从这里开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58cba5e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from child_utils import *\n",
    "from common_utils import *\n",
    "from model_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90f62ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "# cache_dir = '/nas/xd/.cache/torch/transformers/'  # for models besides t5-3b/11b\n",
    "cache_dir = '/mnt/nvme1/xd/.cache/torch/transformers/'  # for gpt-j-6B on elderberry\n",
    "proxies = {'http': '192.168.50.1:1081'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "520d34a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = \"EleutherAI/gpt-j-6B\"\n",
    "# model_name = \"EleutherAI/gpt-neo-1.3B\"\n",
    "# model = GPTJForCausalLM.from_pretrained(model_name, proxies=proxies, cache_dir=cache_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, proxies=proxies, cache_dir=cache_dir)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', cache_dir=cache_dir)\n",
    "models[model_name] = model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "830ce082",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.eval()\n",
    "unify(model)\n",
    "blocks = model.transformer.h\n",
    "attn = blocks[0].attn\n",
    "ln_f = model.transformer.ln_f\n",
    "L, H, embed_dim = len(blocks), attn.num_heads, attn.embed_dim\n",
    "\n",
    "_we = model.transformer.wte.weight.data.t()\n",
    "_wu = model.lm_head.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e50583a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTJAttention(\n",
       "  (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "  (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "  (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c128d0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LayerNorm((4096,), eps=1e-05, elementwise_affine=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd64c2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcbfafc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "we = _we\n",
    "wu = _wu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d82cfd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50400, 4096])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_wu.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef8becf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def T(f): return lambda x: f(x.T).T\n",
    "mlp = lambda x: mlp_forward(blocks[0], x)\n",
    "v = we.size(1) #// 2\n",
    "_we, _wu = we[:, :v], wu[:v]\n",
    "with torch.no_grad(): _e = mlp(_we.T) + _we.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc605c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50400"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9a94c107",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer, head = 4, 5# prev ov: 13-9, next num ov: 14-13, next word ov: 13-4, prepend space ov: 18-3/17-10, isa ov: 14-7, antonym ov: 16-14, copy ov 13-2\n",
    "wq, wk, wv, wo = get_head_weights(model, layer, head, transpose=True)\n",
    "with torch.no_grad():\n",
    "    eq = ek = e = blocks[layer].ln_1(_e)\n",
    "    # A, B = _wu, ln_f(e @ wv @ wo)\n",
    "    A, B = _wu @ wo.T, e @ wv\n",
    "    q, k = eq @ wq, ek @ wk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a7f6529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qk = True\n",
    "with torch.no_grad():  # ve,ed,de,ev->vv\n",
    "    # _m = ln(mlp(_we.T)) @ (wq.T @ wk) @ T(ln)(T(mlp)(_we)) if qk else _wu @ T(ln_f)(wo @ (wv @ T(ln)(T(mlp)(_we))))\n",
    "    _m = q @ k.T if qk else _wu @ ln_f(B @ wo).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "459d21eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.17757728695869446"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_eigv((k.T @ q).eig()[0] if qk else (B.T @ A).eig()[0], start_i=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "801cf7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = _m  # q->k, output->input\n",
    "# m = _m.T  # k->q, input->output\n",
    "values, indices = m.topk(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601637bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "( -> )\n",
    "[ -> ]\n",
    "{ -> }\n",
    "(( -> ))\n",
    "< -> >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d258e52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]] {':[': 92, ')[': 89, 'Ġ[[': 88, '([': 87, '=[': 87, ').[': 85}\n",
      ")] {':[': 94, ')[': 92, ').[': 88, 'Ġ[': 87, '\":[': 84, '=[': 83}\n",
      ".] {':[': 87, ')[': 84, ').[': 84, 'Ġ[': 83, '>[': 82, 'Ġ[[': 80}\n",
      "Ġ))) {')=(': 88, ')(': 85, 'Ġ((': 83, ':(': 82, 'Ġ(': 82, '((': 81}\n",
      ")))) {')=(': 89, ')(': 85, 'Ġ((': 82, 'Ġ(': 81, '((': 79, '))))': 78}\n",
      "))) {')=(': 86, 'Ġ((': 84, ')(': 84, 'Ġ(': 81, '((': 79, ':(': 78}\n",
      ")) {')=(': 84, 'Ġ((': 83, ')(': 82, ':(': 79, 'Ġ(': 79, '((': 79}\n",
      "]) {'Ġ((': 83, 'Ġ([': 80, '((': 79, ')=(': 78, 'Ġ(': 77, '([': 77}\n",
      "?] {')[': 82, 'Ġ[': 82, ':[': 80, ').[': 79, '=[': 75, '\":[': 75}\n",
      "\")) {')=(': 81, 'Ġ((': 81, 'Ġ(': 78, ')(': 78, '((': 77, ':(': 75}\n",
      "...] {':[': 84, 'Ġ[': 81, '([': 78, ')[': 76, 'Ġ([': 76, ').[': 75}\n",
      "!] {':[': 80, 'Ġ[': 79, ')[': 79, '=[': 75, ').[': 74, '\":[': 74}\n",
      "\"] {'Ġ[': 78, ':[': 77, '\":[\"': 77, 'Ġ[\"': 74, ')[': 74, 'Ġ[[': 74}\n",
      "Ġ)) {')=(': 79, ':(': 79, 'Ġ((': 77, ')(': 76, '((': 75, 'Ġ(': 73}\n",
      "Ġ] {':[': 81, 'Ġ[': 75, ').[': 74, ')[': 74, '\":[': 73, '=[': 71}\n",
      "\"], {':[': 78, 'Ġ[[': 76, '\":[\"': 73, '([': 73, 'Ġ[': 72, 'Ġ([': 71}\n",
      "Ġ)] {')[': 76, ':[': 75, 'Ġ[': 74, ').[': 72, 'Ġ([': 71, '=[': 70}\n",
      ".} {'}{': 75, '){': 72, '{': 71, '{\\\\': 70, 'Ġ{{': 70, '{{': 70}\n",
      "]( {')[': 76, ':[': 75, ').[': 72, 'Ġ[[': 70, 'Ġ[': 69, '=[': 66}\n",
      "]+ {':[': 74, 'Ġ[': 73, '=[': 73, '([': 69, 'Ġ[[': 68, 'Ġ([': 66}\n",
      "Ġ*) {'Ġ(': 74, ':(': 71, 'Ġ((': 71, ')=(': 70, '((': 67, 'Ġ$(': 67}\n",
      "] {':[': 76, 'Ġ[': 72, ')[': 70, 'Ġ[[': 70, ').[': 68, '=[': 66}\n",
      "],\" {'\":[\"': 76, '\":[': 75, 'Ġ\"[': 72, ':[': 68, '\".[': 68, 'Ġ[\"': 68}\n",
      "}}} {'}{': 79, 'Ġ{{': 73, '{{': 73, '){': 68, '{\\\\': 65, 'Ġ{\\\\': 65}\n",
      "]' {\"Ġ'[\": 97, ':[': 73, \"Ġ'(\": 71, 'Ġ[': 66, \"Ġ['\": 64, '=[': 63}\n",
      "!) {'Ġ(': 73, 'Ġ((': 69, ')(': 68, ':(': 68, ')=(': 67, '(': 66}\n",
      "]- {':[': 73, 'Ġ[': 72, '-[': 70, ')[': 67, 'Ġ[[': 66, '=[': 65}\n",
      "%] {':[': 72, 'Ġ[[': 70, 'Ġ[': 69, 'Ġ<[': 67, ')[': 66, ').[': 66}\n",
      "Ġ]) {'Ġ([': 73, '([': 72, 'Ġ((': 71, '((': 67, ':(': 65, 'Ġ(': 64}\n",
      "') {\"Ġ'(\": 75, 'Ġ((': 70, 'Ġ(': 66, '((': 66, ':(': 64, ')=(': 63}\n",
      "], {':[': 73, 'Ġ[[': 70, 'Ġ[': 67, '=[': 66, '([': 66, 'Ġ([': 64}\n",
      "\") {'Ġ\"(': 68, 'Ġ((': 67, 'Ġ(': 67, ':(': 65, '((': 64, ')=(': 64}\n",
      "...) {':(': 70, 'Ġ(': 70, 'Ġ((': 69, \"Ġ'(\": 67, ')=(': 64, '((': 63}\n",
      "'] {\"Ġ'[\": 70, ':[': 70, 'Ġ[': 65, 'Ġ[[': 65, \"Ġ['\": 65, ')[': 64}\n",
      "]} {'}{': 72, '){': 68, 'Ġ{{': 65, ')[': 65, ':[': 63, '{': 62}\n",
      "Ġ}} {'}{': 73, 'Ġ{{': 72, '{{': 71, '={': 63, '){': 63, '{\\\\': 62}\n",
      "Ġ], {':[': 72, 'Ġ[': 69, '=[': 67, '([': 66, 'Ġ[[': 64, 'Ġ([': 61}\n",
      ")' {\"Ġ'(\": 94, \"Ġ'[\": 74, ')=(': 65, \"('\": 60, \"Ġ('\": 59, '>(': 59}\n",
      ")), {'Ġ((': 70, ')=(': 68, 'Ġ(': 67, ')(': 66, '))))': 65, '((': 64}\n",
      ">] {':[': 70, ').[': 68, 'Ġ[': 67, ')[': 65, 'Ġ[[': 63, 'Ġ([': 62}\n",
      "}} {'}{': 71, 'Ġ{{': 68, '{{': 67, '){': 64, '{\\\\': 61, 'Ġ{\\\\': 61}\n",
      "?) {'Ġ(': 68, 'Ġ((': 68, ')=(': 65, ':(': 64, \"Ġ'(\": 63, ')(': 63}\n",
      ":] {':[': 67, 'Ġ[': 66, ').[': 65, ')[': 63, '=[': 63, 'Ġ([': 63}\n",
      "âĢ¦] {':[': 70, 'Ġ[': 69, ').[': 66, ')[': 66, 'Ġ([': 62, 'Ġ[[': 60}\n",
      "]\" {'Ġ\"[': 76, '\":[': 68, '\".[': 66, '\"[': 65, '\":[\"': 60, 'Ġ[\"': 59}\n",
      ")( {'Ġ((': 68, ')=(': 66, 'Ġ(': 66, ':(': 64, '((': 63, 'Ġ[(': 62}\n",
      "\"} {'\":{\"': 66, '\":[{\"': 66, 'Ġ([': 62, ':[': 61, 'Ġ{{': 61, 'Ġ{\"': 61}\n",
      "Ġ.) {'Ġ(': 68, 'Ġ((': 65, ':(': 63, '((': 61, '(': 61, \"Ġ'(\": 60}\n",
      "}) {'Ġ((': 66, ')=(': 65, ':(': 64, '((': 63, '({': 61, 'Ġ(': 61}\n",
      "Ġ()) {')=(': 69, 'Ġ((': 64, 'Ġ(': 64, '=(': 62, '>(': 60, ':(': 60}\n",
      ")\", {'Ġ\"(': 68, '\":\"': 68, '\"(': 63, '(\"': 61, '))))': 61, 'Ġ(\"': 58}\n",
      ".) {'Ġ((': 66, 'Ġ(': 66, ')=(': 62, '((': 61, ':(': 61, ')(': 60}\n",
      "+) {'Ġ((': 67, '((': 63, ':(': 63, 'Ġ(': 62, ')=(': 61, \"Ġ'(\": 61}\n",
      "Ġ) {'Ġ(': 64, 'Ġ((': 64, ':(': 64, ')=(': 63, ')(': 59, '((': 59}\n",
      ") {'Ġ((': 67, 'Ġ(': 65, ':(': 62, ')=(': 61, '((': 60, ')(': 59}\n",
      "\"}],\" {'Ġ([': 67, '([': 65, 'Ġ[': 63, '\":[': 61, '\":[\"': 59, 'Ġ[[': 59}\n",
      ",) {'Ġ(': 64, '>(': 62, ')=(': 62, 'Ġ((': 62, ':(': 59, '(': 58}\n",
      "anuts {'ĠMarketable': 63, 'ĠNether': 60, 'ĠGoblin': 60, 'ĠMonsanto': 59, 'ĠCommodore': 59, 'ĠMcDonnell': 58}\n",
      "++) {':(': 65, 'Ġ((': 64, 'Ġ(': 63, ')=(': 62, ')(': 61, '((': 57}\n",
      "*) {'Ġ(*': 64, 'Ġ(': 62, ')=(': 60, 'Ġ((': 60, 'Ġ$(': 60, '>(': 57}\n",
      "\"}, {'\":[{\"': 63, '}{': 62, 'Ġ{{': 60, 'Ġ({': 59, '{{': 58, '({': 58}\n",
      "-) {'Ġ((': 64, 'Ġ(': 62, ':(': 60, '((': 59, ')(': 59, ')=(': 59}\n",
      "',\" {'\":\"': 68, 'Ġ\"\\'': 62, '(\"': 59, 'Ġ\"\"': 59, 'Ġ\"': 58, '=\"': 58}\n",
      "][ {':[': 69, 'Ġ[': 63, '=[': 60, '[': 59, '\":[': 58, ')[': 56}\n",
      "]), {'Ġ((': 65, 'Ġ(': 61, ')=(': 60, '((': 59, 'Ġ([': 59, ')(': 57}\n",
      ")\" {'Ġ\"(': 78, '\"(': 70, '\"))': 57, '))))': 56, '\":\"': 56, 'Ġ\"[': 56}\n",
      "}{ {'}{': 67, '{{': 65, 'Ġ{{': 62, '{\\\\': 60, '{': 59, '){': 57}\n",
      "]; {':[': 66, 'Ġ[[': 59, 'Ġ<[': 59, '=[': 59, 'Ġ[': 59, '([': 56}\n",
      "'), {'Ġ((': 65, '((': 59, \"Ġ'(\": 59, 'Ġ(': 58, ')=(': 57, \"('\": 56}\n",
      ">) {'Ġ((': 62, ':(': 60, ')=(': 60, 'Ġ(': 59, '((': 58, ')(': 58}\n",
      "Ġ)); {')=(': 63, ':(': 61, 'Ġ((': 60, 'Ġ(': 59, '((': 59, '>(': 56}\n",
      ")} {'}{': 66, '){': 65, 'Ġ{{': 57, 'Ġ{\\\\': 56, 'Ġ{': 55, '{': 55}\n",
      ".\") {'Ġ\"(': 60, 'Ġ(': 59, 'Ġ((': 58, '(\\\\': 58, ':(': 56, '((': 56}\n",
      "]= {':[': 63, 'Ġ[': 62, 'Ġ[[': 60, ').[': 56, ')[': 55, 'Ġ([': 55}\n",
      "Ġ}, {'}{': 61, 'Ġ({': 60, '({': 57, '{': 57, '={': 56, 'Ġ{{': 56}\n",
      "]); {'Ġ([': 62, '([': 61, ':[': 59, 'Ġ((': 59, 'Ġ[(': 56, 'Ġ(': 55}\n",
      "Ġ]; {':[': 65, '=[': 60, '([': 57, 'Ġ[': 56, 'Ġ([': 56, ').[': 56}\n",
      "\"]=> {':[': 64, 'Ġ[\"': 63, 'Ġ[': 59, 'Ġ[[': 59, '\":[\"': 57, ').[': 53}\n",
      "],[ {':[': 63, 'Ġ[[': 62, '([': 60, 'Ġ[': 59, '[[': 57, '=[': 53}\n",
      ")]. {':[': 62, ')[': 61, 'Ġ[': 60, 'Ġ[[': 58, ').[': 56, 'Ġ([': 55}\n",
      "].\" {'\":[': 64, 'Ġ\"[': 60, '\":[\"': 59, ':[': 58, '\".[': 57, '\"[': 53}\n",
      "Ġ}) {'({': 63, 'Ġ({': 60, 'Ġ((': 59, ':(': 56, '((': 56, 'Ġ(': 54}\n",
      ")</ {'>(': 71, ')=(': 59, 'Ġ((': 55, 'Ġ(': 54, ':(': 53, 'Ġ$(': 53}\n",
      ")| {')=(': 63, 'Ġ((': 60, 'Ġ[(': 58, '((': 57, '=(': 56, 'Ġ(': 54}\n",
      "âĢ¦) {'Ġ(': 62, ':(': 60, 'Ġ((': 58, ')=(': 55, ')(': 55, '>(': 54}\n",
      ";} {'}{': 61, '){': 60, 'Ġ{\\\\': 57, 'Ġ{{': 56, 'Ġ{*': 54, 'Ġ{:': 53}\n",
      ")\\ {'Ġ(': 61, 'Ġ((': 60, ')=(': 57, ':(': 56, ')(': 55, '((': 55}\n",
      "\"), {'Ġ((': 62, 'Ġ(': 59, '((': 57, ')=(': 57, ':(': 55, '=(': 54}\n",
      "\"/> {'><': 61, 'Ġ><': 60, 'Ġ<[': 57, 'Ġ(<': 57, 'Ġ<': 56, '\"><': 56}\n",
      "]: {':[': 64, ').[': 58, 'Ġ[[': 58, '=[': 56, '>[': 54, ')[': 54}\n",
      "%) {'Ġ((': 61, ':(': 59, 'Ġ(': 57, 'Ġ$(': 56, '((': 55, ')=(': 54}\n",
      "Ġ?) {'Ġ(': 61, 'Ġ((': 59, \"Ġ'(\": 56, '((': 54, ':(': 53, ')=(': 53}\n",
      ")* {')=(': 59, 'Ġ(*': 56, '>(': 56, '=(': 55, 'Ġ$(': 54, 'Ġ((': 53}\n",
      "Ġ][ {':[': 65, 'Ġ[': 60, ')[': 57, '=[': 57, '[': 55, ').[': 50}\n",
      ".>> {'Ġ<[': 66, '><': 59, 'Ġ><': 56, 'Ġ(<': 55, '\"><': 53, '.<': 53}\n",
      ")/ {'Ġ((': 62, '((': 58, 'Ġ(': 54, ':(': 54, ')=(': 54, '>(': 52}\n",
      "Ġ), {'Ġ((': 58, ')=(': 58, 'Ġ(': 57, '=(': 54, ':(': 54, '((': 52}\n",
      "Ġ]. {':[': 59, 'Ġ[': 57, ')[': 55, 'Ġ[[': 55, ').[': 54, '=[': 54}\n",
      ")); {')=(': 58, 'Ġ((': 56, 'Ġ(': 56, ':(': 54, '))))': 53, ')(': 53}\n",
      "!), {'Ġ(': 58, 'Ġ((': 57, ':(': 54, ')=(': 54, ')(': 53, '((': 53}\n",
      "),\" {'Ġ\"(': 66, '\"(': 59, '\":\"': 54, '>(': 52, '(\"': 52, '))))': 51}\n",
      "\", {'\":\"': 64, '=\"': 56, '\":[\"': 54, '(\"': 53, '=\"\"': 53, 'Ġ[\"': 52}\n",
      "), {'Ġ((': 61, 'Ġ(': 58, ')=(': 56, '((': 55, ':(': 53, '=(': 52}\n",
      ")[ {')=(': 58, 'Ġ(': 57, ':(': 56, ')(': 53, '](': 53, 'Ġ((': 53}\n",
      "Ġ;) {'Ġ(': 60, ':(': 59, 'Ġ((': 58, '((': 53, \"Ġ'(\": 51, '>(': 50}\n",
      "/) {'Ġ(': 57, 'Ġ((': 57, ':(': 54, 'Ġ$(': 53, 'Ġ(/': 53, ')=(': 52}\n",
      ".), {'Ġ((': 58, ')=(': 56, 'Ġ(': 56, '((': 53, ':(': 53, '=(': 53}\n",
      ")! {'Ġ(': 60, ')(': 56, 'Ġ((': 56, ')=(': 54, ':(': 54, 'Ġ$(': 51}\n",
      "objects {'ĠDACA': 58, 'ĠAdministrative': 54, 'Ġrenewables': 53, 'ĠMiscellaneous': 53, 'ĠMillennium': 52, 'ĠAccountability': 52}\n",
      "SourceFile {'ĠOblivion': 55, 'ĠBabylon': 54, 'ĠScion': 54, 'ĠYosemite': 53, 'ĠHogwarts': 53, 'ĠControls': 52}\n",
      "ãĢı {\"Ġ'[\": 66, 'ãĢİ': 59, ':[': 54, 'Ġ[': 52, \"Ġ['\": 51, 'Ġ[[': 50}\n",
      "}, {'}{': 56, '={': 54, 'Ġ{{': 53, 'Ġ({': 53, '){': 52, '({': 52}\n",
      "'.\" {'Ġ\"\\'': 61, '\":\"': 56, 'Ġ\"': 53, '=\"': 52, '(\"': 51, 'Ġ\"\\\\': 50}\n",
      "Ġ} {'){': 58, '{': 55, '}{': 55, 'Ġ{': 53, 'Ġ{\\\\': 51, 'Ġ{{': 51}\n",
      "Ġ:) {'Ġ(': 58, 'Ġ((': 57, ':(': 57, '((': 55, 'Ġ$(': 51, '(': 49}\n",
      "\"],\" {'\":[\"': 59, 'Ġ[\"': 57, 'Ġ[[': 54, ':[': 52, 'Ġ([': 50, '([': 50}\n",
      "archives {'ĠMiscellaneous': 54, 'Ġherpes': 53, 'ĠGears': 52, 'ĠToyota': 52, 'ĠKeystone': 52, 'ĠSirius': 51}\n",
      "Malley {'ĠCassidy': 54, 'ĠRidley': 54, 'ĠMarcel': 53, 'ĠClifford': 53, 'ĠNeptune': 51, 'ĠLowell': 51}\n",
      ").\" {'Ġ\"(': 66, '\"(': 58, '\":\"': 51, '))))': 50, '(\"': 49, 'Ġ\"[': 49}\n",
      ")). {'Ġ(': 58, 'Ġ((': 55, ')(': 54, ')=(': 53, '((': 50, ':(': 49}\n",
      "ĠGorsuch {'ĠPercy': 55, 'ĠMarcel': 54, 'ĠBryce': 52, 'ĠDACA': 51, 'ĠClyde': 50, 'ĠGorsuch': 50}\n",
      "ipop {'ĠMonsanto': 54, 'ĠMercury': 53, 'ĠElephant': 53, 'ĠOsama': 52, 'ĠCinnamon': 51, 'ĠKimberly': 50}\n",
      "?), {'Ġ((': 58, 'Ġ(': 55, ')=(': 54, ')(': 51, '((': 51, ':(': 50}\n",
      "Ġ:-) {'Ġ(': 57, ':(': 57, 'Ġ((': 53, '((': 50, ')=(': 50, ')(': 49}\n",
      "()) {'Ġ((': 55, 'Ġ(': 55, ')=(': 53, ':(': 53, 'Ġ$(': 51, ')(': 50}\n",
      "}\\ {'){': 52, 'Ġ{{': 52, '{{': 52, '}{': 52, '{': 51, '{\\\\': 49}\n",
      "anamo {'ĠLazarus': 52, 'ĠFlynn': 51, 'ĠDACA': 51, 'ĠDraco': 51, 'ĠFallout': 50, 'ĠMueller': 49}\n",
      "iddler {'ĠSuperman': 52, 'ĠAstral': 51, 'ĠMercury': 51, 'ĠBreitbart': 50, 'ĠGarrison': 50, 'ĠLibertarian': 49}\n",
      "...\" {'\":\"': 61, 'Ġ\"...': 53, 'Ġ\"âĢ¦': 51, 'Ġ\"\\\\': 49, 'Ġ\"<': 48, 'Ġ\"{': 48}\n",
      "} {'){': 53, '}{': 51, 'Ġ{{': 50, 'Ġ{\\\\': 50, '{': 50, 'Ġ{': 49}\n",
      "}\" {'Ġ\"{': 66, 'Ġ\"(': 50, 'Ġ\"[': 50, '\":{\"': 50, '\":\"': 49, 'Ġ{\"': 47}\n",
      "Materials {'ĠDACA': 55, 'ĠYellowstone': 51, 'ĠYosemite': 50, 'ĠOTHER': 50, 'ĠMetatron': 49, 'ĠMarriott': 48}\n",
      "bestos {'ĠBoko': 54, 'ĠGalile': 50, 'ĠHerbert': 50, 'ĠLudwig': 50, 'ĠLivingston': 49, 'ĠArlington': 49}\n",
      ")=( {'Ġ(': 56, 'Ġ((': 53, ')=(': 52, ')(': 51, ':(': 50, 'Ġ$(': 49}\n",
      "/> {'Ġ<': 56, 'Ġ><': 54, 'Ġ(<': 54, '><': 52, 'Ġ<[': 50, '<': 48}\n",
      "Ġ/> {'><': 61, 'Ġ><': 56, 'Ġ<': 51, '\"><': 51, 'Ġ<[': 48, '.<': 48}\n",
      "pheus {'ĠCutler': 51, 'ĠLucifer': 51, 'ĠDagger': 50, 'ĠPercy': 49, 'ĠOPT': 48, 'ĠSequ': 48}\n",
      ")... {'Ġ(': 57, ':(': 54, ')=(': 52, 'Ġ((': 50, '=(': 47, ')(': 47}\n",
      "lehem {'ĠWillow': 55, 'ĠFuller': 53, 'ĠHighlander': 48, 'ĠMcCabe': 48, 'ĠMercy': 48, 'ĠLowell': 48}\n",
      "orporated {'ĠDACA': 53, 'ĠWellington': 51, 'ĠTsukuyomi': 49, 'ĠEmmanuel': 49, 'ĠKimberly': 49, 'ĠAntioch': 48}\n",
      "}; {'Ġ{{': 51, ':{': 51, '}{': 51, 'Ġ{:': 49, '={': 48, '{{': 48}\n",
      "âĢ¦.\" {'\":\"': 60, 'ĠCatalyst': 52, 'Ġ\"[': 48, 'Ġ\"(': 48, 'Ġ\"...': 48, 'Ġ\"âĢ¦': 47}\n",
      "acons {'ĠAtlantis': 52, 'ĠCic': 50, 'ĠOthers': 50, 'ĠToyota': 48, 'ĠUFO': 48, 'Ġrenewables': 48}\n",
      "earcher {'ĠKimberly': 51, 'ĠMelvin': 50, 'ĠWellington': 50, 'ĠHighland': 48, 'ĠRudolph': 48, 'ĠFrederick': 48}\n",
      "azeera {'ĠValhalla': 51, 'ĠMalik': 50, 'ĠHighlander': 49, 'ĠBigfoot': 49, 'ĠWarlock': 48, 'ĠBabylon': 48}\n",
      "holes {'ĠBarbarian': 51, 'ĠGears': 49, 'ĠToyota': 49, 'ĠGenetics': 48, 'ĠFisheries': 48, 'ĠTelecommunications': 48}\n",
      ")= {'Ġ((': 54, 'Ġ$(': 51, 'Ġ(': 51, ')=(': 50, ':(': 49, '((': 49}\n",
      "ecast {'ĠMosul': 51, 'ĠQualcomm': 49, 'ĠBristol': 49, 'Ġleptin': 49, 'ĠLogic': 49, 'ĠCoinbase': 48}\n",
      "atonin {'Ġ(<': 52, 'ĠKimberly': 50, 'ĠMarcel': 49, 'ĠToyota': 48, 'ĠVolkswagen': 48, 'ĠStanley': 48}\n",
      "\": {'Ġ\"{': 52, 'Ġ{\"': 51, 'Ġ\"<': 49, '{\"': 49, 'Ġ\"\\\\': 49, '=\"': 49}\n",
      "utherford {'ĠTheodore': 51, 'ĠHermes': 49, 'ĠMiko': 49, 'ĠHerod': 49, 'ĠPedro': 48, 'ĠHerbert': 48}\n",
      "', {\"('\": 56, \"Ġ('\": 51, \":'\": 49, 'Ġ\"\\'': 48, \"='\": 48, \"Ġ['\": 48}\n",
      "holders {'ĠYellowstone': 49, 'ĠPercy': 49, 'ĠHercules': 49, 'ĠYosemite': 49, 'ĠWellington': 49, 'ĠHayden': 48}\n",
      "anguard {'ĠIcelandic': 50, 'ĠLibertarian': 50, 'ĠClyde': 49, 'ĠHighlander': 48, 'ĠWikimedia': 48, 'ĠKerala': 48}\n",
      "ileaks {'ĠScion': 49, 'ĠKavanaugh': 49, 'ĠGoblin': 48, 'ĠBloomberg': 48, 'Ġopioid': 48, 'ĠZeus': 48}\n",
      "STDOUT {'ĠDACA': 54, 'ĠOblivion': 49, 'ĠTsukuyomi': 48, 'ĠDomestic': 48, 'ĠKashmir': 48, 'ĠRouse': 47}\n",
      "}. {'}{': 52, '{{': 51, 'Ġ{{': 51, '{': 48, '){': 48, '{\\\\': 47}\n",
      "auntlet {'ĠCertificate': 50, 'ĠCertification': 49, 'ĠMagnus': 49, 'ĠLloyd': 49, 'ĠKimberly': 49, 'ĠManitoba': 48}\n",
      "=] {'Ġ[': 56, 'Ġ[[': 53, ')[': 52, ':[': 49, ').[': 48, '=[': 48}\n",
      ")+ {'Ġ((': 56, '((': 54, ':(': 51, 'Ġ(': 50, ')=(': 50, '=(': 48}\n",
      "ernaut {'ĠGoblin': 52, 'ĠByzantine': 52, 'ĠGutenberg': 50, 'ĠRosenthal': 49, 'ĠMongol': 48, 'ĠAndersen': 46}\n",
      "nesday {'ĠCinnamon': 50, 'ĠHermes': 50, 'ĠGutierrez': 49, 'ĠMeteor': 48, 'ĠLotus': 48, 'ĠMetatron': 48}\n",
      ")- {'Ġ((': 55, ':(': 53, 'Ġ(': 52, ')=(': 49, '((': 49, '=(': 46}\n",
      "Ġ...\" {'\":\"': 59, 'Ġ\"...': 50, 'Ġ\"âĢ¦': 50, 'Ġ\"[': 48, 'Ġ\"\\\\': 47, 'Ġ\"(': 47}\n",
      "): {')=(': 54, ':(': 51, 'Ġ((': 49, '=(': 49, '((': 48, 'Ġ(': 48}\n",
      "ommel {'ĠFuller': 53, 'ĠFavorite': 49, 'ĠFlynn': 49, 'ĠJohn': 48, 'ĠEmmanuel': 48, 'ĠBarbarian': 48}\n",
      "Collins {'ĠYellowstone': 49, 'ĠEdmund': 49, 'ĠMozilla': 48, 'ĠKathryn': 48, 'ĠMiko': 48, 'ĠRudolph': 48}\n",
      "manac {'ĠBabylon': 52, 'ĠFallout': 50, 'ĠDaytona': 49, 'ĠPOLITICO': 48, 'ĠNicarag': 48, 'ĠGears': 47}\n",
      "Sources {'ĠMarketable': 50, 'ĠOffline': 49, 'ĠMarriott': 49, 'ĠGilmore': 48, 'ĠProud': 48, 'ĠAdministrative': 48}\n",
      "xxxx {'ĠSaturn': 51, 'ĠVoyager': 50, 'ĠBigfoot': 48, 'ĠJustin': 48, 'ĠWellington': 48, 'ĠPearson': 48}\n",
      "){ {'>(': 53, ':(': 51, 'Ġ((': 49, 'Ġ(': 49, '.(': 48, '((': 47}\n",
      "gettable {'ĠBigfoot': 52, 'ĠMiscellaneous': 50, 'ĠIMP': 48, 'ĠTheodore': 48, 'ĠDACA': 48, 'ĠGalile': 47}\n",
      "journal {'ĠTacoma': 50, 'ĠMetroid': 50, 'ĠMercury': 50, 'ĠPlayboy': 49, 'ĠHogwarts': 48, 'ĠDoom': 47}\n",
      "Anonymous {'ĠMozilla': 55, 'ĠKimberly': 49, 'ĠDroid': 47, 'ĠNorton': 47, 'ĠDACA': 47, 'ĠAntioch': 47}\n",
      ")-- {'Ġ((': 54, ':(': 52, 'Ġ(': 50, ')=(': 49, '((': 47, '=(': 46}\n",
      "},\" {'\":{\"': 57, 'Ġ{{': 50, 'Ġ\"{': 50, '}{': 47, '({': 47, '{{': 47}\n",
      "enaries {'ĠOdyssey': 52, 'ĠNorton': 49, 'ĠGrizz': 48, 'ĠCrimean': 48, 'ĠCanad': 47, 'ĠRagnarok': 47}\n",
      "'); {\"Ġ'(\": 54, 'Ġ((': 49, \"('\": 48, 'ĠSergei': 47, ')=(': 47, '>(': 47}\n",
      "Ġ}; {'}{': 51, ':{': 50, 'Ġ{{': 50, '{': 48, 'Ġ({': 48, '={': 47}\n",
      "ierrez {'ĠTheodore': 52, 'ĠKhalid': 49, 'ĠAndersen': 47, 'ĠStefan': 47, 'ĠAllan': 47, 'ĠClyde': 47}\n",
      "ĠSnowden {'ĠLucius': 51, 'ĠStefan': 49, 'ĠDeadpool': 49, 'ĠFreddie': 47, 'ĠChristy': 47, 'ĠMarcel': 47}\n",
      "ampions {'Ġirreversible': 50, 'ĠOTHER': 49, 'ĠRedux': 49, 'ĠLogic': 47, 'ĠReincarn': 47, 'ĠProgressive': 47}\n",
      "!\", {'\":\"': 58, '\"},\"': 49, 'ĠElk': 48, 'Ġ\"\\\\': 47, '(\"': 47, '=\"': 46}\n",
      "'). {\"Ġ'(\": 55, 'Ġ((': 51, 'Ġ(': 50, 'Ġ$(': 48, '((': 47, \"('\": 46}\n",
      "umsy {'ĠPalestin': 50, 'ĠNeander': 48, 'ĠDACA': 48, 'ĠKerala': 47, 'ĠNeo': 47, 'ĠUNCLASSIFIED': 47}\n",
      "adoes {'ĠTelecommunications': 51, 'ĠAppropriations': 49, 'ĠMSM': 47, 'ĠRegulatory': 47, 'ĠFuller': 47, 'ĠCooperative': 47}\n",
      ".\"[ {'\":\"': 49, 'Ġ)]': 49, '\"}],\"': 48, '\"]': 48, '],\"': 48, ']\"': 47}\n",
      "?!\" {'Ġ\"<': 52, '\":\"': 50, 'Ġ\"\\\\': 48, 'Ġ\"[': 47, 'Ġ\"(': 47, 'Ġ\"{': 47}\n",
      "ournals {'ĠDACA': 50, 'ĠBattlefield': 50, 'ĠYosemite': 47, 'ĠPOLITICO': 47, 'ĠMarriott': 46, 'ĠDaisy': 46}\n",
      "realDonaldTrump {'ĠSask': 49, 'ĠMarcel': 48, 'ĠJulio': 47, 'ĠCorpus': 47, 'ĠRudolph': 47, 'ĠSaturn': 47}\n",
      "!!\" {'\":\"': 58, 'Ġ\"(': 49, 'Ġ\"\\\\': 48, 'Ġ\"<': 47, '=\"': 46, 'Ġ\"': 46}\n",
      "topia {'ĠGears': 50, 'ĠMetroid': 48, 'ĠNotting': 47, 'ĠTerminator': 47, 'ĠMongol': 47, 'ĠPlanetary': 46}\n",
      "ldom {'Ġambiguous': 49, 'ĠPalestin': 49, 'ĠLibertarian': 49, 'ĠCrypto': 47, 'Ġacidic': 47, 'ĠUNCLASSIFIED': 46}\n",
      "ewitness {'ĠDACA': 52, 'ĠHerz': 47, 'ĠKeystone': 47, 'ĠKashmir': 47, 'ĠTRUE': 46, 'ĠWikimedia': 46}\n",
      "mbuds {'ĠGalile': 50, 'ĠGoblin': 49, 'ĠClayton': 49, 'ĠISIL': 46, 'ĠARC': 46, 'ĠNeville': 46}\n",
      "mith {'ĠAvalon': 49, 'ĠRodney': 49, 'ĠWellington': 47, 'ĠKeystone': 47, 'ĠRousse': 47, 'ĠTacoma': 47}\n",
      "idays {'ĠMiscellaneous': 54, 'ĠWelch': 49, 'ĠToyota': 46, 'ĠRosenthal': 46, 'ĠGreenberg': 45, 'ĠRohingya': 45}\n",
      "ottesville {'ĠBaylor': 49, 'Ġnicotine': 47, 'ĠBarney': 47, 'ĠLabrador': 47, 'ĠLazarus': 47, 'ĠOlson': 46}\n",
      "\"); {'Ġ\"(': 48, 'ĠSergei': 47, 'ĠWestbrook': 47, ')=(': 47, 'Ġ(': 47, 'ĠRamirez': 46}\n",
      "aults {'ĠFisheries': 49, 'ĠGears': 49, 'ĠKoz': 48, 'ĠGrizz': 47, 'ĠGenetics': 46, 'ĠFischer': 46}\n",
      "emouth {'ĠWellington': 49, 'ĠAndromeda': 48, 'ĠInfinity': 47, 'ĠLabrador': 47, 'ĠGilmore': 46, 'ĠHerod': 46}\n",
      "forums {'ĠKeystone': 53, 'ĠValhalla': 51, 'ĠWinchester': 47, 'ĠGDDR': 46, 'ĠMercury': 45, 'ĠSuperman': 45}\n",
      "uments {'ĠMiscellaneous': 49, 'ĠOTHER': 48, 'ĠNeurolog': 48, 'ĠMarketable': 48, 'ĠCongressional': 47, 'ĠDACA': 46}\n",
      "ubis {'ĠMillennium': 49, 'ĠRosenthal': 48, 'ĠLazarus': 47, 'ĠMozilla': 46, 'ĠDoomsday': 46, 'ĠRasmussen': 46}\n",
      "akedown {'ĠFatal': 48, 'ĠDeadly': 47, 'ĠDaytona': 47, 'ĠCriminal': 47, 'Ġsemantic': 46, 'ĠProl': 46}\n",
      "Connor {'ĠClyde': 50, 'ĠKimberly': 50, 'ĠStefan': 49, 'ĠDeadpool': 47, 'ĠWarden': 45, 'ĠHayden': 45}\n",
      "arella {'ĠBuckingham': 48, 'ĠYellowstone': 47, 'ĠScarborough': 47, 'ĠPlayboy': 46, 'ĠRouse': 46, 'ĠClyde': 46}\n",
      "infeld {'ĠGPIO': 49, 'ĠCinnamon': 47, 'ĠEmmanuel': 47, 'ĠGilmore': 47, 'ĠKeystone': 46, 'ĠKimberly': 46}\n",
      "ineries {'ĠAvalon': 48, 'ĠGilmore': 47, 'ĠFairfax': 46, 'ĠCrowley': 46, 'ĠCourtney': 46, 'ĠMiscellaneous': 46}\n",
      "udence {'ĠFuller': 49, 'ĠPlanetary': 48, 'ĠMaritime': 47, 'ĠMotorola': 46, 'ĠCapcom': 46, 'ĠAdministrative': 46}\n",
      "Jones {'ĠChristy': 50, 'ĠCyrus': 47, 'ĠPatricia': 46, 'ĠKimberly': 46, 'ĠRudolph': 46, 'ĠKathryn': 46}\n",
      "âĢ¦\" {'\":\"': 56, 'Ġ\"[': 48, 'Ġ\"\\\\': 48, 'ĠCatalyst': 47, 'Ġ\"(': 47, 'Ġ\"...': 47}\n",
      "Phones {'ĠAvalon': 49, 'ĠTravels': 48, 'ĠYosemite': 47, 'ĠMarriott': 46, 'ĠKimberly': 46, 'ĠCelt': 46}\n",
      "ansky {'ĠKimberly': 51, 'ĠAppalachian': 49, 'ĠWellington': 48, 'ĠWinston': 45, 'ĠHermes': 45, 'ĠEminem': 45}\n",
      "Lago {'ĠValhalla': 50, 'ĠPercy': 46, 'ĠJulio': 46, 'ĠBarbarian': 46, 'ĠHarlem': 46, 'ĠStamford': 45}\n",
      "igsaw {'ĠVK': 49, 'ĠAES': 49, 'ĠMPEG': 47, 'ĠGears': 46, 'ĠOgre': 46, 'ĠRog': 45}\n",
      "espie {'ĠMagnus': 49, 'ĠSatoshi': 47, 'ĠMarcel': 46, 'ĠHerbert': 46, 'ĠWinston': 46, 'ĠHerod': 46}\n",
      "displayText {'ĠMortal': 48, 'ĠUltimate': 48, 'ĠMMO': 46, 'ĠDACA': 46, 'ĠHannibal': 46, 'ĠPaleo': 45}\n",
      "aganda {'Ġpelvic': 49, 'ĠGow': 47, 'ĠMiscellaneous': 47, 'ĠBabylon': 47, 'ĠFisheries': 46, 'ĠByzantine': 46}\n",
      ";\" {'=\"': 51, 'Ġ\",': 49, '\":\"': 48, 'Ġ\"\\\\': 47, 'Ġ\"[': 47, 'Ġ\"(': 46}\n",
      "adelphia {'ĠYellowstone': 48, 'ĠMonsanto': 48, 'ĠDACA': 47, 'ĠMetroid': 46, 'ĠNAFTA': 46, 'ĠMercury': 46}\n",
      "otine {'ĠDaytona': 49, 'ĠKimberly': 49, 'ĠCalder': 48, 'ĠPortsmouth': 46, 'ĠTacoma': 45, 'ĠAppalachian': 45}\n",
      "Walker {'ĠRudolph': 48, 'ĠClyde': 46, 'ĠNether': 46, 'ĠValencia': 46, 'ĠMeier': 46, 'ĠOrtiz': 46}\n",
      "prototype {'ĠAlz': 47, 'ĠFuller': 47, 'ĠCyp': 47, 'ĠHiggins': 47, 'ĠCrypto': 46, 'ĠMarriott': 45}\n",
      "); {'Ġ((': 48, 'Ġ(': 48, ')=(': 48, ':(': 46, 'ĠSergei': 45, '>(': 45}\n",
      "!\" {'\":\"': 51, 'Ġ\"\\\\': 47, 'Ġ\"{': 46, 'ĠAvalon': 46, 'Ġ\"(': 46, 'ĠCatalyst': 45}\n",
      "allery {'ĠValhalla': 52, 'ĠHermes': 50, 'ĠShea': 45, 'ĠHighlander': 45, 'ĠWinchester': 45, 'ĠNorton': 44}\n",
      "apolis {'ĠLazarus': 51, 'ĠTravels': 48, 'ĠValhalla': 47, 'ĠLowell': 45, 'ĠNath': 45, 'ĠGoddard': 45}\n",
      "]. {':[': 50, 'Ġ[[': 49, 'Ġ[': 49, 'Ġ<[': 46, 'Ġ([': 45, '([': 45}\n",
      "ourge {'ĠAllan': 51, 'ĠTroy': 51, 'ĠDaytona': 46, 'ĠClarence': 44, 'ĠMorty': 44, 'ĠCyrus': 44}\n",
      "]). {'Ġ(': 50, 'Ġ([': 50, 'Ġ((': 49, '([': 46, ':[': 45, '((': 44}\n",
      "Roberts {'ĠShelley': 48, 'ĠMiko': 47, 'ĠClyde': 46, 'ĠStefan': 46, 'ĠEdmund': 45, 'ĠYosemite': 45}\n",
      "\"). {'Ġ(': 51, 'Ġ\"(': 49, 'Ġ((': 47, ')=(': 45, 'Ġ$(': 45, '((': 44}\n",
      "shirts {'ĠHerod': 50, 'ĠBabylon': 46, 'ĠTsukuyomi': 46, 'Ġherpes': 45, 'Ġpolygamy': 45, 'ĠAtlantis': 45}\n",
      "obook {'ĠEminem': 51, 'ĠPOLITICO': 47, 'ĠOsama': 45, 'ĠPlayboy': 45, 'ĠCassidy': 45, 'ĠVolkswagen': 45}\n",
      "pmwiki {'ĠMorse': 50, 'ĠOrtiz': 48, 'ĠGears': 47, 'ĠFlores': 45, 'ĠGilmore': 45, 'Ġ630': 44}\n",
      "plings {'ĠMiscellaneous': 53, 'ĠAdministrative': 47, 'Ġcontraceptive': 45, 'ĠFuller': 45, 'ĠJennings': 45, 'ĠGilmore': 44}\n",
      "udeau {'ĠAllan': 48, 'ĠPercy': 47, 'ĠLindsey': 46, 'ĠStamford': 46, 'ĠStefan': 45, 'ĠHelsinki': 45}\n",
      "}); {'({': 52, 'Ġ({': 51, 'Ġ((': 48, ':(': 46, '((': 45, '>(': 43}\n",
      ",\" {'\":\"': 54, 'ĠKimberly': 47, 'ĠCatalyst': 46, 'ĠAvalon': 45, 'Ġ\"(': 44, 'Ġ\"{': 44}\n",
      "Kelly {'ĠClyde': 50, 'ĠWinston': 47, 'ĠStamford': 46, 'ĠCourtney': 45, 'ĠFreder': 45, 'ĠPavel': 44}\n",
      "Footnote {'ĠPercy': 47, 'ĠDianne': 47, 'ĠMalfoy': 46, 'ĠClyde': 46, 'ĠMaher': 45, 'ĠBaylor': 45}\n",
      "ipedia {'ĠBabel': 47, 'ĠAntioch': 46, 'ĠBabylon': 46, 'ĠLatvia': 46, 'ĠBaylor': 45, 'ĠMetroid': 45}\n",
      "mington {'ĠIndigo': 47, 'ĠWellington': 47, 'ĠDemonic': 46, 'ĠMercury': 45, 'ĠLabrador': 45, 'ĠDACA': 45}\n",
      "atron {'ĠMercury': 48, 'ĠLindsey': 48, 'ĠValhalla': 46, 'ĠRidley': 46, 'ĠMalcolm': 45, 'ĠRobinson': 45}\n",
      "epad {'ĠMagical': 46, 'ĠBigfoot': 46, 'ĠCardiff': 46, 'ĠWatergate': 45, 'ĠMercury': 45, 'ĠBridgewater': 45}\n",
      "!' {\"Ġ'[\": 56, \"Ġ'(\": 55, 'ĠAvalon': 50, \"Ġ'\": 45, \"('\": 43, 'ĠMegan': 41}\n",
      "ajor {'ĠNeuroscience': 47, 'ĠJerusalem': 46, 'ĠMercury': 46, 'ĠHogwarts': 45, 'ĠJFK': 45, 'ĠASD': 45}\n",
      "thouse {'ĠRosenthal': 49, 'ĠKavanaugh': 47, 'ĠHerod': 46, 'ĠWasserman': 45, 'ĠHiggins': 45, 'ĠMelvin': 45}\n",
      "chwitz {'ĠTed': 48, 'ĠKimberly': 47, 'ĠRamsay': 47, 'ĠOsama': 45, 'ĠGus': 45, 'ĠGordon': 45}\n",
      "arenthood {'ĠUtility': 48, 'ĠBallistic': 47, 'ĠAberdeen': 47, 'ĠMongol': 46, 'ĠFuller': 44, 'ĠPlanetary': 44}\n",
      ".\", {'\":\"': 56, '=\"': 48, '\":[\"': 45, 'Ġ\"{': 45, '(\"': 44, 'Ġ\"<': 44}\n",
      "inness {'ĠTownsend': 49, 'ĠKhalid': 47, 'ĠMalik': 45, 'ĠEmmanuel': 45, 'ĠDagger': 45, 'ĠRahman': 45}\n",
      "ageddon {'ĠAIDS': 48, 'ĠRagnarok': 47, 'ĠRosenthal': 47, 'ĠTaco': 46, 'ĠNeuroscience': 45, 'ĠMongol': 45}\n",
      "starter {'ĠMozilla': 49, 'ĠWellington': 46, 'ĠPlayboy': 45, 'ĠJacksonville': 45, 'ĠNorthwestern': 45, 'ĠSouthwest': 45}\n",
      "anyahu {'ĠStamford': 49, 'ĠFlynn': 47, 'ĠOsama': 45, 'ĠMarcel': 45, 'ĠClyde': 45, 'ĠScarlett': 44}\n",
      "Assad {'ĠOsama': 48, 'ĠKimberly': 46, 'ĠPercy': 45, 'ĠClyde': 45, 'ĠCassidy': 45, 'ĠKhalid': 45}\n",
      "Scope {'ĠWembley': 47, 'ĠClyde': 46, 'ĠUltron': 46, 'ĠBaylor': 45, 'ĠMorrow': 45, 'ĠStamford': 44}\n",
      "enegger {'ĠFrankfurt': 46, 'ĠLazarus': 46, 'ĠKimberly': 46, 'ĠClyde': 45, 'ĠOsama': 45, 'ĠAndersen': 45}\n",
      "Gameplay {'Ġtherm': 47, 'ĠOrtiz': 46, 'ĠAdministrative': 45, 'ĠMarqu': 45, 'ĠRobo': 45, 'ĠRamsay': 45}\n",
      "Allen {'ĠKimberly': 52, 'ĠClifford': 46, 'ĠHerbert': 45, 'ĠDmitry': 45, 'ĠClyde': 44, 'ĠMagnus': 44}\n",
      "wikipedia {'ĠBigfoot': 48, 'ĠCortana': 46, 'ĠDACA': 46, 'ĠLazarus': 45, 'ĠStamford': 45, 'ĠNEO': 44}\n",
      "Detroit {'ĠGarrison': 48, 'ĠWellington': 47, 'ĠBaylor': 46, 'ĠCourtney': 45, 'ĠDestiny': 44, 'ĠFlynn': 44}\n",
      "\".[ {'Ġ)]': 50, '\"]': 49, '?]': 48, '\"}],\"': 46, '],\"': 44, '\":\"': 44}\n",
      "puters {'ĠCerberus': 46, 'ĠYosemite': 45, 'ĠMercury': 45, 'ĠValhalla': 45, 'ĠYellowstone': 45, 'ĠIndigo': 45}\n",
      "LinkedIn {'ĠDACA': 48, 'ĠValhalla': 46, 'ĠMarriott': 46, 'Ġcel': 45, 'ĠRost': 45, 'ĠMoss': 45}\n",
      "stice {'ĠGHC': 51, 'ĠDaytona': 46, 'ĠAzerbaijan': 45, 'ĠPence': 44, 'ĠPrelude': 44, 'ĠOccasionally': 44}\n",
      "ikarp {'ĠGoblin': 46, 'ĠBoko': 46, 'Ġjuvenile': 45, 'Ġpolygamy': 45, 'ĠKimberly': 44, 'ĠCardiff': 44}\n",
      "capital {'ĠMSM': 48, 'ĠDACA': 46, 'ĠRiley': 45, 'ĠMcCabe': 44, 'ĠFnatic': 44, 'ĠYiannopoulos': 44}\n",
      "agall {'ĠBerman': 47, 'ĠArlington': 46, 'ĠHerbert': 46, 'ĠGutierrez': 44, 'ĠRosenthal': 44, 'ĠAllan': 44}\n",
      "tools {'ĠLazarus': 47, 'ĠFlores': 46, 'ĠMetatron': 46, 'ĠDACA': 46, 'ĠMozilla': 45, 'ĠJulius': 44}\n",
      "atism {'ĠBoko': 46, 'ĠKashmir': 46, 'ĠKimberly': 45, 'ĠLambert': 45, 'ĠTsukuyomi': 44, 'ĠDed': 44}\n",
      "bringer {'ĠRosenthal': 47, 'ĠVenom': 46, 'ĠKimberly': 46, 'ĠTobacco': 45, 'ĠGoblin': 45, 'ĠErdogan': 44}\n",
      "ĠALEC {'ĠTacoma': 48, 'ĠQuincy': 45, 'ĠDmitry': 45, 'ĠRahul': 45, 'ĠPetraeus': 45, 'ĠMozilla': 44}\n",
      "leground {'ĠGoblin': 46, 'ĠLabrador': 46, 'ĠWellington': 45, 'ĠDrupal': 44, 'ĠMalaysian': 44, 'ĠDaytona': 44}\n",
      "ospels {'ĠGears': 47, 'ĠAllan': 46, 'ĠTravels': 46, 'ĠOthers': 45, 'ĠNavigation': 45, 'ĠAppropriations': 45}\n",
      "dayName {'ĠMorse': 47, 'ĠLeo': 45, 'Ġelapsed': 45, 'ĠKuro': 45, 'ĠNielsen': 44, 'ĠNether': 44}\n",
      "onsense {'ĠBarney': 47, 'ĠBoko': 46, 'ĠYellowstone': 46, 'ĠArlington': 45, 'ĠLabrador': 44, 'ĠTeddy': 44}\n",
      "neys {'ĠRosenthal': 47, 'ĠValhalla': 46, 'ĠHercules': 46, 'ĠFuller': 45, 'ĠRusty': 45, 'ĠMetatron': 45}\n",
      "Introduced {'ĠKimberly': 48, 'ĠDACA': 48, 'ĠDeadpool': 44, 'ĠEmmanuel': 44, 'ĠCameroon': 44, 'ĠFnatic': 44}\n",
      ".' {\"Ġ'(\": 53, \"Ġ'[\": 52, 'ĠAvalon': 48, 'ĠKonami': 43, \"('\": 42, \"Ġ'\": 42}\n",
      "estones {'ĠMSM': 50, 'ĠWellington': 45, 'ĠMiscellaneous': 45, 'ĠRosenthal': 45, 'ĠHercules': 44, 'ĠKoz': 44}\n",
      "hole {'ĠCassidy': 47, 'ĠKarma': 47, 'ĠDennis': 45, 'ĠHighlander': 44, 'ĠPortsmouth': 44, 'ĠBoko': 44}\n",
      "rouch {'ĠButler': 47, 'ĠAllan': 46, 'ĠMelvin': 46, 'ĠFranz': 44, 'ĠJulio': 44, 'ĠTroy': 44}\n",
      "ĠâĢ¦\" {'\":\"': 56, 'ĠCatalyst': 47, 'Ġ\"...': 45, '=\"': 44, 'Ġ\"âĢ¦': 44, 'Ġ\"(': 42}\n",
      "tumblr {'ĠBullet': 46, 'ĠRedmond': 45, 'ĠBeaver': 45, 'ĠBridgewater': 44, 'ĠWatergate': 44, 'ĠMississ': 44}\n",
      ",'' {'ĠAvalon': 45, 'ĠYiannopoulos': 45, 'Ġ\"\"': 45, 'ĠCatalyst': 45, 'ĠGillespie': 44, 'ĠFitzpatrick': 44}\n",
      "amiya {'ĠArlington': 46, 'ĠGoddard': 46, 'ĠOwl': 45, 'ĠParsons': 45, 'ĠPolk': 44, 'ĠSutherland': 44}\n",
      "osher {'ĠHerm': 48, 'ĠMetroid': 46, 'ĠGalile': 45, 'ĠLibertarian': 45, 'ĠKyoto': 44, 'ĠKimberly': 44}\n",
      ")âĢĶ {'Ġ(': 50, 'Ġ((': 49, ')=(': 47, ')(': 45, ':(': 45, 'Ġ$(': 45}\n",
      "Leaks {'ĠNerd': 46, 'ĠFlynn': 45, 'ĠHighlander': 45, 'ĠScion': 45, 'ĠMagnus': 44, 'ĠKaty': 44}\n",
      "ubuntu {'ĠLazarus': 48, 'ĠNAFTA': 46, 'ĠAtkins': 45, 'ĠCinnamon': 44, 'ĠBigfoot': 44, 'ĠYellowstone': 43}\n",
      "Latin {'ĠTMZ': 48, 'ĠDACA': 48, 'ĠCowboy': 45, 'ĠMarcel': 44, 'ĠCindy': 43, 'ĠNorton': 43}\n",
      "ifix {'ĠOsama': 47, 'ĠMonsanto': 46, 'ĠDACA': 45, 'Ġmercury': 44, 'ĠMercury': 44, 'ĠRoundup': 44}\n",
      "imgur {'ĠBoeing': 45, 'ĠSubaru': 45, 'ĠVerizon': 45, 'ĠNFC': 44, 'ĠNeo': 44, 'ĠNAFTA': 44}\n",
      ").[ {'Ġ(': 48, '](': 48, '>(': 47, 'Ġ)]': 46, ')(': 44, '?]': 43}\n",
      "makers {'ĠYellowstone': 46, 'ĠAtlantis': 45, 'ĠHerod': 44, 'ĠHighlander': 44, 'ĠGrizz': 44, 'ĠMercury': 44}\n",
      "heter {'ĠKimberly': 46, 'ĠVerizon': 45, 'ĠWellington': 45, 'ĠLieberman': 45, 'ĠMyanmar': 44, 'ĠRedmond': 44}\n",
      "iannopoulos {'ĠAdolf': 47, 'ĠHerod': 47, 'ĠOsama': 45, 'ĠLudwig': 44, 'ĠLazarus': 44, 'ĠYellowstone': 44}\n",
      "ombies {'ĠAllan': 47, 'ĠAvalon': 46, 'ĠGrizz': 46, 'ĠMercury': 44, 'ĠHighland': 44, 'ĠCutler': 43}\n",
      "Denver {'ĠWellington': 47, 'ĠBuffy': 46, 'ĠBaylor': 45, 'ĠYellowstone': 45, 'ĠGarrison': 44, 'ĠMozilla': 44}\n",
      "Forge {'ĠDaytona': 47, 'ĠColombia': 46, 'ĠLabrador': 45, 'ĠLatvia': 45, 'ĠValhalla': 45, 'ĠWinchester': 44}\n",
      "omsday {'Ġmidterm': 48, 'ĠLibertarian': 48, 'Ġsynaptic': 46, 'ĠTsukuyomi': 44, 'Ġcryptographic': 43, 'ĠBarbarian': 43}\n",
      "ujah {'ĠCitizenship': 48, 'ĠAlz': 45, 'ĠWellington': 45, 'ĠNord': 45, 'ĠGilmore': 45, 'ĠCyrus': 43}\n",
      "Ġwhistleblowers {'ĠAdamant': 46, 'ĠDACA': 45, 'ĠPetty': 45, 'ĠManziel': 44, 'Ġunwilling': 44, 'ĠLabrador': 44}\n",
      "leck {'ĠBuckley': 46, 'ĠNorton': 46, 'ĠPOLITICO': 45, 'ĠGears': 45, 'ĠHighlander': 44, 'ĠPerse': 43}\n",
      "uckles {'ĠMiscellaneous': 49, 'ĠTsukuyomi': 46, 'ĠMeteor': 44, 'ĠLotus': 44, 'ĠGoblin': 43, 'ĠFancy': 43}\n",
      "fecture {'ĠTripoli': 47, 'ĠScientology': 46, 'ĠPOLITICO': 45, 'ĠMercury': 45, 'ĠWatergate': 44, 'ĠPolitico': 44}\n",
      "ilight {'ĠMillennium': 45, 'ĠKurdistan': 45, 'ĠMongol': 45, 'ĠBabylon': 45, 'ĠArkham': 44, 'ĠArlington': 44}\n",
      "urrection {'ĠTsukuyomi': 46, 'ĠRagnarok': 46, 'ĠCitizenship': 45, 'ĠStockholm': 45, 'ĠFitzpatrick': 44, 'ĠPlanetary': 44}\n",
      "ixie {'ĠDaytona': 47, 'ĠCheong': 45, 'ĠRosenthal': 45, 'ĠMonica': 44, 'ĠSadd': 44, 'ĠCinnamon': 44}\n",
      "\\) {':(': 47, 'Ġ(': 46, 'Ġ\\\\(': 45, 'Ġ((': 44, 'ĠJulio': 44, 'Ġ$(': 44}\n",
      "amaru {'ĠKimberly': 46, 'ĠCrest': 46, 'ĠLazarus': 45, 'ĠEmmanuel': 45, 'ĠLance': 44, 'ĠBridgewater': 43}\n",
      "auntlets {'ĠMiscellaneous': 48, 'ĠGears': 46, 'ĠAllan': 44, 'ĠMessages': 44, 'ĠCertification': 43, 'ĠMorse': 43}\n",
      "anooga {'ĠWellington': 46, 'ĠYosemite': 46, 'ĠDACA': 44, 'ĠScarborough': 44, 'ĠEmmanuel': 44, 'ĠKimberly': 44}\n",
      "rences {'ĠFisheries': 46, 'ĠWraith': 45, 'ĠMSM': 44, 'ĠTelecommunications': 44, 'ĠFuller': 44, 'ĠGears': 43}\n",
      "'\" {'Ġ\"\\'': 51, '\":\"': 50, 'Ġ\"\\\\': 46, '=\"': 44, 'Ġ\",': 43, 'ĠKimberly': 42}\n",
      "oodoo {'ĠUlster': 48, 'ĠArlington': 47, 'ĠGenocide': 46, 'Ġsubsistence': 45, 'ĠClassical': 44, 'ĠPortsmouth': 42}\n",
      "cedented {'ĠRio': 45, 'ĠTyrann': 44, 'ĠDACA': 44, 'ĠKerala': 44, 'ĠUnicode': 44, 'ĠFriedrich': 44}\n",
      "Reilly {'ĠMozilla': 46, 'ĠWellington': 46, 'ĠYellowstone': 45, 'ĠSyd': 44, 'ĠMonica': 44, 'ĠLabrador': 44}\n",
      "aturdays {'ĠMiscellaneous': 46, 'ĠOffline': 45, 'Ġsemantic': 44, 'ĠYosemite': 44, 'ĠVanilla': 44, 'ĠQuantum': 43}\n",
      "adle {'ĠHighlander': 50, 'ĠValhalla': 44, 'ĠFuller': 44, 'ĠPrometheus': 44, 'ĠPOLITICO': 43, 'ĠVoyager': 43}\n",
      "ergus {'ĠMarcel': 48, 'ĠFlynn': 47, 'ĠMcKenzie': 45, 'ĠClyde': 44, 'ĠStanton': 43, 'ĠScarlett': 42}\n",
      "aretz {'ĠMetroid': 48, 'ĠNicarag': 46, 'ĠAfgh': 45, 'ĠPetraeus': 43, 'ĠXperia': 43, 'ĠPaleo': 43}\n",
      "ibli {'ĠGalile': 46, 'ĠNAFTA': 45, 'ĠMarriott': 45, 'ĠCrowley': 44, 'ĠRost': 43, 'ĠStealth': 43}\n",
      "abba {'ĠMercury': 47, 'ĠAllan': 45, 'ĠMonsanto': 44, 'ĠFreddie': 44, 'ĠShirley': 44, 'ĠFreder': 43}\n",
      "ainers {'ĠMiscellaneous': 46, 'ĠOTHER': 46, 'ĠOdyssey': 44, 'ĠCertification': 44, 'ĠTheodore': 43, 'ĠAvalon': 43}\n",
      "apesh {'ĠLibertarian': 48, 'ĠChevron': 45, 'ĠSurvivors': 45, 'ĠGears': 44, 'ĠGoblin': 43, 'ĠIllegal': 43}\n",
      "ework {'ĠAppalachian': 45, 'ĠUNESCO': 44, 'ĠMotorola': 44, 'ĠJulio': 44, 'ĠPegasus': 44, 'ĠMetroid': 43}\n",
      "oppable {'ĠNether': 45, 'ĠAntioch': 44, 'ĠKenyan': 44, 'ĠMetroid': 44, 'ĠWired': 44, 'ĠTeddy': 44}\n",
      "cience {'ĠPortsmouth': 45, 'ĠRosenthal': 45, 'ĠOrbital': 44, 'ĠRagnarok': 44, 'ĠGutierrez': 44, 'ĠCopenhagen': 44}\n",
      "endez {'ĠAllan': 49, 'ĠStefan': 46, 'ĠLivingston': 43, 'ĠAndersen': 43, 'ĠMarcel': 43, 'ĠHerbert': 43}\n",
      "usterity {'ĠAllan': 47, 'ĠTsukuyomi': 45, 'ĠRudolph': 45, 'ĠBuddy': 43, 'ĠMahmoud': 43, 'ĠEsper': 43}\n",
      "uesday {'ĠRohingya': 45, 'ĠFitzpatrick': 44, 'ĠCanberra': 44, 'ĠGutierrez': 44, 'ĠTyphoon': 44, 'ĠWellington': 43}\n",
      "ĠBlasio {'ĠRaqqa': 45, 'ĠHodg': 44, 'ĠGHC': 44, 'ĠKhalid': 44, 'ĠMayo': 44, 'ĠHubbard': 44}\n",
      "ands {'ĠKathryn': 46, 'ĠMSM': 45, 'ĠNavajo': 44, 'ĠNeander': 44, 'ĠKimberly': 44, 'ĠLilith': 43}\n",
      "?\", {'\":\"': 54, '\":[\"': 44, 'Ġ\"{': 43, 'ĠCatalyst': 43, '\"},\"': 43, 'Ġ\"\"': 43}\n",
      "efined {'ĠCutler': 48, 'ĠNAFTA': 45, 'ĠKimberly': 45, 'ĠFitzpatrick': 45, 'ĠWellington': 45, 'ĠMiko': 43}\n",
      "utils {'ĠMetroid': 46, 'ĠArlington': 45, 'ĠGears': 45, 'ĠKendall': 44, 'ĠYosemite': 44, 'ĠGoblin': 44}\n",
      "istan {'ĠKimberly': 48, 'ĠWatergate': 46, 'ĠGilmore': 45, 'ĠMDMA': 43, 'ĠRosenthal': 43, 'ĠDACA': 43}\n",
      "aceae {'ĠHerm': 46, 'ĠFrieza': 45, 'ĠRahul': 44, 'ĠDmitry': 44, 'ĠChoi': 44, 'ĠGoodwin': 44}\n",
      "ãĢĳ {':[': 48, 'Ġ([': 46, 'Ġ<[': 46, 'Ġ[[': 44, 'ãĢĲ': 43, ').[': 43}\n",
      "alties {'ĠFisheries': 49, 'ĠTsukuyomi': 47, 'ĠMiscellaneous': 44, 'ĠTelecommunications': 44, 'ĠRosenthal': 43, 'ĠAppalachian': 43}\n",
      "Quotes {'ĠDACA': 45, 'ĠAlz': 45, 'ĠFisheries': 44, 'ĠDeadpool': 44, 'ĠTMZ': 44, 'ĠDroid': 43}\n",
      "iddle {'ĠLieberman': 47, 'ĠNAFTA': 46, 'ĠMPEG': 45, 'ĠJudah': 45, 'ĠNavajo': 44, 'ĠCassidy': 43}\n",
      "atson {'ĠSusan': 45, 'ĠKimberly': 45, 'ĠTheodore': 44, 'ĠBetsy': 44, 'ĠJustin': 44, 'ĠLowell': 43}\n",
      "science {'ĠLazarus': 47, 'ĠLieberman': 45, 'ĠMontgomery': 44, 'ĠPortsmouth': 44, 'ĠRudolph': 43, 'ĠNordic': 43}\n",
      "?ãĢį {'Ġ([': 47, '\":[\"': 46, 'ĠãĢĮ': 45, '([': 44, ':[': 43, 'Ġ\"[': 43}\n",
      "Magazine {'ĠDACA': 47, 'ĠTMZ': 46, 'ĠBaylor': 45, 'ĠPlayboy': 44, 'ĠValhalla': 43, 'ĠMotorola': 42}\n",
      "Monday {'ĠMozilla': 47, 'ĠKyoto': 44, 'ĠEthereum': 44, 'Ġcel': 44, 'ĠFitzpatrick': 43, 'ĠHonduras': 43}\n",
      "inelli {'ĠRasmussen': 48, 'ĠGilmore': 46, 'ĠOsama': 44, 'ĠEmmanuel': 43, 'ĠBrad': 43, 'ĠKhalid': 43}\n",
      "xxxxxxxx {'ĠMarriott': 46, 'ĠScarborough': 45, 'ĠCrowley': 44, 'ĠDACA': 44, 'ĠShanahan': 43, 'ĠWellington': 43}\n",
      "ospel {'ĠRaqqa': 45, 'ĠDACA': 45, 'ĠAnglo': 45, 'Ġmorphine': 44, 'ĠRagnarok': 43, 'Ġopioid': 43}\n",
      "itizens {'ĠIntermediate': 48, 'ĠWinchester': 46, 'ĠYosemite': 44, 'ĠYellowstone': 44, 'ĠBorderlands': 43, 'ĠLuxembourg': 43}\n",
      "Untitled {'ĠDACA': 51, 'ĠBigfoot': 44, 'ĠNAFTA': 44, 'ĠYellowstone': 43, 'ĠRyzen': 43, 'ĠPlayboy': 43}\n",
      "ailand {'ĠRohingya': 48, 'ĠBoko': 45, 'ĠBaylor': 44, 'ĠMercury': 43, 'ĠMyanmar': 43, 'ĠHispanic': 42}\n",
      "ĠSpielberg {'ĠEdwin': 45, 'ĠMalcolm': 45, 'ĠLowell': 45, 'ĠKimberly': 44, 'ĠCyrus': 43, 'ĠMacArthur': 43}\n",
      "DonaldTrump {'ĠHitman': 47, 'ĠMozilla': 45, 'ĠMPEG': 45, 'ĠStamford': 44, 'ĠPearson': 43, 'ĠMalcolm': 42}\n",
      "ÙĲ {'ĠFuller': 45, 'ĠPublication': 45, 'ĠMagnus': 44, 'ĠNAFTA': 44, 'Ġleptin': 43, 'ĠMedline': 43}\n",
      "veland {'ĠDagger': 49, 'ĠClifford': 45, 'ĠLethal': 44, 'ĠPavel': 43, 'ĠEmmanuel': 43, 'ĠBuffy': 43}\n",
      "7601 {'ĠMercury': 45, 'ĠPOLITICO': 44, 'ĠDACA': 44, 'ĠNirvana': 44, 'ĠPlayboy': 44, 'ĠTitan': 43}\n",
      "Cola {'ĠPOLITICO': 44, 'ĠBabylon': 44, 'ĠNether': 44, 'ĠNAFTA': 43, 'ĠMcKenzie': 43, 'ĠClyde': 43}\n",
      "ortment {'ĠFuller': 47, 'ĠCrowley': 45, 'ĠDACA': 44, 'ĠGilmore': 43, 'ĠWired': 43, 'ĠPOLITICO': 43}\n",
      "orkshire {'ĠMetroid': 45, 'ĠNicarag': 45, 'ĠGilmore': 44, 'ĠLibertarian': 44, 'ĠJarrett': 43, 'ĠGarrison': 43}\n",
      "istrates {'ĠDACA': 47, 'ĠValhalla': 45, 'ĠFEMA': 44, 'ĠTemporary': 43, 'ĠAppropriations': 43, 'ĠMercury': 43}\n",
      "ezvous {'ĠDACA': 47, 'ĠASIC': 46, 'ĠMMO': 45, 'ĠSNAP': 44, 'ĠDed': 43, 'ĠUNCLASSIFIED': 42}\n",
      "Tools {'ĠMozilla': 47, 'ĠDACA': 47, 'ĠLazarus': 44, 'ĠWikimedia': 44, 'ĠBayer': 43, 'ĠWyatt': 43}\n",
      "BSD {'ĠCinnamon': 46, 'ĠMongol': 44, 'ĠNAFTA': 44, 'ĠPOLITICO': 44, 'ĠRasmussen': 43, 'ĠCanaan': 43}\n",
      "ernels {'ĠMiscellaneous': 45, 'ĠAppalachian': 45, 'ĠBarbie': 45, 'ĠTsukuyomi': 44, 'ĠYosemite': 43, 'ĠFuller': 43}\n",
      "arkin {'ĠRousse': 46, 'ĠKimberly': 44, 'ĠJeremy': 43, 'ĠGalile': 43, 'ĠRidley': 43, 'ĠGilmore': 43}\n",
      ",' {\"Ġ'[\": 50, 'ĠAvalon': 48, \"Ġ'(\": 46, \"('\": 42, 'ĠKimberly': 42, \"Ġ'\": 42}\n",
      "cules {'ĠNether': 47, 'ĠEnemies': 45, 'ĠOthers': 44, 'ĠPharaoh': 43, 'ĠMarriott': 43, 'ĠCic': 43}\n",
      "ackers {'ĠNeurolog': 45, 'ĠAppalachian': 45, 'ĠMercury': 43, 'ĠMiscellaneous': 43, 'ĠAvalon': 43, 'ĠOTHER': 43}\n",
      "antine {'ĠFairfax': 46, 'ĠEmmanuel': 46, 'ĠLowell': 44, 'ĠKimberly': 44, 'ĠRosenthal': 42, 'ĠAllan': 42}\n",
      "Semitism {'ĠMongol': 48, 'ĠClassical': 46, 'ĠBroadcasting': 43, 'ĠNordic': 43, 'ĠQuantum': 42, 'ĠWellington': 42}\n",
      "idae {'ĠTheodore': 47, 'ĠFrieza': 47, 'ĠWeasley': 44, 'ĠDaredevil': 43, 'ĠCthulhu': 43, 'ĠHitman': 42}\n",
      "emark {'ĠDruid': 45, 'ĠPlayboy': 45, 'ĠKurdistan': 44, 'ĠKimberly': 43, 'ĠCowboy': 43, 'ĠYellowstone': 43}\n",
      "rollers {'ĠWellington': 44, 'ĠTsukuyomi': 44, 'ĠFisheries': 44, 'ĠCerberus': 43, 'ĠFlores': 43, 'ĠAppropriations': 43}\n",
      "Ġholes {'ĠMiscellaneous': 46, 'ĠBarbarian': 45, 'ĠToyota': 43, 'ĠKepler': 43, 'ĠIndividuals': 43, 'ĠOthers': 43}\n",
      "apple {'ĠNether': 46, 'ĠAtlantis': 45, 'ĠPortsmouth': 44, 'ĠLibertarian': 43, 'ĠHowell': 43, 'ĠHonduras': 43}\n",
      "hetto {'ĠWelch': 46, 'ĠPercy': 43, 'ĠBerger': 43, 'ĠRosenthal': 43, 'ĠMercury': 43, 'ĠClyde': 43}\n",
      "}: {'}{': 47, 'Ġ{{': 46, '{{': 46, '={': 43, ':{': 43, '){': 42}\n",
      "assis {'ĠRasmussen': 47, 'ĠMetatron': 45, 'ĠGow': 44, 'ĠAtkinson': 43, 'ĠAtlantis': 43, 'ĠCerberus': 42}\n",
      "hell {'ĠRosenthal': 46, 'ĠAdministrative': 45, 'ĠPortsmouth': 44, 'ĠNAFTA': 44, 'ĠWyatt': 43, 'ĠMiscellaneous': 43}\n",
      "!'\" {'\":\"': 52, 'Ġ\"\\'': 48, 'Ġ\"\\\\': 44, 'ĠAvalon': 43, 'ĠKimberly': 42, 'Ġ\"': 41}\n",
      "WHO {'ĠDmitry': 47, 'ĠRosenstein': 45, 'ĠTurnbull': 45, 'ĠNathaniel': 44, 'ĠMiliband': 42, 'ĠPetraeus': 42}\n",
      "seless {'ĠTeddy': 45, 'ĠWoody': 44, 'ĠManny': 44, 'ĠGerard': 44, 'ĠLudwig': 43, 'ĠUCH': 43}\n",
      "herent {'ĠGPIO': 47, 'ĠScient': 46, 'ĠRousse': 44, 'ĠMongol': 43, 'ĠPOLITICO': 42, 'ĠTMZ': 42}\n",
      "ambers {'ĠTheodore': 50, 'ĠGears': 46, 'ĠGilmore': 42, 'ĠGPIO': 42, 'ĠDelicious': 42, 'ĠKimberly': 42}\n",
      "Ġdowntime {'Ġsemantic': 46, 'ĠTyphoon': 45, 'ĠBland': 44, 'ĠUnicode': 43, 'ĠMiscellaneous': 43, 'Ġparasitic': 43}\n",
      "bourne {'ĠDACA': 46, 'ĠBarney': 44, 'ĠPaleo': 44, 'ĠAndersen': 43, 'ĠWeasley': 43, 'ĠLucifer': 43}\n",
      "Miller {'ĠKimberly': 46, 'ĠClyde': 44, 'ĠJulio': 43, 'ĠMozilla': 43, 'ĠWinston': 43, 'ĠMarcel': 43}\n",
      "phones {'ĠMetatron': 45, 'ĠDruid': 44, 'ĠMcCabe': 44, 'ĠMercury': 43, 'ĠAvalon': 43, 'ĠDACA': 43}\n",
      "philis {'ĠNAFTA': 45, 'ĠMongol': 45, 'ĠBerman': 44, 'ĠStockholm': 44, 'ĠGPIO': 42, 'ĠRosenthal': 42}\n",
      "oppers {'ĠThunderbolt': 45, 'ĠAdministrative': 44, 'ĠMyanmar': 44, 'ĠPartial': 44, 'ĠYosemite': 44, 'ĠGodzilla': 43}\n",
      "requently {'ĠGPIO': 46, 'ĠDeutsche': 43, 'ĠDACA': 43, 'ĠWeasley': 43, 'ĠJPMorgan': 43, 'ĠMiscellaneous': 43}\n",
      "Keefe {'ĠKimberly': 47, 'ĠRedmond': 45, 'ĠNorton': 44, 'ĠSeymour': 44, 'ĠRudolph': 42, 'ĠDmitry': 42}\n",
      "*/ {'Ġ/*': 56, '/*': 49, 'Ġ/**': 44, 'ĠWoody': 43, 'ĠSly': 41, 'ĠPercy': 41}\n",
      "ince {'ĠAtlantis': 46, 'ĠClifford': 44, 'ĠAllan': 44, 'ĠPOLITICO': 43, 'ĠMetatron': 43, 'ĠWatergate': 42}\n",
      "Ġ=> {'ĠBirmingham': 45, 'ĠLeBron': 45, 'ĠEminem': 44, 'ĠKimberly': 44, 'ĠPortsmouth': 43, 'ĠTurnbull': 43}\n",
      "ceptions {'ĠTelecommunications': 45, 'ĠFisheries': 45, 'ĠMiscellaneous': 44, 'ĠNeurolog': 43, 'ĠAppalachian': 43, 'ĠGenetics': 43}\n",
      "racuse {'ĠPortsmouth': 49, 'ĠLeicester': 46, 'ĠPulitzer': 43, 'ĠRidley': 43, 'ĠBabylon': 42, 'ĠLockheed': 42}\n",
      "Characters {'ĠKimberly': 44, 'ĠFischer': 44, 'ĠRusty': 43, 'ĠDACA': 43, 'ĠKeystone': 43, 'ĠOkin': 43}\n",
      "otti {'ĠMorty': 47, 'ĠDianne': 44, 'ĠCheong': 43, 'ĠCourtney': 43, 'ĠRonald': 43, 'ĠAmos': 43}\n",
      "ppers {'ĠAvalon': 45, 'ĠYellowstone': 44, 'ĠOblivion': 44, 'ĠNathaniel': 44, 'ĠYosemite': 43, 'ĠFisheries': 42}\n",
      "issors {'ĠWinchester': 45, 'Ġnylon': 44, 'ĠTMZ': 43, 'ĠStainless': 43, 'ĠMonsanto': 43, 'ĠBuckingham': 43}\n",
      "()); {'ĠTimothy': 45, 'ĠMiliband': 44, 'ĠWestbrook': 44, 'ĠMcConnell': 43, 'ĠRasmussen': 43, 'ĠRonald': 42}\n",
      "aptop {'ĠLazarus': 46, 'ĠSkywalker': 46, 'ĠShinra': 44, 'ĠMelvin': 43, 'ĠPlayboy': 43, 'ĠMetatron': 42}\n",
      "utterstock {'ĠDACA': 47, 'ĠKushner': 44, 'ĠStamford': 44, 'ĠDeadpool': 43, 'ĠSnape': 43, 'ĠOsama': 42}\n",
      "namese {'ĠCherokee': 44, 'ĠDaytona': 44, 'ĠBelarus': 44, 'ĠMaya': 44, 'ĠRohingya': 43, 'ĠMyanmar': 43}\n",
      "usalem {'ĠScion': 44, 'ĠTurnbull': 44, 'ĠPOLITICO': 43, 'ĠDACA': 43, 'ĠTacoma': 43, 'ĠMetroid': 43}\n",
      "agons {'ĠAppropriations': 45, 'ĠEnemies': 44, 'ĠFuller': 44, 'ĠTelecommunications': 43, 'ĠFisheries': 43, 'ĠOdyssey': 43}\n",
      "backs {'ĠChristy': 44, 'ĠFischer': 44, 'ĠAvalon': 44, 'ĠOD': 43, 'ĠFisheries': 43, 'ĠGreenberg': 43}\n",
      "ghazi {'ĠMDMA': 44, 'ĠDACA': 44, 'ĠMSM': 43, 'ĠMercury': 43, 'Ġpelvic': 43, 'Ġfentanyl': 43}\n",
      "kowski {'ĠPercy': 46, 'ĠRosenstein': 45, 'ĠSeymour': 44, 'ĠHerod': 43, 'ĠArpaio': 43, 'ĠPerkins': 42}\n",
      "opers {'ĠChristy': 46, 'ĠClifford': 44, 'ĠCourtney': 44, 'ĠAllan': 43, 'ĠNYU': 42, 'ĠHerod': 42}\n",
      "Linux {'ĠLazarus': 45, 'ĠYellowstone': 45, 'ĠDACA': 44, 'ĠMercury': 43, 'ĠScorpion': 42, 'ĠSloan': 42}\n",
      "utm {'ĠDACA': 48, 'ĠYiannopoulos': 45, 'ĠDraco': 44, 'ĠSkyrim': 42, 'ĠDirectX': 42, 'ĠDSL': 42}\n",
      "raits {'ĠGPIO': 45, 'ĠTelecommunications': 44, 'ĠRohingya': 44, 'ĠTsukuyomi': 43, 'ĠDACA': 43, 'ĠMetallic': 42}\n",
      "umper {'ĠRosenthal': 45, 'ĠGutierrez': 44, 'ĠHighlander': 44, 'ĠJeremy': 43, 'ĠTimothy': 43, 'ĠAchilles': 42}\n",
      "bilt {'ĠMonsanto': 45, 'ĠFlynn': 44, 'ĠHerod': 44, 'ĠLazarus': 43, 'ĠMarcel': 43, 'ĠPerkins': 42}\n",
      "acco {'ĠLazarus': 46, 'ĠLeo': 44, 'ĠPaddock': 43, 'ĠGoddard': 43, 'ĠValhalla': 43, 'ĠMichele': 43}\n",
      "otto {'ĠAppalachian': 47, 'ĠRouse': 44, 'ĠGoddard': 43, 'ĠGilmore': 43, 'ĠFreddie': 43, 'ĠRousse': 42}\n",
      "atsuki {'ĠKimberly': 47, 'ĠPlayboy': 45, 'ĠAppalachian': 44, 'ĠOsama': 43, 'ĠClyde': 42, 'ĠCinnamon': 42}\n",
      ".\" {'ĠKimberly': 45, 'ĠAvalon': 44, '\":\"': 44, 'Ġ\"<': 44, 'ĠCatalyst': 44, 'Ġ\"{': 43}\n",
      "ynes {'ĠAdin': 47, 'ĠEdmund': 45, 'ĠHerod': 44, 'ĠKathryn': 43, 'ĠGalile': 43, 'ĠClifford': 42}\n",
      "Documents {'ĠDACA': 49, 'ĠMozilla': 43, 'ĠMarketable': 43, 'ĠYellowstone': 43, 'ĠScion': 43, 'ĠGalile': 42}\n",
      "ospace {'ĠStub': 45, 'ĠKimberly': 44, 'ĠFlores': 43, 'ĠMillennium': 43, 'ĠElias': 43, 'ĠVengeance': 43}\n",
      "chers {'ĠAvalon': 44, 'ĠTelecommunications': 44, 'ĠTsukuyomi': 43, 'ĠSeymour': 43, 'ĠNeurolog': 43, 'ĠAppalachian': 42}\n",
      "() {'ĠBridgewater': 45, 'ĠWellington': 44, 'ĠKM': 44, 'ĠMiliband': 43, 'ĠHermes': 42, 'ĠGoodwin': 42}\n",
      "Ġsources {'ĠSecondary': 45, 'ĠMarketable': 44, 'ĠHighlander': 43, 'ĠOTHER': 43, 'ĠIntermediate': 43, 'ĠArcane': 43}\n",
      "unctions {'ĠMiscellaneous': 44, 'ĠFisheries': 43, 'ĠRohingya': 43, 'ĠDACA': 43, 'ĠKoz': 43, 'ĠMarketable': 43}\n",
      "Ġ); {')=(': 49, 'Ġ(': 46, ':(': 45, 'Ġ((': 43, '>(': 43, '=(': 42}\n",
      "acters {'ĠMiscellaneous': 46, 'ĠWellington': 43, 'ĠNeurolog': 43, 'ĠFischer': 43, 'ĠYosemite': 43, 'ĠAdministrative': 42}\n",
      ",'\" {'\":\"': 52, 'Ġ\"\\'': 47, 'ĠAvalon': 42, '\":[\"': 42, 'ĠKimberly': 41, 'Ġ\"[': 41}\n",
      "rentices {'ĠDACA': 47, 'ĠTravels': 45, 'ĠAppropriations': 44, 'ĠBethlehem': 42, 'ĠGilmore': 42, 'ĠNewtown': 42}\n",
      "iculture {'ĠWellington': 45, 'ĠKashmir': 45, 'ĠCrypto': 44, 'ĠGarrison': 43, 'ĠMetroid': 43, 'ĠKimberly': 43}\n",
      "thus {'ĠLucifer': 46, 'ĠFuller': 43, 'ĠMcGregor': 43, 'ĠMelvin': 43, 'ĠOrtiz': 43, 'ĠDiscord': 42}\n",
      "itles {'ĠFisheries': 46, 'ĠTsukuyomi': 43, 'ĠUFO': 43, 'ĠGears': 43, 'ĠComposite': 43, 'ĠMetallic': 42}\n",
      "Ġbonds {'ĠDACA': 46, 'ĠHSBC': 45, 'ĠTelecommunications': 44, 'ĠGDDR': 43, 'ĠMSM': 43, 'ĠCourtney': 42}\n",
      "classes {'ĠYosemite': 46, 'ĠMiscellaneous': 44, 'ĠTsukuyomi': 43, 'ĠSirius': 43, 'ĠLindsey': 42, 'ĠKimberly': 42}\n",
      "ossus {'ĠMcCabe': 45, 'ĠGears': 44, 'ĠBorderlands': 43, 'ĠLibertarian': 43, 'ĠEmmanuel': 42, 'ĠGutierrez': 42}\n",
      "\"; {'ĠKimberly': 44, '=\"': 44, '\"},\"': 43, 'Ġ\"{': 43, '\":\"': 43, 'ĠHulk': 42}\n",
      "braska {'ĠUlster': 45, 'ĠWellington': 44, 'ĠCourtney': 44, 'ĠQuentin': 43, 'ĠFitzpatrick': 42, 'ĠSophia': 42}\n",
      "gov {'ĠDACA': 47, 'ĠYellowstone': 44, 'ĠSuperman': 43, 'ĠLazarus': 43, 'ĠNAV': 43, 'ĠBigfoot': 42}\n",
      "%), {'Ġ((': 48, 'Ġ(': 44, ')=(': 43, ':(': 43, '((': 42, ')(': 42}\n",
      "ĠZombies {'ĠMozilla': 46, 'ĠWinnipeg': 45, 'ĠCanberra': 43, 'ĠAvalon': 42, 'ĠMcN': 42, 'ĠCutler': 42}\n",
      "ggies {'ĠOthers': 45, 'ĠMiscellaneous': 45, 'ĠYellowstone': 44, 'ĠMarketable': 43, 'ĠOTHER': 42, 'ĠYosemite': 42}\n",
      "cdn {'ĠMetatron': 45, 'ĠBoko': 45, 'ĠPegasus': 43, 'ĠClyde': 43, 'ĠRichardson': 42, 'ĠMcDonnell': 42}\n",
      "undrum {'ĠGears': 45, 'ĠScarlett': 44, 'ĠGordon': 43, 'ĠCheney': 43, 'ĠBoko': 43, 'ĠParliamentary': 42}\n",
      "ampunk {'ĠPaleo': 48, 'ĠGoblin': 44, 'ĠSic': 44, 'ĠOsama': 42, 'ĠCrimean': 42, 'ĠBigfoot': 42}\n",
      "gerald {'ĠRosenthal': 48, 'ĠAllan': 44, 'ĠCyrus': 43, 'ĠLudwig': 43, 'ĠWellington': 42, 'ĠHerod': 42}\n",
      "phabet {'ĠDACA': 45, 'ĠNAFTA': 45, 'ĠPakistan': 43, 'ĠFISA': 43, 'ĠSkywalker': 43, 'ĠSnapchat': 42}\n",
      "uties {'ĠGears': 47, 'ĠMiscellaneous': 47, 'ĠFisheries': 43, 'ĠDACA': 43, 'Ġinnumerable': 43, 'ĠNeurolog': 42}\n",
      "agher {'ĠPhelps': 48, 'ĠMelanie': 47, 'ĠIbrahim': 43, 'ĠSeymour': 43, 'ĠMorty': 42, 'ĠHerod': 41}\n",
      "?????- {'ĠGarmin': 46, 'ĠEminem': 43, 'ĠNAFTA': 43, 'ĠRoku': 43, 'ĠRedux': 42, 'ĠNeville': 42}\n",
      "hene {'ĠSeymour': 44, 'ĠVoyager': 44, 'ĠOblivion': 43, 'ĠAnything': 43, 'ĠMercury': 43, 'ĠRagnarok': 42}\n",
      "Ġarms {'ĠSty': 45, 'ĠBarbarian': 44, 'ĠMiscellaneous': 43, 'ĠFrieza': 42, 'ĠDACA': 42, 'ĠProtective': 42}\n",
      "comings {'ĠMarketable': 44, 'ĠLegislative': 44, 'ĠAdministrative': 43, 'ĠHayden': 43, 'ĠImplementation': 42, 'ĠFuller': 42}\n",
      "Wikipedia {'ĠDACA': 46, 'ĠGilmore': 44, 'ĠDartmouth': 43, 'ĠBaylor': 43, 'ĠBabel': 43, 'ĠMozilla': 42}\n",
      "apeshifter {'ĠKashmir': 45, 'ĠLibertarian': 45, 'ĠScarborough': 44, 'ĠBorder': 43, 'ĠWellington': 42, 'ĠMongol': 42}\n",
      "notes {'ĠFisheries': 45, 'ĠDACA': 44, 'ĠOTHER': 44, 'ĠUNC': 43, 'ĠGDDR': 42, 'ĠMagnus': 42}\n",
      "'; {'ĠLazarus': 44, 'ĠSergei': 43, 'ĠRobbins': 43, 'ĠKonami': 42, 'ĠKimberly': 42, 'ĠSusan': 42}\n",
      "CHQ {'ĠBaylor': 46, 'ĠFnatic': 43, 'ĠRamsey': 43, 'ĠVerizon': 42, 'ĠLazarus': 42, 'ĠPearson': 42}\n",
      "onday {'ĠComposite': 45, 'ĠTransparency': 44, 'ĠNeuroscience': 44, 'ĠKendrick': 42, 'ĠBabylon': 42, 'ĠAdministrative': 42}\n",
      "Ġdevices {'ĠOTHER': 47, 'ĠArcane': 43, 'ĠBetsy': 43, 'ĠMathemat': 42, 'ĠSecondary': 42, 'ĠCourtney': 42}\n",
      "OTUS {'ĠFEMA': 46, 'ĠRousse': 43, 'ĠSasha': 43, 'ĠAriel': 43, 'ĠAdamant': 42, 'ĠVaughan': 42}\n",
      "linux {'ĠMontgomery': 44, 'ĠClockwork': 44, 'ĠOblivion': 43, 'ĠCinderella': 42, 'ĠBigfoot': 42, 'ĠDACA': 42}\n",
      "adata {'ĠBerman': 45, 'ĠKimberly': 44, 'ĠCynthia': 43, 'ĠBarney': 43, 'ĠMaher': 43, 'ĠMalik': 42}\n",
      "FontSize {'ĠHermes': 48, 'ĠVoyager': 44, 'ĠNether': 42, 'ĠArpaio': 42, 'ĠSpider': 42, 'ĠPuerto': 41}\n",
      "Connell {'ĠWinston': 44, 'ĠPercy': 43, 'ĠCommodore': 43, 'ĠGoff': 42, 'ĠMelvin': 42, 'ĠCutler': 42}\n",
      "ibaba {'ĠJulius': 44, 'ĠOsama': 43, 'ĠIbrahim': 43, 'ĠKhalid': 43, 'ĠOrlando': 42, 'ĠAllison': 42}\n",
      "appers {'ĠOthers': 46, 'ĠNathaniel': 43, 'ĠAppalachian': 42, 'ĠAdamant': 42, 'ĠTsukuyomi': 42, 'ĠMercury': 42}\n",
      "leases {'ĠYosemite': 45, 'ĠFuller': 45, 'ĠDACA': 44, 'ĠNeuroscience': 43, 'ĠBabylon': 42, 'ĠTsukuyomi': 42}\n",
      "ĠBasics {'ĠDACA': 44, 'ĠHogan': 44, 'ĠMetall': 44, 'ĠKimberly': 43, 'ĠMoto': 42, 'ĠBigfoot': 42}\n",
      "ĠAvenue {'ĠVaughan': 46, 'ĠKimberly': 44, 'ĠKobe': 43, 'ĠPegasus': 42, 'ĠWellington': 42, 'ĠMiliband': 42}\n",
      "ThumbnailImage {'ĠEminem': 44, 'ĠDj': 44, 'ĠNeg': 43, 'ĠMcN': 43, 'ĠNichols': 42, 'ĠProphe': 42}\n",
      "Friday {'ĠMozilla': 46, 'ĠEthereum': 45, 'ĠOPT': 43, 'ĠDACA': 43, 'ĠKyoto': 43, 'ĠNotting': 41}\n",
      "zbollah {'ĠBoko': 45, 'ĠHighlander': 43, 'ĠFlynn': 43, 'ĠWraith': 43, 'ĠTroll': 43, 'ĠClyde': 42}\n",
      "xit {'ĠPaleo': 44, 'ĠBridgewater': 44, 'ĠMDMA': 44, 'ĠCalais': 43, 'ĠTMZ': 42, 'ĠStockholm': 42}\n",
      "assies {'ĠDACA': 45, 'ĠMetatron': 44, 'ĠMiscellaneous': 44, 'ĠRohingya': 43, 'ĠFisheries': 42, 'ĠEmmanuel': 42}\n",
      "Ġ). {'Ġ(': 49, ')=(': 45, 'Ġ((': 43, ')(': 43, 'Ġ$(': 42, '=(': 41}\n",
      "Ġwitnesses {'ĠExternal': 44, 'ĠTelecommunications': 43, 'ĠMcAuliffe': 43, 'ĠInfinite': 43, 'Ġtelecommunications': 42, 'ĠVarious': 42}\n",
      "holder {'ĠPercy': 45, 'ĠNichols': 43, 'ĠLibertarian': 43, 'ĠSuffolk': 43, 'ĠFuller': 42, 'ĠPolitico': 42}\n",
      "ieties {'ĠMarketable': 45, 'ĠAppalachian': 45, 'ĠMiscellaneous': 43, 'ĠGilmore': 42, 'ĠGears': 42, 'ĠProgressive': 42}\n",
      "6666 {'ĠPercy': 44, 'ĠOlson': 43, 'ĠMercury': 43, 'ĠScarlet': 43, 'ĠCutler': 43, 'ĠAllan': 43}\n",
      "ophobic {'ĠAuschwitz': 44, 'ĠMedicaid': 44, 'ĠDACA': 43, 'ĠRohingya': 43, 'ĠLuxembourg': 42, 'ĠScarborough': 42}\n",
      "ilus {'ĠValhalla': 45, 'ĠLazarus': 43, 'ĠAllan': 43, 'ĠGoddard': 42, 'ĠNeville': 42, 'ĠGalile': 42}\n",
      "FAULT {'ĠDACA': 47, 'ĠAES': 44, 'ĠByte': 44, 'ĠUSB': 42, 'ĠSHA': 42, 'ĠOPT': 42}\n",
      "=> {'ĠEminem': 46, 'ĠLeBron': 45, 'ĠTammy': 43, 'Ġ(<': 42, 'ĠPortsmouth': 42, 'ĠTsarnaev': 42}\n",
      ".): {')=(': 48, ':(': 45, 'ĠBoko': 44, '=(': 42, 'Ġ$(': 42, '((': 41}\n",
      "payers {'ĠKimberly': 47, 'ĠPerkins': 44, 'ĠAdamant': 43, 'ĠHerod': 43, 'ĠGalile': 42, 'ĠYosemite': 41}\n",
      "inators {'ĠMetatron': 44, 'ĠWikimedia': 43, 'ĠLowell': 43, 'ĠMercury': 42, 'ĠSeymour': 42, 'ĠGilmore': 42}\n",
      "bidden {'ĠDACA': 51, 'ĠKimberly': 44, 'ĠDemonic': 44, 'ĠHeroic': 42, 'ĠBigfoot': 41, 'ĠMandatory': 41}\n",
      "ples {'ĠTelecommunications': 45, 'ĠMiscellaneous': 45, 'ĠGears': 44, 'ĠNeurolog': 43, 'ĠYosemite': 42, 'ĠGPIO': 42}\n",
      "externalActionCode {'ĠIke': 44, 'ĠFlynn': 44, 'ĠMotorola': 43, 'ĠEminem': 42, 'ĠOsama': 42, 'ĠFallout': 42}\n",
      "igators {'ĠAdamant': 44, 'ĠRosenthal': 43, 'ĠTelecommunications': 43, 'ĠNeurolog': 43, 'ĠWellington': 42, 'ĠMiscellaneous': 42}\n",
      "zanne {'ĠAllan': 46, 'ĠPercy': 46, 'ĠFiona': 43, 'ĠGrizz': 42, 'ĠMelanie': 42, 'ĠClyde': 42}\n",
      "Setup {'ĠMagnum': 46, 'ĠSkywalker': 44, 'ĠMcCl': 44, 'ĠArlington': 43, 'ĠWembley': 42, 'ĠBabel': 42}\n",
      "uterte {'ĠMarcel': 46, 'ĠRidley': 43, 'ĠKimberly': 42, 'ĠClyde': 42, 'ĠOrtiz': 42, 'ĠNikola': 42}\n",
      "ources {'ĠMiscellaneous': 46, 'ĠOTHER': 43, 'ĠValhalla': 42, 'ĠMarketable': 42, 'ĠClassical': 42, 'ĠAlternate': 42}\n",
      "unders {'ĠMiscellaneous': 47, 'ĠMSM': 45, 'ĠYosemite': 44, 'ĠESL': 42, 'ĠGPIO': 42, 'ĠGenetics': 42}\n",
      "versible {'ĠMetroid': 49, 'ĠKeystone': 44, 'ĠOswald': 42, 'ĠNAFTA': 42, 'ĠGPIO': 42, 'ĠManziel': 41}\n",
      "abeth {'ĠClyde': 45, 'ĠHermes': 44, 'ĠNarc': 43, 'ĠKhalid': 43, 'ĠValhalla': 42, 'ĠKimberly': 41}\n",
      "items {'ĠMiscellaneous': 49, 'ĠOTHER': 43, 'ĠNeuroscience': 42, 'ĠOther': 42, 'ĠPegasus': 42, 'ĠMillennium': 42}\n",
      "ĠHebdo {'ĠGPIO': 46, 'ĠPOLITICO': 45, 'ĠMcKin': 43, 'ĠBloomberg': 43, 'ĠDACA': 42, 'ĠRTX': 41}\n",
      "juries {'ĠNotting': 47, 'ĠTsukuyomi': 46, 'ĠMiscellaneous': 44, 'ĠMSM': 42, 'ĠArcane': 42, 'ĠTelecommunications': 42}\n",
      "errors {'ĠMiscellaneous': 49, 'ĠRosenstein': 45, 'ĠFisheries': 44, 'ĠGenetics': 43, 'ĠHayden': 42, 'ĠHerod': 40}\n",
      "Philadelphia {'ĠDACA': 47, 'ĠAntioch': 43, 'ĠGarrison': 43, 'ĠTheodore': 42, 'ĠDeadpool': 42, 'ĠStamford': 41}\n",
      "arlane {'ĠTheodore': 46, 'ĠMichele': 44, 'ĠHowell': 43, 'ĠGoddard': 43, 'ĠPerkins': 42, 'ĠKimberly': 42}\n",
      "Where {'ĠWellington': 45, 'ĠNAFTA': 43, 'ĠPortsmouth': 42, 'ĠSicily': 42, 'ĠQualcomm': 42, 'ĠCalais': 42}\n",
      "leness {'ĠTsukuyomi': 44, 'ĠFuller': 43, 'ĠPlanetary': 43, 'ĠAppalachian': 43, 'ĠKashmir': 42, 'ĠYosemite': 42}\n",
      "berra {'ĠGarrison': 46, 'ĠMage': 44, 'ĠPeyton': 43, 'ĠTurnbull': 42, 'ĠFlynn': 42, 'ĠVerizon': 42}\n",
      "abwe {'Ġcivic': 44, 'ĠGalile': 42, 'ĠTeddy': 42, 'ĠNotably': 42, 'ĠTart': 42, 'ĠParticularly': 42}\n",
      "ITNESS {'ĠDACA': 46, 'ĠLucifer': 45, 'ĠGPIO': 42, 'ĠCertificate': 41, 'Ġheavenly': 41, 'ĠKashmir': 41}\n",
      "strom {'ĠMagnus': 45, 'ĠValhalla': 45, 'ĠCyrus': 43, 'ĠHeller': 42, 'ĠFuller': 42, 'ĠCourtney': 42}\n",
      "awareness {'ĠMongol': 46, 'ĠZub': 44, 'ĠStockholm': 44, 'ĠTsukuyomi': 43, 'ĠGPIO': 43, 'ĠCitizenship': 42}\n",
      ".,\" {'\":\"': 48, 'ĠCatalyst': 45, 'ĠAvalon': 45, 'ĠReneg': 43, 'ĠKimberly': 42, 'ĠSherman': 40}\n",
      "container {'ĠPanda': 45, 'ĠBabylon': 44, 'ĠBigfoot': 43, 'ĠOdyssey': 43, 'ĠBullet': 42, 'ĠCherokee': 41}\n",
      "rolet {'ĠFlynn': 45, 'ĠMSM': 43, 'ĠJFK': 42, 'ĠMayo': 42, 'ĠMcF': 42, 'ĠJPM': 42}\n",
      "eways {'ĠMiscellaneous': 49, 'ĠGears': 44, 'ĠVarious': 42, 'ĠAchilles': 42, 'ĠMarketable': 41, 'ĠPossible': 41}\n",
      "afi {'ĠOsama': 47, 'ĠNavajo': 43, 'ĠPubMed': 42, 'ĠAndersen': 42, 'ĠValerie': 41, 'ĠPrometheus': 41}\n",
      "enton {'ĠRouse': 47, 'ĠEnrique': 44, 'ĠJoyce': 44, 'ĠEmmanuel': 42, 'ĠHag': 41, 'ĠMelody': 41}\n",
      "mode {'ĠPaleo': 44, 'ĠGutierrez': 44, 'ĠCassidy': 43, 'ĠZub': 43, 'ĠMaul': 42, 'ĠCraig': 42}\n",
      "isconsin {'ĠGilmore': 44, 'ĠWellington': 43, 'ĠValhalla': 43, 'ĠLudwig': 42, 'ĠRosenthal': 42, 'ĠNether': 42}\n",
      "actionDate {'ĠBabylon': 46, 'ĠNavajo': 44, 'ĠNAV': 43, 'ĠByzantine': 42, 'ĠMPEG': 42, 'ĠCherokee': 42}\n",
      "Ġ\", {'\":\"': 58, '\":[\"': 48, '=\"': 45, ':\"': 40, '\"},\"': 40, '\":{\"': 39}\n",
      "Ġcollectors {'ĠAdamant': 46, 'Ġirresponsible': 43, 'ĠTelecommunications': 42, 'ĠStamford': 42, 'ĠCourtney': 41, 'ĠGrave': 41}\n",
      "ounces {'ĠAppalachian': 47, 'ĠKimberly': 43, 'ĠComposite': 43, 'ĠNeurolog': 42, 'ĠCourtney': 42, 'ĠFisheries': 41}\n",
      "acles {'ĠFisheries': 45, 'ĠMiscellaneous': 44, 'ĠDACA': 43, 'ĠBarbarian': 42, 'ĠTravels': 42, 'ĠAllan': 42}\n",
      "emption {'ĠCongressional': 45, 'ĠRosenthal': 44, 'ĠAdministrative': 43, 'ĠEmmanuel': 42, 'ĠMongol': 42, 'ĠRasmussen': 41}\n",
      "wreck {'ĠOblivion': 47, 'ĠTyph': 43, 'ĠMorsi': 43, 'ĠBreach': 42, 'ĠTrog': 42, 'ĠGears': 41}\n",
      "ividually {'ĠMercury': 44, 'Ġ(<': 43, 'ĠHermes': 43, 'ĠDACA': 43, 'ĠEminem': 43, 'ĠGPIO': 41}\n",
      "Things {'ĠYosemite': 47, 'ĠYellowstone': 45, 'ĠMiscellaneous': 43, 'ĠOTHER': 42, 'ĠGilmore': 42, 'ĠCalder': 41}\n",
      "ecided {'ĠDACA': 47, 'ĠBabylon': 43, 'ĠKeller': 42, 'ĠKimberly': 42, 'ĠWellington': 42, 'ĠBigfoot': 42}\n",
      "devices {'ĠOTHER': 47, 'ĠOthers': 45, 'ĠLazarus': 42, 'ĠValhalla': 42, 'ĠUFOs': 41, 'ĠMiscellaneous': 41}\n",
      "insk {'ĠAlz': 44, 'ĠRaqqa': 43, 'ĠPaleo': 43, 'ĠValhalla': 42, 'ĠNightmares': 42, 'ĠGoblin': 42}\n",
      "ilies {'ĠMiscellaneous': 45, 'ĠYosemite': 45, 'ĠCic': 42, 'ĠGilmore': 42, 'ĠiCloud': 42, 'ĠTravels': 42}\n",
      "Contents {'ĠYosemite': 44, 'ĠDACA': 44, 'ĠMcCabe': 43, 'ĠTanaka': 43, 'ĠWinchester': 42, 'ĠOkin': 42}\n",
      "itals {'ĠDACA': 45, 'ĠMSM': 44, 'ĠFisheries': 43, 'ĠMarriott': 43, 'ĠAvalon': 41, 'ĠMcCabe': 41}\n",
      "readable {'ĠStockholm': 45, 'ĠGutierrez': 44, 'ĠMetroid': 43, 'ĠDelicious': 42, 'ĠSirius': 42, 'ĠKimberly': 42}\n",
      "engu {'ĠDACA': 46, 'ĠCowboy': 44, 'ĠLuxem': 42, 'ĠNAFTA': 42, 'ĠPOLITICO': 42, 'ĠMalk': 42}\n",
      "Source {'ĠValhalla': 44, 'ĠDeadpool': 44, 'ĠRosenthal': 44, 'ĠHighlander': 44, 'ĠWellington': 42, 'ĠBaylor': 42}\n",
      "Qaida {'ĠHighlander': 45, 'ĠFrieza': 44, 'ĠBridgewater': 43, 'ĠRamsay': 43, 'ĠMetroid': 42, 'ĠBigfoot': 42}\n",
      "keye {'ĠFenrir': 43, 'ĠUnicode': 43, 'ĠHighlander': 42, 'ĠCheong': 42, 'Ġsubsistence': 42, 'ĠBigfoot': 42}\n",
      "washer {'ĠMercury': 46, 'ĠLyon': 46, 'ĠiCloud': 42, 'ĠJudah': 41, 'ĠLogic': 41, 'ĠCourtney': 41}\n",
      "tein {'ĠMagnus': 45, 'ĠClifford': 45, 'ĠCheong': 44, 'ĠGregory': 42, 'ĠKendrick': 41, 'ĠNichols': 41}\n",
      "isle {'ĠGenetics': 43, 'ĠAdministrative': 42, 'ĠPOLITICO': 42, 'ĠFisheries': 42, 'ĠBabylon': 42, 'ĠCheney': 42}\n",
      "Ġ.\" {'\":\"': 49, '=\"': 44, 'Ġ\"(': 42, 'Ġ\"[': 42, 'Ġ\"{': 41, 'Ġ\"\\\\': 41}\n",
      "ampion {'Ġhereditary': 46, 'ĠIntermediate': 42, 'ĠNeuroscience': 42, 'ĠProgressive': 42, 'ĠHerz': 42, 'ĠAlpha': 41}\n",
      "malink {'ĠScion': 44, 'ĠWellington': 44, 'ĠSuicide': 43, 'ĠFuller': 42, 'ĠUltra': 42, 'ĠScorpion': 42}\n",
      "?' {\"Ġ'[\": 54, \"Ġ'(\": 48, 'ĠAvalon': 45, 'Ġ\"\\'': 41, 'ĠKendall': 39, 'ĠKonami': 39}\n",
      "Resources {'ĠMarriott': 46, 'ĠKimberly': 43, 'ĠMozilla': 43, 'ĠWikimedia': 42, 'ĠStamford': 41, 'ĠYellowstone': 41}\n",
      "uine {'ĠLibertarian': 45, 'ĠMongol': 44, 'ĠSatanic': 44, 'ĠTheodore': 43, 'ĠSlav': 41, 'ĠLabrador': 41}\n",
      "/\" {'ĠVolcano': 44, 'Ġ\"\\\\': 43, 'ĠSpock': 43, '=\"/': 43, 'ĠAlv': 42, 'Ġ\"/': 42}\n",
      "ournal {'ĠStamford': 44, 'ĠCowboy': 43, 'ĠTacoma': 43, 'ĠWellington': 42, 'ĠPortsmouth': 42, 'ĠWinchester': 42}\n",
      "isse {'ĠDeadpool': 46, 'ĠPlayboy': 45, 'ĠDaytona': 44, 'ĠKimberly': 42, 'ĠAppalachian': 42, 'ĠBuckingham': 41}\n",
      "omez {'ĠBreitbart': 47, 'ĠKimberly': 43, 'ĠAllan': 42, 'ĠSmithsonian': 42, 'ĠDeadpool': 42, 'ĠYiannopoulos': 41}\n",
      "ochet {'ĠClyde': 44, 'ĠSatanic': 44, 'ĠCheong': 43, 'ĠStefan': 43, 'ĠShanahan': 43, 'ĠJacqu': 41}\n",
      "inally {'ĠKimberly': 45, 'ĠSchwarz': 44, 'ĠKoz': 42, 'ĠMelvin': 42, 'ĠLibertarian': 42, 'ĠAzerb': 41}\n",
      "agate {'ĠClifford': 45, 'ĠKimberly': 44, 'ĠYellowstone': 44, 'ĠPercy': 42, 'ĠWatergate': 41, 'ĠChristina': 41}\n",
      "trump {'ĠUltron': 44, 'ĠLazarus': 43, 'ĠMarcel': 43, 'ĠStamford': 43, 'ĠTyrann': 42, 'ĠCowboy': 42}\n",
      "gencies {'ĠMiscellaneous': 46, 'ĠRohingya': 45, 'ĠMarketable': 43, 'ĠOthers': 42, 'ĠVarious': 41, 'ĠInterstellar': 41}\n",
      "bits {'ĠHerod': 44, 'ĠMiscellaneous': 43, 'ĠMayweather': 42, 'ĠDOD': 42, 'ĠManny': 42, 'ĠMarriott': 41}\n",
      "dirty {'ĠHerod': 45, 'ĠMiscellaneous': 44, 'Ġsynaptic': 42, 'ĠMonsanto': 42, 'ĠHerbert': 42, 'ĠBigfoot': 42}\n",
      "©¶æ¥µ {'ĠScient': 45, 'ĠPaleo': 43, 'ĠLibertarian': 43, 'Ġpositional': 42, 'Ġantitrust': 42, 'Ġscient': 41}\n",
      "odder {'ĠWinchester': 44, 'ĠMozilla': 43, 'ĠWilderness': 42, 'ĠBuffy': 42, 'ĠOkin': 42, 'ĠPlayboy': 41}\n",
      "worms {'ĠYosemite': 45, 'ĠLogic': 44, 'ĠMetallic': 42, 'ĠYellowstone': 42, 'ĠLabrador': 42, 'ĠHighland': 42}\n",
      "itle {'ĠComposite': 44, 'ĠGilmore': 42, 'ĠUlster': 42, 'ĠToxic': 42, 'ĠSic': 42, 'ĠMercury': 42}\n",
      "tones {'ĠTheodore': 43, 'ĠNeurolog': 43, 'ĠEmmanuel': 42, 'ĠCerberus': 42, 'ĠVarious': 42, 'ĠHercules': 42}\n",
      "ollywood {'ĠStamford': 45, 'ĠGarrison': 43, 'ĠPaleo': 42, 'ĠGilmore': 42, 'ĠMongol': 42, 'ĠEmmanuel': 42}\n",
      "letters {'ĠDACA': 47, 'ĠTelecommunications': 44, 'ĠThunderbolt': 43, 'ĠScion': 43, 'ĠRohingya': 42, 'ĠMiscellaneous': 41}\n",
      "aples {'ĠPlayboy': 44, 'ĠCourtney': 43, 'ĠNeuroscience': 42, 'ĠGlac': 42, 'ĠJacqu': 42, 'Ġdiscretionary': 42}\n",
      "earchers {'ĠWinchester': 43, 'ĠGrave': 43, 'ĠMSM': 43, 'ĠRepeat': 43, 'ĠMercury': 42, 'ĠFairfax': 42}\n",
      "eland {'ĠPlayboy': 46, 'ĠKimberly': 46, 'ĠSutherland': 42, 'ĠDACA': 41, 'ĠPOLITICO': 41, 'ĠTMZ': 41}\n",
      "Nature {'ĠMongol': 46, 'ĠRasmussen': 42, 'ĠLuxembourg': 42, 'ĠPortsmouth': 42, 'ĠNicarag': 42, 'ĠNavajo': 42}\n",
      "Games {'ĠMagnus': 45, 'ĠFlores': 43, 'ĠAvalon': 43, 'ĠValhalla': 43, 'ĠMiscellaneous': 42, 'ĠGlac': 42}\n",
      "umn {'ĠDmitry': 47, 'ĠFisheries': 42, 'ĠRasmussen': 42, 'ĠDefinitive': 42, 'ĠCthulhu': 41, 'ĠCaldwell': 41}\n",
      "axies {'ĠBarbarian': 44, 'ĠDecoder': 44, 'ĠYellowstone': 44, 'ĠYosemite': 42, 'ĠAppalachian': 42, 'ĠISIL': 41}\n",
      "recy {'ĠTsukuyomi': 47, 'ĠAero': 46, 'ĠPortsmouth': 44, 'ĠGreenwich': 42, 'ĠTyphoon': 41, 'ĠToxic': 40}\n",
      "!). {'Ġ(': 48, ')=(': 43, 'Ġ((': 42, 'Ġ$(': 42, ')(': 42, '(\\\\': 41}\n",
      "yrights {'ĠHerod': 43, 'ĠMiscellaneous': 43, 'ĠGears': 43, 'ĠKM': 43, 'ĠCabrera': 42, 'ĠMSM': 41}\n",
      "inces {'ĠYellowstone': 44, 'ĠDACA': 43, 'ĠCourtney': 43, 'ĠTheodore': 42, 'ĠFEMA': 42, 'ĠNeander': 41}\n",
      "ython {'ĠNAFTA': 44, 'ĠRasmussen': 44, 'ĠWool': 43, 'ĠNg': 42, 'ĠMSM': 42, 'ĠRamsey': 42}\n",
      "lington {'ĠDACA': 44, 'ĠWillow': 43, 'ĠMalk': 43, 'ĠNeptune': 42, 'ĠMcCartney': 42, 'ĠNFC': 41}\n",
      "ousy {'Ġabundantly': 47, 'Ġexclusively': 43, 'ĠAdministrative': 43, 'Ġnotoriously': 42, 'Ġcollectively': 41, 'ĠTyrann': 41}\n",
      "ucker {'ĠTroy': 43, 'ĠHighlander': 43, 'ĠGilmore': 43, 'ĠHerod': 42, 'ĠRosenthal': 42, 'ĠValerie': 42}\n",
      "ango {'ĠAppropriations': 45, 'ĠWashington': 43, 'ĠBuckingham': 42, 'ĠAmmunition': 42, 'ĠCaldwell': 41, 'ĠPortsmouth': 41}\n",
      "votes {'ĠMSM': 45, 'ĠFisheries': 44, 'ĠCongressional': 43, 'ĠSurvivor': 42, 'ĠMiscellaneous': 42, 'ĠJennings': 41}\n",
      "=~ {'ĠTeresa': 43, 'ĠSophia': 43, 'ĠFuller': 43, 'ĠJackie': 42, 'ĠDennis': 42, 'ĠPepe': 41}\n",
      "outine {'ĠRobo': 43, 'ĠRudolph': 42, 'ĠSatanic': 42, 'ĠAdministrative': 42, 'ĠKeystone': 42, 'ĠSecondary': 42}\n",
      "?\" {'Ġ\"<': 46, 'Ġ\"{': 44, '\":\"': 43, 'ĠAvalon': 42, 'ĠCatalyst': 42, 'Ġ\"[': 42}\n",
      "yrim {'ĠGalile': 46, 'ĠBabel': 43, 'ĠRaqqa': 43, 'ĠCheong': 42, 'ĠRohingya': 42, 'ĠMahmoud': 41}\n",
      "availability {'ĠRohingya': 48, 'ĠBigfoot': 42, 'ĠMongol': 42, 'ĠHispanic': 42, 'ĠQuebec': 41, 'ĠLatino': 41}\n",
      "Phill {'ĠKimberly': 45, 'ĠYellowstone': 42, 'ĠGabe': 42, 'ĠDeadpool': 42, 'ĠNathaniel': 42, 'ĠYosemite': 42}\n",
      "enders {'ĠAppropriations': 46, 'ĠCongressional': 43, 'ĠBenedict': 42, 'ĠCourtney': 41, 'ĠSeymour': 41, 'ĠOthers': 41}\n",
      "blems {'ĠMiscellaneous': 50, 'ĠFisheries': 43, 'ĠGears': 42, 'ĠTravels': 42, 'ĠHogwarts': 41, 'ĠWellington': 40}\n",
      "krit {'ĠKimberly': 45, 'Ġhypothal': 42, 'ĠNordic': 42, 'ĠMongol': 42, 'ĠYellowstone': 41, 'ĠKyoto': 41}\n",
      "uits {'ĠMiscellaneous': 47, 'ĠGilmore': 42, 'ĠGears': 42, 'ĠDACA': 42, 'Ġcontraceptive': 41, 'ĠGodzilla': 41}\n",
      "ĠGazette {'ĠDeadpool': 45, 'ĠAirbus': 42, 'ĠTacoma': 42, 'ĠBloomberg': 42, 'ĠMozilla': 42, 'ĠNavajo': 41}\n",
      "yards {'ĠMiscellaneous': 47, 'ĠAtlantis': 44, 'ĠValhalla': 43, 'ĠEndless': 42, 'ĠGlasgow': 41, 'ĠEnemies': 41}\n",
      "iddles {'ĠMiscellaneous': 47, 'ĠGears': 45, 'ĠNAFTA': 43, 'ĠAdministrative': 41, 'ĠDraco': 40, 'ĠMarriott': 40}\n",
      "Welcome {'ĠYosemite': 46, 'ĠBaylor': 44, 'ĠKyoto': 43, 'ĠMacy': 42, 'ĠDACA': 42, 'ĠKeller': 41}\n",
      "nikov {'ĠFenrir': 44, 'Ġ780': 44, 'ĠGoddard': 44, 'ĠSaturn': 42, 'ĠFuller': 41, 'ĠDACA': 41}\n",
      "Companies {'ĠOTHER': 46, 'ĠOthers': 46, 'ĠYosemite': 45, 'Ġothers': 42, 'ĠYellowstone': 41, 'ĠLazarus': 40}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "games {'ĠMiscellaneous': 45, 'ĠRosenthal': 44, 'ĠFisheries': 44, 'ĠMagnus': 42, 'ĠFlores': 42, 'ĠAvalon': 41}\n",
      "liners {'ĠWellington': 44, 'ĠRosenthal': 43, 'ĠYellowstone': 43, 'ĠNeurolog': 42, 'ĠKimberly': 42, 'ĠGoodwin': 41}\n",
      "Info {'ĠYosemite': 44, 'ĠNether': 43, 'ĠCynthia': 42, 'ĠHogwarts': 42, 'ĠJudah': 41, 'ĠKimberly': 41}\n",
      "heres {'ĠMiscellaneous': 44, 'ĠFuller': 43, 'ĠSeymour': 42, 'ĠRosenthal': 42, 'ĠAppalachian': 42, 'ĠUsername': 41}\n",
      "bles {'ĠFisheries': 45, 'ĠTsukuyomi': 44, 'ĠMiscellaneous': 43, 'ĠGPIO': 43, 'ĠGears': 42, 'ĠFISA': 41}\n",
      "Ġpodium {'ĠXeon': 44, 'ĠImper': 43, 'ĠHDMI': 43, 'ĠDACA': 42, 'ĠDSM': 42, 'ĠIMF': 41}\n",
      "humans {'ĠKimberly': 43, 'ĠKashmir': 42, 'ĠRohingya': 42, 'ĠTsukuyomi': 42, 'ĠOriental': 42, 'ĠBoko': 42}\n",
      "Methods {'ĠDACA': 45, 'ĠNAFTA': 43, 'ĠOTHER': 42, 'ĠMiscellaneous': 42, 'ĠAzerb': 41, 'ĠTol': 41}\n",
      "citizens {'ĠIntermediate': 43, 'ĠLibertarian': 43, 'ĠYellowstone': 42, 'ĠCrimean': 42, 'ĠRohingya': 42, 'ĠAdamant': 41}\n",
      "Wednesday {'ĠMozilla': 45, 'ĠEthereum': 43, 'ĠFitzpatrick': 42, 'ĠHerod': 42, 'ĠRedmond': 42, 'ĠScion': 42}\n",
      "omew {'ĠKimberly': 44, 'Ġherpes': 44, 'Ġskeletal': 43, 'ĠBarkley': 42, 'ĠGloria': 42, 'ĠSutherland': 41}\n",
      "Books {'ĠPOLITICO': 43, 'ĠMSM': 43, 'ĠMozilla': 43, 'ĠFisheries': 42, 'ĠAtari': 42, 'ĠDACA': 42}\n",
      "forum {'ĠValhalla': 53, 'ĠRaqqa': 43, 'ĠAlibaba': 42, 'ĠIdlib': 41, 'ĠWatergate': 41, 'ĠMercury': 40}\n",
      "berus {'ĠRagnarok': 45, 'ĠFenrir': 42, 'ĠClyde': 42, 'ĠProceedings': 42, 'ĠGoblin': 42, 'ĠPerkins': 42}\n",
      "nect {'ĠSiber': 43, 'ĠALEC': 42, 'ĠAlibaba': 42, 'ĠiCloud': 42, 'ĠNAFTA': 42, 'ĠJFK': 41}\n",
      "ĠHolder {'ĠMcA': 44, 'ĠVaughan': 42, 'ĠAdin': 42, 'ĠCourtney': 42, 'ĠEminem': 41, 'ĠUzbek': 41}\n",
      "gamer {'ĠPlayboy': 47, 'ĠCain': 43, 'ĠHighlander': 42, 'ĠBigfoot': 41, 'ĠPOLITICO': 41, 'ĠWellington': 41}\n",
      "alli {'ĠMorse': 47, 'ĠMagnus': 44, 'ĠFuller': 43, 'ĠMorty': 42, 'ĠGoddard': 41, 'ĠCalder': 40}\n",
      "ijuana {'ĠPOLITICO': 44, 'ĠMercury': 43, 'ĠMongol': 43, 'ĠMSM': 42, 'ĠSirius': 42, 'ĠMinotaur': 41}\n",
      "opa {'ĠRamsey': 44, 'ĠCynthia': 44, 'ĠComposite': 43, 'ĠGrave': 43, 'ĠFuller': 43, 'ĠGamble': 41}\n",
      "shine {'ĠMagnus': 44, 'ĠJM': 43, 'ĠSirius': 43, 'ĠCodex': 42, 'ĠHerod': 42, 'ĠMSM': 42}\n",
      "omething {'ĠKimberly': 43, 'ĠLibertarian': 43, 'Ġdisposable': 43, 'ĠCelsius': 42, 'ĠAmbrose': 42, 'ĠScarborough': 41}\n",
      "endix {'ĠDraco': 43, 'ĠKramer': 42, 'ĠPumpkin': 42, 'ĠShea': 42, 'ĠTravels': 42, 'ĠGiles': 42}\n",
      "oldemort {'ĠEmmanuel': 42, 'ĠKimberly': 42, 'ĠFlynn': 42, 'ĠWyatt': 42, 'ĠOsama': 42, 'ĠClyde': 42}\n",
      "onge {'ĠVictoria': 46, 'ĠGlasgow': 43, 'ĠPlayboy': 42, 'ĠHighlander': 42, 'ĠEminem': 42, 'ĠKerala': 41}\n",
      "aughlin {'ĠOsama': 44, 'ĠWinston': 43, 'ĠTheodore': 42, 'ĠAbdul': 42, 'ĠAllan': 42, 'ĠStefan': 42}\n",
      "lander {'ĠClifford': 44, 'ĠClassical': 43, 'ĠKimberly': 43, 'ĠCassidy': 43, 'ĠHighlander': 42, 'ĠCherokee': 41}\n",
      "ateurs {'ĠRosenthal': 45, 'ĠSeymour': 42, 'ĠTelecommunications': 42, 'ĠAdamant': 42, 'ĠRamsay': 42, 'ĠNorton': 41}\n",
      "paralleled {'ĠDACA': 44, 'ĠOPT': 44, 'ĠMetroid': 42, 'ĠTsukuyomi': 42, 'ĠNAFTA': 42, 'ĠUNESCO': 41}\n",
      "aunders {'ĠManny': 43, 'ĠRobbins': 43, 'ĠTheodore': 42, 'ĠCyrus': 42, 'ĠClifford': 42, 'ĠStaples': 42}\n",
      "ĠGutenberg {'ĠDeadpool': 45, 'ĠScorpion': 44, 'ĠPlayboy': 42, 'ĠTMZ': 42, 'ĠKimberly': 41, 'ĠYosemite': 41}\n",
      "adesh {'ĠGPIO': 49, 'ĠCalder': 42, 'ĠHarlem': 41, 'ĠSurvivors': 41, 'ĠTroy': 41, 'ĠJudah': 41}\n",
      "rongh {'ĠDACA': 44, 'ĠOsama': 44, 'ĠNAFTA': 43, 'ĠLibertarian': 42, 'ĠKabul': 42, 'ĠTMZ': 41}\n",
      "storms {'ĠCooperative': 44, 'ĠMarketable': 43, 'ĠTsukuyomi': 42, 'ĠMiscellaneous': 42, 'ĠRoller': 42, 'ĠRosenthal': 41}\n",
      "ornia {'ĠGilmore': 44, 'ĠValhalla': 44, 'ĠMongolia': 44, 'ĠBelarus': 43, 'ĠSirius': 42, 'ĠMongol': 42}\n",
      "ophy {'ĠWellington': 43, 'ĠKimberly': 43, 'ĠWestminster': 42, 'ĠArlington': 42, 'ĠYosemite': 42, 'ĠAdministrative': 42}\n",
      "rentice {'ĠPlayboy': 44, 'ĠMercury': 43, 'ĠDACA': 42, 'ĠWellington': 42, 'ĠGreenpeace': 42, 'ĠAntioch': 42}\n",
      "itures {'ĠFisheries': 46, 'ĠGears': 43, 'ĠMiscellaneous': 42, 'ĠElements': 42, 'ĠWraith': 41, 'ĠRosenthal': 41}\n",
      "`, {'Ġ`': 56, '`': 47, 'ĠMalfoy': 43, 'ĠHogwarts': 41, 'ĠLeBron': 40, 'ĠObamacare': 39}\n",
      "adiator {'ĠMongol': 45, 'ĠLibertarian': 43, 'ĠMercury': 42, 'ĠWellington': 41, 'ĠCalgary': 41, 'ĠOrlando': 41}\n",
      "byn {'ĠDeadpool': 43, 'ĠDorothy': 43, 'ĠDerek': 42, 'ĠKimberly': 41, 'ĠEmmanuel': 41, 'ĠMelania': 41}\n",
      "ĠCoulter {'ĠDmitry': 45, 'ĠKhalid': 44, 'ĠRudolph': 42, 'ĠRafael': 41, 'ĠKimberly': 41, 'ĠAdolf': 41}\n",
      "locks {'ĠTsukuyomi': 46, 'ĠSeymour': 42, 'ĠMiscellaneous': 41, 'ĠBoko': 41, 'ĠNavajo': 41, 'ĠFisheries': 41}\n",
      "ĠSources {'ĠMarketable': 44, 'ĠMarriott': 42, 'ĠHighlander': 42, 'ĠMultiplayer': 42, 'ĠOffline': 41, 'ĠDACA': 41}\n",
      "atown {'ĠBelfast': 43, 'ĠWellington': 43, 'ĠKarachi': 43, 'ĠKavanaugh': 42, 'ĠArkham': 41, 'ĠUlster': 41}\n",
      "aepernick {'ĠMarcel': 46, 'ĠEclipse': 42, 'ĠBuffy': 42, 'ĠClyde': 42, 'ĠKhalid': 41, 'ĠJulian': 41}\n",
      "Thursday {'ĠEthereum': 44, 'ĠMozilla': 44, 'ĠHerod': 43, 'ĠFitzpatrick': 42, 'ĠKeller': 41, 'ĠGutierrez': 41}\n",
      "ultimate {'ĠGrizz': 45, 'ĠNicarag': 43, 'ĠPaleo': 42, 'ĠCrypto': 41, 'ĠEmmy': 41, 'ĠBigfoot': 41}\n",
      "Ġacademia {'ĠRafael': 44, 'ĠWellington': 44, 'ĠMetroid': 43, 'ĠWatergate': 42, 'ĠMalk': 41, 'ĠTripoli': 41}\n",
      "letes {'ĠYosemite': 47, 'ĠTsukuyomi': 43, 'ĠMathemat': 43, 'ĠMercury': 42, 'ĠAppalachian': 41, 'ĠLibertarian': 41}\n",
      "Tuesday {'ĠEthereum': 44, 'ĠMozilla': 44, 'ĠFitzpatrick': 42, 'ĠRedmond': 42, 'ĠBelarus': 41, 'ĠHonduras': 41}\n",
      "Ġ()); {')=(': 46, 'Ġ(': 44, 'ĠTimothy': 42, 'Ġ$(': 42, '))))': 41, ':(': 41}\n",
      "anta {'ĠJPMorgan': 42, 'ĠBabylon': 42, 'ĠPOLITICO': 42, 'ĠHermione': 42, 'ĠBuckingham': 42, 'ĠDACA': 42}\n",
      "STEM {'ĠLazarus': 45, 'ĠWellington': 42, 'ĠDACA': 42, 'ĠGoodman': 42, 'ĠYellowstone': 41, 'ĠBriggs': 41}\n",
      "osphere {'ĠRosenthal': 44, 'ĠUnc': 43, 'ĠRagnarok': 42, 'ĠFuller': 42, 'ĠKimberly': 42, 'ĠBelarus': 42}\n",
      "ormons {'ĠTelecommunications': 46, 'ĠAntarctic': 42, 'Ġneurological': 42, 'ĠLibertarian': 41, 'ĠNeurolog': 41, 'ĠDACA': 41}\n",
      "ople {'ĠAtlantis': 44, 'ĠCivilization': 42, 'ĠTelecommunications': 42, 'ĠDorothy': 42, 'ĠLuxembourg': 41, 'ĠSurvivors': 41}\n",
      "stocks {'ĠBorderlands': 44, 'ĠAtlantis': 43, 'ĠYosemite': 43, 'ĠGears': 41, 'ĠHerod': 41, 'ĠHogwarts': 41}\n",
      "Cache {'ĠBaylor': 47, 'ĠLatvia': 44, 'ĠOlson': 43, 'ĠPerkins': 41, 'ĠCourtney': 41, 'ĠOrtiz': 41}\n",
      "vind {'ĠMelvin': 43, 'ĠHerod': 42, 'ĠFlores': 42, 'ĠCannabis': 42, 'ĠKimberly': 42, 'ĠJM': 41}\n",
      "initions {'ĠNeurolog': 45, 'ĠAppalachian': 44, 'ĠGrizz': 42, 'ĠCongressional': 42, 'ĠCutler': 41, 'ĠNorton': 41}\n",
      "slaught {'ĠDag': 43, 'ĠNieto': 42, 'ĠMohammed': 42, 'ĠToken': 42, 'ĠSamson': 42, 'ĠBuddy': 41}\n",
      "magic {'ĠArlington': 45, 'ĠBabylon': 44, 'ĠTMZ': 42, 'ĠHighlander': 41, 'ĠCheong': 41, 'ĠRagnarok': 41}\n",
      "minded {'ĠMelissa': 43, 'ĠRudolph': 43, 'ĠMeh': 42, 'ĠDerek': 41, 'ĠOsama': 41, 'ĠNeph': 41}\n",
      "ixtures {'ĠMarriott': 45, 'ĠGPIO': 45, 'ĠMiscellaneous': 43, 'ĠDACA': 42, 'ĠHerod': 41, 'ĠAzerb': 41}\n",
      "lasses {'ĠMiscellaneous': 45, 'ĠTsukuyomi': 43, 'ĠPetty': 42, 'ĠBattlefield': 42, 'ĠGears': 41, 'ĠTravels': 41}\n",
      "autions {'ĠMiscellaneous': 45, 'ĠFisheries': 44, 'Ġcounterterrorism': 44, 'ĠDACA': 41, 'ĠMSM': 41, 'Ġmisconceptions': 41}\n",
      "Ġobjects {'ĠDACA': 45, 'ĠMiscellaneous': 44, 'ĠGears': 42, 'ĠOTHER': 42, 'ĠSecondary': 41, 'ĠMcAuliffe': 40}\n",
      "ottage {'ĠValhalla': 48, 'ĠManny': 42, 'ĠJohnson': 41, 'ĠHowell': 41, 'ĠStaples': 41, 'ĠLazarus': 41}\n",
      "ModLoader {'ĠClyde': 49, 'ĠDraco': 45, 'ĠMercury': 44, 'ĠGoblin': 42, 'ĠMPEG': 40, 'ĠGalile': 39}\n",
      "ĠLuffy {'ĠLyndon': 43, 'ĠKimberly': 43, 'ĠClyde': 42, 'ĠOprah': 42, 'ĠViktor': 41, 'ĠLockheed': 41}\n",
      "onse {'ĠAdministrative': 44, 'ĠUNCLASSIFIED': 43, 'ĠMagnus': 42, 'ĠMSM': 42, 'ĠHowell': 41, 'ĠComposite': 41}\n",
      "kward {'ĠSatanic': 45, 'ĠClayton': 42, 'ĠOsama': 42, 'ĠNether': 42, 'ĠNotting': 42, 'Ġpsychotic': 40}\n",
      "geries {'ĠMiscellaneous': 46, 'ĠGPIO': 43, 'ĠMSM': 43, 'ĠRosenthal': 42, 'ĠCitizenship': 41, 'ĠKimberly': 41}\n",
      "Wisconsin {'ĠValhalla': 43, 'ĠKimberly': 42, 'ĠPercy': 42, 'ĠTrinidad': 42, 'ĠFreddie': 41, 'ĠNotting': 41}\n",
      "amus {'ĠPerkins': 45, 'ĠMarcel': 43, 'ĠGutierrez': 42, 'ĠGoodman': 41, 'ĠMahmoud': 41, 'ĠScarlett': 41}\n",
      "estone {'ĠWellington': 44, 'ĠMSM': 43, 'ĠRosenthal': 43, 'ĠDACA': 42, 'ĠEmmanuel': 41, 'ĠMcCabe': 41}\n",
      "Ġ}); {'({': 50, 'Ġ({': 49, 'Ġ((': 41, ':(': 40, 'Ġ([': 40, 'Ġ(': 39}\n",
      "paces {'ĠAvalon': 44, 'ĠLiberty': 42, 'ĠJFK': 42, 'ĠMiscellaneous': 42, 'ĠHermes': 41, 'ĠGilmore': 41}\n",
      "adra {'ĠAlexandria': 45, 'ĠValhalla': 44, 'ĠArlington': 41, 'ĠClayton': 41, 'ĠIntermediate': 41, 'ĠGlasgow': 41}\n",
      "breaker {'ĠDaytona': 44, 'ĠLuxembourg': 42, 'ĠWeasley': 42, 'ĠYellowstone': 42, 'ĠGenetics': 42, 'ĠEmmanuel': 41}\n",
      "croft {'ĠHercules': 43, 'ĠGoodman': 42, 'ĠALEC': 42, 'ĠDACA': 42, 'ĠGoodwin': 41, 'ĠPOLITICO': 41}\n",
      "eger {'ĠHerz': 45, 'ĠKarma': 43, 'ĠJudah': 42, 'ĠHighlander': 42, 'ĠKimberly': 41, 'ĠVertical': 41}\n",
      "uters {'ĠNether': 43, 'ĠAllan': 42, 'ĠNathaniel': 42, 'ĠAbram': 42, 'ĠRidley': 41, 'ĠTheodore': 41}\n",
      "photos {'ĠTravels': 44, 'ĠABE': 42, 'ĠOTHER': 41, 'ĠAllan': 41, 'ĠSamantha': 41, 'ĠSirius': 41}\n",
      "far {'ĠEminem': 46, 'ĠGPIO': 44, 'ĠOsama': 42, 'ĠNFC': 42, 'ĠTammy': 42, 'ĠKimberly': 41}\n",
      "pox {'ĠNeuroscience': 47, 'ĠCountdown': 43, 'ĠFriendship': 42, 'ĠNeural': 41, 'ĠMacBook': 41, 'ĠSonic': 41}\n",
      "aroo {'ĠHermione': 45, 'ĠFrankie': 42, 'ĠMolly': 42, 'ĠBecky': 41, 'ĠMeredith': 41, 'ĠSusan': 41}\n",
      "eatures {'ĠTravels': 46, 'ĠMiscellaneous': 44, 'ĠGears': 43, 'ĠCerberus': 41, 'ĠHogwarts': 41, 'ĠFlores': 40}\n",
      "ĠFiorina {'ĠDmitry': 45, 'ĠJared': 44, 'ĠColin': 42, 'ĠCyrus': 41, 'ĠOsama': 41, 'ĠHillary': 41}\n",
      "testers {'ĠKimberly': 43, 'ĠChristy': 43, 'ĠFischer': 42, 'ĠWarranty': 42, 'ĠTsukuyomi': 42, 'ĠIndigo': 41}\n",
      "cember {'ĠMueller': 47, 'ĠHermes': 43, 'ĠCinnamon': 41, 'ĠRog': 41, 'ĠMohammed': 41, 'ĠHarrison': 41}\n",
      "rollment {'ĠRohingya': 44, 'ĠRagnarok': 42, 'ĠFuller': 42, 'ĠPlanetary': 42, 'ĠMercury': 41, 'ĠCongressional': 41}\n",
      "lymp {'ĠMercury': 46, 'ĠMarriott': 44, 'ĠFiat': 44, 'ĠSinclair': 41, 'ĠMPEG': 41, 'ĠMSM': 40}\n",
      "things {'ĠMiscellaneous': 44, 'ĠPortsmouth': 43, 'ĠGilmore': 42, 'ĠOTHER': 42, 'ĠYosemite': 41, 'ĠYellowstone': 41}\n",
      "Journal {'ĠPortsmouth': 46, 'ĠMozilla': 43, 'ĠMetroid': 42, 'ĠTMZ': 42, 'ĠDaytona': 41, 'ĠTacoma': 41}\n",
      "redits {'ĠMetatron': 43, 'ĠHogwarts': 42, 'ĠUFO': 42, 'ĠMedline': 42, 'ĠDACA': 42, 'ĠTheodore': 41}\n",
      "mails {'ĠMetallic': 44, 'Ġleftover': 42, 'ĠNeo': 42, 'ĠFuller': 42, 'ĠMiscellaneous': 41, 'ĠMetall': 41}\n",
      "phies {'ĠFuller': 45, 'ĠDACA': 44, 'ĠDecoder': 42, 'ĠMillions': 41, 'ĠMagnus': 40, 'ĠGram': 40}\n",
      "oyle {'ĠFreddie': 43, 'ĠGlasgow': 42, 'ĠFitzpatrick': 42, 'ĠDamien': 41, 'ĠAppalachian': 41, 'ĠVoyager': 41}\n",
      "forces {'ĠMSM': 44, 'ĠGenetics': 43, 'ĠFisheries': 42, 'ĠiCloud': 41, 'ĠCameroon': 41, 'ĠKaufman': 41}\n",
      "initialized {'ĠDACA': 45, 'ĠKimberly': 42, 'ĠEllison': 42, 'ĠHeidi': 42, 'ĠDrew': 41, 'ĠPamela': 41}\n",
      "robat {'ĠPortsmouth': 45, 'ĠGears': 44, 'ĠDaytona': 42, 'ĠPOLITICO': 41, 'ĠGoblin': 41, 'ĠQuake': 41}\n",
      "Ġholidays {'ĠMiscellaneous': 42, 'ĠRohingya': 42, 'ĠKepler': 42, 'ĠMetall': 41, 'ĠAllaah': 41, 'ĠKoz': 41}\n",
      "ither {'ĠConstantinople': 43, 'ĠFisheries': 42, 'ĠMedline': 42, 'ĠBabylon': 42, 'ĠPastebin': 42, 'ĠVolkswagen': 41}\n",
      "vich {'ĠBridgewater': 42, 'ĠSyd': 42, 'ĠMarcel': 42, 'ĠJerry': 42, 'ĠDACA': 41, 'ĠManny': 41}\n",
      "pointers {'ĠGears': 46, 'ĠAppropriations': 43, 'ĠMiscellaneous': 42, 'Ġdiscretionary': 41, 'ĠGenetics': 41, 'ĠTelecommunications': 40}\n",
      "enez {'ĠGrayson': 43, 'ĠMcKenzie': 43, 'ĠCrowley': 43, 'ĠMcKenna': 42, 'ĠBlumenthal': 41, 'ĠWarlock': 41}\n",
      "Credits {'ĠMillennium': 43, 'ĠFisheries': 42, 'ĠDSL': 42, 'ĠMetatron': 42, 'ĠDACA': 42, 'ĠTsukuyomi': 41}\n",
      "Availability {'ĠBaylor': 44, 'ĠRohingya': 42, 'ĠDroid': 42, 'ĠQuebec': 42, 'ĠMongol': 41, 'ĠYosemite': 41}\n",
      "ĠKaepernick {'ĠMarcel': 46, 'ĠEmmanuel': 42, 'ĠKhalid': 42, 'ĠYellowstone': 41, 'ĠClyde': 41, 'ĠBuffy': 41}\n",
      "bots {'ĠFisheries': 43, 'ĠDACA': 43, 'ĠMetatron': 42, 'ĠOriental': 41, 'ĠStamford': 41, 'ĠCelt': 41}\n",
      "ĠIssa {'ĠGarry': 42, 'ĠRonald': 42, 'ĠEminem': 42, 'ĠMalik': 42, 'ĠGarland': 42, 'ĠDennis': 41}\n",
      "beard {'ĠDeadpool': 43, 'ĠBuffy': 43, 'ĠPink': 42, 'ĠBuzz': 42, 'ĠScarlett': 41, 'ĠOsama': 41}\n",
      "iquette {'ĠGears': 47, 'ĠNeurolog': 42, 'ĠPortsmouth': 41, 'ĠBerman': 41, 'ĠHind': 41, 'ĠBorder': 41}\n",
      "flation {'ĠWraith': 42, 'ĠRosenthal': 42, 'ĠMSM': 42, 'ĠLieberman': 42, 'ĠWestminster': 41, 'ĠRasmussen': 41}\n",
      "ibliography {'ĠCongressional': 43, 'ĠAdministrative': 42, 'ĠAlz': 42, 'ĠShiite': 41, 'ĠFisheries': 41, 'ĠNuclear': 41}\n",
      "oldown {'ĠCage': 43, 'ĠOrtiz': 42, 'ĠVulkan': 41, 'ĠFahrenheit': 41, 'ĠHogwarts': 41, 'ĠRasmussen': 41}\n",
      "ppelin {'ĠBarbarian': 44, 'ĠMonsanto': 42, 'ĠHerod': 42, 'ĠArist': 42, 'ĠBYU': 42, 'ĠRidley': 41}\n",
      "legate {'ĠPortsmouth': 45, 'ĠSidney': 43, 'ĠRosenthal': 42, 'ĠWellington': 41, 'ĠChristy': 41, 'ĠGlasgow': 41}\n",
      "Indiana {'ĠTrinidad': 43, 'ĠFranklin': 42, 'ĠValhalla': 42, 'ĠJulio': 42, 'ĠManny': 41, 'ĠWillow': 41}\n",
      "oglobin {'ĠMercury': 43, 'ĠGarrison': 42, 'ĠGoat': 42, 'ĠGarfield': 42, 'ĠMcCabe': 42, 'ĠMarriott': 41}\n",
      "arms {'ĠMiscellaneous': 47, 'ĠBarbarian': 42, 'ĠNotting': 42, 'ĠFisheries': 42, 'ĠOthers': 41, 'ĠOTHER': 41}\n",
      "Exception {'ĠMathematics': 43, 'ĠVeterans': 42, 'ĠGladiator': 41, 'ĠPortsmouth': 41, 'ĠCrypto': 41, 'ĠRosenthal': 41}\n",
      "amara {'ĠRidley': 43, 'ĠArlington': 43, 'ĠSmithsonian': 42, 'ĠNYU': 41, 'ĠKimberly': 41, 'ĠBoeing': 41}\n",
      "Brien {'ĠHermes': 43, 'ĠClyde': 42, 'ĠMarcel': 42, 'ĠMPEG': 42, 'ĠSeymour': 41, 'ĠKhalid': 41}\n",
      "azines {'ĠDACA': 45, 'ĠAES': 42, 'ĠARC': 42, 'ĠEPS': 41, 'ĠGPIO': 41, 'ĠCAL': 40}\n",
      "agascar {'ĠNottingham': 44, 'ĠTacoma': 43, 'ĠMueller': 42, 'ĠStamford': 41, 'ĠRafael': 41, 'ĠPercy': 41}\n",
      "shirt {'Ġpolygamy': 44, 'ĠBabylon': 43, 'ĠHerod': 42, 'ĠHispanic': 42, 'ĠFiesta': 41, 'ĠHispanics': 40}\n",
      "Ġfixtures {'ĠDACA': 46, 'ĠMacro': 41, 'ĠMSM': 41, 'ĠMarketable': 41, 'ĠGalile': 41, 'ĠMillennium': 41}\n",
      "steamapps {'ĠDACA': 47, 'ĠGray': 43, 'ĠDraco': 42, 'ĠFEMA': 41, 'ĠShiny': 40, 'ĠYellowstone': 40}\n",
      "seys {'ĠValhalla': 44, 'ĠBarbarian': 41, 'ĠPaleo': 41, 'ĠNavajo': 41, 'ĠMetroid': 41, 'ĠHogwarts': 41}\n",
      "userc {'ĠGreenwich': 43, 'ĠKimberly': 42, 'ĠNavajo': 41, 'ĠClyde': 41, 'ĠPaddock': 41, 'ĠGoddard': 41}\n",
      "soType {'ĠYellowstone': 44, 'ĠMercury': 44, 'ĠBoehner': 41, 'ĠFrederick': 41, 'ĠMoses': 41, 'ĠBuffy': 41}\n",
      "aukee {'ĠRih': 43, 'ĠTurnbull': 43, 'ĠMercury': 42, 'ĠBigfoot': 42, 'ĠBuffy': 41, 'ĠYellowstone': 41}\n",
      "atars {'ĠAllan': 44, 'ĠNightmares': 42, 'ĠCutler': 42, 'ĠAbram': 42, 'ĠTravels': 41, 'ĠMelanie': 41}\n",
      "ruary {'ĠHermes': 44, 'ĠFlores': 42, 'ĠWebs': 42, 'ĠMueller': 42, 'ĠMercury': 41, 'ĠPerse': 40}\n",
      "hunt {'ĠHuff': 43, 'ĠOlson': 42, 'ĠFrazier': 42, 'ĠPearson': 42, 'ĠLieberman': 41, 'ĠLindsey': 41}\n",
      "porary {'ĠMichele': 43, 'ĠGPIO': 42, 'ĠHighlander': 42, 'ĠChau': 41, 'ĠGrizz': 41, 'ĠDACA': 41}\n",
      "itzerland {'ĠTacoma': 44, 'ĠMetroid': 42, 'ĠGrizz': 42, 'ĠKimberly': 41, 'ĠRohingya': 41, 'ĠRudolph': 41}\n",
      "Ġentities {'ĠMiscellaneous': 43, 'ĠTemporary': 42, 'ĠDACA': 42, 'Ġmicroscopic': 41, 'ĠArcane': 41, 'ĠSecondary': 41}\n",
      "herty {'ĠWinston': 43, 'ĠAllan': 43, 'ĠEminem': 42, 'ĠOsama': 42, 'ĠJonathan': 41, 'ĠPercy': 41}\n",
      "minist {'ĠWellington': 45, 'ĠAtkins': 43, 'Ġlogistical': 43, 'Ġnominal': 41, 'ĠPaleo': 40, 'ĠDefinitive': 40}\n",
      "ansas {'ĠDACA': 43, 'ĠByrne': 42, 'ĠWellington': 42, 'ĠBlackburn': 42, 'ĠSlayer': 41, 'ĠGrimes': 41}\n",
      "earances {'ĠMiscellaneous': 44, 'ĠFuller': 43, 'ĠAdministrative': 42, 'ĠTelecommunications': 42, 'ĠCongressional': 42, 'ĠFisheries': 40}\n",
      "Pages {'ĠRobbins': 45, 'ĠAtari': 42, 'ĠWinchester': 42, 'ĠBelarus': 41, 'ĠHogwarts': 41, 'ĠRochester': 41}\n",
      "ulz {'ĠFuller': 44, 'ĠLabrador': 43, 'ĠMagnus': 42, 'ĠMohammed': 41, 'ĠTomato': 41, 'ĠCyrus': 41}\n",
      "ousel {'ĠGilmore': 44, 'ĠOPT': 43, 'ĠGPIO': 42, 'ĠNAFTA': 41, 'ĠKimberly': 41, 'ĠBabel': 41}\n",
      "ActionCode {'ĠNAFTA': 43, 'ĠMPEG': 41, 'ĠDaredevil': 41, 'ĠYellowstone': 41, 'ĠMalfoy': 41, 'ĠGoblin': 41}\n",
      "itchie {'ĠKimberly': 42, 'ĠCaldwell': 42, 'ĠEdmund': 42, 'ĠWinston': 42, 'ĠMonsanto': 41, 'ĠMelvin': 41}\n",
      "istries {'ĠMiscellaneous': 44, 'ĠISIL': 42, 'ĠYosemite': 41, 'ĠTsukuyomi': 41, 'ĠMSM': 41, 'ĠTelecommunications': 41}\n",
      "leaders {'ĠYosemite': 43, 'ĠNeurolog': 42, 'ĠAppalachian': 42, 'ĠAdamant': 42, 'ĠTelecommunications': 41, 'ĠAppropriations': 41}\n",
      "Reuters {'ĠPOLITICO': 45, 'ĠDennis': 42, 'ĠPaleo': 42, 'ĠGorsuch': 41, 'ĠAtkins': 41, 'ĠMedline': 41}\n",
      "packages {'ĠKeller': 43, 'ĠGears': 43, 'ĠMetatron': 42, 'ĠJPM': 41, 'ĠKM': 41, 'ĠNether': 40}\n",
      "tymology {'ĠDACA': 43, 'ĠFuller': 43, 'ĠKhalid': 42, 'ĠPaleo': 41, 'ĠSuk': 41, 'ĠSlayer': 41}\n",
      "?'\" {'Ġ\"\\'': 50, '\":\"': 47, 'Ġ\"<': 42, \"Ġ'[\": 41, 'Ġ\"[': 40, 'ĠAvalon': 39}\n",
      "rums {'ĠCourtney': 44, 'ĠMiscellaneous': 44, 'ĠGears': 41, 'ĠSands': 41, 'ĠMcGu': 41, 'ĠNeurolog': 41}\n",
      "Details {'ĠBigfoot': 44, 'ĠYellowstone': 42, 'ĠHogwarts': 42, 'ĠMSM': 41, 'ĠBoeing': 41, 'ĠGPIO': 41}\n",
      "ppard {'ĠFairfax': 43, 'ĠMarcel': 42, 'ĠWellington': 42, 'ĠMelvin': 42, 'ĠClifford': 41, 'ĠNorton': 41}\n",
      "uliffe {'ĠCutler': 43, 'ĠMarketable': 42, 'ĠMoss': 41, 'Ġunintentional': 41, 'ĠCardinal': 41, 'ĠNether': 41}\n",
      "Ġcases {'ĠMiscellaneous': 46, 'ĠMSM': 43, 'ĠBarbarian': 41, 'ĠTelecommunications': 41, 'ĠSerious': 41, 'ĠYosemite': 41}\n",
      "*, {'Ġ*': 49, 'Ġ(*': 46, 'Ġ[*': 42, 'Ġ{*': 40, '(*': 40, 'Ġ*)': 39}\n",
      "?). {'Ġ(': 49, 'Ġ((': 44, ')(': 42, ')=(': 41, ':(': 40, '(': 40}\n",
      "Batman {'ĠLibertarian': 44, 'ĠMozilla': 44, 'ĠGarrison': 42, 'ĠStamford': 41, 'ĠLuxembourg': 41, 'ĠBlaz': 41}\n",
      "stones {'ĠGears': 43, 'ĠWellington': 42, 'ĠCourtney': 42, 'ĠMSM': 41, 'ĠDACA': 41, 'ĠRosenthal': 41}\n",
      "cade {'ĠCitizenship': 43, 'ĠFitzpatrick': 42, 'ĠComcast': 42, 'ĠRosenthal': 42, 'ĠFuller': 41, 'ĠMongol': 41}\n",
      "otechnology {'ĠLazarus': 45, 'ĠWellington': 43, 'ĠGarrison': 42, 'ĠAmmunition': 42, 'ĠMetroid': 42, 'ĠKimberly': 40}\n",
      "Street {'ĠWellington': 45, 'ĠOblivion': 42, 'ĠMercury': 42, 'ĠNeptune': 41, 'ĠLuxembourg': 41, 'ĠKimberly': 41}\n",
      "anwhile {'ĠJared': 43, 'ĠMSM': 42, 'ĠAdministrative': 41, 'ĠMelvin': 41, 'ĠLabrador': 41, 'ĠDj': 41}\n",
      "recated {'ĠKimberly': 45, 'ĠPerez': 43, 'ĠWellington': 43, 'ĠBerman': 43, 'ĠRosenstein': 41, 'ĠJared': 40}\n",
      "ĠJones {'ĠChristy': 44, 'ĠPatricia': 42, 'ĠKathryn': 41, 'ĠKimberly': 41, 'ĠCyrus': 41, 'ĠJulio': 41}\n",
      "cert {'ĠDACA': 47, 'ĠTMZ': 41, 'ĠDaytona': 41, 'ĠTacoma': 41, 'ĠUFO': 41, 'ĠTCU': 40}\n",
      "habi {'ĠFrieza': 43, 'ĠPaleo': 42, 'ĠHighlander': 42, 'ĠSharif': 41, 'ĠZoro': 41, 'ĠCrowley': 41}\n",
      "200000 {'ĠNether': 45, 'ĠMercury': 43, 'ĠCyrus': 42, 'ĠGHC': 41, 'ĠTitan': 40, 'ĠChallenger': 40}\n",
      "ovember {'ĠCipher': 43, 'ĠTransparency': 42, 'ĠDag': 42, 'Ġdependency': 41, 'Ġcipher': 41, 'ĠMedia': 41}\n",
      "fy {'ĠNicarag': 44, 'ĠRasmussen': 43, 'ĠAvalon': 41, 'ĠBabylon': 41, 'ĠMongol': 41, 'ĠUlster': 41}\n",
      "mberg {'ĠFlynn': 44, 'ĠMarcel': 44, 'ĠKhalid': 42, 'ĠFenrir': 42, 'ĠTed': 41, 'ĠClyde': 40}\n",
      "*=- {'Ġ*': 44, 'Ġ[*': 43, 'ĠNathaniel': 42, 'ĠJackie': 41, 'ĠJacqu': 41, 'ĠLazarus': 41}\n",
      "NULL {'ĠYosemite': 43, 'ĠGreenwich': 42, 'ĠMcGill': 42, 'ĠBigfoot': 42, 'ĠDACA': 42, 'ĠMercury': 41}\n",
      "emonium {'ĠRagnarok': 45, 'ĠSatanic': 42, 'ĠImplementation': 41, 'ĠLegislative': 41, 'ĠTsukuyomi': 41, 'ĠINFORMATION': 41}\n",
      "Ġisland {'ĠMercury': 46, 'ĠAlz': 43, 'ĠEminem': 42, 'ĠKimberly': 41, 'ĠCedar': 41, 'ĠEmmanuel': 41}\n",
      "Appearances {'ĠFuller': 43, 'ĠMSM': 42, 'ĠMobility': 41, 'ĠUnicode': 41, 'ĠTelevision': 41, 'ĠCompliance': 41}\n",
      "iasco {'ĠBoko': 45, 'ĠPerkins': 42, 'ĠQuentin': 41, 'ĠFuller': 41, 'ĠNotting': 41, 'ĠWilkinson': 40}\n",
      "Ġcapitals {'ĠDACA': 48, 'ĠMcCabe': 44, 'ĠMiscellaneous': 43, 'ĠJPM': 40, 'ĠTravels': 40, 'ĠPaige': 40}\n",
      "cerpt {'ĠRobinson': 44, 'ĠScarborough': 42, 'ĠPastor': 41, 'ĠNeon': 41, 'ĠDACA': 41, 'ĠPalest': 41}\n",
      "ueller {'ĠLazarus': 43, 'ĠMorty': 43, 'ĠAdamant': 41, 'ĠHerbert': 41, 'ĠFlynn': 41, 'ĠNathaniel': 41}\n",
      "asons {'ĠMiscellaneous': 43, 'ĠGears': 43, 'ĠTheodore': 42, 'ĠOTHER': 41, 'ĠEthereum': 41, 'ĠDACA': 41}\n",
      "ĠParenthood {'ĠValhalla': 42, 'ĠMetroid': 42, 'ĠZub': 41, 'ĠPercy': 41, 'ĠHighlander': 41, 'ĠRamsay': 41}\n",
      "andise {'ĠGutierrez': 42, 'ĠLotus': 42, 'ĠBug': 42, 'ĠMMO': 41, 'ĠMDMA': 41, 'ĠGow': 41}\n",
      "Error {'ĠGladiator': 42, 'ĠMarriott': 42, 'ĠYosemite': 41, 'ĠBoko': 41, 'ĠBYU': 41, 'ĠCheney': 41}\n",
      "free {'ĠKimberly': 42, 'ĠZika': 42, 'ĠGodzilla': 42, 'ĠAntioch': 41, 'ĠHerod': 41, 'ĠGPIO': 41}\n",
      "bleacher {'ĠClyde': 44, 'ĠGoblin': 42, 'ĠArlington': 42, 'ĠMagnus': 41, 'ĠNewport': 41, 'ĠBuffy': 41}\n",
      "lations {'ĠNeurolog': 43, 'ĠGenetics': 43, 'ĠFisheries': 42, 'ĠMiscellaneous': 42, 'ĠMarriott': 41, 'ĠMSM': 41}\n",
      "orship {'ĠLieberman': 44, 'ĠFuller': 42, 'ĠGilmore': 42, 'ĠSheldon': 42, 'ĠOlivia': 41, 'ĠAllan': 40}\n",
      "raints {'ĠMiscellaneous': 44, 'ĠTsukuyomi': 44, 'ĠGPIO': 43, 'ĠGilmore': 43, 'ĠGenetics': 41, 'ĠRohingya': 40}\n",
      "classified {'ĠKimberly': 45, 'ĠDACA': 42, 'ĠWellington': 42, 'ĠDmitry': 41, 'ĠTMZ': 41, 'ĠCortana': 41}\n",
      "avorite {'ĠLibertarian': 47, 'ĠGoblin': 43, 'ĠParliamentary': 40, 'ĠHogwarts': 40, 'ĠBabylon': 40, 'ĠHerz': 40}\n",
      "abama {'ĠValerie': 43, 'ĠValhalla': 42, 'ĠRudolph': 41, 'ĠLafayette': 41, 'ĠSutherland': 41, 'ĠScarlet': 41}\n",
      "Notes {'ĠKobe': 42, 'ĠFisheries': 42, 'ĠDACA': 42, 'ĠCourtney': 41, 'ĠFlickr': 41, 'ĠWellington': 41}\n",
      "REDACTED {'ĠDACA': 46, 'ĠNAFTA': 44, 'ĠSCP': 43, 'ĠWikimedia': 41, 'ĠYellowstone': 41, 'ĠBoko': 41}\n",
      "atibility {'ĠRohingya': 42, 'ĠYellowstone': 42, 'ĠYosemite': 42, 'ĠBarkley': 41, 'ĠWellington': 41, 'ĠDACA': 41}\n",
      "Court {'ĠLuxembourg': 43, 'ĠPortsmouth': 42, 'ĠSmithsonian': 42, 'ĠWinchester': 41, 'ĠDaytona': 41, 'ĠWyatt': 41}\n",
      "Johnson {'ĠClyde': 44, 'ĠStamford': 42, 'ĠRudolph': 42, 'ĠMiko': 41, 'ĠHighlander': 41, 'ĠArlington': 40}\n",
      "ocytes {'ĠKimberly': 44, 'ĠRohingya': 44, 'ĠTelecommunications': 43, 'ĠSeymour': 41, 'ĠNeander': 40, 'ĠMongolia': 40}\n",
      "Ġgloves {'ĠMorse': 42, 'ĠSophia': 42, 'ĠFancy': 42, 'ĠMozilla': 42, 'ĠErica': 41, 'ĠDaisy': 41}\n",
      "ixture {'ĠDACA': 45, 'ĠAzerb': 42, 'ĠRasmussen': 41, 'ĠGPIO': 41, 'ĠLarson': 41, 'ĠGoddard': 40}\n",
      "ãĢį {'ĠãĢĮ': 52, 'ãĢĮ': 44, '\":[\"': 43, 'Ġ\"[': 41, ':[': 40, '\":[': 38}\n",
      "apes {'ĠHerod': 43, 'ĠHowell': 42, 'ĠFuller': 42, 'ĠGears': 42, 'ĠAppalachian': 41, 'ĠValhalla': 41}\n",
      "prone {'ĠWellington': 46, 'ĠGPIO': 43, 'ĠNFC': 42, 'ĠGilmore': 41, 'ĠBenghazi': 41, 'ĠBelarus': 40}\n",
      "\"> {'Ġ\"<': 50, 'Ġ<': 46, 'Ġ(<': 46, '><': 43, '.<': 40, '<': 40}\n",
      "inator {'ĠMyanmar': 43, 'ĠWellington': 42, 'ĠMercury': 42, 'ĠPortsmouth': 41, 'ĠLuxembourg': 41, 'ĠHonduras': 41}\n",
      "ough {'ĠHerbert': 42, 'ĠMelvin': 41, 'ĠClifford': 41, 'ĠAdministrative': 41, 'ĠButler': 41, 'ĠHighlander': 41}\n",
      "ropy {'ĠTsukuyomi': 43, 'ĠKislyak': 42, 'ĠFisheries': 41, 'ĠVenom': 41, 'ĠOrbital': 41, 'ĠAnderson': 41}\n",
      "Dallas {'ĠGarrison': 43, 'ĠScarlet': 43, 'ĠArlington': 42, 'ĠDj': 41, 'ĠDACA': 41, 'ĠWellington': 40}\n",
      "freedom {'ĠPOLITICO': 42, 'ĠKimberly': 42, 'ĠHispanic': 41, 'ĠTsukuyomi': 41, 'ĠBigfoot': 41, 'ĠRohingya': 41}\n",
      "otypes {'ĠHannibal': 43, 'ĠYosemite': 43, 'ĠGilmore': 43, 'ĠKimberly': 42, 'ĠOdyssey': 40, 'ĠCassidy': 40}\n",
      "uality {'ĠTsukuyomi': 44, 'ĠAdministrative': 42, 'ĠNorton': 42, 'ĠKashmir': 42, 'ĠTelecommunications': 41, 'ĠGPIO': 41}\n",
      "Putin {'ĠAntioch': 42, 'ĠCindy': 42, 'ĠMarcel': 41, 'ĠStamford': 41, 'ĠRudolph': 41, 'ĠWinston': 41}\n",
      "Carter {'ĠRudolph': 43, 'ĠFreder': 42, 'ĠOlson': 42, 'ĠWinston': 41, 'ĠSasha': 41, 'ĠSatoshi': 41}\n",
      "ences {'ĠTsukuyomi': 43, 'ĠMiscellaneous': 42, 'ĠGears': 41, 'ĠMSM': 41, 'ĠTelecommunications': 41, 'ĠAppalachian': 40}\n",
      "%); {'ĠTimothy': 45, 'ĠSergei': 43, 'ĠMiliband': 42, 'ĠRasmussen': 41, 'ĠWestbrook': 40, 'ĠSweeney': 40}\n",
      "arnaev {'ĠBigfoot': 45, 'ĠYellowstone': 43, 'ĠUltron': 42, 'ĠFairfax': 42, 'ĠLockheed': 41, 'ĠTurnbull': 39}\n",
      "ocalypse {'ĠFriedman': 43, 'ĠRasmussen': 43, 'ĠObamaCare': 41, 'ĠRosenthal': 41, 'Ġglutamate': 40, 'ĠFletcher': 40}\n",
      "%\" {'Ġ\"<': 48, 'ĠKimberly': 44, 'Ġ\"{': 43, 'Ġ\"%': 41, 'Ġ\"(': 41, 'Ġ\"$': 40}\n",
      "pects {'ĠJFK': 42, 'ĠWraith': 42, 'ĠMiscellaneous': 42, 'ĠHermes': 41, 'ĠJulius': 41, 'ĠGears': 41}\n",
      "renches {'ĠMiscellaneous': 46, 'ĠValhalla': 43, 'ĠFisheries': 42, 'ĠBarbarian': 41, 'ĠMongolia': 40, 'ĠAllan': 40}\n",
      "risome {'ĠBabylon': 45, 'ĠMetroid': 45, 'ĠPaleo': 42, 'ĠStockholm': 41, 'ĠAdministrative': 41, 'ĠArlington': 39}\n",
      "BOOK {'ĠMacy': 43, 'ĠTMZ': 43, 'ĠPOLITICO': 42, 'ĠRasmussen': 41, 'ĠRousse': 41, 'ĠFedEx': 40}\n",
      "blogspot {'ĠHerz': 46, 'ĠVerizon': 42, 'ĠGott': 42, 'ĠHebrew': 41, 'ĠDruid': 40, 'ĠNavajo': 40}\n",
      "izons {'ĠNightmares': 42, 'ĠAppalachian': 42, 'ĠBoko': 42, 'ĠNotting': 41, 'Ġmethodological': 41, 'ĠRegulatory': 41}\n",
      "tests {'ĠMiscellaneous': 42, 'ĠFuller': 42, 'ĠGears': 41, 'ĠSpice': 41, 'ĠCourtney': 41, 'ĠNeurolog': 41}\n",
      "iffin {'ĠSatoshi': 42, 'ĠJared': 42, 'ĠPayton': 41, 'ĠLazarus': 41, 'ĠShinji': 41, 'ĠScarborough': 41}\n",
      "headers {'ĠSirius': 43, 'ĠMiscellaneous': 42, 'ĠASIC': 41, 'ĠNeurolog': 41, 'ĠGenetics': 41, 'ĠGilmore': 41}\n",
      "geist {'ĠGenius': 43, 'ĠLogic': 43, 'ĠNordic': 43, 'ĠGoblin': 42, 'ĠUncommon': 41, 'ĠLibertarian': 40}\n",
      "Featured {'ĠDACA': 44, 'ĠCinnamon': 42, 'ĠOrtiz': 42, 'ĠNAV': 40, 'ĠKimberly': 40, 'ĠNAFTA': 40}\n",
      "obyl {'ĠFitzpatrick': 42, 'ĠWellington': 41, 'ĠGilmore': 41, 'ĠQualcomm': 41, 'ĠHarrington': 41, 'ĠGreenwich': 41}\n",
      "ggy {'ĠPOLITICO': 43, 'ĠNether': 41, 'ĠKimberly': 41, 'ĠVoyager': 41, 'ĠLazarus': 41, 'ĠScarborough': 40}\n",
      "iaries {'ĠGilmore': 43, 'ĠGears': 42, 'ĠYosemite': 42, 'ĠDaisy': 41, 'ĠAdamant': 41, 'ĠCourtney': 40}\n",
      "Translation {'ĠDartmouth': 44, 'ĠHartford': 42, 'ĠRohingya': 42, 'ĠMSM': 41, 'ĠPortsmouth': 41, 'ĠFisheries': 40}\n",
      "ĠKislyak {'ĠTup': 44, 'ĠMarcel': 43, 'ĠScarlett': 41, 'ĠDmitry': 41, 'ĠBrittany': 40, 'ĠBrigham': 40}\n",
      "ombie {'ĠJacksonville': 43, 'ĠAllan': 42, 'ĠCaldwell': 41, 'ĠJonathan': 41, 'ĠAppalachian': 40, 'ĠWellington': 40}\n",
      "ools {'ĠHerod': 42, 'ĠNorton': 42, 'ĠAppropriations': 41, 'ĠGiles': 41, 'ĠAppalachian': 41, 'ĠYosemite': 41}\n",
      "Leader {'ĠYosemite': 44, 'ĠLibertarian': 43, 'ĠLiberia': 42, 'ĠGenie': 41, 'ĠKeyboard': 41, 'ĠKurdistan': 41}\n",
      "restrial {'ĠHighlander': 44, 'ĠWellington': 42, 'ĠLucifer': 41, 'ĠRohingya': 41, 'ĠYellowstone': 41, 'ĠGrizz': 40}\n",
      "Privacy {'ĠNorton': 43, 'ĠVaughan': 43, 'ĠAero': 42, 'ĠManit': 42, 'ĠPOLITICO': 41, 'ĠKimberly': 41}\n",
      "Ġholders {'ĠDACA': 43, 'ĠYellowstone': 42, 'ĠHercules': 41, 'ĠOblivion': 41, 'ĠMcGu': 41, 'ĠKimberly': 41}\n",
      "Orderable {'ĠRw': 43, 'ĠYellowstone': 43, 'ĠNavajo': 41, 'ĠUnicode': 41, 'ĠScient': 41, 'ĠFANT': 41}\n",
      "bably {'ĠDACA': 46, 'ĠTheodore': 42, 'Ġunavoid': 42, 'ĠKoz': 41, 'ĠTeddy': 40, 'ĠKhalid': 40}\n",
      "verson {'ĠRamsey': 43, 'ĠYellowstone': 42, 'ĠPaddock': 42, 'ĠMueller': 41, 'ĠHerod': 41, 'ĠTheodore': 40}\n",
      "Ġmakers {'ĠOTHER': 42, 'ĠMozilla': 42, 'ĠYellowstone': 41, 'ĠOblivion': 41, 'ĠOthers': 41, 'ĠBorderlands': 41}\n",
      "Ġforums {'ĠValhalla': 46, 'ĠKeystone': 41, 'ĠBarbarian': 41, 'ĠMetatron': 40, 'ĠSirius': 40, 'ĠDraco': 40}\n",
      "gments {'ĠKoz': 43, 'ĠMiscellaneous': 43, 'ĠMarketable': 42, 'ĠMarriott': 42, 'ĠFuller': 41, 'ĠJulius': 40}\n",
      "Authorities {'ĠYellowstone': 42, 'ĠIcelandic': 42, 'ĠBaylor': 42, 'ĠWinchester': 41, 'ĠFEMA': 41, 'ĠMotorola': 41}\n",
      "Ġeasily {'ĠPercy': 43, 'ĠTeddy': 42, 'ĠWeasley': 41, 'ĠJPMorgan': 41, 'ĠLabrador': 41, 'ĠSchl': 40}\n",
      "Ġturnout {'ĠRasmussen': 45, 'ĠMSM': 44, 'ĠFuller': 40, 'ĠVerizon': 40, 'ĠObamaCare': 40, 'ĠCitizenship': 40}\n",
      "ometown {'ĠBabylon': 44, 'ĠHighlander': 42, 'ĠRealm': 41, 'ĠParticipant': 41, 'ĠBattlefield': 40, 'ĠHau': 40}\n",
      "otonin {'ĠMarriott': 45, 'ĠSuperior': 41, 'ĠOsama': 41, 'ĠCanberra': 41, 'ĠShogun': 41, 'ĠLockheed': 40}\n",
      "istor {'ĠKimberly': 46, 'ĠGutierrez': 42, 'ĠMelvin': 41, 'ĠSherman': 41, 'ĠNavajo': 41, 'ĠRosenthal': 40}\n",
      "alks {'ĠFuller': 45, 'ĠMehran': 44, 'ĠCrowley': 42, 'ĠNeurolog': 41, 'ĠNau': 41, 'ĠJackson': 40}\n",
      "odus {'ĠMagnus': 43, 'ĠMiscellaneous': 42, 'ĠDACA': 42, 'ĠSatanic': 42, 'ĠRasmussen': 40, 'ĠFundamental': 40}\n",
      "Ġquarry {'ĠValerie': 42, 'ĠMelvin': 42, 'ĠRaqqa': 41, 'ĠMohammed': 41, 'ĠLegendary': 41, 'ĠJulio': 41}\n",
      "Stage {'ĠRaqqa': 47, 'ĠRagnarok': 42, 'ĠKarachi': 41, 'ĠPercy': 41, 'ĠDraco': 40, 'ĠHarlem': 40}\n",
      "fulness {'ĠPersonality': 44, 'ĠKashmir': 43, 'ĠMetroid': 41, 'ĠElements': 40, 'ĠAdministrative': 40, 'ĠTranscript': 40}\n",
      "ricanes {'ĠHob': 43, 'ĠGPIO': 42, 'ĠBelarus': 41, 'ĠNotting': 41, 'ĠRosenthal': 41, 'ĠJericho': 40}\n",
      "umni {'ĠRohing': 45, 'ĠChomsky': 42, 'ĠLivingston': 42, 'ĠRohingya': 40, 'ĠDACA': 40, 'ĠBoko': 40}\n",
      "style {'ĠWellington': 46, 'ĠLaurel': 42, 'ĠLazarus': 42, 'ĠPortsmouth': 41, 'ĠSherlock': 40, 'ĠAnderson': 40}\n",
      "Houston {'ĠBaylor': 44, 'ĠWellington': 42, 'ĠKimberly': 41, 'ĠCourtney': 41, 'ĠLudwig': 41, 'ĠOrtiz': 40}\n",
      "Ġprotagonists {'ĠOkin': 43, 'ĠAdamant': 41, 'ĠLogic': 41, 'ĠLibertarian': 41, 'ĠSharif': 41, 'ĠBorders': 41}\n",
      "ooks {'ĠMiscellaneous': 44, 'ĠNathaniel': 43, 'ĠAllan': 42, 'ĠParticularly': 41, 'ĠAppalachian': 41, 'ĠTheodore': 40}\n",
      "anyon {'ĠPOLITICO': 44, 'ĠNether': 42, 'ĠOblivion': 42, 'ĠMarriott': 41, 'ĠDaytona': 41, 'ĠScarborough': 41}\n",
      "hesda {'ĠClifford': 42, 'ĠNether': 42, 'ĠLowell': 41, 'ĠWinston': 41, 'ĠLibertarian': 41, 'ĠPavel': 40}\n",
      "Nich {'ĠKimberly': 44, 'ĠYosemite': 43, 'ĠMonsanto': 42, 'ĠPlayboy': 42, 'ĠMozilla': 42, 'ĠMotorola': 41}\n",
      "kefeller {'ĠAdamant': 42, 'ĠNirvana': 42, 'ĠEmmanuel': 41, 'ĠYosemite': 41, 'ĠFelix': 41, 'ĠChristy': 41}\n",
      "obar {'ĠWeasley': 42, 'ĠMercury': 42, 'ĠTownsend': 42, 'ĠTyrann': 41, 'ĠFrieza': 40, 'ĠHerod': 40}\n",
      "duino {'ĠLazarus': 45, 'ĠOrlando': 43, 'ĠFlynn': 42, 'ĠMyanmar': 41, 'ĠCedar': 41, 'ĠCassandra': 40}\n",
      "levard {'ĠValhalla': 43, 'ĠWellington': 43, 'ĠLieberman': 41, 'ĠAndersen': 41, 'ĠForth': 41, 'ĠForbes': 40}\n",
      "ARDIS {'ĠGears': 46, 'ĠPaleo': 43, 'ĠInvisible': 41, 'ĠResponsibility': 41, 'ĠDed': 40, 'ĠHerod': 40}\n",
      "isites {'ĠDACA': 44, 'ĠGPIO': 42, 'ĠMSM': 41, 'ĠCerberus': 41, 'ĠMiscellaneous': 41, 'ĠHerod': 40}\n",
      "ventures {'ĠFuller': 46, 'ĠWraith': 41, 'ĠDecoder': 41, 'ĠOthers': 40, 'ĠJennings': 40, 'ĠMiscellaneous': 40}\n",
      "ĠNotes {'ĠDACA': 43, 'ĠKobe': 42, 'ĠBYU': 41, 'ĠNau': 41, 'ĠCourtney': 41, 'ĠTMZ': 41}\n",
      "ĠZuckerberg {'ĠPercy': 43, 'ĠStamford': 42, 'ĠFreddie': 42, 'ĠMarilyn': 41, 'ĠNigel': 40, 'ĠJulio': 40}\n",
      "uana {'ĠLazarus': 42, 'ĠNatasha': 41, 'ĠSasha': 41, 'ĠCutler': 41, 'ĠMead': 41, 'ĠAvalon': 41}\n",
      "iances {'ĠFisheries': 44, 'ĠMiscellaneous': 42, 'ĠAdministrative': 42, 'ĠAppropriations': 42, 'ĠFuller': 41, 'ĠUtilities': 39}\n",
      "tarians {'ĠRusty': 42, 'ĠAppalachian': 42, 'ĠHighland': 41, 'ĠTelecommunications': 41, 'ĠLibertarian': 41, 'ĠAppropriations': 40}\n",
      "andals {'ĠRosenstein': 45, 'ĠMiscellaneous': 43, 'ĠPossible': 42, 'ĠMarketable': 42, 'ĠOTHER': 40, 'ĠRosenthal': 40}\n",
      "CVE {'ĠDACA': 43, 'ĠGiul': 42, 'ĠXue': 41, 'ĠTMZ': 41, 'ĠJarrett': 41, 'ĠSequ': 41}\n",
      "Ġfaults {'ĠTsukuyomi': 43, 'Ġnumerous': 41, 'ĠMiscellaneous': 41, 'Ġpolygamy': 41, 'ĠMSM': 40, 'ĠOthers': 40}\n",
      "oine {'ĠKimberly': 46, 'ĠFlynn': 43, 'ĠStanton': 42, 'ĠClyde': 41, 'ĠMalik': 40, 'ĠSophia': 39}\n",
      ")? {'Ġ(': 50, 'Ġ((': 46, 'Ġ([': 41, ')(': 41, ':(': 40, ':[': 39}\n",
      "lance {'ĠNAFTA': 43, 'ĠPOLITICO': 43, 'ĠAdministrative': 41, 'ĠDACA': 41, 'ĠWellington': 41, 'ĠSaturn': 40}\n",
      "iosis {'ĠRohingya': 45, 'ĠBoko': 43, 'ĠMongol': 40, 'ĠGPIO': 40, 'ĠGow': 40, 'ĠRasmussen': 40}\n",
      "ettle {'ĠFuller': 43, 'ĠComposite': 42, 'ĠJupiter': 41, 'ĠRubber': 41, 'ĠUlster': 40, 'ĠDaytona': 40}\n",
      "abytes {'ĠTravels': 43, 'ĠEstimates': 43, 'ĠPalestinians': 41, 'Ġmilliseconds': 41, 'ĠUses': 40, 'ĠGenerations': 40}\n",
      "AppData {'ĠRedmond': 44, 'ĠMorg': 42, 'ĠBaylor': 42, 'ĠYellowstone': 41, 'ĠYosemite': 40, 'ĠPaige': 40}\n",
      "erity {'ĠHarriet': 42, 'ĠVaughan': 41, 'ĠMagnum': 41, 'ĠTsukuyomi': 40, 'ĠLeo': 40, 'ĠPlanetary': 40}\n",
      "few {'ĠCutler': 44, 'ĠLibertarian': 43, 'ĠLabrador': 42, 'ĠGalile': 40, 'ĠEmerald': 40, 'ĠJacksonville': 40}\n",
      "assador {'ĠHerz': 45, 'ĠOrtiz': 41, 'ĠCord': 41, 'ĠGoddard': 40, 'ĠMayo': 40, 'ĠClyde': 40}\n",
      "inet {'ĠEminem': 44, 'ĠNAFTA': 41, 'ĠMercury': 41, 'ĠPOLITICO': 40, 'ĠLeBron': 40, 'ĠPlayboy': 40}\n",
      "idelines {'ĠGilmore': 42, 'ĠMaher': 41, 'ĠKoz': 41, 'ĠDed': 41, 'ĠMiscellaneous': 41, 'ĠDaisy': 40}\n",
      "oulos {'ĠGoddard': 41, 'ĠWoody': 41, 'ĠEdmund': 41, 'ĠBuddy': 41, 'ĠRusty': 41, 'ĠSyd': 41}\n",
      "ursday {'ĠHermes': 45, 'ĠMetall': 41, 'ĠToken': 41, 'ĠGutierrez': 40, 'ĠOPT': 40, 'ĠParad': 40}\n",
      "America {'ĠKimberly': 43, 'ĠLazarus': 41, 'ĠGilmore': 41, 'ĠShinra': 40, 'ĠBuckingham': 40, 'ĠLibertarian': 40}\n",
      "Ġpartisans {'ĠAdamant': 43, 'ĠCrimean': 43, 'ĠBorderlands': 42, 'ĠBorder': 42, 'ĠGoblin': 40, 'ĠPixel': 40}\n",
      "ĠDeVos {'ĠGeoff': 42, 'ĠTheodore': 41, 'ĠDmitry': 41, 'ĠEminem': 41, 'ĠDeadpool': 41, 'ĠKimberly': 40}\n",
      "forge {'ĠBarbarian': 44, 'ĠDaytona': 42, 'ĠAbuse': 41, 'ĠMedline': 41, 'ĠValhalla': 40, 'ĠLabrador': 40}\n",
      "arrell {'ĠLazarus': 44, 'ĠMolly': 42, 'ĠRousse': 42, 'ĠMeyer': 40, 'ĠHighlander': 40, 'ĠAllan': 40}\n",
      "(); {'ĠTimothy': 42, 'ĠMiliband': 42, 'ĠBuckley': 41, 'ĠWestbrook': 41, 'ĠRonald': 40, 'ĠWellington': 40}\n",
      "iasm {'ĠDSL': 42, 'ĠBoeing': 42, 'ĠSeymour': 41, 'ĠCitizenship': 41, 'ĠBabel': 41, 'ĠSchneider': 40}\n",
      "otions {'ĠMiscellaneous': 46, 'ĠFisheries': 43, 'ĠRohingya': 41, 'ĠGenetics': 40, 'ĠRasmussen': 40, 'ĠTelecommunications': 39}\n",
      "arations {'ĠNeurolog': 42, 'ĠMetatron': 41, 'ĠRohingya': 41, 'ĠFuller': 41, 'ĠOdyssey': 41, 'ĠHermes': 40}\n",
      "Ġdoses {'ĠMSM': 43, 'ĠCantor': 43, 'ĠChambers': 41, 'ĠComput': 41, 'ĠColossus': 40, 'ĠXperia': 40}\n",
      "appropriate {'ĠMyanmar': 43, 'ĠBridgewater': 42, 'ĠMedicaid': 41, 'ĠMMO': 41, 'ĠWellington': 40, 'ĠTsukuyomi': 40}\n",
      "ijing {'ĠGarrison': 45, 'ĠPaleo': 44, 'ĠWatergate': 41, 'ĠBroadcasting': 41, 'ĠHitman': 40, 'ĠDroid': 40}\n",
      "desc {'ĠDSM': 46, 'ĠMaher': 42, 'ĠSuarez': 41, 'ĠGenetics': 40, 'ĠPersona': 40, 'ĠEminem': 40}\n",
      "aques {'ĠMiscellaneous': 47, 'ĠGilmore': 42, 'ĠTsukuyomi': 42, 'ĠWeasley': 40, 'ĠOTHER': 40, 'ĠMSM': 40}\n",
      "ivari {'ĠWatergate': 43, 'ĠLyndon': 42, 'ĠNerd': 42, 'ĠFasc': 40, 'ĠDroid': 40, 'ĠVolks': 40}\n",
      "cers {'ĠNeurolog': 42, 'ĠHogwarts': 41, 'ĠGenetics': 41, 'ĠHerod': 41, 'ĠMercury': 41, 'ĠAvalon': 40}\n",
      "wright {'ĠWellington': 45, 'ĠGoodwin': 42, 'ĠRandy': 41, 'ĠRodney': 40, 'ĠKimberly': 40, 'ĠBuffy': 40}\n",
      "arge {'ĠPOLITICO': 44, 'ĠHogwarts': 42, 'ĠNavajo': 41, 'ĠBarbarian': 40, 'ĠPersian': 40, 'ĠComposite': 40}\n",
      "ĠSpectre {'ĠMorty': 42, 'ĠCheney': 41, 'ĠGutenberg': 40, 'ĠTyph': 40, 'ĠRudolph': 40, 'ĠPOLITICO': 40}\n",
      "ignty {'ĠKimberly': 45, 'ĠTsukuyomi': 42, 'ĠJessica': 41, 'ĠLazarus': 41, 'ĠHispanics': 39, 'ĠRosenthal': 39}\n",
      "clear {'ĠDaytona': 47, 'ĠShinra': 42, 'ĠWellington': 42, 'ĠMongol': 41, 'ĠAtlantis': 40, 'ĠStockholm': 39}\n",
      "ampires {'ĠHighland': 42, 'ĠCrowley': 42, 'ĠBorder': 41, 'ĠBarney': 41, 'ĠNotting': 40, 'ĠRosenthal': 40}\n",
      "ophile {'ĠPalo': 42, 'ĠPag': 42, 'ĠKerala': 41, 'ĠChattanooga': 41, 'ĠWellington': 40, 'ĠLuxembourg': 40}\n",
      "aciously {'ĠAdministrative': 43, 'Ġcryptographic': 41, 'ĠGPIO': 41, 'ĠOxy': 41, 'ĠCele': 41, 'Ġperf': 40}\n",
      "ernel {'ĠLazarus': 43, 'ĠMeier': 42, 'ĠScorpion': 42, 'ĠTsukuyomi': 40, 'ĠBigfoot': 40, 'ĠSatoshi': 40}\n",
      "right {'ĠGilmore': 44, 'ĠGreenberg': 42, 'ĠLafayette': 41, 'ĠFlores': 41, 'ĠHighlander': 40, 'ĠJulio': 40}\n",
      "cellaneous {'ĠYellowstone': 44, 'ĠMiscellaneous': 43, 'Ġrelational': 41, 'ĠOriental': 41, 'ĠMarriott': 41, 'ĠByzantine': 39}\n",
      "icago {'ĠComcast': 41, 'ĠMonsanto': 41, 'ĠScarborough': 41, 'ĠDaredevil': 41, 'ĠGarrison': 41, 'ĠYosemite': 40}\n",
      "chair {'ĠMercury': 43, 'ĠAntioch': 41, 'ĠWinchester': 41, 'ĠMyanmar': 41, 'ĠBabylon': 41, 'ĠMozilla': 40}\n",
      "mpeg {'ĠNAFTA': 47, 'ĠCic': 43, 'ĠSloan': 42, 'ĠAtkins': 40, 'ĠMacy': 39, 'ĠIGF': 39}\n",
      "urtles {'ĠYosemite': 44, 'ĠRohingya': 42, 'ĠHimal': 40, 'ĠHerod': 40, 'ĠAllan': 40, 'ĠGlasgow': 40}\n",
      "zilla {'ĠHermione': 42, 'ĠYosemite': 41, 'ĠBattlefield': 41, 'ĠAllan': 41, 'ĠCerberus': 40, 'ĠDag': 40}\n",
      "elines {'ĠFisheries': 43, 'ĠMiscellaneous': 43, 'ĠAppalachian': 43, 'ĠValhalla': 41, 'ĠAppropriations': 41, 'ĠUtilities': 40}\n",
      "Ġmasks {'ĠDACA': 44, 'ĠChau': 42, 'ĠGrizz': 41, 'ĠHSBC': 41, 'ĠTsukuyomi': 40, 'ĠSophia': 40}\n",
      "ffee {'ĠKimberly': 42, 'ĠTsukuyomi': 41, 'ĠBabylon': 41, 'ĠPOLITICO': 41, 'ĠPlymouth': 41, 'Ġglyphosate': 40}\n",
      "erey {'ĠBabylon': 43, 'ĠTheodore': 43, 'ĠNewfoundland': 42, 'ĠToyota': 40, 'ĠPlayboy': 40, 'ĠLivingston': 40}\n",
      "ependence {'ĠCitizenship': 43, 'ĠMongol': 42, 'ĠLieberman': 41, 'ĠTsukuyomi': 40, 'ĠMortgage': 40, 'ĠOrbital': 40}\n",
      "ces {'ĠFisheries': 42, 'ĠMedline': 41, 'ĠHerod': 41, 'ĠKM': 40, 'ĠGenetics': 40, 'ĠCic': 40}\n",
      "amon {'ĠKimberly': 42, 'ĠPOLITICO': 42, 'ĠAppalachian': 41, 'ĠRedmond': 41, 'ĠVirtue': 41, 'ĠPerkins': 41}\n",
      "addafi {'ĠOsama': 44, 'ĠPercy': 43, 'ĠKhalid': 42, 'ĠMahmoud': 41, 'ĠEminem': 40, 'ĠLilith': 40}\n",
      "Ġimpunity {'ĠEditorial': 42, 'ĠTyrann': 42, 'ĠEmmanuel': 41, 'ĠDick': 41, 'ĠVerizon': 40, 'ĠBoeing': 40}\n",
      "00200000 {'ĠGilbert': 42, 'ĠCheong': 41, 'ĠBigfoot': 41, 'ĠWilkinson': 41, 'ĠShah': 41, 'ĠHerod': 40}\n",
      "bish {'ĠRichie': 42, 'ĠOswald': 42, 'ĠDennis': 41, 'ĠLaurie': 41, 'ĠPercy': 41, 'ĠTyph': 41}\n",
      "omination {'ĠRosenthal': 45, 'ĠPlanetary': 42, 'ĠLieberman': 41, 'ĠMarriott': 41, 'ĠIntermediate': 40, 'ĠFriedman': 40}\n",
      "auto {'ĠBoko': 44, 'ĠRohingya': 42, 'ĠMSM': 41, 'ĠWikimedia': 40, 'ĠHogwarts': 40, 'ĠTsukuyomi': 40}\n",
      "entials {'ĠMetatron': 43, 'ĠUtilities': 41, 'ĠOTHER': 41, 'ĠSophia': 40, 'ĠGPIO': 40, 'ĠMiscellaneous': 40}\n",
      "Ġnewsp {'ĠCommodore': 45, 'ĠMacy': 41, 'ĠSunderland': 40, 'ĠISIL': 40, 'ĠCeltic': 40, 'ĠUFO': 40}\n",
      "entle {'ĠNAFTA': 44, 'ĠLabrador': 42, 'Ġglyphosate': 42, 'ĠPaleo': 40, 'ĠSanta': 40, 'ĠTyp': 40}\n",
      "redients {'ĠMiscellaneous': 43, 'ĠHogwarts': 43, 'ĠDACA': 42, 'ĠNeurolog': 41, 'ĠGears': 40, 'ĠMosul': 40}\n",
      "something {'ĠWinchester': 43, 'ĠScarborough': 42, 'ĠKimberly': 42, 'ĠPalo': 41, 'ĠWellington': 40, 'ĠCelsius': 40}\n",
      "ancers {'ĠMiscellaneous': 42, 'ĠAtlantis': 41, 'ĠHerod': 41, 'ĠFisheries': 40, 'ĠCerberus': 40, 'ĠGears': 40}\n",
      "dump {'ĠObamaCare': 42, 'ĠVoldemort': 41, 'ĠTMZ': 41, 'ĠPolitico': 41, 'ĠAtkins': 41, 'ĠDaytona': 41}\n",
      "iences {'ĠTelecommunications': 43, 'ĠMiscellaneous': 43, 'ĠTsukuyomi': 42, 'ĠSeymour': 40, 'ĠLod': 40, 'ĠGPIO': 39}\n",
      "places {'ĠMiscellaneous': 43, 'ĠDelicious': 43, 'ĠValhalla': 40, 'ĠDACA': 40, 'ĠGenetics': 40, 'ĠBarbarian': 40}\n",
      "Officials {'ĠDACA': 43, 'ĠMozilla': 42, 'ĠBenedict': 41, 'ĠDraco': 41, 'ĠYellowstone': 40, 'ĠWinchester': 40}\n",
      "ophobia {'ĠTelecommunications': 41, 'ĠZionism': 41, 'ĠRohingya': 41, 'ĠTsukuyomi': 41, 'ĠBabylon': 41, 'ĠAutism': 41}\n",
      "localhost {'ĠLazarus': 47, 'ĠMercury': 42, 'ĠFlynn': 41, 'ĠKavanaugh': 40, 'ĠScarborough': 40, 'ĠLuxem': 40}\n",
      "Ġ): {')=(': 48, ':(': 42, '=(': 42, 'Ġ$(': 42, ')(': 39, '>(': 39}\n",
      "innie {'ĠDaytona': 42, 'ĠWinchester': 41, 'ĠNorton': 41, 'ĠRosenthal': 41, 'ĠKimberly': 41, 'ĠMedline': 40}\n",
      "adden {'ĠTheodore': 43, 'ĠRidley': 42, 'ĠKimberly': 42, 'ĠClifford': 41, 'ĠBrendan': 40, 'ĠMarcel': 40}\n",
      "ĠAnonymous {'ĠMozilla': 47, 'ĠDmitry': 41, 'ĠKimberly': 41, 'ĠOnePlus': 41, 'ĠNFC': 41, 'ĠRahul': 39}\n",
      "Instance {'ĠDagger': 44, 'ĠCic': 42, 'ĠRosenthal': 41, 'ĠGlac': 41, 'ĠClark': 40, 'ĠTripoli': 40}\n",
      "Links {'ĠDACA': 44, 'ĠMSM': 42, 'ĠValhalla': 41, 'ĠAvalon': 40, 'ĠMiscellaneous': 40, 'ĠTMZ': 40}\n",
      "ãĤī {'ĠFrieza': 42, 'ĠRouse': 41, 'ĠDeadpool': 41, 'ĠWraith': 40, 'ĠGilmore': 40, 'ĠNAFTA': 40}\n",
      "rossover {'ĠLieberman': 45, 'ĠScientology': 43, 'ĠDaylight': 41, 'ĠRasmussen': 40, 'ĠShapiro': 40, 'ĠRagnarok': 40}\n",
      "ops {'ĠFisheries': 43, 'ĠMSM': 42, 'ĠGenetics': 41, 'ĠFuller': 41, 'ĠMarriott': 40, 'ĠMiscellaneous': 40}\n",
      "omsky {'ĠHighlander': 44, 'ĠYellowstone': 42, 'ĠWinchester': 42, 'ĠAppalachian': 41, 'ĠHerod': 40, 'ĠKimberly': 40}\n",
      "antom {'ĠGutierrez': 42, 'ĠAtlantis': 42, 'ĠUtility': 41, 'ĠDerrick': 40, 'ĠWellington': 40, 'ĠKimberly': 40}\n",
      "anges {'ĠMiscellaneous': 41, 'ĠGears': 41, 'ĠBuckingham': 41, 'ĠMetatron': 41, 'ĠFuller': 41, 'ĠNAFTA': 40}\n",
      "gorithm {'ĠLazarus': 44, 'ĠCerberus': 42, 'ĠNAFTA': 40, 'ĠBoko': 40, 'ĠAnderson': 40, 'ĠScorpion': 40}\n",
      "Client {'ĠSuffolk': 43, 'ĠMozilla': 42, 'ĠMcGill': 42, 'ĠCinnamon': 40, 'ĠBoko': 40, 'ĠMercury': 40}\n",
      "Investigators {'ĠAdamant': 43, 'ĠDACA': 42, 'ĠWellington': 41, 'ĠYellowstone': 40, 'ĠOTHER': 40, 'Ġprenatal': 40}\n",
      "razil {'ĠGilmore': 44, 'ĠCrowley': 44, 'ĠFisheries': 41, 'ĠHighlander': 40, 'ĠOrc': 40, 'ĠMarriott': 40}\n",
      "auldron {'ĠFuller': 43, 'ĠPerkins': 41, 'ĠMelvin': 41, 'ĠMorse': 41, 'ĠGlasgow': 40, 'ĠGoblin': 40}\n",
      "ividual {'ĠPOLITICO': 42, 'ĠKashmir': 42, 'ĠLazarus': 40, 'ĠOblivion': 40, 'ĠYosemite': 40, 'ĠWellington': 40}\n",
      "icter {'ĠGoblin': 44, 'ĠMelvin': 42, 'ĠCertification': 41, 'ĠAllan': 41, 'ĠAdamant': 40, 'ĠProceedings': 40}\n",
      ".\"\" {'\":\"': 50, '=\"\"': 43, 'Ġ\"\"': 43, 'Ġ\"\"\"': 42, 'ĠCatalyst': 39, '\":[\"': 39}\n",
      "elson {'ĠGoddard': 44, 'ĠFuller': 41, 'ĠWinchester': 40, 'ĠMagnus': 40, 'ĠSutherland': 40, 'ĠMarcel': 40}\n",
      "adium {'ĠKislyak': 42, 'ĠMagnus': 42, 'ĠRosenstein': 41, 'ĠClyde': 41, 'ĠMegan': 40, 'ĠRasmussen': 40}\n",
      "ĠMachina {'ĠMMO': 43, 'ĠDACA': 42, 'ĠZeus': 41, 'ĠFEMA': 41, 'ĠBungie': 40, 'ĠStamford': 40}\n",
      "scope {'ĠPercy': 43, 'ĠTheodore': 42, 'ĠKimberly': 41, 'ĠFrieza': 40, 'ĠStamford': 40, 'ĠColiseum': 40}\n",
      "Ġtrump {'ĠHyder': 42, 'ĠTyrann': 41, 'ĠLich': 41, 'ĠNavajo': 41, 'ĠGilmore': 40, 'ĠRarity': 40}\n",
      "Ġhelmet {'Ġpolygamy': 44, 'ĠMetroid': 43, 'ĠMillennium': 42, 'ĠMoody': 40, 'ĠSic': 40, 'ĠPaleo': 40}\n",
      "otten {'ĠMiscellaneous': 44, 'ĠMagnus': 41, 'ĠMelvin': 41, 'ĠScand': 40, 'ĠBigfoot': 40, 'ĠHerbert': 40}\n",
      "Fans {'ĠCelt': 42, 'ĠTravels': 42, 'ĠPerkins': 41, 'ĠDroid': 41, 'ĠHispan': 40, 'ĠBorderlands': 40}\n",
      "amacare {'ĠBabylon': 44, 'ĠDACA': 42, 'ĠAntioch': 41, 'ĠMongol': 40, 'ĠOsama': 40, 'ĠLazarus': 40}\n",
      "fully {'ĠGPIO': 43, 'ĠNeural': 41, 'ĠMetroid': 41, 'ĠPercy': 40, 'ĠMercury': 40, 'ĠAdministrative': 40}\n",
      "hirt {'ĠBabylon': 45, 'ĠComet': 42, 'ĠHerod': 41, 'ĠMercury': 40, 'ĠAntioch': 40, 'ĠCyp': 40}\n",
      "Website {'ĠBaylor': 43, 'ĠMagnum': 42, 'ĠFul': 40, 'ĠMillennium': 40, 'ĠDACA': 40, 'ĠTMZ': 40}\n",
      "ilot {'ĠBoko': 43, 'ĠPortsmouth': 42, 'ĠPOLITICO': 41, 'ĠHighland': 40, 'ĠDaytona': 40, 'ĠHonduras': 40}\n",
      "Ġcensorship {'ĠMedieval': 44, 'ĠSatanic': 42, 'ĠEpiscopal': 41, 'ĠBinary': 40, 'ĠMechanical': 40, 'Ġsemantic': 40}\n",
      "angered {'ĠWellington': 47, 'ĠGilmore': 43, 'ĠWired': 40, 'ĠBelarus': 40, 'ĠKimberly': 40, 'ĠNevertheless': 39}\n",
      "axe {'ĠHighlander': 42, 'ĠBabylon': 42, 'ĠCheong': 41, 'ĠSamson': 41, 'ĠJudah': 40, 'ĠMongol': 40}\n",
      "itches {'ĠFisheries': 43, 'ĠMiscellaneous': 42, 'ĠTheodore': 42, 'ĠHerod': 41, 'ĠAppalachian': 40, 'ĠTelecommunications': 39}\n"
     ]
    }
   ],
   "source": [
    "show_topk.indices_fn = tokenizer.convert_ids_to_tokens\n",
    "ans1 = []\n",
    "for i in values.mean(1).topk(1000).indices.tolist():\n",
    "    ans = tokenizer.convert_ids_to_tokens(i), show_topk(values[i][:6].long(), indices[i][:6])\n",
    "#     ans1.append([ans,i])\n",
    "\n",
    "    print(tokenizer.convert_ids_to_tokens(i), show_topk(values[i][:6].long(), indices[i][:6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b77e6029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ġ)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Ġ(': 64.562,\n",
       " 'Ġ((': 64.479,\n",
       " ':(': 64.131,\n",
       " ')=(': 63.856,\n",
       " ')(': 59.57,\n",
       " '((': 59.148,\n",
       " '>(': 59.114,\n",
       " '=(': 57.791,\n",
       " '(': 56.857,\n",
       " 'Ġ$(': 56.849,\n",
       " '.(': 55.51,\n",
       " '(\\\\': 53.457,\n",
       " 'Ġ([': 50.429,\n",
       " \"Ġ'(\": 49.701,\n",
       " '-(': 49.51,\n",
       " 'Ġ[(': 48.359,\n",
       " '+(': 44.766,\n",
       " '\"(': 44.743,\n",
       " 'Ġ\"(': 44.379,\n",
       " '([': 43.437}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = tokenizer.encode(' )!')[0]; \n",
    "print(tokenizer.convert_ids_to_tokens(i))\n",
    "show_topk(*m[i].topk(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "45ed7510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ġ!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ĠMerry': 29.408,\n",
       " 'ĠEminem': 28.619,\n",
       " 'ĠLimbaugh': 28.026,\n",
       " 'ĠKendall': 27.807,\n",
       " 'ĠHogan': 27.728,\n",
       " 'ĠMelania': 27.219,\n",
       " 'ĠZap': 27.216,\n",
       " 'ĠHuawei': 27.003,\n",
       " 'ĠShiva': 26.809,\n",
       " 'ĠBarbie': 26.793,\n",
       " 'ĠSergei': 26.767,\n",
       " 'ĠMiliband': 26.68,\n",
       " 'ĠSchwar': 26.567,\n",
       " 'ĠDempsey': 26.444,\n",
       " 'ĠMalik': 26.387,\n",
       " 'ĠRouse': 26.308,\n",
       " 'ĠSutherland': 26.208,\n",
       " 'ĠSasuke': 26.203,\n",
       " 'ĠHowell': 26.035,\n",
       " 'ĠMilo': 25.878}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = tokenizer.encode(' !)')[0]; \n",
    "print(tokenizer.convert_ids_to_tokens(i))\n",
    "show_topk(*m[i].topk(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c168801f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "052c1e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_token = 'Ġ!'; prompt_id = tokenizer._convert_token_to_id(prompt_token)\n",
    "bop_str = 'Instruction: '; bop_id = tokenizer.encode(bop_str)[0]  # 'Inst'\n",
    "eop_str = '. For example:'; eop_id = tokenizer.encode(eop_str)[2] # 'Ġexample'\n",
    "bos_id = tokenizer._convert_token_to_id('Ġ->')\n",
    "eos_id = tokenizer._convert_token_to_id('Ċ')\n",
    "\n",
    "\n",
    "class CHILDDataset(Dataset):\n",
    "    def __init__(self, input_strs, tokenizer):\n",
    "        if tokenizer.pad_token is None: tokenizer.pad_token = '!'\n",
    "        self.inputs = tokenizer.batch_encode_plus(input_strs, add_special_tokens=False, padding=True, return_tensors='pt')#长的截，短的补\n",
    "        input_ids = self.inputs.input_ids\n",
    "        self.labels = torch.ones_like(input_ids) * (-100)\n",
    "\n",
    "        for bi in range(input_ids.size(0)): \n",
    "            bop_idx = (input_ids[bi] == bop_id).nonzero().squeeze(1) #prompt\n",
    "            eop_idx = (input_ids[bi] == eop_id).nonzero().squeeze(1) #context\n",
    "\n",
    "            if len(bop_idx) > 0:\n",
    "                assert len(bop_idx) == 1 and len(eop_idx) == 1\n",
    "                bop_idx, eop_idx = bop_idx.item(), eop_idx.item() #取出单元素张量的元素值并返回该值，保持原元素类型不变\n",
    "                #bop: 0   eop:6\n",
    "                input_ids[bi, bop_idx: eop_idx + 2] *= -1  # use prompt embedding for prompt tokens\n",
    "  \n",
    "            bos_indices = (input_ids[bi] == bos_id).nonzero().squeeze(1)\n",
    "#             print(\"bos_indices:\",bos_indices)\n",
    "            eos_indices = (input_ids[bi] == eos_id).nonzero()[-len(bos_indices):].squeeze(1) #每一位 eos都比bos大2\n",
    "#             print(\"eos_indices:\",eos_indices)\n",
    "            for i, (bos_i, eos_i) in enumerate(zip(bos_indices.tolist(), eos_indices.tolist())):\n",
    "                assert eos_i > bos_i + 1\n",
    "                if i >= 0:  #zero-shot\n",
    "                    self.labels[bi, bos_i + 1: eos_i] = input_ids[bi, bos_i + 1: eos_i] \n",
    "        \n",
    "        \n",
    "    def re_input(self):\n",
    "        return self.inputs['input_ids']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputs['input_ids'])\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {'input_ids': self.inputs['input_ids'][i],  #输入\n",
    "                'attention_mask': self.inputs['attention_mask'][i],\n",
    "                'labels': self.labels[i]}   #结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b322160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4613, 198)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_id,eos_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "696ea332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from child_utils import *\n",
    "torch.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56fcd441",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedEmbedding(nn.Module):\n",
    "    def __init__(self,  \n",
    "                wte: nn.Embedding,  #正常向量\n",
    "                prompt_id: int = None,\n",
    "                prompt_len: int = 10, \n",
    "                random_range: float = 0.5,\n",
    "                initialize_from_vocab: bool = True):\n",
    "        super(WrappedEmbedding, self).__init__()\n",
    "#         self.wte = wte\n",
    "#         self.prompt_id = prompt_id\n",
    "#         self.prompt_len = prompt_len\n",
    "        self.__dict__.update(locals()); del self.self #locals()以字典类型返回当前位置的全部局部变量\n",
    "        if self.prompt_id is not None: #prompt_embedding prompt词向量\n",
    "            self.prompt_embedding = nn.parameter.Parameter( #将一个不可训练的类型Tensor转换成可以训练的类型parameter\n",
    "                self.initialize_embedding(random_range, initialize_from_vocab)).to(self.wte.weight.device) #在-0.5-0.5中随机取值初始化\n",
    "        else:\n",
    "            self.prompt_embedding = nn.Embedding(self.prompt_len, self.wte.weight.size(1)).to(self.wte.weight.device)\n",
    "                                        #词典大小（总共输入多少词） 嵌入向量维度（多少维表示一个符号）\n",
    "            \n",
    "            assert initialize_from_vocab\n",
    "            self.init_prompt_embedding_()  #将wte的weight值作为初始化\n",
    "#             self.prompt_embedding.weight.data = self.initialize_embedding(random_range, initialize_from_vocab)     \n",
    " \n",
    "    def initialize_embedding(self, random_range: float = 0.5, initialize_from_vocab: bool = True):\n",
    "        if initialize_from_vocab: return self.wte.weight[:self.prompt_len].clone().detach() #返回一个新的tensor，新的tensor和原来的tensor共享数据内存，但不涉及梯度计算\n",
    "        return torch.FloatTensor(self.prompt_len, self.wte.weight.size(1)).uniform_(-random_range, random_range) #产生随机数\n",
    "    \n",
    "    def init_prompt_embedding_(self):\n",
    "#         print(self.wte.weight)\n",
    "        self.prompt_embedding.weight.data[:] = self.wte.weight[:self.prompt_len]\n",
    "\n",
    "        \n",
    "    def forward(self, input_ids):\n",
    "        if self.prompt_id is not None:\n",
    "            input_embeds = self.wte(input_ids)\n",
    "            input_embeds[input_ids == self.prompt_id] = self.prompt_embedding.expand(input_embeds.size(0), -1, -1)\n",
    "        else: # adapted from cpm-2\n",
    "            prompt_mask = input_ids < 0  #返回bool类型\n",
    "#             print(\"prompt_mask:\",prompt_mask.shape)\n",
    "            prompt_ids = -input_ids * prompt_mask #将prompt的值变为正数，其他置零\n",
    "#             print(\"prompt_ids:\",prompt_ids)\n",
    "#             print(prompt_ids < self.prompt_len)\n",
    "#             print(prompt_ids)\n",
    "            assert torch.all(prompt_ids < self.prompt_len)\n",
    "#             print(self.prompt_embedding(prompt_ids).shape)\n",
    "            p_embeds = self.prompt_embedding(prompt_ids) * prompt_mask.float().unsqueeze(-1)\n",
    "#             print(\"p_embeds:\",p_embeds.shape)\n",
    "            input_ids = input_ids * ~prompt_mask\n",
    "            w_embeds = self.wte(input_ids) * (~prompt_mask).float().unsqueeze(-1)\n",
    "#             print(\"w_embeds:\",w_embeds.shape)\n",
    "            input_embeds = w_embeds + p_embeds \n",
    "#         print(input_embeds)\n",
    "        return input_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44b17b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from cpm-2: https://github.com/TsinghuaAI/CPM-2-Finetune/blob/master/utils.py#L133-L164    #不训练模型参数，只训练prompt_embading，这个函数是取这些参数\n",
    "def get_params_for_prompt_optimization(module: nn.Module): \n",
    "    params = []\n",
    "    for t in module.named_modules():\n",
    "        if \"prompt_embedding\" in t[0]:\n",
    "            params.append({'params': [p for p in list(t[1]._parameters.values()) if p is not None]})\n",
    "    for t in module.named_parameters():\n",
    "        if \"prompt\" not in t[0]:\n",
    "            t[1].requires_grad_(False)    \n",
    "    return params\n",
    "\n",
    "def create_optimizer(model, training_args):\n",
    "    from torch.nn.parallel.distributed import DistributedDataParallel as DDP\n",
    "    while isinstance(model, (DDP, )): model = model.module\n",
    "        \n",
    "    we.init_prompt_embedding_()\n",
    "    param_groups = get_params_for_prompt_optimization(model)\n",
    "    optimizer = AdamW(param_groups, lr=training_args.learning_rate, \n",
    "                      betas=(training_args.adam_beta1, training_args.adam_beta2),eps=training_args.adam_epsilon)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39b4f350",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wte = model.get_input_embeddings() #提取 embedding 中的 词向量部分\n",
    "if hasattr(wte, 'wte'): wte = wte.wte  # already been wrapped\n",
    "we = WrappedEmbedding(wte, prompt_len=20000)\n",
    "model.set_input_embeddings(we) #为词向量赋值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae3bb45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbalize(obj):\n",
    "    if type(obj) == bool: return 'Yes' if obj else 'No'\n",
    "    return str(obj)\n",
    "\n",
    "def list2str(l): return ' '.join(str(i) for i in l)\n",
    "def pairs2str(pairs): return ', '.join(str(k) + ': ' + str(v) for k, v in pairs)\n",
    "\n",
    "def make_context_str(cxt):\n",
    "    if type(cxt) == list:\n",
    "        return pairs2str(cxt) if type(cxt[0]) == tuple and len(cxt[0]) == 2 else list2str(cxt)\n",
    "    if type(cxt) == tuple:\n",
    "        return '; '.join(make_context_str(c) for c in cxt)  # 用分号分隔context的不同部分\n",
    "    \n",
    "def make_query_str(instruction, query):\n",
    "    if instruction is None and query is None: return ''\n",
    "    s = '.'\n",
    "    if instruction is not None: s = s + ' ' + instruction\n",
    "    if query is not None:\n",
    "        if type(query) in [int, bool, str]: query = [query]\n",
    "        if type(query) == dict:# and list(query.keys())[0] != \"CS\"):  # by nrk\n",
    "            s = s + ' ' + '{' + ','.join([' replace %s with %s' % (str(k), str(v)) for k, v in query.items()]) + ' }'\n",
    "        if type(query) in [list, tuple]:\n",
    "            s = s + ' ' + ' '.join([list2str(i) if type(i) == list else str(i) for i in query])\n",
    "    return s\n",
    "\n",
    "def make_example_str(example, query2str):\n",
    "    instruction, cxt, query, ans = example\n",
    "    if type(ans) not in [Sequence, list]: ans = [ans]\n",
    "    ans = [verbalize(a) for a in ans]\n",
    "#     return '%s -> %s' % (''.join(l[0]) + make_query_str(instruction if with_instruction else None, query), ' '.join(ans))  # by nrk\n",
    "#     return '%s -> %s' % (' '.join(l) + make_query_str(instruction if with_instruction else None, query), ' '.join(ans))  # by XD\n",
    "#     return '%s -> %s' % (make_context_str(cxt) + make_query_str(instruction if with_instruction else None, query[0]), ' '.join(ans))\n",
    "    return '%s -> %s' % (make_context_str(cxt) + query2str(query), ' '.join(ans))\n",
    "\n",
    "\n",
    "def sample_rand_len(vocab, k): return sample(vocab, k=randint(1, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df63ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def promptize(s):\n",
    "#     return prompt_token * len(s.split())\n",
    "    return bop_str + s + eop_str\n",
    "\n",
    "courses_vocab=[\"Sql\",\"Math\",\"English\",\"Chinese\",\"Art\",\"Music\",\"History\",\"Biology\",\"Chemistry\",\"Physics\",\"Geography\"]\n",
    "all_vocab = [\"apple\",\"pear\",\"peach\",\"grape\",\"banana\",\"pineapple\",\"lemon\",\"strawberry\",\"cola\",\"juice\",\"coffee\",\"milk\",\"wine\",\"beer\",\"whisky\",\"vodka\",\"brandy\"]\n",
    "solid_vocab=[\"apple\",\"pear\",\"peach\",\"grape\",\"banana\",\"pineapple\",\"lemon\",\"strawberry\"]\n",
    "liquid_vocab=[\"cola\",\"juice\",\"coffee\",\"milk\",\"wine\",\"beer\",\"whisky\",\"vodka\",\"brandy\"]\n",
    "names_vocab =  [i for i in string.ascii_uppercase]\n",
    "depts_vocab = [\"CS\",\"Chi\",\"Eng\",\"Mat\"]\n",
    "sl = [\"solid\"]*len(solid_vocab)+[\"liquid\"]*len(liquid_vocab)\n",
    "sl_vocab = dict(zip(all_vocab,sl))\n",
    "toys = [\"ball\",\"doll\",\"puppet\",\"weiqi\",\"chess\",\"slide\",\"diabolo\",\"plasticine\",\"tumbler\"]\n",
    "                                              #滑梯     空竹      橡皮泥      不倒翁\n",
    "boys = [\"Alex\",\"Dylan\",\"Daniel\",\"Patrick\",\"Austin\",\"Harrison\",\"Tom\",\"Neil\"]\n",
    "girls = [\"Ashley\",\"jessica\",\"Sarah\",\"Amanda\",\"Nicole\",\"Katherine\",\"Anne\",\"Eva\"]\n",
    "all = boys+girls\n",
    "bg = [\"boys\"]*len(boys)+[\"girls\"]*len(girls)\n",
    "bg_vocab = dict(zip(all,bg))\n",
    "\n",
    "all = solid_vocab+toys\n",
    "ft = [\"fruits\"]*len(solid_vocab)+[\"toys\"]*len(toys)\n",
    "ft_vocab = dict(zip(all,ft))\n",
    "\n",
    "def make_input_str(task, nrows=4, ncols=4, full_vocab=None, ans_vocab=[True, False]):\n",
    "    if full_vocab is None: full_vocab = string.ascii_uppercase + string.digits\n",
    "    transform_fn, vocab_fn, sample_fn, query_fn, query2str = task\n",
    "    instruction = transform_fn.__name__.replace('_', ' ')\n",
    "    if vocab_fn is None: vocab_fn = lambda: full_vocab\n",
    "    if query_fn is None: query_fn = lambda *_: None\n",
    "        \n",
    "    examples = []\n",
    "    query = None\n",
    "    for i in range(nrows):\n",
    "        vocab = vocab_fn()\n",
    "        l = sample_fn(vocab, k=ncols)\n",
    "        query = query_fn(l, vocab, ncols)\n",
    "        examples.append([instruction, l, query, transform_fn(l, query=query)])\n",
    "#     examples = balance(examples,ans_vocab)\n",
    "\n",
    "    desc = promptize(instruction) if True else ''\n",
    "    text = '\\n'.join([make_example_str(e, query2str) for e in examples])\n",
    "    text = desc + '\\n' + text + '\\n'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd0c286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def balance(examples, ans_vocab=[True, False]):\n",
    "# def balance1(examples, ans_vocab):\n",
    "#     groups = seq(examples).group_by(_[-1]).map(_[1])  # 按ans分组\n",
    "# #     assert groups.len() == len(ans_vocab), '%d < %d' % (groups.len(), len(ans_vocab))  # 保证每种ans都出现\n",
    "#     min_cnt = groups.map(lambda x: len(x)).min()\n",
    "#     examples = groups.map(lambda x: sample(x, min_cnt)).flatten().list() # 每组都采样最小个数后去分组\n",
    "#     return sample(examples, len(examples))  # 重新打乱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d664342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(examples, ans_vocab):\n",
    "    groups = seq(examples).group_by(_[-1]).map(_[1])  # 按ans分组\n",
    "#     min_cnt = groups.map(lambda x: len(x)).min()\n",
    "    min_cnt =3\n",
    "    if(groups.len()>3):\n",
    "        min_cnt = 3\n",
    "    elif(groups.len()==3):\n",
    "        min_cnt = 3\n",
    "    if(min_cnt > 2):\n",
    "        examples = groups.map(lambda x: sample(x, 3)).flatten().list() # 每组都采样最小个数后去分组\n",
    "        return sample(examples, len(examples))  # 重新打乱\n",
    "    else:\n",
    "        examples = groups.map(lambda x: sample(x, min_cnt)).flatten().list() # 每组都采样最小个数后去分组\n",
    "        return sample(examples, len(examples))  # 重新打乱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab80cfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools  \n",
    "def Do_all_students_choose_courses_in_a_department(cxt, query):\n",
    "    SC, CD = cxt  # SC paris: studeng-course relation, CD pairs: course-department function\n",
    "    ss, d = query  # ss: 学生子集（可以*不止两个学生*），d: 课程\n",
    "#     return seq(ss).map(lambda s: seq(SC).filter(_[0] == s).map(_[1]).intersection(CD.filter(_.[1] == d).map(_.[0])).non_empty()).all()\n",
    "    return (seq(ss)\n",
    "            .map(lambda s: seq(SC).filter(_[0] == s).map(_[1])  # 学生s选的所有课程\n",
    "                 .intersection(\n",
    "                     seq(CD).filter(_[1] == d).map(_[0])) # d系的课程\n",
    "                 .non_empty())  # s选了d系的课程\n",
    "            .all())  # 学生子集ss都选了d系的课程\n",
    "\n",
    "def all_a_sample(vocab, k):\n",
    "    S_vocab, C_vocab, D_vocab = vocab  # vocabs of students, courses, departments\n",
    "    k_S, k_C, k_D, k_SC = k  # default values: k_S = 3, k_C = 3, k_D = 2, k_SC = 5\n",
    "    S, C, D = sample(S_vocab, k_S), sample(C_vocab, k_C), sample(D_vocab, k_D)\n",
    "    \n",
    "    while len(set(CD := choices(D, k=k_C))) < k_D: continue  # ds里每个系的课都要出现\n",
    "    CD = list(zip(C, CD))  # 得到每门课所属的系\n",
    "    \n",
    "    all_SC = list(itertools.product(S, C))  # or seq(S).cartesian(C).list()\n",
    "    while seq(SC := sample(all_SC, k_SC)).map(_[0]).distinct().len() < k_S: continue  # ss里每个学生都要选课\n",
    "    return SC, CD\n",
    "\n",
    "def select_distinct(tuples, col): return seq(tuples).map(_[col]).distinct().list()\n",
    "    \n",
    "def all_a_query(cxt,vocab,k):\n",
    "    SC, CD = cxt\n",
    "    k_S, k_C, k_D, k_SC = k\n",
    "    S, D = select_distinct(SC, 0), select_distinct(CD, 1)\n",
    "#     k_ss = randint(2, len(S))\n",
    "    ss = sample(S, 2)\n",
    "    d = choice(D)\n",
    "    return ss, d\n",
    "\n",
    "def all_a_query2str(query):\n",
    "    ss, d = query\n",
    "    query_str = '%s,%s?' % (', '.join(ss[:-1]) + ' and ' + ss[-1], d)\n",
    "    return '. ' + query_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8103db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_b(cxt, query):\n",
    "    SC, CD = cxt\n",
    "    ss,d = query\n",
    "    return (seq(CD).filter(_[1] == d).map(_[0])\n",
    "                 .difference(\n",
    "                     seq(SC).filter(_[0] == ss).map(_[1]))\n",
    "                 .empty())\n",
    "\n",
    "def all_b_sample(vocab, k):\n",
    "    S_vocab, C_vocab, D_vocab = vocab  \n",
    "    k_S, k_C, k_D, k_SC = k  # default values: k_S = 2, k_C = 3, k_D = 2, k_SC = 5\n",
    "    S, C, D = sample(S_vocab, k_S), sample(C_vocab, k_C), sample(D_vocab, k_D)\n",
    "    \n",
    "    while len(set(CD := choices(D, k=k_C))) < k_D: continue  \n",
    "    CD = list(zip(C, CD)) \n",
    "    \n",
    "    all_SC = list(itertools.product(S, C))  \n",
    "    while seq(SC := sample(all_SC, k_SC)).map(_[0]).distinct().len() < k_S: continue  # ss里每个学生都要选课\n",
    "    return SC, CD\n",
    "   \n",
    "def all_b_query(cxt,vocab,k):  # XD: 不要给qeury_fn加st参数\n",
    "    SC, CD = cxt\n",
    "    k_S, k_C, k_D, k_SC = k\n",
    "    S, D = select_distinct(SC, 0), select_distinct(CD, 1)\n",
    "#     k_ss = randint(2, len(S))  # XD: k_ss unused\n",
    "    ss = choice(S)\n",
    "    d = choice(D)\n",
    "    return ss, d\n",
    "    # XD: 不要在query_fn里转str！！这里转str，transform_fn里再解析回来，两边不是白折腾吗！\n",
    "\n",
    "def all_b_query2str(query):\n",
    "    ss, d = query\n",
    "    query_str = 'Does %s take all %s courses?' % (ss, d)\n",
    "    return '. ' + query_str\n",
    "\n",
    "\n",
    "def Is_the_intersection_of_two_sets_empty(cxt, query):\n",
    "    SC= cxt\n",
    "    s,d = query\n",
    "    return (seq(SC).filter(_[0] == s).map(_[1])\n",
    "                 .intersection(\n",
    "                     seq(SC).filter(_[0] == d).map(_[1]))\n",
    "                 .non_empty())\n",
    "\n",
    "def intersection_query(cxt,vocab,k):\n",
    "    SC= cxt\n",
    "    k_S, k_C, k_SC = k #k_s = 3, k_C = 5 , k_sc = 6\n",
    "    S = select_distinct(SC, 0)\n",
    "    s,d = sample(S,2)\n",
    "    return s, d\n",
    "\n",
    "def intersection_query2str(query):\n",
    "    s, d = query\n",
    "    query_str = \"%s,%s?\" % (s, d)\n",
    "    return '. ' + query_str\n",
    "\n",
    "def intersection_sample(vocab, k):\n",
    "    S_vocab, C_vocab = vocab  \n",
    "    k_S, k_C, k_SC = k  # k_S = 3, k_C = 5, , k_SC = 6\n",
    "    S, C= sample(S_vocab, k_S), sample(C_vocab, k_C)\n",
    "    all_SC = list(itertools.product(S, C))  \n",
    "    while seq(SC := sample(all_SC, k_SC)).map(_[0]).distinct().len() < k_S: continue \n",
    "    return SC\n",
    "\n",
    "def Is_the_first_set_a_subset_of_the_second_one(cxt, query):\n",
    "    SC= cxt\n",
    "    s,d = query\n",
    "    return (seq(SC).filter(_[0] == d).map(_[1])\n",
    "                 .union(\n",
    "                     seq(SC).filter(_[0] == s).map(_[1]))\n",
    "                 ).distinct().len()== seq(SC).filter(_[0] == d).map(_[1]).distinct().len()\n",
    "\n",
    "def complement_query(cxt,vocab,k):\n",
    "    SC= cxt\n",
    "    k_S, k_C, k_SC = k #k_s = 3, k_C = 5 , k_sc = 6\n",
    "    S = select_distinct(SC, 0)\n",
    "    s,d = sample(S,2)\n",
    "    return s, d\n",
    "\n",
    "def complement_query2str(query):\n",
    "    s, d = query\n",
    "    query_str = \"%s,%s?\" % (s, d)\n",
    "    return '. ' + query_str\n",
    "\n",
    "def complement_sample(vocab, k):\n",
    "    S_vocab, C_vocab = vocab  \n",
    "    k_S, k_C, k_SC = k  # k_S = 3, k_C = 4, k_SC = 5\n",
    "    S, C= sample(S_vocab, k_S), sample(C_vocab, k_C)\n",
    "    all_SC = list(itertools.product(S, C))  \n",
    "    while seq(SC := sample(all_SC, k_SC)).map(_[0]).distinct().len() < k_S: continue \n",
    "    return SC\n",
    "\n",
    "def Are_they_the_union_of_the_last_element(cxt, query):\n",
    "    SC, DC = cxt\n",
    "    ss,d = query\n",
    "    return (seq(ss)\n",
    "            .map(lambda s: seq(SC).filter(_[0] == s).map(_[1]) \n",
    "                 .union(\n",
    "                     seq(DC).filter(_[0] == d).map(_[1])) \n",
    "                 .distinct().len() == seq(DC).filter(_[0] == d).map(_[1]).distinct().len())  \n",
    "            .all()) \n",
    "\n",
    "def union_sample(vocab, k):\n",
    "    S_vocab, C_vocab, D_vocab = vocab  \n",
    "    k_S, k_C, k_D, k_SC = k  # k_S = 3, k_C = 4, k_D = 2, k_SC = 6\n",
    "    S, C, D = sample(S_vocab, k_S), sample(C_vocab, k_C), sample(D_vocab, k_D)\n",
    "    \n",
    "    while len(set(DC := choices(D, k=k_C))) < k_D: continue  \n",
    "    DC = list(zip(DC,C)) \n",
    "    \n",
    "    all_SC = list(itertools.product(S, C))  \n",
    "    while seq(SC := sample(all_SC, k_SC)).map(_[0]).distinct().len() < k_S: continue  \n",
    "    return SC, DC\n",
    "   \n",
    "def union_query(cxt,vocab,k): \n",
    "    SC, DC = cxt\n",
    "    k_S, k_C, k_D, k_SC = k\n",
    "    S, D = select_distinct(SC, 0), select_distinct(DC, 0)\n",
    "    k_ss = randint(2, len(S))\n",
    "    ss = sample(S, k_ss)\n",
    "    d = choice(D)\n",
    "    return ss, d\n",
    "\n",
    "def union_query2str(query):\n",
    "    ss, d = query\n",
    "    query_str = '%s,%s?' % (', '.join(ss[:-1]) + ' and ' + ss[-1], d)\n",
    "    return '. ' + query_str\n",
    "\n",
    "def Are_there_elements_belonging_to_the_same_class(cxt, query): #新建联系，把vocab和属性连起来形成新集合\n",
    "    NA, DA = cxt\n",
    "    s,d = query\n",
    "    D = seq(DA).filter(_[0] == d).map(_[1])\n",
    "    return (seq(NA).filter(_[0] == s).map(_[1]).select(lambda x: sl_vocab[x] == sl_vocab[D[0]]).any())\n",
    "      \n",
    "    \n",
    "def find_sample(vocab, k): \n",
    "    name_vocab, all_vocab = vocab\n",
    "    k_name, k_all, k_D, k_SA = k  # k_name = 3, k_all = 4, k_D = 2, k_SA = 6\n",
    "    S = list(all_vocab.keys())\n",
    "    N, A, D = sample(name_vocab, k_name), sample(S, k_all), sample(string.ascii_lowercase, k_D)\n",
    "#     D = sample(d := name_vocab.pop(name_vocab.index(a) for a in N),k_D)\n",
    "    A1 = sample(S, k_D)\n",
    "    DA = list(zip(D,A1)) \n",
    "    \n",
    "    all_NA = list(itertools.product(N, A))  \n",
    "    while seq(NA := sample(all_NA, k_SA)).map(_[0]).distinct().len() < k_name: continue  \n",
    "    return NA, DA\n",
    "   \n",
    "def find_query(cxt,vocab,k): \n",
    "    NA, DA = cxt\n",
    "    k_name, k_all, k_D, k_SA = k\n",
    "    S,D = select_distinct(NA, 0), select_distinct(DA, 0)\n",
    "    s,d = choice(S), choice(D)\n",
    "    return s, d\n",
    "\n",
    "def find_query2str(query):\n",
    "    s, d = query\n",
    "    query_str = '%s,%s?' % (s, d)\n",
    "    return '. ' + query_str\n",
    "\n",
    "\n",
    "def Are_there_any_elements_different_from_other_elements(cxt, query):\n",
    "    NA = cxt\n",
    "    ss = query\n",
    "    return (seq(ss).map(lambda s: seq(NA).filter(_[0] == s).map(_[1])\n",
    "                        .select(lambda x: sl_vocab[x])[0])\n",
    "            .distinct().len( ) == 2)\n",
    "               \n",
    "def find_dif_sample(vocab, k):\n",
    "    name_vocab, all_vocab = vocab\n",
    "    k_name, k_all, k_SA = k  # k_name = 4, k_all = 4, k_SA= 3\n",
    "    N, A = sample(name_vocab, k_name), sample(list(all_vocab.keys()), k_all) \n",
    "    NA = list(zip(N,A)) \n",
    "    return NA\n",
    "   \n",
    "def find_dif_query(cxt,vocab,k): \n",
    "    NA = cxt\n",
    "    k_name, k_all, k_NA = k\n",
    "    S = select_distinct(NA, 0)\n",
    "    ss = sample(S,k_NA)\n",
    "    return ss\n",
    "\n",
    "\n",
    "def find_dif_query2str(query):\n",
    "    ss = query\n",
    "    query_str = '%s?' % (', '.join(ss[:-1]) + ' and ' + ss[-1])\n",
    "    return '. ' + query_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "464efbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def How_many_elements_are_similar_to_the_case(cxt, query):\n",
    "    s = cxt\n",
    "    q = query\n",
    "    return seq(s).filter(lambda x: sl_vocab[x] == sl_vocab[q[0]]).len()\n",
    "                     \n",
    "def count_sample(vocab, k):\n",
    "    all_vocab = vocab\n",
    "    k_cxt,k_query = k  # k_cxt = 4 ,k_query =1\n",
    "    N = list(all_vocab.keys())\n",
    "    s = sample(N, k_cxt) \n",
    "    return s\n",
    "   \n",
    "def count_query(cxt,vocab,k): \n",
    "    NA = cxt\n",
    "    k_cxt,k_query = k\n",
    "    N = list(vocab.keys())\n",
    "    q = sample(N,k_query)\n",
    "    return q\n",
    "\n",
    "def count_query2str(query):\n",
    "    q = query\n",
    "    query_str = '%s?' % (q[0])\n",
    "    return '. ' + query_str\n",
    "\n",
    "def Is_the_number_of_first_elements_greater_than_the_second_one(cxt, query):\n",
    "    s = cxt\n",
    "    q = query\n",
    "    return (seq(s).filter(lambda x: sl_vocab[x] == sl_vocab[q[0]]).len() >= len(s)/2)\n",
    "                     \n",
    "def compare_sample(vocab, k):\n",
    "    all_vocab,s_vocab,l_vocab = vocab\n",
    "    k_cxt,k_query = k  # k_cxt = 5 ,k_query =2\n",
    "    N = list(all_vocab.keys())\n",
    "    s = sample(N, k_cxt) \n",
    "    return s\n",
    "   \n",
    "def compare_query(cxt,vocab,k): \n",
    "    NA = cxt\n",
    "    all_vocab,s_vocab,l_vocab = vocab\n",
    "    k_cxt,k_query = k\n",
    "    q = sample(s_vocab,1)+sample(l_vocab,1)\n",
    "    random.shuffle(q)\n",
    "    return q\n",
    "\n",
    "def compare_query2str(query):\n",
    "    ss,q = query\n",
    "    query_str = '%s,%s?' % (ss,q)\n",
    "    return '. ' + query_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62aee837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ascii_size_existence(l, query): return seq(l).map(_[0] > query).any()\n",
    "def Ascii_size_all(l, query): return seq(l).map(_[0] > query).all()\n",
    "def Ascii_size_None(l, query): return seq(l).filter(_[0] > query).empty()\n",
    "def ith_element(l, query=None): return seq(l).slice(1, 2)\n",
    "def ith_group(l, query=None): return seq(l).group_by(_).select(_[1]).slice(1, 2).flatten()#.distinct()# davinci F w/ and wo dist\n",
    "# def element_at_index(l, query): return seq(l).slice(query, query + 1) # davinci F\n",
    "def element_at_index(l, query): return seq(l).enumerate().filter(_[0] == query).select(_[1])\n",
    "def replace(l, query): return seq(l).map(lambda x: query.get(x, x))\n",
    "def replace_with_the_other(l, query): # davinci F\n",
    "    query = {k: (set(l) - {k}).pop() for k in l}\n",
    "    return replace(l, query)\n",
    "def replace_all_with(l, query): return seq(l).map(lambda x: query)  # davinci F?!\n",
    "def interleave_with(l, query): return seq(l).flat_map(lambda x: [x, query])  # davinci T!!\n",
    "def unique_elements(l, query=None): return seq(l).distinct() # davinci F\n",
    "def how_many_unique_elements(l, query=None): return seq(l).distinct().len()  # davinci F\n",
    "def how_many(l, query): return seq(l).filter(_ == query).len() # davinci F\n",
    "def select_same_as(l, query): return seq(l).filter(_ == query) # simpler version of how_many. davinci F\n",
    "def select_same_number_as(l, query): return seq(l).group_by(_).select(_[1]).filter(lambda x: len(x) == len(query)).flatten() # F\n",
    "def includes(l, query): return seq(l).union(seq(query)).distinct().len() == seq(l).distinct().len() # davinci F\n",
    "def is_included_by(l, query): return seq(l).difference(seq(query)).empty() # davinci F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "388dd77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compare_the_values_of_two_sets(cxt, query):\n",
    "    s = cxt\n",
    "    q = query\n",
    "    if(seq(s).filter(lambda x: sl_vocab[x] == sl_vocab[q[0]]).len() > len(s)/2):\n",
    "        return \">\"\n",
    "    elif(seq(s).filter(lambda x: sl_vocab[x] == sl_vocab[q[0]]).len() < len(s)/2):\n",
    "        return \"<\"\n",
    "    else:\n",
    "        return \"=\"\n",
    "\n",
    "def Compare_sample(vocab, k):\n",
    "    all_vocab,s_vocab,l_vocab = vocab\n",
    "    k_cxt,k_query = k  # k_cxt = 5 ,k_query =2\n",
    "    N = list(all_vocab.keys())\n",
    "    s = sample(N, k_cxt) \n",
    "    return s\n",
    "   \n",
    "def Compare_query(cxt,vocab,k): \n",
    "    NA = cxt\n",
    "    all_vocab,s_vocab,l_vocab = vocab\n",
    "    k_cxt,k_query = k\n",
    "    q = sample(s_vocab,1)+sample(l_vocab,1)\n",
    "    random.shuffle(q)\n",
    "    return q\n",
    "\n",
    "def Compare_query2str(query):\n",
    "    ss,q = query\n",
    "    query_str = '%s,%s?' % (ss,q)\n",
    "    return '. ' + query_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48028352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Relationship_between_two_sets(cxt, query): #新建联系，把vocab和属性连起来形成新集合\n",
    "    NA = cxt\n",
    "    s,q= query   #s:boys/girls  q:fruits/toys\n",
    "    name = seq(NA).filter(lambda x: bg_vocab[x[0]] == s)\n",
    "    if(seq(name).map(_[1]).filter(lambda x: ft_vocab[x] == q).len() == seq(name).len()):\n",
    "        return \"all\"\n",
    "    elif(seq(name).map(_[1]).filter(lambda x: ft_vocab[x] == q).empty()):\n",
    "        return \"none\"\n",
    "    else:\n",
    "        return \"some\"\n",
    "    \n",
    "def Relationship_sample(vocab, k): \n",
    "    name_vocab, all_vocab = vocab\n",
    "    k_name, k_all, k_SA = k  # k_name = 4, k_all = 4, k_SA = 4\n",
    "    Name = list(name_vocab.keys())\n",
    "    S = list(all_vocab.keys())\n",
    "    N, A = sample(Name, k_name), sample(S, k_all)\n",
    "#     D = sample(d := name_vocab.pop(name_vocab.index(a) for a in N),k_D)\n",
    "    \n",
    "    all_NA = list(itertools.product(N, A))  \n",
    "    while seq(NA := sample(all_NA, k_SA)).map(_[0]).distinct().len() < k_name: continue  \n",
    "    return NA\n",
    "   \n",
    "def Relationship_query(cxt,vocab,k): \n",
    "    NA = cxt\n",
    "    name_vocab, all_vocab = vocab\n",
    "    k_name, k_all, k_SA = k\n",
    "    S,D = select_distinct(NA, 0),select_distinct(NA, 1)\n",
    "    s,d = choice(S),choice(D)\n",
    "    s1,d1 = name_vocab[s],all_vocab[d]\n",
    "    return s1,d1\n",
    "\n",
    "def Relationship_query2str(query):\n",
    "    s,q = query\n",
    "    query_str = '[] %s have %s. [all / some / none]?' % (s,q)\n",
    "    return '. ' + query_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f199b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\n",
    "    (ith_element,            None,                               sample,    None,None),\n",
    "    (ith_group,              None, lambda vocab, k: seq(sample(vocab, k)).map(lambda x:[x]*randint(1, 3)).flatten().list(),None,None),\n",
    "    (element_at_index,       lambda: upper_letters,              sample,    lambda l,vocab,k: randint(0, min(2,len(l)-1))),\n",
    "    (replace,                None,                               sample,    lambda l,vocab,k: {choice(l): choice(vocab)}),\n",
    "    (replace_with_the_other, lambda: sample(full_vocab, 2),   lambda vocab,k: sample(vocab+choices(vocab, k=k-2),k), None),\n",
    "    (replace_all_with,       None,                               sample_rand_len, lambda l,vocab,k: choice(vocab)),\n",
    "    (interleave_with,        None,                               sample_rand_len, lambda l,vocab,k: choice(vocab)),\n",
    "    (unique_elements,        lambda: sample(upper_letters, 3),   choices,   None),\n",
    "    (how_many_unique_elements,lambda: sample(upper_letters, 3),  choices,   None),\n",
    "    (how_many,               lambda: sample(upper_letters, 3),   choices,   lambda l,vocab,k: choice(list(set(l)))),\n",
    "    (select_same_as,         lambda: sample(upper_letters, 3),   choices,   lambda l,vocab,k: choice(list(set(l)))),\n",
    "    (select_same_number_as,  None, lambda vocab, k: seq(sample(vocab, k)).map(lambda x:[x]*randint(1, 3)).flatten().list(),   \n",
    "     lambda l,vocab,k: [choice(vocab)]*randint(1, 3)),\n",
    "    (includes,               lambda: sample(upper_letters, 6),   sample,    lambda l,vocab,k: sample(vocab, 3)),\n",
    "    (is_included_by,         lambda: sample(upper_letters, 6),   sample,    lambda l,vocab,k: sample(vocab, 5)),\n",
    "    \n",
    "    (Ascii_size_None,        lambda: string.ascii_uppercase,              sample,    lambda l,vocab,k: \"Is there no element greater than %s?\" % choice(list(set(l)))),\n",
    "    (Ascii_size_all,         lambda: string.ascii_uppercase,              sample,    lambda l,vocab,k: \"Are all elements greater than %s?\" % choice(list(set(l)))),\n",
    "    (Ascii_size_existence,   lambda: string.ascii_uppercase,              sample,    lambda l,vocab,k: \"Is there an element greater than %s?\" % choice(list(set(l)))),\n",
    "    \n",
    "#     (all_a,                  lambda: [names_vocab,courses_vocab,depts_vocab],     all_a_sample,    all_a_query, all_a_query2str),\n",
    "    (Do_all_students_choose_courses_in_a_department,    lambda: [names_vocab,courses_vocab,depts_vocab],     all_a_sample,    all_a_query, all_a_query2str),\n",
    "    (Compare_the_values_of_two_sets,  lambda: [sl_vocab,solid_vocab,liquid_vocab],  Compare_sample,    Compare_query, Compare_query2str),\n",
    "    (Relationship_between_two_sets,   lambda: [bg_vocab,ft_vocab],               Relationship_sample,    Relationship_query, Relationship_query2str),\n",
    "    (Is_the_intersection_of_two_sets_empty,           lambda: [string.ascii_uppercase,string.ascii_lowercase],     intersection_sample,    intersection_query, intersection_query2str),\n",
    "    (Is_the_first_set_a_subset_of_the_second_one,           lambda: [string.ascii_uppercase,string.ascii_lowercase],     complement_sample,    complement_query, complement_query2str),\n",
    "    (Are_they_the_union_of_the_last_element,                lambda: [string.ascii_uppercase,string.ascii_lowercase,depts_vocab],     union_sample,    union_query, union_query2str),\n",
    "    (Are_there_elements_belonging_to_the_same_class,            lambda: [string.ascii_uppercase,sl_vocab],      find_sample,    find_query, find_query2str ),\n",
    "    (Are_there_any_elements_different_from_other_elements,          lambda: [string.ascii_uppercase,sl_vocab],      find_dif_sample,  find_dif_query, find_dif_query2str ),\n",
    "    (How_many_elements_are_similar_to_the_case,                lambda: sl_vocab,                                      count_sample,            count_query,count_query2str),\n",
    "    (Is_the_number_of_first_elements_greater_than_the_second_one,              lambda: [sl_vocab,solid_vocab,liquid_vocab],          compare_sample,            compare_query,compare_query2str),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1365,
   "id": "105e915f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-8], nrows=30, ncols=(4, 4, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "91683062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-9], nrows=8, ncols=(4,2))) #比较，query中给了两个元素（固体、液体），\n",
    "                                                        #若前一个元素的类型数目大于后一个，就输出YES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "dc45005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-9], nrows=80, ncols=(2, 3, 2, 5))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "e98e87d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Are there any elements different from other elements. For example:\n",
      "M: beer, N: pear, B: milk, G: peach. N, B and G? -> Yes\n",
      "F: juice, P: cola, E: coffee, G: pineapple. F, P and E? -> No\n",
      "U: grape, C: whisky, Z: juice, T: beer. Z, C and T? -> No\n",
      "H: whisky, R: apple, L: strawberry, O: brandy. R, L and O? -> Yes\n",
      "V: juice, W: brandy, P: coffee, O: banana. O, W and P? -> Yes\n",
      "H: banana, J: pineapple, E: coffee, G: grape. H, G and J? -> No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(make_input_str(tasks[-3], nrows=80, ncols=(4,4,3))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "6fb4988c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Are there elements belonging to the same class. For example:\n",
      "P: banana, P: brandy, I: brandy, U: peach; v: grape, b: wine. I,b? -> Yes\n",
      "K: whisky, P: apple, K: cola, L: apple; v: whisky, a: strawberry. K,a? -> No\n",
      "R: pear, R: cola, E: strawberry, M: cola; q: pear, h: vodka. E,h? -> No\n",
      "N: pineapple, Z: pineapple, C: coffee, C: juice; p: lemon, j: milk. N,p? -> Yes\n",
      "E: beer, J: milk, I: peach, I: beer; j: peach, n: banana. E,j? -> No\n",
      "R: grape, P: grape, P: juice, N: grape; k: milk, n: vodka. P,k? -> Yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(make_input_str(tasks[-4], nrows=100, ncols=(3,4,2,4)))  #找相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "f4070da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-1], nrows=8, ncols=(5,2))) #比较，query中给了两个元素（固体、液体），\n",
    "                                                        #若前一个元素的类型数目大于后一个，就输出YES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "4f3668d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-2], nrows=30, ncols=(3,1), ans_vocab=[0,1,2,3]))    #数数，数cxt中与query中元素同类的个数\n",
    "                                                                                  #这里修改了balance函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "db442a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-5], nrows=10, ncols=(3,4,2,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "eadf0bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-6], nrows=18, ncols=(3,11,5))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "c8c59a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-7], nrows=4, ncols=(3,4,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1377,
   "id": "c3df9c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Do all students choose courses in a department. For example:\n",
      "L: Geography, L: English, B: Chemistry, L: Chemistry, Z: Chemistry; English: Eng, Geography: Eng, Chemistry: Mat. B and L,Eng? -> No\n",
      "J: History, O: Art, O: History, J: Math, D: History; History: CS, Art: Mat, Math: Mat. D and O,CS? -> Yes\n",
      "Z: Sql, Z: Music, P: Chemistry, P: Sql, T: Music; Sql: Eng, Music: Eng, Chemistry: Chi. P and Z,Chi? -> No\n",
      "J: Chinese, J: Music, U: Music, J: Sql, H: Chinese; Chinese: CS, Sql: Eng, Music: Eng. J and H,CS? -> Yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(make_input_str(tasks[-10], nrows=100, ncols=(3, 3, 2, 5))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "06d90c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-2], nrows=8, ncols=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "3185653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if n_total == 1:\n",
    "#     inputs = tokenizer.encode_plus(text, return_tensors='pt')\n",
    "#     inputs = prepare_inputs(inputs, model.device)\n",
    "#     outputs = model(**inputs, output_attentions=False)\n",
    "\n",
    "#     # assert inputs.input_ids.size(0) == 1\n",
    "#     input_ids = inputs.input_ids\n",
    "#     logits = outputs.logits\n",
    "\n",
    "#     bsz = input_ids.size(0); assert bsz == 1\n",
    "#     labels = torch.ones_like(input_ids) * (-100)\n",
    "#     for bi in range(bsz):\n",
    "#         bos_indices = (input_ids[bi] == bos_id).nonzero().squeeze(1)\n",
    "#         eos_indices = (input_ids[bi] == eos_id).nonzero()[-nrows:].squeeze(1)\n",
    "#         for i, (example, bos_i, eos_i) in enumerate(zip(examples, bos_indices.tolist(), eos_indices.tolist())):\n",
    "#             print(' ' + make_example_str(example))\n",
    "#             ans_ids = input_ids[bi, bos_i + 1: eos_i]\n",
    "#             if i >= 2: labels[bi, bos_i: eos_i - 1] = ans_ids\n",
    "#             ans_prob_dist = logits[bi, bos_i: eos_i - 1].softmax(-1)\n",
    "#             ans_probs = ans_prob_dist[torch.arange(ans_prob_dist.size(0)), ans_ids]\n",
    "#             ans_tokens = tokenizer.convert_ids_to_tokens(ans_ids)\n",
    "#             for ans_id, ans_token, ans_prob, dist in zip(ans_ids, ans_tokens, numpy(ans_probs, decimals=3), ans_prob_dist):\n",
    "#                 top1_correct = (dist.argmax() == ans_id).item()\n",
    "#                 print(('*' if top1_correct else ' ') + ans_token, ans_prob, \n",
    "#                       show_topk(*dist.topk(5), indices_fn=tokenizer.convert_ids_to_tokens)) \n",
    "#     loss = nn.CrossEntropyLoss()(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "#     loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "6b5d2b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.convert_ids_to_tokens(617)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "f7d6edbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(s.count('Yes') for s in input_strs)\n",
    "# sum(s.count('No') for s in input_strs)\n",
    "# sum(s.count('all') for s in input_strs)\n",
    "# sum(s.count('none') for s in input_strs)\n",
    "# sum(s.count('some') for s in input_strs)\n",
    "# sum(s.count('3') for s in input_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d64330f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [e['input_ids'] for e in train_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ee181c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.convert_ids_to_tokens(([e['input_ids'] for e in train_dataset][0]).numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4ff9a2be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(eval_dataset.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c759bca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f588b59",
   "metadata": {},
   "source": [
    "# 请从这里开始,肖老师"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "17373019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Relationship between two sets. For example:\n",
      "Daniel: lemon, Ashley: grape, Amanda: grape, Harrison: pear. [] boys have fruits. [all / some / none]? -> all\n",
      "\n",
      "Instruction: Relationship between two sets. For example:\n",
      "Sarah: lemon, Alex: peach, Harrison: grape, Eva: plasticine. [] boys have toys. [all / some / none]? -> none\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# n_total, n_valid = 500, 100  #全部数目，测试数目\n",
    "# n_total, n_valid = 800, 200\n",
    "n_total, n_valid = 180, 30\n",
    "# n_total, n_valid =4,2\n",
    "n_train = n_total - n_valid\n",
    "# input_strs = [make_input_str(tasks[-7], nrows=1, ncols=(3,4,5)) for __ in range(n_total)]# Is the intersection of two sets empty.\n",
    "# input_strs = [make_input_str(tasks[-3], nrows=1, ncols=(4,4,3)) for __ in range(n_total)]# Are there any elements different from other elements\n",
    "# input_strs = [make_input_str(tasks[-4], nrows=1, ncols=(3,4,2,4)) for __ in range(n_total)]# Are_there_elements_belonging_to_the_same_class\n",
    "# input_strs = [make_input_str(tasks[-1], nrows=1, ncols=(5,2)) for __ in range(n_total)]#Is_the_number_of_first_elements_greater_than_the_second_one\n",
    "# input_strs = [make_input_str(tasks[-2], nrows=1, ncols=(3,1), ans_vocab=[0,1,2,3]) for __ in range(n_total)] #How_many_elements_are_similar_to_the_example\n",
    "# input_strs = [make_input_str(tasks[-5], nrows=1, ncols=(3,4,2,4)) for __ in range(n_total)] #Are_they_the_union_of_the_last_element\n",
    "# input_strs = [make_input_str(tasks[-6], nrows=1, ncols=(3,11,5)) for __ in range(n_total)]#Is the first set a subset of the second one\n",
    "# input_strs = [make_input_str(tasks[-10], nrows=1, ncols=(3, 3, 2, 5)) for __ in range(n_total)]\n",
    "# input_strs = [make_input_str(tasks[-9], nrows=1, ncols=(4,2)) for __ in range(n_total)] #Compare the values of two sets.\n",
    "input_strs = [make_input_str(tasks[-8], nrows=1, ncols=(4, 4, 4)) for __ in range(n_total)] #Relationship between two sets.\n",
    "\n",
    "for s in sample(input_strs, 2): print(s)\n",
    "# print(input_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "58f1d494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s,end = input_strs[0].index(\":\"),input_strs[0].index(\"For\")\n",
    "# name = input_strs[0][s+2:end]\n",
    "# import json\n",
    "# filename = './nrk/'+name\n",
    "# with open(filename,\"w\") as file_obj:\n",
    "#     json.dump(input_strs,file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "2e64ee95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Is this sentence correct. For example:\n",
      "A is less difficult to carry than B because A is smaller. Is that right? -> Yes\n",
      "\n",
      "Instruction: Is this sentence correct. For example:\n",
      "A is more dangerous to look at than B because A is less luminous. Is that right? -> No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in sample(text, 2): print(s)\n",
    "n_total, n_valid = 180, 30\n",
    "n_train = n_total - n_valid\n",
    "text = text[:180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "e2f80b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "# train_dataset = CHILDDataset(input_strs[:-n_valid], tokenizer)\n",
    "# eval_dataset = CHILDDataset(input_strs[-n_valid:], tokenizer)\n",
    "train_dataset = CHILDDataset(text[:-n_valid], tokenizer)\n",
    "eval_dataset = CHILDDataset(text[-n_valid:], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82ad27d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'WrappedEmbedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-c6a08e8d5cba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_input_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#提取 embedding 中的 词向量部分\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwte\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wte'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwte\u001b[0m  \u001b[0;31m# already been wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWrappedEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwte\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_input_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#为词向量赋值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'WrappedEmbedding' is not defined"
     ]
    }
   ],
   "source": [
    "wte = model.get_input_embeddings() #提取 embedding 中的 词向量部分\n",
    "if hasattr(wte, 'wte'): wte = wte.wte  # already been wrapped\n",
    "we = WrappedEmbedding(wte, prompt_len=40000)\n",
    "model.set_input_embeddings(we) #为词向量赋值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "416bbc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = []\n",
    "    bos_indices = []\n",
    "    eos_indices = []\n",
    "    preds = []\n",
    "    m = nn.Softmax(dim = -1)\n",
    "    labels_loc = pred.label_ids.argmax(-1)\n",
    "    for i in range(len(labels_loc)):\n",
    "        labels.append(pred.label_ids[i][labels_loc[i]])\n",
    "                                                                                 #     arraypre = pred.predictions[0] # 6B\n",
    "    arraypre = pred.predictions                                                                              # 1.3B\n",
    "    predss = arraypre.argmax(-1)\n",
    "    num = \"\"\n",
    "   \n",
    "    for bi in range(predss.shape[0]):\n",
    "        num = labels_loc[bi]\n",
    "        preds.append(predss[bi, num-1:num]) \n",
    "        t = torch.from_numpy(pred.predictions[bi,num-1:num])                        #1.3B\n",
    "                                                                                    #         t = torch.from_numpy(pred.predictions[0][bi,num-1:num])  #6B\n",
    "        n = m(t)\n",
    "        ids = torch.topk(n,3)[1].numpy().tolist()                                              #ids   /[0] 概率\n",
    "        loc = torch.topk(n,3)[0].numpy().tolist()\n",
    "                                                                                                 #         print(ids)\n",
    "        ids = tokenizer.convert_ids_to_tokens(ids[0])\n",
    "        loc = [float('{:.4f}'.format(i)) for i in loc[0]]\n",
    "        precision = [i+\" : \"+str(j) for i,j in zip(ids,loc)]\n",
    "    acc = accuracy_score(labels, list(preds))    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "d34fd7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, 3363, -100, -100, -100, -100,\n",
       "        -100, -100])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset[0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "eb7bf973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_metrics(pred):\n",
    "#     labels = []\n",
    "#     bos_indices = []\n",
    "#     preds = []\n",
    "#     labels_loc = pred.label_ids.argmax(-1)\n",
    "#     for i in range(len(labels_loc)):\n",
    "#         labels.append(pred.label_ids[i][labels_loc[i]])\n",
    "# #     print(labels)\n",
    "#     arraypre = pred.predictions[0] # 6B\n",
    "# # #     arraypre = pred.predictions # 1.3B\n",
    "#     print(arraypre)\n",
    "#     predss = arraypre.argmax(-1)\n",
    "#     sent = tokenizer.convert_ids_to_tokens(predss[0])\n",
    "#     sent1 = \" \".join(sent)\n",
    "#     sent1=sent1.replace(\"Ġ\",\"\")\n",
    "#     sent1=sent1.replace(\"Ċ\",\"\\n\")\n",
    "#     print(sent1)\n",
    "#     for bi in range(predss.shape[0]):\n",
    "#         for j in range(predss.shape[1]):\n",
    "#             if(predss[bi][j] == bos_id):\n",
    "#                 bos_indices.append(j)\n",
    "#         bos_i = bos_indices[-1]\n",
    "#         preds.append(predss[bi, bos_i + 1:bos_i + 2])\n",
    "    \n",
    "#     acc = accuracy_score(labels, list(preds))\n",
    "#     return {\n",
    "# #         'accuracy': acc,\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "6ebf074a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(output_dir=\"./models/model_name\",                                                             #模型预测和检查点的输出目录\n",
    "    overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=True, \n",
    "    per_device_train_batch_size=1, per_device_eval_batch_size=1,                                                  #每个GPU / TPU内核/ CPU的批处理大小\n",
    "    gradient_accumulation_steps=6,eval_steps=5, \n",
    "    weight_decay=0.001, adam_beta2=0.98, adam_epsilon=1e-6,                                      #weight_decay要应用的权重衰减,adam_epsilon AdamW优化器的ε超参数\n",
    "    lr_scheduler_type='constant', learning_rate=0.001, num_train_epochs=5,                                  #learning_rate:Adam初始学习率\n",
    "    logging_strategy ='epoch',  save_steps=0,                                             #save_steps保存两个检查点之前的更新步骤数\n",
    "    no_cuda=True, report_to='none',                                                         # to avoid report to wandb\n",
    "    evaluation_strategy ='steps',\n",
    "#     evaluation_strategy ='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "ff25273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(filename,\"a\") as f:\n",
    "#         f.write(str(training_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "d89c7d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/xd/projects/transformers/src/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, training_args, train_dataset=train_dataset, eval_dataset=eval_dataset,compute_metrics=compute_metrics,\n",
    "                  optimizers=(create_optimizer(model, training_args), None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "0aa95c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 01:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.5578513145446777,\n",
       " 'eval_accuracy': 0.0,\n",
       " 'eval_precision': ['ĠA : 0.1883', 'ĠIs : 0.059', 'ĠB : 0.0472'],\n",
       " 'eval_runtime': 9.2024,\n",
       " 'eval_samples_per_second': 3.26,\n",
       " 'eval_steps_per_second': 3.26}"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "c5b8d21d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 150\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 750\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 09:14, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.616900</td>\n",
       "      <td>1.304838</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>['ĠYes : 0.6459', 'ĠNo : 0.1877', 'Ġ[ : 0.0194']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.889400</td>\n",
       "      <td>13.196543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>['ĊĊ : 0.1545', 'Ċ : 0.1327', '\\\\ : 0.0873']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10.558700</td>\n",
       "      <td>12.672831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>['Ġthe : 0.1758', 'Ġof : 0.0498', '- : 0.0434']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9.712600</td>\n",
       "      <td>9.770533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>['Ġ : 0.273', 'Ġthe : 0.0731', 'Ġlike : 0.035']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.668000</td>\n",
       "      <td>2.120934</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>['ĠNo : 0.1628', 'ĠYes : 0.1345', 'Ġthe : 0.0488']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=750, training_loss=5.889138916015625, metrics={'train_runtime': 554.7103, 'train_samples_per_second': 1.352, 'train_steps_per_second': 1.352, 'total_flos': 224246237184000.0, 'train_loss': 5.889138916015625, 'epoch': 5.0})"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "90777ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 10\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.735599160194397, 'test_accuracy': 0.5, 'test_precision': ['ĠYes : 0.6578', 'ĠNo : 0.3009', 'Ġyes : 0.0071'], 'test_runtime': 3.1062, 'test_samples_per_second': 3.219, 'test_steps_per_second': 3.219}\n"
     ]
    }
   ],
   "source": [
    "test_dataset = CHILDDataset(text[:10], tokenizer)\n",
    "a = trainer.predict(test_dataset) #此处新生成了测试集\n",
    "print(a.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8d29120e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 30\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.0003098619054071605, 'test_accuracy': 1.0, 'test_precision': ['ĠNo : 0.9999', 'No : 0.0', 'Ġ : 0.0'], 'test_runtime': 50.5283, 'test_samples_per_second': 0.594, 'test_steps_per_second': 0.594}\n"
     ]
    }
   ],
   "source": [
    "# input_strs = [make_input_str(tasks[-7], nrows=100, ncols=(3,4,5)) for __ in range(30)]# Is the intersection of two sets empty.\n",
    "# input_strs = [make_input_str(tasks[-3], nrows=100, ncols=(4,4,3)) for __ in range(30)]# Are there any elements different from other elements\n",
    "# input_strs = [make_input_str(tasks[-4], nrows=100, ncols=(3,4,2,4)) for __ in range(30)]# Are_there_elements_belonging_to_the_same_class\n",
    "# input_strs = [make_input_str(tasks[-1], nrows=120, ncols=(5,2)) for __ in range(30)]#Is_the_number_of_first_elements_greater_than_the_second_one\n",
    "# input_strs = [make_input_str(tasks[-2], nrows=80, ncols=(3,1), ans_vocab=[0,1,2,3]) for __ in range(30)] #How_many_elements_are_similar_to_the_example\n",
    "# input_strs = [make_input_str(tasks[-5], nrows=100, ncols=(3,4,2,4)) for __ in range(30)] #Are_they_the_union_of_the_last_element\n",
    "# input_strs = [make_input_str(tasks[-6], nrows=100, ncols=(3,11,5)) for __ in range(30)]#Is the first set a subset of the second one\n",
    "# input_strs = [make_input_str(tasks[-10], nrows=100, ncols=(3, 3, 2, 5)) for __ in range(30)]\n",
    "# input_strs = [make_input_str(tasks[-9], nrows=100, ncols=(4,2)) for __ in range(30)] #Compare the values of two sets.\n",
    "# input_strs = [make_input_str(tasks[-8], nrows=100, ncols=(4, 4, 4)) for __ in range(30)] #Relationship between two sets.\n",
    "test_dataset = CHILDDataset(input_strs[:], tokenizer)\n",
    "a = trainer.predict(test_dataset) #此处新生成了测试集\n",
    "print(a.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d1961b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ef98c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedb8237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4622d39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a194cd0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afa17cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e6b876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b37a9874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.place_model_on_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9b4b3eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prev(elem):\n",
    "    i, v = elem\n",
    "    return _l[i - 1] if i > 0 else None\n",
    "\n",
    "false = lambda *_: False\n",
    "true  = lambda *_: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "721cb66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Element = namedtuple('Element', 'index value')\n",
    "_l = 'A B C B'.split()\n",
    "n = len(_l)\n",
    "# l = [Element._make(e) for e in enumerate(l)]\n",
    "l = seq(_l)\n",
    "l = l.enumerate().map(Element._make)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9f22f664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  index</th><th>value  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">      0</td><td>A      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      1</td><td>B      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      2</td><td>C      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      3</td><td>B      </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[Element(index=0, value='A'), Element(index=1, value='B'), Element(index=2, value='C'), Element(index=3, value='B')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['C']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['b']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['C', 'A', 'B', 'B']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['B', 'B', 'C', 'A']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  index</th><th>value  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">      0</td><td>A      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      1</td><td>A      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      2</td><td>C      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      3</td><td>B      </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[Element(index=0, value='A'), Element(index=1, value='A'), Element(index=2, value='C'), Element(index=3, value='B')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'B', 'C', 'C']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 1, 2, 3]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['B']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['B']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.map(lambda x: {'B': 'D'}.get(x, x))\n",
    "\n",
    "l.filter(lambda x: get_prev(x) == 'B').select(_.value)\n",
    "\n",
    "find_fn = _.index == 1\n",
    "l.filter(find_fn).select(_.value).map(lower)\n",
    "\n",
    "find_fn = _.value == 'C'\n",
    "l.filter(find_fn).select(_.index)\n",
    "\n",
    "# move x to first\n",
    "update_filter = _.value == 'C'\n",
    "get_new = lambda x: -1\n",
    "l.map(lambda x: Element(update_fn(x, 'index'), x.value)).order_by(_.index).select(_.value)\n",
    "\n",
    "# swap first and last\n",
    "update_filter = true\n",
    "get_new = lambda x: {0: n - 1, n - 1: 0}.get(x.index, x.index)\n",
    "l.map(lambda x: Element(update_fn(x, 'index'), x.value)).order_by(_.index).select(_.value)\n",
    "\n",
    "# get inbetween == drop_while + take_while?\n",
    "\n",
    "# update by index to its prev\n",
    "update_filter = _.index == 1\n",
    "get_new = lambda x: get_prev(x)\n",
    "def update_fn(x, update_field): return get_new(x) if update_filter(x) else getattr(x, update_field)\n",
    "l.map(lambda x: Element(x.index, update_fn(x, 'value')))\n",
    "\n",
    "# if two adjacent elements by indices are equal\n",
    "l.filter(lambda x: x.index in [0, 1]).select(_.value).distinct().len() == 1\n",
    "\n",
    "seq('A B C B C'.split()).group_by(_).select(_[1]).flatten()\n",
    "\n",
    "# count occurance till current\n",
    "seq('A B A C B A'.split()).inits().reverse().tail().map(lambda x: x.filter(_ == x.last()).len())\n",
    "\n",
    "# find special\n",
    "seq('A B A A'.split()).count_by_value().filter(_[1] == 1).select(_[0])\n",
    "\n",
    "# generalized find special\n",
    "seq('A A B C C D D'.split()).group_by(_).map(lambda x: (x[0], len(x[1]))).filter(_[1] == 1).select(_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b3e124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
