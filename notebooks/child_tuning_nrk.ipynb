{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6ea7a72",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (4.17.0)\n",
      "Requirement already satisfied: sacremoses in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: filelock in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (2021.10.8)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/xd/.local/lib/python3.8/site-packages (from transformers) (4.60.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (0.11.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/xd/.local/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages/PyYAML-6.0-py3.8-linux-x86_64.egg (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (1.21.2)\n",
      "Requirement already satisfied: requests in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/xd/.local/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: six in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "0faf2697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.12 | packaged by conda-forge | (default, Jan 30 2022, 23:53:36) \\n[GCC 9.4.0]'"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e11bc1d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pyfunctional\n",
      "  Using cached PyFunctional-1.4.3-py3-none-any.whl (49 kB)\n",
      "Requirement already satisfied: dill>=0.2.5 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from pyfunctional) (0.3.4)\n",
      "Requirement already satisfied: tabulate<=1.0.0 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from pyfunctional) (0.8.9)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pyfunctional\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed pyfunctional-1.4.3\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pyfunctional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "367b7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run \"context_learning_nrk.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "9398a888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Is this sentence correct. For example:\n",
      "A should be easier to melt than B because B is hotter. Is that right? -> No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text1 = text\n",
    "print(text1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7292808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54a886cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ['HF_HOME'] = '/raid/xd/.cache/torch'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from types import MethodType\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, OrderedDict, Counter\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "from itertools import chain\n",
    "import math\n",
    "from functools import reduce\n",
    "import numpy as np \n",
    "# np.set_printoptions(threshold=np.inf)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data.sampler import RandomSampler, Sampler, SequentialSampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from transformers.data.data_collator import DataCollator, default_data_collator\n",
    "from transformers import AutoConfig, pipeline\n",
    "from transformers import RobertaForMaskedLM, RobertaTokenizer, GPT2LMHeadModel, GPT2Tokenizer, GPTNeoForCausalLM, AutoModelForCausalLM\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import HfArgumentParser, Trainer, TrainingArguments, set_seed, AdamW\n",
    "# from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "# from transformers.trainer_utils import EvaluationStrategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f54c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPTNeoForCausalLM, GPTJForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd287822",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/nas/xd/projects/PyFunctional')\n",
    "from functional import seq\n",
    "from functional.pipeline import Sequence\n",
    "from fn import _\n",
    "from collections import namedtuple \n",
    "import sys\n",
    "# sys.path.insert(0, '/nas/xd/projects/transformers/src/transformers')\n",
    "import os\n",
    "# device_mappings = {0: 1, 1: 5, 2: 6, 3: 7, 4: 2, 5: 3, 6: 0, 1: 4}\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(device_mappings[2])\n",
    "\n",
    "import random\n",
    "import string\n",
    "from collections import defaultdict, OrderedDict\n",
    "from itertools import product, chain\n",
    "import math\n",
    "import numpy as np\n",
    "from pattern.en import comparative\n",
    "import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "a2a577ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/nas/xd/projects/PyFunctional')\n",
    "from functional import seq\n",
    "from functional.pipeline import Sequence\n",
    "from fn import _\n",
    "from collections import namedtuple \n",
    "import sys\n",
    "# sys.path.insert(0, '/nas/xd/projects/transformers/src/transformers')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "7d5907ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "import openai\n",
    "openai.api_key = open('/nas/xd/projects/openai_api_keys.txt').readlines()[-1].split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "86a17aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Do all students choose courses in a department. For example:\n",
      "D: Chinese, U: Art, A: Art, U: Chinese, D: Art; Art: Chi, Chinese: Eng, Physics: Eng. A and U,Chi? -> Yes\n",
      "\n",
      "Instruction: Do all students choose courses in a department. For example:\n",
      "C: Sql, H: Physics, H: Sql, H: Chemistry, K: Sql; Sql: Chi, Physics: Chi, Chemistry: Eng. H and C,Eng? -> No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_total, n_valid =2,1\n",
    "n_train = n_total - n_valid\n",
    "# input_strs = [make_input_str(tasks[-7], nrows=1, ncols=(3,4,5)) for __ in range(n_total)]# Is the intersection of two sets empty.\n",
    "# input_strs = [make_input_str(tasks[-3], nrows=1, ncols=(4,4,3)) for __ in range(n_total)]# Are there any elements different from other elements\n",
    "# input_strs = [make_input_str(tasks[-4], nrows=1, ncols=(3,4,2,4)) for __ in range(n_total)]# Are_there_elements_belonging_to_the_same_class\n",
    "# input_strs = [make_input_str(tasks[-1], nrows=1, ncols=(5,2)) for __ in range(n_total)]#Is_the_number_of_first_elements_greater_than_the_second_one\n",
    "# input_strs = [make_input_str(tasks[-2], nrows=1, ncols=(3,1), ans_vocab=[0,1,2,3]) for __ in range(n_total)] #How_many_elements_are_similar_to_the_example\n",
    "# input_strs = [make_input_str(tasks[-5], nrows=1, ncols=(3,4,2,4)) for __ in range(n_total)] #Are_they_the_union_of_the_last_element\n",
    "# input_strs = [make_input_str(tasks[-6], nrows=1, ncols=(3,11,5)) for __ in range(n_total)]#Is the first set a subset of the second one\n",
    "input_strs = [make_input_str(tasks[-10], nrows=1, ncols=(3, 3, 2, 5)) for __ in range(n_total)]\n",
    "# input_strs = [make_input_str(tasks[-9], nrows=1, ncols=(4,2)) for __ in range(n_total)] #Compare the values of two sets.\n",
    "# input_strs = [make_input_str(tasks[-8], nrows=1, ncols=(4, 4, 4)) for __ in range(n_total)] #Relationship between two sets.\n",
    "\n",
    "for s in sample(input_strs, 2): print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "21465a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_fn(engine):  # XD\n",
    "    def fn(text):\n",
    "        return openai.Completion.create(engine=engine, prompt=text, max_tokens=1, echo=True, logprobs=5).choices[0]\n",
    "    return fn\n",
    "\n",
    "engines = ['davinci', 'curie']\n",
    "for engine in engines:\n",
    "    model_name = 'openai_api_' + engine\n",
    "#     model = lambda x: openai.Completion.create(engine=engine, prompt=x, max_tokens=0, echo=True, logprobs=5).choices[0]\n",
    "    model = get_model_fn(engine)\n",
    "    models[model_name] = model, tokenizer\n",
    "    \n",
    "# model_name = 'openai_api_davinci'\n",
    "model_name = 'openai_api_curie'\n",
    "model, tokenizer = models[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "bf3af01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['EleutherAI/gpt-j-6B'])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "693f563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_dist(d, topk=5): return {k: round(math.exp(v), 3) for k, v in sorted(d.items(), key=lambda x: x[1], reverse=True)[:topk]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "77d1817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ans_indices0(input_ids):\n",
    "    bos_id = tokenizer._convert_token_to_id('Ġ->')\n",
    "    eos_id = tokenizer._convert_token_to_id('Ċ')\n",
    "    bos_indices = (input_ids == bos_id).nonzero().squeeze(1).tolist()\n",
    "    eos_indices = (input_ids == eos_id).nonzero()[-len(bos_indices):].squeeze(1).tolist()\n",
    "    return bos_indices, eos_indices\n",
    "\n",
    "# def get_ans_indices1(input_ids):\n",
    "#     bos_id = tokenizer._convert_token_to_id('?')\n",
    "# #     print(\"bos_id\",bos_id)\n",
    "#     eos_id = tokenizer._convert_token_to_id('Ċ')\n",
    "#     period_ids = [tokenizer._convert_token_to_id('.'), tokenizer._convert_token_to_id('Ġ.')]\n",
    "# #     print(\"period_ids:\",period_ids)\n",
    "# #     l_bracket_id, r_bracket_id = tokenizer._convert_token_to_id('Ġ['), tokenizer._convert_token_to_id('Ġ]')\n",
    "# #     print(\"l_bracket_id\",l_bracket_id)\n",
    "# #     print(\"r_bracket_id:\",r_bracket_id)\n",
    "#     eos_indices = (input_ids == eos_id).nonzero().squeeze(1).tolist() #.nonezero()取非零元素坐标\n",
    "# #     print(\"eos_indices0:\",eos_indices)\n",
    "#     eos_indices = [i - 1 if input_ids[i - 1] in period_ids else i for i in eos_indices]\n",
    "# #     print(\"eos_indices1:\",eos_indices)\n",
    "# #     eos_indices = [i - 1 if input_ids[i - 1] == r_bracket_id else i for i in eos_indices]\n",
    "# #     print(\"eos_indices2:\",eos_indices)\n",
    "    \n",
    "#     def find_bos_index(start_i):\n",
    "#         for bos_i in range(start_i, start_i - 3, -1):\n",
    "# #             if input_ids[bos_i] == bos_id or input_ids[bos_i] == l_bracket_id and input_ids[bos_i - 1] == bos_id:\n",
    "#             if input_ids[bos_i] == bos_id:\n",
    "#                 if bos_i != start_i: print('subtokens:', tokenizer.convert_ids_to_tokens(input_ids[bos_i + 1: start_i + 2]))\n",
    "#                 return bos_i\n",
    "#         assert False\n",
    "#     bos_indices = [find_bos_index(i - 2) for i in eos_indices]\n",
    "# #     print(\"bos:\",bos_indices)\n",
    "# #     print(\"eos:\",eos_indices)\n",
    "#     return bos_indices, eos_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "bb474e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_num = 0\n",
    "def predict(model, text, ans_indices_fn, topk=5, return_reduced_loss=False, verbose=True):\n",
    "    use_openai_api = type(model) in [types.MethodType, types.FunctionType]  # openai.Completion.create\n",
    "    print(\"[]\",[types.MethodType, types.FunctionType])\n",
    "    print(\"type(model):\",type(model))\n",
    "    inputs = tokenizer.encode_plus(text, return_tensors='pt')\n",
    "    print(inputs)\n",
    "    input_ids = inputs.input_ids\n",
    "#     print(input_ids)\n",
    "    bsz = input_ids.size(0)\n",
    "#     print(\"bsz = \",bsz)\n",
    "    labels = torch.ones_like(input_ids) * (-100)\n",
    "    if use_openai_api:\n",
    "        assert bsz == 1\n",
    "#         outputs = model(engine=engine, prompt=text, max_tokens=0, echo=True, logprobs=5).choices[0].logprobs\n",
    "        outputs = model(text).logprobs  # XD\n",
    "        ans_nlls = []\n",
    "    else:\n",
    "        inputs = prepare_inputs(inputs, model.device)\n",
    "        outputs = model(**inputs, output_attentions=False)\n",
    "        logits = outputs.logits\n",
    "    for bi in range(bsz):\n",
    "\n",
    "        bos_indices, eos_indices = ans_indices_fn(input_ids[bi])\n",
    "#         print(\"input_ids :\",input_ids[bi])\n",
    "#         print(\"ans_indices_fn:\",ans_indices_fn(input_ids[bi]))\n",
    "#         print(\"bos_indices:\",bos_indices)\n",
    "#         print(\"eos_indices:\",eos_indices)\n",
    "        examples = text.strip().split('\\n')\n",
    "#         print(\"bos_indices:\",bos_indices)\n",
    "        print(\"examples:\",examples)\n",
    "        assert len(bos_indices) == len(examples)-1, '%d != %d' % (len(bos_indices), len(examples))\n",
    "        num = 0\n",
    "        for i, (example, bos_i, eos_i) in enumerate(zip(examples, bos_indices, eos_indices)):\n",
    "#             if verbose: print(' ' + example, end='\\t')\n",
    "            ans_ids = input_ids[bi, bos_i + 1: eos_i]\n",
    "            print(\"ans_ids:\",ans_ids)\n",
    "            labels[bi, bos_i: eos_i - 1] = ans_ids\n",
    "            if use_openai_api:\n",
    "                ans_prob_dist = [get_prob_dist(d, topk=topk) for d in outputs.top_logprobs[bos_i + 1: eos_i]]\n",
    "                ans_probs = [math.exp(lp) for lp in outputs.token_logprobs[bos_i + 1: eos_i]]\n",
    "                ans_nlls += [-lp for lp in outputs.token_logprobs[bos_i + 1: eos_i]]\n",
    "            else:\n",
    "                ans_prob_dist = logits[bi, bos_i: eos_i - 1].softmax(-1)\n",
    "                ans_probs = ans_prob_dist[torch.arange(ans_prob_dist.size(0)), ans_ids]\n",
    "            ans_tokens = tokenizer.convert_ids_to_tokens(ans_ids)\n",
    "            num += 1\n",
    "            for ans_id, ans_token, ans_prob, dist in zip(ans_ids, ans_tokens, numpy(ans_probs, decimals=3), ans_prob_dist):\n",
    "                top1_correct = max(dist.items(), key=lambda x: x[1])[0] == ans_token.replace('Ġ', ' ') \\\n",
    "                    if use_openai_api else (dist.argmax() == ans_id).item()  \n",
    "                \n",
    "                if verbose:\n",
    "                    if(num == 1 and top1_correct):\n",
    "                        global correct_num\n",
    "                        correct_num += 1\n",
    "                    if(len(ans_tokens) <= 1):\n",
    "#                         if(top1_correct):\n",
    "#                             dictlocation1[example] = 1\n",
    "                        print(('！！！' if top1_correct else ' ') + ans_token, ans_prob, \n",
    "                              dist if use_openai_api else show_topk(*dist.topk(topk), indices_fn=tokenizer.convert_ids_to_tokens)) \n",
    "                        \n",
    "                    else:\n",
    "                        pass\n",
    "    if use_openai_api:\n",
    "        loss = ans_nlls if return_reduced_loss else sum(ans_nlls) / len(ans_nlls)\n",
    "    else:\n",
    "        loss = nn.CrossEntropyLoss()(logits.view(-1, logits.size(-1)), labels.view(-1)) if return_reduced_loss \\\n",
    "            else nn.CrossEntropyLoss(reduction='none')(logits.view(-1, logits.size(-1)), labels.view(-1))[labels.view(-1)>=0].tolist()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "f49b21a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Instruction: Do all students choose courses in a department. For example:\n",
      "D: Chinese, U: Art, A: Art, U: Chinese, D: Art; Art: Chi, Chinese: Eng, Physics: Eng. A and U,Chi? -> Yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(input_strs))\n",
    "print(input_strs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "490ff768",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [<class 'method'>, <class 'function'>]\n",
      "type(model): <class 'function'>\n",
      "{'input_ids': tensor([[ 6310,  2762,    25,  2141,   477,  2444,  3853, 10902,   287,   257,\n",
      "          5011,    13,  1114,  1672,    25,   198,    35,    25,  3999,    11,\n",
      "           471,    25,  3683,    11,   317,    25,  3683,    11,   471,    25,\n",
      "          3999,    11,   360,    25,  3683,    26,  3683,    25, 21380,    11,\n",
      "          3999,    25,  1985,    11, 23123,    25,  1985,    13,   317,   290,\n",
      "           471,    11,  1925,    72,    30,  4613,  3363,   198]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'D: Chinese, U: Art, A: Art, U: Chinese, D: Art; Art: Chi, Chinese: Eng, Physics: Eng. A and U,Chi? -> Yes']\n",
      "ans_ids: tensor([3363])\n",
      " ĠYes 0.008 {' A': 0.086, ' U': 0.047, ' D': 0.037, ' Art': 0.031, ' Eng': 0.025}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.8359756"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [<class 'method'>, <class 'function'>]\n",
      "type(model): <class 'function'>\n",
      "{'input_ids': tensor([[ 6310,  2762,    25,  2141,   477,  2444,  3853, 10902,   287,   257,\n",
      "          5011,    13,  1114,  1672,    25,   198,    34,    25,   311, 13976,\n",
      "            11,   367,    25, 23123,    11,   367,    25,   311, 13976,    11,\n",
      "           367,    25, 27867,    11,   509,    25,   311, 13976,    26,   311,\n",
      "         13976,    25, 21380,    11, 23123,    25, 21380,    11, 27867,    25,\n",
      "          1985,    13,   367,   290,   327,    11,  7936,    30,  4613,  1400,\n",
      "           198]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'C: Sql, H: Physics, H: Sql, H: Chemistry, K: Sql; Sql: Chi, Physics: Chi, Chemistry: Eng. H and C,Eng? -> No']\n",
      "ans_ids: tensor([1400])\n",
      " ĠNo 0.018 {' H': 0.067, ' S': 0.056, ' Eng': 0.045, ' C': 0.03, ' K': 0.026}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.990212"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_num = 0\n",
    "for i in input_strs:\n",
    "# for i in text1:\n",
    "    text = i\n",
    "    predict(model, text, get_ans_indices0, verbose=True, topk=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c1fe66",
   "metadata": {},
   "source": [
    "# 从这里开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58cba5e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from child_utils import *\n",
    "from common_utils import *\n",
    "from model_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90f62ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "# cache_dir = '/nas/xd/.cache/torch/transformers/'  # for models besides t5-3b/11b\n",
    "cache_dir = '/mnt/nvme1/xd/.cache/torch/transformers/'  # for gpt-j-6B on elderberry\n",
    "proxies = {'http': '192.168.50.1:1081'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "520d34a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = \"EleutherAI/gpt-j-6B\"\n",
    "# model_name = \"EleutherAI/gpt-neo-1.3B\"\n",
    "# model = GPTJForCausalLM.from_pretrained(model_name, proxies=proxies, cache_dir=cache_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, proxies=proxies, cache_dir=cache_dir)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', cache_dir=cache_dir)\n",
    "models[model_name] = model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "830ce082",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.eval()\n",
    "unify(model)\n",
    "blocks = model.transformer.h\n",
    "attn = blocks[0].attn\n",
    "ln_f = model.transformer.ln_f\n",
    "L, H, embed_dim = len(blocks), attn.num_heads, attn.embed_dim\n",
    "\n",
    "_we = model.transformer.wte.weight.data.t()\n",
    "_wu = model.lm_head.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e50583a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTJAttention(\n",
       "  (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "  (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "  (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c128d0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LayerNorm((4096,), eps=1e-05, elementwise_affine=True)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cd64c2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d82cfd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50400, 4096])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_wu.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "ef8becf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def T(f): return lambda x: f(x.T).T\n",
    "mlp = lambda x: mlp_forward(blocks[0], x)\n",
    "v = we.size(1) #// 2\n",
    "_we, _wu = we[:, :v], wu[:v]\n",
    "with torch.no_grad(): _e = mlp(_we.T) + _we.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "9a94c107",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer, head = 2, 0 # prev ov: 13-9, next num ov: 14-13, next word ov: 13-4, prepend space ov: 18-3/17-10, isa ov: 14-7, antonym ov: 16-14, copy ov 13-2\n",
    "wq, wk, wv, wo = get_head_weights(model, layer, head, transpose=True)\n",
    "with torch.no_grad():\n",
    "    eq = ek = e = blocks[layer].ln_1(_e)\n",
    "    # A, B = _wu, ln_f(e @ wv @ wo)\n",
    "    A, B = _wu @ wo.T, e @ wv\n",
    "    q, k = eq @ wq, ek @ wk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "a7f6529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qk = True\n",
    "with torch.no_grad():  # ve,ed,de,ev->vv\n",
    "    # _m = ln(mlp(_we.T)) @ (wq.T @ wk) @ T(ln)(T(mlp)(_we)) if qk else _wu @ T(ln_f)(wo @ (wv @ T(ln)(T(mlp)(_we))))\n",
    "    _m = q @ k.T if qk else _wu @ ln_f(B @ wo).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "459d21eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7862626314163208"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_eigv((k.T @ q).eig()[0] if qk else (B.T @ A).eig()[0], start_i=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "801cf7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = _m  # q->k, output->input\n",
    "# m = _m.T  # k->q, input->output\n",
    "values, indices = m.topk(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "d258e52b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ġnor {'Ġnot': 30, 'not': 28, 'ĠNOT': 24, 'ĠNot': 24, 'NOT': 22, 'Not': 22}\n",
      "nor {'Ġnot': 22, 'not': 21, 'ĠNOT': 20, 'NOT': 18, 'ĠNot': 18, 'Ġcannot': 17}\n",
      "Nor {'not': 19, 'Ġnot': 18, 'ĠNot': 17, 'Not': 17, 'ĠNOT': 17, 'NOT': 16}\n",
      "Ġitself {'itutes': 17, 'Ġkinds': 16, 'Ġregulars': 16, 'Ġmoderators': 16, 'Ġmanners': 16, 'Ġpubs': 16}\n",
      "ĠNor {'Ġnot': 18, 'not': 17, 'ĠNOT': 16, 'NOT': 16, 'Ġnobody': 15, 'ĠNot': 15}\n",
      "hes {'ĠWAS': 17, 'Ġwasn': 16, 'ED': 16, 'Ġstemmed': 16, 'was': 15, 'Ġwas': 15}\n",
      "cat {'Ġdivers': 17, 'Ġnationals': 17, 'Ġyoungsters': 15, 'Ġrodents': 15, 'Ġenvironmentalists': 15, 'Ġglasses': 15}\n",
      "raw {'Ġdusty': 16, 'ĠKimber': 15, 'ĠFres': 15, 'Ġmajors': 15, 'Ġnipples': 15, 'Ġrapists': 15}\n",
      "active {'Ġworkshop': 16, 'Ġtaboo': 15, 'Ġcottage': 15, 'Ġaquarium': 14, 'Ġneighb': 14, 'workshop': 14}\n",
      "Ġconstant {'Ġkeeps': 15, 'keeping': 15, 'aintain': 15, 'Ġstays': 15, 'Ġstaying': 15, 'ĠKeeping': 14}\n",
      "Ġanymore {\"'t\": 17, 'Ġdont': 16, 'Ġnot': 15, 'Ġain': 15, 'not': 14, 'Ġdoesnt': 14}\n",
      "Ġyourselves {'ĠFight': 15, 'Choose': 15, 'Ask': 15, 'Fight': 14, 'Research': 14, 'ify': 14}\n",
      "read {'Ġhumans': 15, 'humans': 15, 'ĠArabs': 15, 'Ġvoters': 14, 'Ġforests': 14, 'Ġmortals': 14}\n",
      "Ġforever {'Ġremains': 16, 'Ġstays': 15, 'Ġremain': 15, 'Ġshall': 15, 'Ġstaying': 14, 'Ġstay': 14}\n",
      "acc {'Ġballot': 16, 'ĠBeacon': 15, 'ĠSurve': 14, 'Ġglimps': 14, 'ĠBryce': 14, 'Ġcustomary': 14}\n",
      "ant {'Ġcarbohydrates': 15, 'ĠFamilies': 14, 'Ġvillagers': 14, 'Ġsocieties': 14, 'Ġfamilies': 14, 'ĠIsraelis': 14}\n",
      "SS {'ĠBrune': 16, 'ĠMorg': 15, 'ĠChoi': 14, 'Ġsq': 14, 'Girl': 14, 'ĠSaudi': 13}\n",
      "inf {'Ġfavorites': 15, 'ĠChampionships': 15, 'esters': 14, 'Studies': 14, 'Ġpregnancies': 14, 'ĠAnimals': 14}\n",
      "esc {'Ġboards': 16, 'Ġfriendships': 15, 'Ġbaskets': 14, 'Ġcurrents': 14, 'boards': 14, 'ĠBoards': 14}\n",
      "unt {'ĠMediterranean': 16, 'Ġgroundwater': 15, 'Ġrighteousness': 14, 'ĠBiblical': 14, 'Ġdangerously': 14, 'Ġunintended': 14}\n",
      "op {'LinkedIn': 16, 'ĠLinkedIn': 15, 'ĠChristensen': 14, 'Ġparliamentary': 14, 'ĠLeague': 13, 'ĠMalays': 13}\n",
      "Ġyourself {'ĠDebate': 15, 'sequence': 14, 'iry': 14, 'ĠFight': 14, 'ĠTie': 14, 'Ġchalleng': 14}\n",
      "ty {'ĠMalays': 16, 'ĠTayyip': 14, 'Ġfrail': 14, 'ĠToro': 14, 'ĠRyu': 14, 'ĠPhilippines': 13}\n",
      "category {'fall': 15, 'ĠFall': 14, 'Ġfall': 14, 'ĠMatch': 14, 'Fall': 14, 'Ġtape': 14}\n",
      "head {'Study': 15, 'study': 15, 'Ġblanket': 14, 'ĠStudy': 14, 'Ġstudy': 14, 'pin': 13}\n",
      "Ġfuture {'onna': 14, 'Ġaura': 14, 'Ġwill': 14, 'ĠWill': 14, 'will': 14, 'ĠWILL': 14}\n",
      "special {'ĠCounsel': 16, 'Ġcounsel': 15, 'Ġcamoufl': 13, 'aler': 13, 'ĠCandle': 13, 'ĠClapper': 13}\n",
      "isse {'Ġbasal': 15, 'Ġmaximal': 14, 'ĠIA': 14, 'ĠClassical': 14, 'ĠCardinals': 14, 'inia': 13}\n",
      "anc {'ampires': 14, 'Fil': 14, 'Cass': 14, 'ĠIMAGES': 14, 'Ġcass': 13, 'Ġcoales': 13}\n",
      "hard {'Ġdesserts': 14, 'Ġsund': 14, 'Ġcontrad': 14, 'Ġvulnerabilities': 14, 'ĠMonsters': 14, 'ĠButt': 13}\n",
      "_ {'Ġlatent': 15, 'Marie': 14, 'Ġtits': 14, 'Ġbride': 14, 'Ġinappropriate': 14, 'Ġfetal': 13}\n",
      "rec {'ĠCaucus': 14, 'femin': 14, 'ĠHor': 14, 'ĠTight': 13, 'Ġsensitive': 13, 'Ġlighter': 13}\n",
      "lic {'Ġgems': 14, 'Ġseekers': 14, 'ĠIsraelis': 14, 'seekers': 13, 'Ġrooms': 13, 'Ġvillages': 13}\n",
      "ess {'quin': 15, 'ĠLanc': 14, 'ĠLionel': 13, 'ĠBakr': 13, 'ĠBiden': 13, 'Ġbikini': 13}\n",
      "ad {'Ġreun': 14, 'Ġpermanent': 14, 'Ġlegitim': 14, 'Ġlegit': 13, 'Ġcohesive': 13, 'Ġorthodox': 13}\n",
      "ug {'ĠLore': 14, 'ĠConscious': 14, 'Ġsubconscious': 14, 'ĠKhe': 13, 'ĠKant': 13, 'ĠJean': 13}\n",
      "ri {'ĠFemin': 15, 'ĠAriel': 14, 'ĠCarroll': 13, 'ĠHarvard': 13, 'Ġfemin': 13, 'ĠJung': 13}\n",
      "onto {'GD': 16, 'ĠPE': 15, 'PE': 14, 'FH': 14, 'ĠGD': 13, 'ĠSPL': 13}\n",
      "rad {'ĠGuests': 14, 'Ġvulnerabilities': 14, 'Ġguests': 14, 'Ġvulnerable': 13, 'Ġgorgeous': 13, 'Ġshrouded': 13}\n",
      "late {'Ġdevelopments': 15, 'Ġdemonstrators': 14, 'Ġbudding': 13, 'Ġdemonstration': 13, 'Ġdemonstrations': 13, 'Ġlatent': 13}\n",
      "ung {'ĠMAR': 15, 'Ġemergence': 14, 'Ġavoidance': 14, 'MAR': 14, 'ĠKitty': 13, 'Ġcollector': 13}\n",
      "rest {'Ġhottest': 15, 'Ġviable': 14, 'ĠSCHOOL': 14, 'Ġsizable': 14, 'ĠMGM': 13, 'Ġstable': 13}\n",
      "unders {'ĠChrist': 15, 'Christ': 14, 'ĠFemin': 14, 'ĠGong': 13, 'Ġfraudulent': 13, 'ĠCapcom': 13}\n",
      "mel {'ĠPatt': 14, 'ĠScher': 14, 'ĠZurich': 14, 'ĠMartian': 14, 'ĠKoz': 13, 'pent': 13}\n",
      "agn {'Ġexcept': 14, 'except': 14, 'Ġevid': 14, 'ĠExcept': 14, 'Ġwrongly': 13, 'ĠPol': 13}\n",
      "ast {'Ġwidespread': 15, 'Ġrapists': 14, 'Ġprogressives': 14, 'Ġsexual': 13, 'ĠSexual': 13, 'ĠJapan': 13}\n",
      "med {'school': 14, 'Ġhierarch': 14, 'ilight': 13, 'Ġvest': 13, 'Ġnutrit': 13, 'Ġcavern': 13}\n",
      "que {'Ġbaseline': 14, 'ĠJud': 14, 'Ġvenerable': 13, 'Ġhateful': 13, 'Ġgorgeous': 13, 'Ġforemost': 13}\n",
      "standard {'Ġreferee': 14, 'Ġpsychologists': 14, 'ĠLeague': 13, 'aler': 13, 'ĠAbbey': 13, 'Ġbiologist': 13}\n",
      "able {'Ġmarine': 15, 'ĠMonteneg': 14, 'ĠMarine': 14, 'aer': 14, 'ĠAvatar': 13, 'Ġcampus': 13}\n",
      "package {'Ġrequest': 14, 'Ġnotify': 14, 'Ġprotest': 14, 'Ġcriticize': 13, 'warn': 13, 'Ġdiscourage': 13}\n",
      "ends {'Ġprotocol': 14, 'Ġformulations': 14, 'Ġformulation': 13, 'Ġcomposition': 13, 'ĠProtocol': 13, 'Ġcompanions': 13}\n",
      "ha {'arta': 14, 'Ġchiefly': 13, 'utable': 13, 'Ġpremiered': 13, 'Ġglared': 13, 'Ġmarked': 13}\n",
      "unc {'Ġcaucus': 14, 'Ġstash': 14, 'Ġstill': 14, 'Ġremaining': 13, 'Ġremain': 13, 'Ġhiber': 13}\n",
      "Ġspace {'Ġfarmers': 15, 'ĠBridges': 13, 'Ġpeasants': 13, 'Ġfarms': 13, 'acles': 13, 'Ġfarmer': 13}\n",
      "en {'Ġmodest': 15, 'Ġhealthier': 14, 'Ġdramatically': 13, 'Ġtight': 13, 'Ġdrastically': 13, 'Ġvaliant': 13}\n",
      "Ġits {'Ġdistinguishes': 14, 'ifies': 14, 'Ġassociates': 14, 'aunts': 13, 'ys': 13, 'Ġcontrasts': 13}\n",
      "ere {'ATT': 15, 'ATH': 14, 'ĠATT': 14, 'Ġcx': 13, 'Ġcords': 13, 'Att': 13}\n",
      "until {'Ġstayed': 14, 'Ġremained': 14, 'Ġkept': 13, 'Ġpersisted': 13, 'Ġpersistent': 13, 'Ġheld': 13}\n",
      "counter {'Dutch': 15, 'ĠDutch': 14, 'Ġnest': 13, 'Ġfats': 13, 'irds': 13, 'Ġcooks': 13}\n",
      "odd {'Ġprototypes': 15, 'Ġclassmates': 14, 'finals': 13, 'Ġprototype': 13, 'Ġgraffiti': 13, 'lass': 13}\n",
      "ani {'acqu': 15, 'Ġobtained': 14, 'Ġgained': 14, 'Ġacquired': 13, 'Ġacqu': 13, 'ĠGained': 13}\n",
      "its {'Ġsocieties': 14, 'ases': 13, 'Ġcaucuses': 13, 'Ġpoised': 13, 'Ġcampaigners': 13, 'Ġshares': 13}\n",
      "coming {'Ġconsultancy': 15, 'Ġspotlight': 14, 'Ġconsortium': 13, 'ĠAw': 13, 'ĠEye': 13, 'Ġcounsel': 13}\n",
      "ran {'apolog': 14, 'nex': 14, 'major': 13, 'Ġbipolar': 13, 'Ġsimilarly': 13, 'Ġfoolish': 13}\n",
      "ear {'READ': 14, 'ĠREAD': 14, 'ĠSCHOOL': 13, 'Ġetiquette': 13, 'ĠArab': 13, 'Ġproposal': 13}\n",
      "bon {'Ġclassrooms': 14, 'Ġrats': 14, 'Ġguests': 14, 'Ġclasses': 13, 'ĠGPUs': 13, 'Ġcontexts': 13}\n",
      "fe {'Prep': 14, 'Ġpopulations': 14, 'ĠPublic': 14, 'prep': 13, 'Ġpopulation': 13, 'Ġrecomm': 13}\n",
      "vet {'ĠPair': 14, 'ĠBald': 14, 'Ġpup': 13, 'Ġbrun': 13, 'Ġblond': 13, 'ĠJaune': 13}\n",
      "con {'Ġsinners': 14, 'Ġterrestrial': 14, 'Ġfisheries': 13, 'ĠMalays': 13, 'Ġracists': 13, 'Ġvictims': 13}\n",
      "rs {'Ġadip': 14, 'ĠRei': 14, 'school': 13, 'Ġcollege': 13, 'olesc': 13, 'Ġcollegiate': 13}\n",
      "ubb {'Ġobscene': 14, 'Ġgorgeous': 14, 'Ġgrotesque': 14, 'Ġdelighted': 13, 'Ġtremendously': 13, 'Ġentirely': 13}\n",
      "Ġunchanged {'Ġremains': 14, 'Ġremain': 14, 'Ġstaying': 14, 'Ġremaining': 13, 'keeping': 13, 'ĠKeeping': 13}\n",
      "rush {'Ġembr': 13, 'Ġhusbands': 13, 'usions': 13, 'Ġpregnant': 13, 'ĠAudrey': 13, 'ĠClaudia': 13}\n",
      "orig {'Ġfue': 14, 'ĠWAS': 14, 'ĠCAM': 13, 'ĠCBO': 13, 'was': 13, 'ĠDOD': 13}\n",
      "rah {'ĠMam': 14, 'Eh': 13, 'EH': 13, 'ĠMith': 13, 'habi': 13, 'eh': 13}\n",
      "fil {'Ġrepetitive': 14, 'Ġimmature': 13, 'Ġpup': 13, 'ĠPett': 13, 'Ġqueer': 13, 'ĠTrop': 13}\n",
      "du {'Ġopposes': 15, 'Ġoppose': 14, 'Ġrelates': 13, 'Ġreacts': 13, 'Ġcelebrates': 13, 'Ġbackgrounds': 13}\n",
      "ex {'Ġqueer': 15, 'Ġgrotesque': 14, 'hematic': 13, 'Ġegregious': 13, 'Ġdelicate': 13, 'ĠNicolas': 13}\n",
      "ir {'ework': 13, 'erey': 13, 'ĠDomin': 13, 'itimate': 13, 'BOX': 13, 'Ġori': 13}\n",
      "solid {'ĠWebs': 14, 'ĠChev': 13, 'Ġneuronal': 13, 'ĠNiger': 13, 'Ġfib': 13, 'ĠSiber': 13}\n",
      "ped {'Ġparental': 14, 'Ġcool': 13, 'ĠFidel': 13, 'ĠCool': 13, 'Cool': 13, 'Ġlumin': 13}\n",
      "ava {'ĠBoards': 14, 'Ġbaskets': 14, 'Ġstereotypes': 13, 'Ġseams': 13, 'Ġconspicuous': 13, 'Ġcoats': 13}\n",
      "ient {'ĠEuropean': 14, 'ĠEuropeans': 13, 'ĠEU': 13, 'Ġworldwide': 13, 'ĠWorldwide': 13, 'ĠEurope': 13}\n",
      "thy {'Ġlandfall': 16, 'ĠPerspect': 14, 'ĠFifth': 13, 'inth': 13, 'ĠPyth': 13, 'Ġhikers': 12}\n",
      "bro {'ĠSUPER': 14, 'pal': 13, 'ĠLunar': 13, 'sun': 13, 'ĠMartian': 13, 'uper': 13}\n",
      "ent {'Ġembarrassment': 13, 'ategor': 13, 'Ġsociology': 13, 'Ġtemper': 13, 'Ġluggage': 13, 'Ġbaggage': 13}\n",
      "disc {'Ġreferences': 15, 'ĠReferences': 14, 'Ġdivorce': 14, 'Ġheart': 13, 'Ġcurls': 13, 'Ġspouse': 13}\n",
      "lav {'Ġboards': 14, 'Ġfats': 13, 'ĠBoards': 13, 'Ġvictims': 13, 'boards': 13, 'Ġcorpses': 13}\n",
      "im {'akers': 14, 'Ġbystanders': 13, 'Ġelders': 13, 'raphics': 13, 'ampires': 13, 'Ġenvironmentalists': 13}\n",
      "tom {'ĠBrune': 14, 'LGBT': 14, 'Ġdownturn': 13, 'Ġbow': 13, 'Ġshines': 13, 'atts': 13}\n",
      "aus {'Ġbets': 14, 'ĠBeaut': 14, 'Ġshoes': 13, 'Ġdaylight': 13, 'Ġlewd': 13, 'Ġobscene': 13}\n",
      "rog {'ĠModels': 13, 'Ġvariant': 13, 'ĠPhysicians': 13, 'ĠCertification': 13, 'Ġantibodies': 13, 'ĠPartner': 13}\n",
      "f {'Ġspac': 14, 'ĠTumblr': 14, 'Ġfortun': 13, 'ĠEsper': 13, 'Ġbikini': 13, 'Ġsecurely': 13}\n",
      "ch {'Ġcharter': 13, 'Ġamplify': 13, 'asper': 13, 'Ġlegality': 13, 'Ġbrav': 13, 'Ġlawful': 13}\n",
      "box {'school': 14, 'Ġuniversity': 13, 'Ġschool': 13, 'Ġmemorial': 13, 'Ġfolks': 13, 'ĠSCHOOL': 13}\n",
      "hus {'Ġfavorites': 14, 'redits': 14, 'ĠBL': 13, 'ĠGuests': 13, 'ĠGames': 13, 'ĠGuest': 13}\n",
      "ake {'att': 15, 'ATT': 14, 'Ġtemper': 13, 'vel': 13, 'Ġtighter': 13, 'ĠATT': 13}\n",
      "af {'Ġbreasts': 15, 'Ġboobs': 14, 'Ġcolleges': 13, 'Ġspheres': 13, 'Ġareas': 12, 'Ġpanties': 12}\n",
      "aca {'Ġembr': 15, 'Ġace': 14, 'Ġdeck': 13, 'Ġrecl': 13, 'Ġprimaries': 13, 'eas': 13}\n",
      "ogn {'Ġ361': 13, 'Ġ359': 13, 'Ġ255': 13, 'Ġ335': 13, '905': 13, 'Ġ655': 13}\n",
      "on {'ĠFair': 15, 'Fair': 13, 'ĠRel': 13, 'fair': 13, 'Ġfair': 13, 'REL': 13}\n",
      "ong {'eca': 14, 'ĠWells': 13, 'ĠAvatar': 13, 'Ġtreasurer': 13, 'ĠTreasurer': 13, 'ĠEsper': 13}\n",
      "ever {'ĠNBA': 13, 'ĠGotham': 13, 'Sac': 13, 'ĠLinkedIn': 13, 'ĠNaruto': 13, 'ĠPaper': 13}\n",
      "ren {'ĠAmber': 14, 'mber': 14, 'Ġhappier': 13, 'Ġdominant': 13, 'BER': 13, 'auc': 13}\n",
      "oe {'Ġcultures': 14, 'ĠBridges': 13, 'Ġsettlements': 13, 'ĠBott': 13, 'Ġsmallest': 13, 'Ġhouseholds': 13}\n",
      "Ġbasis {'Ġforms': 14, 'Ġform': 14, 'ĠForms': 13, 'ĠForm': 13, 'Ġforming': 13, 'Form': 13}\n",
      "gl {'Ġguy': 15, 'ĠGuy': 14, 'guy': 14, 'Ġboy': 13, 'Guy': 13, 'Ġawkward': 12}\n",
      "ane {'Ġemerging': 14, 'Ġexecutions': 13, 'Ġhonorable': 13, 'oggle': 13, 'Ġplantations': 13, 'Ġemergence': 13}\n",
      "arch {'Ġservings': 13, 'Ġpanties': 13, 'Ġportions': 13, 'Ġoptimizations': 13, 'Ġlungs': 13, 'Ġaspects': 13}\n",
      "aku {'ĠSurve': 13, 'ĠTDs': 13, 'doms': 13, 'Ġmoms': 13, 'ĠFathers': 13, 'ĠReps': 13}\n",
      "sh {'Ġlucrative': 14, 'Ġmessy': 13, 'Ġsleek': 13, 'ĠMisty': 13, 'Ġcumbersome': 13, 'Ġattractive': 13}\n",
      "ect {'Ġsinners': 14, 'Ġwhispers': 13, 'Ġbreasts': 13, 'Ġmoms': 13, 'obos': 13, 'ĠSHAR': 13}\n",
      "po {'ALD': 14, 'ĠLeague': 14, 'Ġclassical': 13, 'ĠLaws': 13, 'Ġapartheid': 13, 'ĠSatoshi': 13}\n",
      "static {'ĠKuwait': 13, 'Ġcaravan': 13, 'ĠMazda': 13, 'ĠToyota': 13, 'ĠJews': 13, 'ĠGrave': 13}\n",
      "reg {'Ġauthors': 14, 'ĠEsper': 13, 'Ġfolk': 13, 'Ġproper': 13, 'Ġliterature': 13, 'ĠPublications': 13}\n",
      "oid {'ĠHM': 14, 'ĠEC': 14, 'Ġsquash': 13, 'ĠCJ': 13, 'Ob': 13, 'ĠBP': 13}\n",
      "end {'Ġprim': 14, 'Ġremaining': 13, 'Ġlingering': 13, 'ĠFIL': 13, 'Ġadequate': 13, 'Fil': 13}\n",
      "heading {'ĠTree': 14, 'Coun': 14, 'ĠCoun': 13, 'ĠIgn': 13, 'Tree': 13, 'GRE': 13}\n",
      "ings {'ĠKah': 13, 'ĠHaram': 13, 'Ġneighbourhood': 13, 'ĠKle': 13, 'Ġgobl': 13, 'Ġoverweight': 13}\n",
      "me {'ĠChel': 14, 'ĠKath': 13, 'ĠClifford': 13, 'Ġelegant': 13, 'ĠSoph': 13, 'ĠLeague': 13}\n",
      "race {'Ġprud': 15, 'ĠCoalition': 13, 'nex': 13, 'Ġcircum': 13, 'Ġbackyard': 13, 'secut': 13}\n",
      "une {'lycer': 14, 'ĠWaiting': 13, 'Ġresiding': 13, 'Ġbilling': 13, 'Ġwaiting': 13, 'Ġlingering': 13}\n",
      "ion {'ĠJuliet': 15, 'ĠMarian': 13, 'ĠNikki': 13, 'ĠClaire': 13, 'ĠCaroline': 12, 'ĠElena': 12}\n",
      "desc {'eal': 13, 'Ġdisgust': 13, 'ffect': 13, 'assault': 13, 'reet': 13, 'ĠImpact': 13}\n",
      "age {'Ġhabitual': 14, 'Ġaccustomed': 13, 'ĠLeague': 13, 'Ġcampus': 13, 'ĠIG': 13, 'ĠMosque': 13}\n",
      "empt {'ĠLabour': 14, 'ĠLabor': 14, 'ĠInitiative': 13, 'Labor': 13, 'Ġinitiative': 13, 'Labour': 12}\n",
      "agg {'Ġlenses': 14, 'Ġsupplements': 13, 'Ġstereotypes': 13, 'stakes': 13, 'Ġsupplement': 13, 'Ġlens': 13}\n",
      "hyper {'Ġresemb': 14, 'Ġnorm': 14, 'norm': 13, 'Ġresemblance': 13, 'ĠRevel': 13, 'Ġrevel': 12}\n",
      "bl {'Ġfitt': 14, 'Ġcorporate': 13, 'Ġpencil': 13, 'Ġskelet': 13, 'Ġbombshell': 13, 'schild': 13}\n",
      "block {'table': 14, 'Ġadolescent': 13, 'beer': 13, 'school': 13, 'mass': 13, 'ser': 13}\n",
      "sect {'Ġpassports': 14, 'papers': 13, 'Ġdoubts': 13, 'Ġpanties': 13, 'Ġshoppers': 13, 'Ġshroud': 12}\n",
      "Ġsomeday {'Ġwill': 14, 'will': 13, 'Ġshall': 13, 'shall': 13, 'ĠWILL': 13, 'ĠShall': 13}\n",
      "flo {'Ġuniversity': 14, 'estial': 13, 'Ġunderworld': 13, 'Ġterrestrial': 13, 'Ġhairst': 13, 'ĠKuwait': 13}\n",
      "ener {'Ġprevalent': 15, 'Ġdirectly': 13, 'Ġadhere': 13, 'Ġadherent': 13, 'Ġambassador': 13, 'Ġmonetary': 13}\n",
      "hem {'ĠRevelations': 14, 'ĠCarly': 13, 'ĠCapitalism': 13, 'ĠSeasons': 13, 'ĠPsyNet': 13, 'bu': 13}\n",
      "ness {'Ġfolk': 14, 'ĠEuropeans': 13, 'Ġladies': 13, 'Ġfolks': 13, 'Ġcubic': 13, 'Ġfemales': 13}\n",
      "ory {'ĠNewly': 14, 'Ġnewly': 13, 'ĠNEW': 13, 'Ġnew': 13, 'bish': 13, 'Ġwealthy': 13}\n",
      "beh {'Ġgrizz': 13, 'Ġgraveyard': 13, 'Ġmar': 13, 'Ġfuner': 13, 'ĠPax': 13, 'Jessica': 13}\n",
      "open {'REL': 15, 'ĠREL': 15, 'ĠLag': 13, 'ĠMPEG': 12, 'rel': 12, 'ĠSTAND': 12}\n",
      "body {'Ġempath': 15, 'ĠTumblr': 13, 'ĠMcKenzie': 13, 'GD': 12, 'Ġjungle': 12, 'ĠGD': 12}\n",
      "ann {'Ġballots': 13, 'ĠCatholics': 13, 'Cath': 13, 'uits': 13, 'ĠApost': 13, 'ĠDEC': 13}\n",
      "upt {'ĠAP': 14, 'ĠManafort': 13, 'Font': 13, 'Ġattendants': 13, 'ĠFont': 13, 'CA': 13}\n",
      "red {'Ġholiday': 14, 'ĠHoliday': 14, 'ĠLal': 13, 'Ġplayoff': 13, 'ĠGrail': 12, 'LGBT': 12}\n",
      "rat {'ĠFemales': 14, 'ĠLegs': 13, 'ĠMothers': 13, 'ĠAdults': 13, 'Ġbreasts': 13, 'Ġhouseholds': 12}\n",
      "hel {'ĠThankfully': 13, 'Ġsizable': 13, 'ATT': 13, 'ĠGOP': 13, 'Thankfully': 13, 'Ġthankfully': 12}\n",
      "ordinary {'luster': 14, 'ĠCollabor': 13, 'ĠEnemies': 13, 'ĠConsortium': 13, 'Ġpatrons': 13, 'ĠStudents': 12}\n",
      "anger {'Ġleagues': 13, 'Ġswords': 13, 'Ġschools': 13, 'ĠKats': 13, 'ĠCavaliers': 13, 'ĠMovies': 13}\n",
      "th {'Ġterrestrial': 14, 'Ġcess': 13, 'Ġarter': 13, 'ĠJPEG': 13, 'Ġcollege': 13, 'Ġreefs': 12}\n",
      "ab {'birth': 14, 'Ġbirth': 13, 'marriage': 13, 'Ġsexual': 13, 'Ġnewborn': 13, 'Birth': 13}\n",
      "oma {'ĠRomney': 14, 'ĠSchumer': 13, 'ĠWebb': 13, 'Scott': 13, 'ĠLucifer': 13, 'Romney': 13}\n",
      "ongo {'Ġcontinu': 15, 'Ġspa': 13, 'ĠGarland': 13, 'Meet': 13, 'ĠMeet': 13, 'ĠCLA': 12}\n",
      "@ {'Ġvaliant': 14, 'ĠJean': 13, 'Jean': 13, 'Ġreminis': 13, 'Ġeyel': 13, 'Ġgrateful': 12}\n",
      "sal {'ĠLeap': 14, 'Ġballots': 13, 'Ġboards': 13, 'brace': 13, 'ĠTube': 13, 'Ġtread': 13}\n",
      "au {'Ġfairly': 15, 'Ġmomentarily': 14, 'Ġfam': 13, 'Ġexponentially': 12, 'Ġcomparatively': 12, 'Ġcardiovascular': 12}\n",
      "rig {'Ġcompliance': 14, 'ĠCompliance': 14, 'Applic': 14, 'ĠPerspect': 12, 'Ġeffectively': 12, 'ĠSett': 12}\n",
      "title {'Ġduck': 13, 'Ġducks': 13, 'ĠDuck': 13, 'Ġrebirth': 13, 'Ġislands': 13, 'Ġtrash': 13}\n",
      "ux {'Ġdiscreet': 13, 'Ġcolleg': 13, 'Ġearly': 13, 'Ġobligations': 13, 'Ġlazy': 13, 'Ġcourageous': 13}\n",
      "mode {'Ġfifth': 14, 'Ġfourth': 14, 'Ġthird': 13, 'Ġsixth': 13, 'Ġseventh': 13, 'fifth': 13}\n",
      "opt {'ĠFIL': 15, 'Ġkil': 13, 'fil': 13, 'Ġwives': 13, 'ĠITV': 13, 'ureen': 12}\n",
      "quant {'ĠKurds': 14, 'ĠAlive': 14, 'ĠSurv': 13, 'ĠThick': 13, 'ĠNay': 12, 'ĠSurvivors': 12}\n",
      "wind {'ĠFat': 13, 'Uncommon': 13, 'DATA': 13, 'Fat': 13, 'Data': 13, 'ĠData': 12}\n",
      "ose {'Ġcelebrating': 13, 'Ġrecomb': 13, 'Ġpos': 13, 'Ġstatewide': 13, 'ĠJindal': 13, 'Ġpapers': 13}\n",
      "om {'ĠLaksh': 15, 'ĠGob': 13, 'ĠSeth': 12, 'Clar': 12, 'ĠLarry': 12, 'ĠAbe': 12}\n",
      "Counter {'Ġdesigners': 13, 'Dutch': 13, 'Ġpreschool': 13, 'Ġfrench': 13, 'Ġfirms': 12, 'Ġscholars': 12}\n",
      "qu {'mber': 14, 'Ġsnug': 14, 'Ġhappier': 13, 'ĠAmber': 13, 'Ġrelax': 13, 'ĠDARK': 12}\n",
      "future {'Ġmortar': 13, 'iger': 13, 'ĠTTL': 13, 'enda': 13, 'Ġrepository': 13, 'endas': 13}\n",
      "> {'Ġsilk': 14, 'ĠKarin': 13, '********************************': 13, 'Ġsir': 13, 'Ġfirm': 13, 'ĠFirm': 12}\n",
      "ĠQu {'Ġeasy': 14, 'easy': 14, 'Ġeasier': 14, 'Ġappe': 13, 'Ġquicker': 13, 'Ġconvenient': 12}\n",
      "ree {'Ġvehement': 14, 'Ġchast': 13, 'Ġunclear': 13, 'Ġmessy': 13, 'Ġobst': 13, 'Ġobscene': 12}\n",
      "ise {'Ġgeography': 13, 'ĠTPP': 13, 'Ġgeographically': 13, 'Ġvirtually': 13, 'Native': 13, 'Ġrestrictions': 12}\n",
      "[ {'Ġdow': 15, 'Ġemulate': 13, 'support': 13, 'Ġsadd': 13, 'Ġcourageous': 13, 'ĠJump': 12}\n",
      "run {'ĠINTER': 13, 'ĠPrim': 13, 'ĠKab': 13, 'ibel': 13, 'prim': 13, 'Ġfolks': 13}\n",
      "nic {'Clark': 14, 'Ġfing': 13, 'ASHINGTON': 13, 'ĠClark': 13, 'Day': 12, 'ĠFinger': 12}\n",
      "iat {'Ġshelf': 13, 'UNCH': 13, 'utra': 13, 'Ġfoll': 13, 'Gamer': 13, 'Ġbreeze': 13}\n",
      "rose {'Ġfal': 14, 'fal': 14, 'ethical': 13, 'Fal': 13, 'ĠEconomic': 12, 'ĠAgricultural': 12}\n",
      "lin {'Ġprim': 14, 'Ġlumin': 13, 'Ġmaternal': 13, 'Ġpremiere': 13, 'Ġvaliant': 13, 'Ġvulnerabilities': 13}\n",
      "template {'Ġpreseason': 14, 'ĠFest': 13, 'Fest': 13, 'ĠConcert': 13, 'ĠBrawl': 13, 'ĠLang': 12}\n",
      "âĢĭ {'Ġfe': 14, 'ĠRd': 13, 'ĠFi': 13, 'ĠMcKin': 12, 'Ġpm': 12, 'Ġdont': 12}\n",
      "unch {'GGGGGGGG': 13, 'ĠIraq': 13, 'Ġunusually': 13, 'ĠIraqis': 13, 'Ġhuman': 13, 'ĠIraqi': 12}\n",
      "ym {'ĠHorowitz': 14, 'Ġgrowing': 13, 'Ġingested': 12, 'Ġgrassroots': 12, 'Ġdeceased': 12, 'Ġcreator': 12}\n",
      "` {'ĠSCHOOL': 14, 'ĠLOVE': 13, 'Ġschool': 13, 'ĠHELL': 12, 'ATE': 12, 'ĠPARK': 12}\n",
      "ium {'ĠSATA': 13, 'ubb': 13, 'ĠTrilogy': 13, 'ĠJal': 13, 'ĠRub': 13, 'auc': 13}\n",
      "ao {'Ġsal': 13, 'Ġgp': 13, 'Ġcl': 13, 'Ġvast': 13, 'Ġrall': 12, 'Ġcapit': 12}\n",
      "chal {'ĠEsper': 13, 'owitz': 13, 'peak': 13, 'icip': 13, 'currently': 13, 'anamo': 12}\n",
      "rip {'ĠMB': 14, 'PL': 14, 'ĠKap': 13, 'ĠAP': 12, 'ĠKl': 12, 'ĠPrague': 12}\n",
      "st {'ĠKepler': 14, 'Fil': 13, 'ĠFIL': 13, 'Ġvert': 13, 'Ġfil': 12, 'Ġbreasts': 12}\n",
      "ij {'Ġ780': 14, 'Ġten': 13, 'Ġostensibly': 13, 'ikk': 13, 'Ġearly': 12, 'Ġinitially': 12}\n",
      "nice {'urnal': 14, 'ĠCNS': 13, 'ĠIter': 13, 'ĠGuests': 12, 'Ġincidents': 12, 'Ġpots': 12}\n",
      "Ġreliably {'Ġcan': 14, 'can': 14, 'ĠCan': 13, 'Ġcannot': 12, 'Can': 12, 'Ġenables': 12}\n",
      "v {'Ġimpractical': 14, 'ĠLuxembourg': 13, 'ĠJasper': 13, 'JP': 13, 'Ġcamouflage': 12, 'Ġawkward': 12}\n",
      "less {'Ġcass': 14, 'ĠHubble': 13, 'Ġbullpen': 13, 'ĠFollow': 13, 'ĠEpstein': 12, 'Ġvocal': 12}\n",
      "alt {'Ġtrove': 15, 'Narr': 13, 'Ġbikini': 12, 'escap': 12, 'Ġlaure': 12, 'Ġsilk': 12}\n",
      "oz {'Ġdemocracies': 13, 'Ġapartheid': 13, 'Ġprimaries': 13, 'Ġcryptocurrencies': 13, 'Ġgenitals': 12, 'Ġsubreddits': 12}\n",
      "ref {'ĠLuxembourg': 13, 'ĠPop': 13, 'ĠTermin': 13, 'ieu': 12, 'Ġpermanent': 12, 'ĠQuit': 12}\n",
      "Request {'Blood': 14, 'ĠBlood': 14, 'Ġblood': 13, 'Pref': 13, 'ĠZy': 13, 'Adam': 12}\n",
      "ros {'ĠAgriculture': 14, 'Ġagriculture': 13, 'ĠAgricultural': 13, 'Ġagricultural': 13, 'Ġacademia': 13, 'Ġinnocuous': 12}\n",
      "CC {'ĠPartnership': 14, 'ĠLarry': 13, 'ĠJungle': 13, 'Tags': 13, 'ĠAbdullah': 12, 'ĠConfederation': 12}\n",
      "Ġonto {'Ġslipping': 14, 'Ġfalling': 13, 'Ġsliding': 13, 'Ġsurging': 13, 'Ġspitting': 12, 'Ġfallen': 12}\n",
      "space {'Ġcongreg': 13, 'Ġdudes': 13, 'Ġpeoples': 13, 'ĠChristians': 12, 'ĠFlores': 12, 'Ġglasses': 12}\n",
      "ok {'ĠTayyip': 13, 'ĠUX': 13, 'Bal': 13, 'ĠIX': 13, 'Ġauditory': 12, 'Ġdenim': 12}\n",
      "ts {'Ġadolescence': 13, 'Ġyearly': 13, 'ĠGalactic': 13, 'olesc': 13, 'ĠYEAR': 12, 'Ġteenage': 12}\n",
      "summary {'Ġministers': 13, 'ĠCrown': 13, 'ĠFinals': 13, 'Ġprimates': 13, 'ĠMinisters': 13, 'ĠJets': 12}\n",
      "ich {'Ġoriginally': 14, 'Ġinterestingly': 13, 'Ġluckily': 13, 'Ġearlier': 13, 'Interestingly': 12, 'fortunately': 12}\n",
      "stat {'ĠANG': 14, 'Ġvel': 13, 'ĠVel': 13, 'Tang': 12, 'ĠTang': 12, 'ĠBecker': 12}\n",
      "Ġcontrast {'Ġcoats': 13, 'Ġpositions': 13, 'itions': 13, 'Ġjobs': 12, 'Ġgraphics': 12, 'Ġcommissions': 12}\n",
      "Ġmyself {'icent': 13, 'assembly': 13, 'Ġstiff': 13, 'sequence': 13, 'Assembly': 12, 'Ġlieu': 12}\n",
      ":: {'Ġbishop': 14, 'orget': 14, 'Ġcrotch': 13, 'ĠHelmet': 13, 'Ġdiligent': 13, 'iegel': 12}\n",
      "cre {'Ġfeminists': 14, 'ĠPascal': 13, 'asper': 13, 'ĠHarper': 13, 'ĠHalifax': 13, 'ESA': 12}\n",
      "Ġparallel {'Ġorganizing': 14, 'Ġorganising': 13, 'running': 13, 'Ġorganize': 12, 'Ġdefining': 12, 'Ġrunning': 12}\n",
      "ore {'ĠLoll': 13, 'Ġwont': 13, 'ĠSuz': 13, 'Ġbron': 13, 'Ġgoat': 12, 'Bob': 12}\n",
      "by {'Ġhelpful': 13, 'Ġcooled': 13, 'Ġcool': 13, 'ĠBL': 13, 'ĠOD': 13, 'Ġfacilitated': 12}\n",
      "iss {'ĠMandarin': 13, 'ĠBul': 13, 'Ġmul': 13, 'Ġlegendary': 13, 'Heart': 13, 'Ġori': 12}\n",
      "arr {'ĠHOR': 13, 'Ġvaliant': 13, 'Ġrep': 13, 'Ġjealous': 13, 'Ġcoinc': 13, 'Ġaffirmative': 12}\n",
      "tab {'Ġfestival': 13, 'Ġtrial': 13, 'Ġseason': 13, 'Ġillustrates': 13, 'Ġdaytime': 12, 'Ġilluminate': 12}\n",
      "volume {'ĠEsper': 14, 'irth': 13, 'ĠPatriots': 13, 'ĠCups': 13, 'ĠUniversities': 12, 'ĠSchools': 12}\n",
      "init {'Ġoutspoken': 13, 'Ġcourageous': 13, 'Ġnewborn': 13, 'Ġresilient': 13, 'Ġnascent': 12, 'prim': 12}\n",
      "real {'Ġpubs': 13, 'ĠUniversities': 13, 'Ġbaths': 13, 'ĠRavens': 13, 'ĠCommunities': 13, 'ĠAreas': 12}\n",
      "her {'ĠLegs': 14, 'Ġlegit': 13, 'Ready': 13, 'Ġadequate': 12, 'ĠReady': 12, 'Ġcomple': 12}\n",
      "load {'Ġforest': 14, 'ĠLuxembourg': 13, 'ĠHyd': 13, 'anthrop': 13, 'Ġanthrop': 12, 'ĠCaucasus': 12}\n",
      "RA {'Ġelite': 14, 'Ġelites': 13, 'Ġmale': 13, 'Ġdudes': 13, 'Ġmales': 13, 'Ġja': 12}\n",
      "cens {'ĠAvoid': 14, 'Avoid': 14, 'avoid': 13, 'Ġavoid': 12, 'ĠDisk': 12, 'Ġabuser': 12}\n",
      "ini {'Initialized': 13, 'ĠLoaded': 13, 'ĠClinical': 13, 'ĠMarried': 13, 'Ġoriginally': 13, 'aved': 12}\n",
      "card {'ĠPixel': 13, 'Mouse': 13, 'ixel': 13, 'ĠMouse': 12, 'Ġmouse': 12, 'Pixel': 12}\n",
      "cop {'Ġhometown': 13, 'Ġaquatic': 13, 'Ġworldview': 13, 'Ġrenal': 13, 'Ġautism': 12, 'Ġrural': 12}\n",
      "options {'ĠMadrid': 13, 'ĠThree': 13, 'Ġ]': 13, 'Ġegregious': 12, 'ĠFour': 12, 'ĠSCHOOL': 12}\n",
      "caps {'Ġnexus': 14, 'Ġnetworks': 13, 'Ġnetwork': 13, 'ĠShadows': 12, 'Ġdusk': 12, 'Ġbranch': 12}\n",
      "upp {'swick': 13, 'ĠMozilla': 13, 'hurst': 13, 'ĠLann': 13, 'Ġalgebra': 13, 'ĠGOLD': 13}\n",
      "uz {'ĠGuantanamo': 14, 'adh': 13, 'because': 12, 'Ġbecause': 12, 'Ġdecom': 12, 'ĠGuant': 12}\n",
      "ĠActive {'Ġsoft': 13, 'Ġjail': 13, 'Ġprison': 13, 'Ġimprison': 13, 'Ġstone': 12, 'Ġsecrecy': 12}\n",
      "se {'Ġevening': 13, 'iffin': 13, 'asper': 13, 'Ġpregnancies': 12, 'ĠHarper': 12, 'Ġbathing': 12}\n",
      "gu {'ĠGamer': 13, 'Ġcollegiate': 13, 'ĠLeague': 13, 'Ġdub': 12, 'Ġlact': 12, 'Ġfav': 12}\n",
      "erest {'Veter': 14, 'ODUCT': 13, 'ĠWorldwide': 13, 'Compat': 12, 'Money': 12, 'restrial': 12}\n",
      "ray {'Ġcolorful': 14, 'Ġglamorous': 13, 'Ġamusing': 13, 'Ġhilarious': 13, 'Ġjealous': 12, 'Ġhumorous': 12}\n",
      "sur {'Ġembassies': 14, 'Ġcouples': 13, 'icts': 13, 'Ġlovers': 13, 'Ġschools': 12, 'Ġcourts': 12}\n",
      "rant {'Ġcampuses': 13, 'essors': 13, 'ĠCampus': 13, 'ĠWAR': 13, 'Ġcampus': 12, 'ossal': 12}\n",
      "ito {'ĠAad': 14, 'Ġlodging': 13, 'Ġstartup': 13, 'Ġsatur': 13, 'Ġepoch': 12, 'Ġoriginating': 12}\n",
      "ac {'ĠBoards': 14, 'Ġcameras': 13, 'Ġboards': 13, 'ĠConfeder': 12, 'Ġformal': 12, 'Ġballots': 12}\n",
      "use {'ĠMalays': 14, 'Ġcub': 13, 'Ġcush': 13, 'Ġcel': 12, 'Ġprim': 12, 'Ġlenses': 12}\n",
      "dist {'Ġbins': 14, 'Ġarrays': 13, 'Ġbans': 12, 'Ġpots': 12, 'Ġmarkets': 12, 'Ġmalls': 12}\n",
      "ss {'ĠMane': 13, 'ĠKardashian': 13, 'Ġbikini': 13, 'ĠLinkedIn': 13, 'Ġmaiden': 13, 'Ġbacklog': 12}\n",
      "uns {'ĠREL': 14, 'ĠB': 13, 'tr': 13, 'Ġprev': 13, 'ĠT': 13, 'ĠConfeder': 12}\n",
      "com {'Ġreferen': 13, 'opal': 13, 'Ġbourgeois': 13, 'ĠCaucasus': 13, 'Ġmisses': 13, 'ĠOP': 12}\n",
      "ut {'Ġlewd': 14, 'ĠBund': 13, 'ĠShroud': 12, 'Temp': 12, 'ĠHidden': 12, 'ĠNordic': 12}\n",
      "uid {'ĠKash': 14, 'ĠSaud': 13, 'ĠEB': 12, 'ĠCA': 12, 'ĠCalder': 12, 'ĠCups': 12}\n",
      "hy {'ĠNavajo': 13, 'Ġsexual': 13, 'ĠJewish': 13, 'except': 12, 'Ġexcept': 12, 'Ġinterestingly': 12}\n",
      "reads {'Ġprevents': 13, 'Ġavoids': 13, 'Ġteachers': 13, 'Ġclassics': 13, 'Ġparticipates': 12, 'Ġnationals': 12}\n",
      "ys {'unicip': 13, 'Ġcardinal': 13, 'Ġmunicip': 13, 'ĠConscious': 12, 'Ġfeminine': 12, 'odiac': 12}\n",
      "lock {'ĠHots': 13, 'ĠHOT': 13, 'Ġhots': 13, 'current': 13, 'alth': 13, 'Ġmalf': 13}\n",
      "Ġreal {'Ġcoastline': 13, 'Ġhotels': 13, 'Ġchains': 13, 'Ġbeaches': 12, 'Ġbeds': 12, 'abases': 12}\n",
      "fl {'yahoo': 13, 'Wallet': 13, 'Ġcampus': 12, 'umblr': 12, 'hillary': 12, 'Ġwives': 12}\n",
      "filter {'ĠCluster': 14, 'ĠLesbian': 13, 'ĠConfeder': 13, 'ĠRican': 13, 'ĠGlobe': 12, 'ĠJung': 12}\n",
      "ef {'Ġtrillions': 15, 'Ġbillions': 14, 'Ġtrillion': 13, 'Ġfundamentals': 12, 'Ġbirths': 12, 'illions': 12}\n",
      "asm {'Parents': 13, 'Ġparents': 13, 'parents': 13, 'Ġmoms': 12, 'ĠParents': 12, 'Ġmom': 12}\n",
      "rap {'Ġgorgeous': 14, 'Ġconspicuous': 13, 'Ġcardinal': 13, 'arthy': 12, 'ĠFair': 12, 'ĠCardinal': 12}\n",
      "ens {'ĠVaj': 14, 'ĠFemin': 13, 'ĠLegion': 12, 'ĠInher': 12, 'Ġwealthier': 12, 'Ġgeographically': 12}\n",
      "bre {'ĠGrac': 14, 'Ġtim': 13, 'ĠPixel': 13, 'Rat': 13, 'Pixel': 12, 'pal': 12}\n",
      "oust {'Ġdamage': 13, 'Ġprejudice': 13, 'ĠDamage': 13, 'Ġprejudices': 12, 'Ġsupplements': 12, 'Ġheadphones': 12}\n",
      "Ġcategory {'ĠFit': 13, 'Ġfits': 13, 'fitting': 13, 'Ġfit': 13, 'fits': 13, 'Ġfall': 12}\n",
      "one {'ĠLeague': 14, 'League': 14, 'ĠMalays': 12, 'ĠCameroon': 12, 'ĠLakes': 12, 'Ġleague': 12}\n",
      "wal {'Ġfifty': 14, 'Ġ75': 13, 'Ġsixty': 13, 'Ġthirty': 12, 'Ġ50': 12, 'Ġninety': 12}\n",
      "Ġspe {'concept': 13, 'Ġinitiation': 13, 'translation': 13, 'Ġrecollection': 12, 'elect': 12, 'Ġdeline': 12}\n",
      "pre {'ĠRenaissance': 13, 'ĠShia': 13, 'DP': 13, 'ECD': 13, 'ĠANG': 13, 'ĠLeague': 12}\n",
      "cle {'Ġhorizontal': 14, 'Ġcompact': 13, 'Ġblack': 12, 'Ġlipstick': 12, 'ĠKurds': 12, 'Ġhairst': 12}\n",
      "ring {'Ġcelebr': 14, 'Ġsocial': 14, 'ĠSocial': 13, 'ĠSuz': 12, 'ĠCher': 12, 'Ġsilently': 12}\n",
      "cas {'Ġdarkest': 13, 'bags': 12, 'Ġbaths': 12, 'agos': 12, 'sters': 12, 'Ġsandbox': 12}\n",
      "ng {'ĠKrypt': 14, 'Ġfil': 14, 'ilater': 13, 'Ġimpat': 12, 'ĠColleg': 12, 'ĠNordic': 12}\n",
      "ali {'Ġconscious': 14, 'Ġmajority': 13, 'Ġenlarg': 12, 'benef': 12, 'Ġpredomin': 12, 'Ġparliament': 12}\n",
      "rum {'Ġnobility': 14, 'irth': 14, 'Ġbirthplace': 12, 'mint': 12, 'University': 12, 'ĠUniversity': 12}\n",
      "Ġdirection {'Ġcycling': 13, 'Ġbaking': 13, 'estyle': 13, 'utation': 12, 'Ġskating': 12, 'Ġdisplacement': 12}\n",
      "Ã¡ {'ĠLaksh': 13, 'ĠReincarn': 13, 'Ġpaired': 13, 'Ġparked': 12, 'ĠNavajo': 12, 'Ġlandfall': 12}\n",
      "und {'Ġmisogyny': 13, 'Ġpious': 13, 'Ġfisheries': 12, 'Ġfolks': 12, 'Ġpiety': 12, 'although': 12}\n",
      "storm {'Ġcouples': 15, 'Ġcouple': 13, 'Ġhubs': 12, 'Ġshortcuts': 12, 'Ġcycles': 12, 'Ġshorts': 12}\n",
      "ÂŃ {'Ġmosquit': 14, 'Ġmosquitoes': 13, 'Ġuniversities': 12, 'Ġscriptures': 12, 'Ġballot': 12, 'Ġbiodiversity': 12}\n",
      "ade {'Ġpatriotic': 13, 'Ġwidespread': 13, 'Ġinterconnected': 13, 'Ġlegalized': 13, 'Ġrecru': 12, 'Ġindispensable': 12}\n",
      "ala {'Ġmysql': 13, 'ĠNg': 12, 'DAQ': 12, 'ARE': 12, 'ĠArea': 12, 'ĠPartners': 12}\n",
      "ser {'Ġviable': 13, 'Ġposs': 13, 'ĠSTUD': 13, 'Ġfeas': 13, 'Ġguardian': 12, 'Ġfeasible': 12}\n",
      "uh {'Ġpatented': 13, 'Ġunderstandably': 13, 'qua': 13, 'Ġprivat': 13, 'Ġdemocratically': 12, 'sighted': 12}\n",
      "gap {'Ġaccordingly': 13, 'Ġhouseholds': 13, 'Ġheadquartered': 13, 'Ġmemor': 12, 'Ġkitchens': 12, 'Ġshortest': 12}\n",
      "rex {'ĠJag': 14, 'ĠJasper': 13, 'ĠPap': 13, 'bec': 13, 'ĠJal': 12, 'ĠBabe': 12}\n",
      "orth {'Ġaccepted': 13, 'Ġreasonably': 13, 'ĠEnvironment': 12, 'Ġimposed': 12, 'Ġenclosed': 12, 'Ġhandcuffed': 12}\n",
      "Ġrecommendation {'Ġdegree': 13, 'ĠDegree': 13, 'amn': 13, 'Ġnick': 12, 'Ġcapit': 12, 'come': 12}\n",
      "land {'Ġpertinent': 14, 'Ġcollegiate': 14, 'pants': 13, 'ĠComic': 12, 'Ġcheerful': 12, 'Ġgenius': 12}\n",
      "Ġsolid {'Ġcarbohyd': 13, 'Ġcalcium': 13, 'Ġneuronal': 13, 'Ġelectro': 13, 'Ġwilderness': 13, 'Ġsch': 12}\n",
      "dr {'Ġplugs': 14, 'Ġdams': 13, 'Ġanomalies': 13, 'Ġbikini': 13, 'Ġshelves': 12, 'Ġverge': 12}\n",
      "add {'ĠEB': 13, 'Ġcass': 13, 'Ġsubconscious': 13, 'Ġdesert': 12, 'Ġcoales': 12, 'Ġsadd': 12}\n",
      "na {'ĠSatoshi': 13, 'ĠMalays': 13, 'ĠNiger': 13, 'ĠCBC': 12, 'Ġnascent': 12, 'Ġcameras': 12}\n",
      "full {'ĠCorker': 13, 'ĠDigest': 13, 'ĠParticip': 13, 'ĠANN': 13, 'ĠFIGHT': 12, 'Ġrapport': 12}\n",
      "ahn {'Ġnoticeably': 16, 'Ġinitially': 13, 'Ġespecially': 13, 'Ġnoticeable': 12, 'Ġoriginally': 12, 'especially': 12}\n",
      "d {'Ġlatt': 14, 'Ġcorp': 12, 'Ġenclave': 12, 'Ġorbits': 12, 'Ġfriendships': 12, 'Ġlol': 12}\n",
      "tone {'ĠOttoman': 14, 'ĠABS': 13, 'ĠKyoto': 13, 'ĠKatz': 12, 'ĠHH': 12, 'ĠKurt': 12}\n",
      "isc {'Ġscant': 13, 'Ġloss': 13, 'Ġfrequent': 13, 'Ġloosely': 13, 'weak': 12, 'Ġwiser': 12}\n",
      "Ġthemselves {'aron': 13, 'oran': 13, 'van': 13, 'zan': 13, 'iden': 13, 'MAN': 12}\n",
      "hom {'ĠBag': 13, 'Ġbag': 13, 'bag': 12, 'Ġsche': 12, 'Ġschematic': 12, 'Ġmass': 12}\n",
      "oor {'Ġmasculine': 14, 'Ġmascul': 13, 'Ġripe': 12, 'Ġclassical': 12, 'Ġinex': 12, 'Ġilliter': 12}\n",
      "str {'acons': 14, 'ĠACPI': 12, 'Ġgays': 12, 'ĠLup': 12, 'ĠKatz': 12, 'Ġvel': 12}\n",
      "akh {'atern': 14, 'Ġanomaly': 13, 'Ġnewcomer': 12, 'Ġnewcomers': 12, 'college': 12, 'Ġcollege': 12}\n",
      "ul {'Ġheck': 14, 'Ġnoticeably': 13, 'ĠPNG': 12, 'sha': 12, 'ĠPig': 12, 'ĠCAM': 12}\n",
      "tr {'Ġneurot': 14, 'Ġdangerously': 13, 'Ġparanormal': 13, 'Ġpainfully': 12, 'Ġmosquit': 12, 'Ġdystop': 12}\n",
      "nu {'Ġmarriages': 13, 'Ġcampuses': 13, 'Ġjournals': 12, 'glers': 12, 'Ġpractitioners': 12, 'Ġprimates': 12}\n",
      "co {'jp': 13, 'ĠAnglic': 13, 'Ġeminent': 13, 'ĠMalays': 12, 'ĠGupta': 12, 'Ġlogical': 12}\n",
      "rac {'ĠBeir': 14, 'ĠMothers': 13, 'asper': 13, 'carb': 13, 'Ġmothers': 12, 'Ġcob': 12}\n",
      "ict {'ĠHik': 14, 'ĠCOP': 13, 'ITAL': 13, 'kish': 12, 'ĠJPM': 12, 'Ġseaw': 12}\n",
      "aut {'Ġtang': 14, 'Ġterritories': 13, 'Ġconfig': 12, 'Ġclout': 12, 'dx': 12, 'ĠLeague': 12}\n",
      "bind {'ĠBell': 13, 'Bell': 13, 'ĠAmber': 13, 'ĠBerg': 12, 'Ġegregious': 12, 'Ġpenis': 12}\n",
      "mis {'iversal': 13, 'é¾įå¥': 13, 'ĠJupiter': 13, 'ĠGrimm': 13, 'ĠHomo': 12, 'ĠXie': 12}\n",
      "Ġbeen {'Ġhasn': 14, 'Ġhaven': 13, 'Ġhas': 13, 'Ġhave': 12, 'ĠHas': 12, 'ĠHaven': 12}\n",
      "ns {'ordial': 13, 'hiba': 13, 'Ġpelvic': 12, 'Ġfabric': 12, 'asper': 12, 'Ġvictim': 12}\n",
      "ets {'ĠCarlos': 13, 'ĠNob': 13, 'ĠThames': 13, 'ilar': 12, 'ĠMeier': 12, 'ĠFounders': 12}\n",
      "Ġtransfer {'ĠYankee': 14, 'ĠCaribbean': 13, 'Ġpatriotic': 12, 'ĠPacific': 12, 'outhern': 12, 'download': 12}\n",
      "unit {'ĠFINAL': 13, 'Ġclock': 13, 'ĠMartian': 12, 'clock': 12, 'Ġcircadian': 12, 'uary': 12}\n",
      "sy {'Ġconvers': 13, 'Ġding': 13, 'wered': 13, 'Ġlou': 12, 'Ġemulate': 12, 'Ġfeminine': 12}\n",
      "ost {'Fif': 13, 'Ġrebounds': 13, 'Ġposes': 12, 'Ġhorrors': 12, 'Ġcrates': 12, 'Ġblows': 12}\n",
      "T {'Ġbreasts': 14, 'Ġbikini': 13, 'Ġlaure': 12, 'Ġbreast': 12, 'Ġboobs': 12, 'Ġtits': 12}\n",
      "tur {'Ġplanets': 13, 'Ġspouses': 13, 'Ġbatteries': 12, 'Ġtasks': 12, 'Ġchunks': 12, 'Ġslaves': 12}\n",
      "kill {'Ġhorizont': 13, 'Ġyr': 13, 'Ġar': 12, 'Ġmedieval': 12, 'Ġeste': 12, 'Ġmillennial': 12}\n",
      "host {'Ġconstantly': 13, 'ĠJensen': 13, 'Ġrepe': 13, 'ignment': 13, 'blance': 12, 'ĠConfederation': 12}\n",
      "col {'ĠRays': 13, 'ĠMalays': 13, 'ĠMass': 13, 'ĠEpic': 12, 'ĠButt': 12, 'ĠSEA': 12}\n",
      "aa {'Ġobsc': 13, 'ĠEB': 13, 'Ġobscene': 13, 'Ġdele': 12, 'Ġadam': 12, 'Ġvaliant': 12}\n",
      "ue {'Ġobscene': 15, 'Ġlewd': 13, 'Ġgrotesque': 13, 'Ġqueer': 12, 'Ġobvious': 12, 'ĠHopkins': 12}\n",
      "ae {'Ġgraveyard': 13, 'Ġgenitals': 13, 'Ġexpires': 13, 'Ġlaunchers': 12, 'ĠEB': 12, 'Ġbreasts': 12}\n",
      "under {'ĠFair': 13, 'Ġcompetent': 13, 'Ġfair': 13, 'ĠLeague': 12, 'Ġcommission': 12, 'Ġfaire': 12}\n",
      "hol {'Ġstakeholders': 14, 'Ġvehemently': 13, 'ĠMillions': 13, 'Ġprett': 12, 'Ġnotoriously': 12, 'smart': 12}\n",
      "hum {'ĠEthernet': 14, 'Ġausp': 13, 'ĠSATA': 13, 'antage': 12, 'ĠServer': 12, 'ĠTournament': 12}\n",
      "day {'Ġcle': 13, 'ĠLeigh': 13, 'Ġshrew': 12, 'ĠOlsen': 12, 'ĠHolden': 12, 'ĠMPEG': 12}\n",
      "fin {'Ġsuperheroes': 14, 'Ġpeoples': 13, 'Ġnationality': 12, 'ĠCitizens': 12, 'Ġjurors': 12, 'Ġplanets': 12}\n",
      "oen {'ĠEtsy': 13, 'Ë': 13, 'umblr': 12, 'Ġlenders': 12, 'Ġescapes': 12, 'Ġgossip': 12}\n",
      "aven {'Ġanomalies': 14, 'ĠUniversities': 13, 'Ġidentities': 13, 'Ġanomaly': 13, 'CONCLUS': 12, 'Ġuniversities': 12}\n",
      "amm {'Ġtwenties': 13, 'Ġemerging': 13, 'Ġemergence': 12, 'Ġincarnation': 12, 'Ġharvesting': 12, 'Ġallev': 12}\n",
      "ru {'school': 13, 'Ġschool': 13, 'ĠSCHOOL': 13, 'ãĥŃ': 13, 'ĠKob': 12, 'ĠHB': 12}\n",
      "hest {'ĠAad': 14, 'ĠKam': 13, 'ĠWed': 12, 'ĠKis': 12, 'ĠMad': 12, 'ĠCame': 12}\n",
      "ach {'Ġpanties': 13, 'Ġpractitioners': 13, 'ĠSeth': 13, 'Ġmothers': 12, 'Ġgirls': 12, 'Ġopioids': 12}\n",
      "ult {'ĠKurdistan': 13, 'ĠPutin': 13, 'ĠTibetan': 12, 'Putin': 12, 'ĠIranians': 12, 'ĠConfederate': 12}\n",
      "rice {'ĠCrescent': 13, 'ĠRash': 13, 'ĠOro': 12, 'ĠApart': 12, 'ĠHorizon': 12, 'ĠInvestors': 12}\n",
      "ans {'ĠLeague': 13, 'popular': 13, 'acqu': 13, 'ĠAbdullah': 12, 'Ġcompetent': 12, 'heartedly': 12}\n",
      "Fun {'Pol': 14, 'POL': 14, 'ĠPOL': 13, 'ĠPol': 12, 'IME': 12, 'pol': 12}\n",
      "urn {'ĠOTHER': 13, 'STER': 13, 'ĠDifferent': 12, 'Ġnewer': 12, 'Ġother': 12, 'ĠOther': 12}\n",
      "union {'Ġcelebr': 13, 'ĠAlive': 13, 'ĠMandatory': 12, 'Ġexistence': 12, 'Ġviable': 12, 'Ġhabitual': 12}\n",
      "disabled {'Ġleak': 14, 'ĠFloat': 14, 'ĠStudy': 13, 'ĠTrial': 12, 'ĠThunderbolt': 12, 'Ġtrial': 12}\n",
      "gate {'Ġgar': 15, 'rig': 12, 'gu': 12, 'ĠAxel': 12, 'Ġdude': 12, 'Ġshaft': 12}\n",
      "Ġexcess {'urry': 13, 'Ġtedious': 12, 'Ġoffender': 12, 'contract': 12, 'Ġautomobile': 12, 'Ġexped': 12}\n",
      "acqu {'Ġsupplements': 13, 'Ġreinforces': 13, 'aments': 13, 'Ġaugmented': 12, 'Ġbalances': 12, 'Ġoptimizations': 12}\n",
      "vern {'Ġclassmate': 13, 'ĠBlood': 13, 'Desktop': 12, 'Ġcap': 12, 'ĠCoc': 12, 'Ġcannibal': 12}\n",
      "cos {'Ġquaint': 15, 'Ġclueless': 13, 'Ġnaive': 12, 'amb': 12, 'ĠLLP': 12, 'Ġdens': 12}\n",
      "endo {'Ġemerging': 13, 'Ġawake': 13, 'Ġemulate': 12, 'Ġawaken': 12, 'Ġemergence': 12, 'Ġemerge': 12}\n",
      "ays {'Ġrubbish': 13, 'Ġuniformly': 13, 'Ġinvariably': 13, 'Ġrepertoire': 12, 'Ġinevitably': 12, 'Ġobsolete': 12}\n",
      "are {'Ġsizable': 13, 'Ġvehement': 13, 'Ġartificial': 13, 'Ġviable': 12, 'Ġlikely': 12, 'Ġfeasible': 12}\n",
      "bench {'Ġsmoker': 13, 'Ġstrugg': 13, 'Ġgarg': 12, 'Ġcourtyard': 12, 'Ġtoilet': 12, 'Ġbur': 12}\n",
      "Ġhard {'ĠBes': 14, 'wings': 13, 'Ġtrump': 12, 'trump': 12, 'ĠBush': 12, 'Ġarmies': 12}\n",
      "ins {'ĠJur': 13, 'Ġpersons': 13, 'Ġviable': 13, 'ĠREST': 12, 'Ġpract': 12, 'Ġrecl': 12}\n",
      "Å {'Ġvampires': 13, 'ampires': 13, 'Ġconsiderations': 12, 'Ġrepentance': 12, 'lore': 12, 'Ġsensibilities': 12}\n",
      "empty {'Ġpict': 13, 'Ġsightings': 13, 'ritis': 12, 'table': 12, 'Ġstalls': 12, 'ĠCanadiens': 12}\n",
      "bi {'Ġgreed': 13, 'EFF': 12, 'lbs': 12, 'Ġbeams': 12, 'Ġbeam': 12, 'ĠDATA': 12}\n",
      "enter {'Ġroyalties': 13, 'Ġshareholders': 13, 'Ġexposures': 12, 'Ġrelies': 12, 'Ġsurvivors': 12, 'Ġcitizens': 12}\n",
      "Ġphysical {'Ġcompanions': 14, 'Ġgardens': 13, 'Ġpens': 12, 'Ġfarms': 12, 'Ġgarden': 12, 'Ġguitars': 12}\n",
      "met {'Ġconglomer': 13, 'Ġfri': 13, 'ĠHOT': 13, 'Ġcurs': 12, 'Ġincumb': 12, 'ĠGrimm': 12}\n",
      "FD {'ĠData': 14, 'ĠDATA': 13, 'Ġdata': 13, 'Data': 12, 'Ġorbital': 12, 'Ġorbiting': 12}\n",
      "Ġoriginally {'Ġwasn': 14, 'Ġweren': 13, 'Ġwere': 12, 'Ġwas': 12, 'Ġresided': 12, 'Ġexisted': 12}\n",
      "earth {'ĠSCHOOL': 14, 'Ġschool': 13, 'ĠCemetery': 12, 'Ġuniversity': 12, 'school': 12, 'School': 12}\n",
      "position {'ĠChampions': 13, 'ighters': 12, 'ĠLH': 12, 'Ġtranslations': 12, 'Ġnegotiators': 12, 'Ġchampions': 12}\n",
      "spect {'Ġbehest': 13, 'Ġjeopard': 13, 'Ġfans': 12, 'Ġmeetings': 12, 'Ġcessation': 12, 'Ġdemise': 12}\n",
      "Ġswitches {'Ġchanging': 13, 'Ġalteration': 12, 'Ġchange': 12, 'change': 12, 'Ġflip': 12, 'Ġtransformation': 12}\n",
      "- {'Ġplanets': 13, 'Ġcords': 13, 'Ġgirls': 12, 'Ġbride': 12, 'Ġcasinos': 12, 'Ġcoffers': 12}\n",
      "hist {'ĠReps': 13, 'ĠMankind': 13, 'ĠGuests': 13, 'Ġguests': 12, 'ĠDevelopers': 12, 'Ġchefs': 12}\n",
      "ling {'Ġ960': 13, 'ĠYue': 13, 'Ġhearts': 13, 'ĠHide': 12, 'Ġail': 12, 'Ġ550': 12}\n",
      "act {'ĠCoh': 13, 'ĠBeacon': 13, 'ĠCemetery': 12, 'ĠGrave': 12, 'Ġmosque': 12, 'Ġguardian': 12}\n",
      "gy {'Ġoxy': 13, 'ĠJelly': 13, 'ĠWee': 12, 'ĠWolfe': 12, 'ĠOxy': 12, 'ĠFem': 12}\n",
      "wide {'ĠZig': 13, 'ĠCapcom': 13, 'ĠNah': 13, 'Vict': 12, 'ĠSmile': 12, 'ĠNBA': 12}\n",
      "iod {'Ġboards': 13, 'Ġbarbaric': 13, 'Ġseekers': 13, 'Ġcommenters': 12, 'Ġfounders': 12, 'per': 12}\n",
      "GET {'76561': 13, '115': 12, '643': 12, '635': 12, '551': 12, '763': 12}\n",
      "od {'Ġothers': 13, 'ĠHillary': 12, 'ĠPodesta': 12, 'ĠKuwait': 12, 'ĠJPM': 12, 'ĠSaudi': 12}\n",
      "Ġtraffic {'Ġairports': 14, 'ĠHills': 13, 'icester': 12, 'ms': 12, 'aea': 12, 'balls': 12}\n",
      "aud {'Ġrecl': 13, 'ĠHelmet': 13, 'Ġhelmet': 13, 'hair': 12, 'haired': 12, 'Ġbourgeois': 12}\n",
      "eral {'Ġfitting': 13, 'ĠMovies': 13, 'Ġclothing': 13, 'fitting': 12, 'Ġdrawings': 12, 'Ġmovies': 12}\n",
      "hand {'ĠLegisl': 13, 'ĠPublic': 13, 'Public': 12, 'ĠVacc': 12, 'ĠVision': 12, 'ĠLegacy': 12}\n",
      "rate {'ĠFei': 14, 'ĠMattis': 12, 'ĠCool': 12, 'ĠLal': 12, 'Cool': 12, 'ĠAmpl': 12}\n",
      "Ġper {'ĠRegina': 13, 'ĠErin': 13, 'Ġger': 13, 'ĠObamaCare': 12, 'ĠBecky': 12, 'ĠCarney': 12}\n",
      "tw {'Ġdigest': 13, 'ĠJung': 13, 'jit': 12, 'ĠDigest': 12, 'Ġglim': 12, 'ZE': 12}\n",
      "aki {'ĠShared': 13, 'ĠVintage': 13, 'Ġgp': 12, 'att': 12, 'Ġnascent': 12, 'ĠPAX': 12}\n",
      "Ġnoise {'ĠKenyan': 13, 'ĠKenya': 13, 'ĠVienna': 13, 'ĠMoscow': 12, 'ĠZurich': 12, 'ĠPoland': 12}\n",
      "text {'ĠSch': 13, 'Ind': 12, 'Tim': 12, 'ĠIndiana': 12, 'ĠGregg': 12, 'ĠYus': 12}\n",
      "rh {'Ġterrestrial': 13, 'restrial': 13, 'ĠTian': 13, 'schild': 12, 'ĠEdu': 12, 'Ġcomparatively': 12}\n",
      "pro {'ĠLesbian': 13, 'Ġlesbian': 13, 'ĠGrim': 12, 'Ġinco': 12, 'Ġellipt': 12, 'Ġidiot': 12}\n",
      "occup {'Ġdescendants': 13, 'Ġpope': 13, 'ĠPope': 12, 'ĠInternational': 12, 'Ġspecialists': 12, 'Ġprojectiles': 12}\n",
      "oc {'Ġarri': 13, 'Ġlegit': 13, 'ihar': 12, 'Ġguardians': 12, 'Ġhind': 12, 'Ġfeas': 12}\n",
      "Ġactive {'Ġcottage': 14, 'Ġstrict': 13, 'Ġprison': 12, 'Ġnotoriously': 12, 'ĠMountain': 12, 'Ġag': 12}\n",
      "ary {'Ġmice': 13, 'Ġveterin': 12, 'Ġwives': 12, 'Ġcomple': 12, 'ĠGABA': 12, 'Ġambassadors': 12}\n",
      "ve {'Ġsizable': 12, 'ĠAugustine': 12, 'Ġdiscrepancy': 12, 'Ġshorter': 12, 'gment': 12, 'Ġsizeable': 12}\n",
      "Ġindefinitely {'Ġremains': 13, 'Ġmaintain': 13, 'Ġremain': 13, 'aintain': 13, 'Ġmaintains': 13, 'Ġretains': 12}\n",
      "Ġpreviously {'Ġbeen': 13, 'Ġlaying': 13, 'Ġlaid': 12, 'Ġconstituted': 12, 'Ġsocietal': 12, 'been': 12}\n",
      "lands {'Ġgreed': 13, 'ĠTeams': 13, 'Ġschools': 12, 'ĠSchools': 12, 'Ġcorpses': 12, 'Ġsquads': 12}\n",
      "PRO {'Ġamplified': 13, 'Ġrec': 13, 'Ġdiarr': 13, 'Ġmisc': 12, 'Ġhatched': 12, 'Ġamplification': 12}\n",
      "pop {'uel': 13, 'Ġcivilians': 13, 'ĠPerez': 13, 'Ġcoconut': 12, 'idia': 12, 'ĠDirectX': 12}\n",
      "FB {'Ġshared': 13, 'Ġdivided': 12, 'Ġfragmented': 12, 'Ġfeminist': 12, 'Ġnascent': 12, 'Ġridiculed': 12}\n",
      "ump {'ĠBF': 13, 'Ġkh': 12, 'Ġcool': 12, 'ĠMG': 12, 'ĠCool': 12, 'ĠGEAR': 12}\n",
      "nam {'inis': 14, 'Ġperennial': 12, 'Ġgraphical': 12, 'Ġmodesty': 12, 'ĠGUI': 12, 'ĠGenius': 12}\n",
      "am {'ĠLunar': 13, 'Ġbab': 13, 'ĠBab': 12, 'Ġrespons': 12, 'ribut': 12, 'Ġrabb': 12}\n",
      "ma {'rehensible': 13, 'izable': 13, 'uable': 12, 'ateful': 12, 'itable': 12, 'Ġsore': 12}\n",
      "ties {'ĠMyth': 13, 'ĠExploration': 12, 'Ġexplor': 12, 'ĠStarfleet': 12, 'ĠPremiership': 12, 'Ġfilesystem': 12}\n",
      "ple {'Ġcod': 14, 'Ġbanks': 13, 'Ġbanking': 12, 'ĠBank': 12, 'Ġdigest': 12, 'Ġgrapp': 12}\n",
      "ESS {'Ġmale': 14, 'Ġcorpse': 12, 'Ġboss': 12, 'Ġbastard': 12, 'ĠMale': 12, 'ĠPERSON': 12}\n",
      "ode {'ĠJPM': 14, 'Ġwomen': 13, 'Women': 13, 'Ġethn': 12, 'ĠWomen': 12, 'ĠAsians': 12}\n",
      "jen {'Ġsizeable': 13, 'Ġnoticeably': 13, 'Ġmarkedly': 13, 'Ġhealthier': 12, 'Ġseverely': 12, 'Ġnoticeable': 12}\n",
      "press {'ĠJavaScript': 13, 'ĠHaskell': 12, 'Ġjavascript': 12, 'Ġcongressional': 12, 'ĠJavascript': 12, 'ĠJupiter': 12}\n",
      "reading {'Ġnewcomers': 14, 'Ġcontributions': 13, 'Ġnewcomer': 12, 'Ġrigid': 12, 'Fair': 12, 'Ġemer': 12}\n",
      "hur {'ĠClassic': 14, 'Ġavoided': 13, 'Classic': 13, 'Ġbl': 12, 'Ġclassic': 12, 'ĠHOT': 12}\n",
      "oir {'Ġspherical': 13, 'herical': 13, 'Ġderivatives': 12, 'Ġcelebrations': 12, 'Ġprinces': 12, 'ĠCardinal': 12}\n",
      "ond {'ĠSurprisingly': 14, 'Ġsurprisingly': 13, 'Ġsurprising': 12, 'prisingly': 12, 'Ġgriev': 12, 'Ġmaximal': 12}\n",
      "Ġeasily {'Ġcan': 14, 'Ġkan': 13, 'Ġmay': 12, 'can': 12, 'Ġpossible': 12, 'may': 12}\n",
      "ps {'secure': 13, 'Ġfeder': 12, 'Ġsecuring': 12, 'Ġgrapp': 12, 'IPP': 12, 'Ġvein': 12}\n",
      "** {'ĠCait': 13, 'Ġlime': 13, 'Ġfeminine': 12, 'Ġfe': 12, 'ĠLis': 12, 'Ġoccas': 12}\n",
      "wart {'College': 13, 'ĠEDT': 12, 'ĠTesting': 12, 'ĠReading': 12, 'Training': 12, 'Reading': 12}\n",
      "ull {'ixty': 13, 'ĠMB': 13, 'ĠForty': 12, 'Ġpuberty': 12, 'ett': 12, 'ĠThirty': 12}\n",
      "dead {'isine': 13, 'icht': 13, 'ĠSaur': 12, 'Pinterest': 12, 'Ġ=>': 12, 'Ġneur': 12}\n",
      "mut {'ĠBL': 13, 'Ġcollaps': 13, 'ĠSchneider': 12, 'ĠBangladesh': 12, 'ĠBG': 12, 'ĠMalaysia': 12}\n",
      "ide {'Ġdataset': 13, 'Ġdatasets': 13, 'Ġcontinental': 13, 'ĠWORLD': 12, 'Saharan': 12, 'Ġsimultaneously': 12}\n",
      "HL {'Ġcached': 13, 'Ġhidden': 13, 'ĠHidden': 12, 'Ġvested': 12, 'Ġhid': 12, 'Ġfailed': 12}\n",
      "bo {'Ġspac': 13, 'Ġconve': 13, 'Ġgoof': 13, 'Ġcurric': 12, 'icc': 12, 'Ġcurriculum': 12}\n",
      "DB {'å¿': 14, 'Ġobsc': 13, 'Ġhiber': 13, 'Ġprag': 12, 'Ġnerv': 12, 'meat': 11}\n",
      "Ġstandard {'ĠCorrespond': 13, 'Ġcorrespond': 13, 'Ġcorresponds': 13, 'Ġreflect': 12, 'Ġcorrespondent': 12, 'Ġprograms': 12}\n",
      "command {'Ġconsent': 14, 'ĠConsent': 13, 'ĠTournament': 12, 'Ġpossibility': 12, 'ortality': 12, 'ĠAnthropology': 12}\n",
      "ome {'Ġsplendid': 13, 'Ġnobles': 13, 'ĠLaksh': 13, 'ĠNicole': 13, 'ĠLaurel': 12, 'Raven': 12}\n",
      "SL {'ĠFemales': 13, 'Ġmosquit': 13, 'ĠGuardians': 13, 'Ġfemales': 12, 'Ġteenagers': 12, 'Ġgirls': 12}\n",
      "Ġunits {'ĠChester': 13, 'ĠYORK': 12, 'ĠDock': 12, 'ĠRedmond': 12, 'ĠEdinburgh': 12, 'ĠJerusalem': 12}\n",
      "um {'Ġembod': 13, 'Ġinitial': 13, 'ĠSCHOOL': 12, 'ĠSchool': 12, 'Ġprimitive': 12, 'Ã¯': 12}\n",
      "our {'ĠConfeder': 13, 'Ġminiature': 13, 'Ġmothers': 12, 'Ġtermin': 12, 'Ġcamoufl': 12, 'Ġsevere': 12}\n",
      "heter {'Ġrep': 13, 'Ġresc': 13, 'Ġreference': 13, 'ĠReference': 12, 'Ġbreadth': 12, 'Ġpractitioner': 12}\n",
      "acl {'Ġheirs': 14, 'Ġcapitals': 13, 'Ġministries': 12, 'ĠCups': 12, 'Ġyouths': 12, 'ksh': 12}\n",
      "oll {'ĠKnot': 14, 'Ġunbel': 13, 'verty': 12, 'ol': 12, 'Ġknots': 12, 'oll': 12}\n",
      "Cat {'Ġlayouts': 13, 'Ġfoundations': 12, 'ĠEmpires': 12, 'Ġlesions': 12, 'ĠRooms': 12, 'ĠLimits': 12}\n",
      "HD {'shit': 12, 'Dad': 12, 'Gamer': 12, 'Player': 12, 'Ġguerrilla': 12, 'Ġpopulace': 12}\n",
      "cats {'Ġstreng': 13, 'Ġpact': 13, 'ĠTens': 13, 'ĠTess': 12, 'keye': 12, 'ĠZur': 12}\n",
      "rou {'Ġairport': 13, 'ĠHale': 12, 'etz': 12, 'ĠEagle': 12, 'ĠCoastal': 12, 'orget': 12}\n",
      "Ġbadly {'Ġwants': 14, 'Ġwanted': 13, 'Ġwant': 12, 'ĠWant': 12, 'ĠWanted': 12, 'Ġwanting': 12}\n",
      "pal {'Ġarrays': 14, 'Ġearly': 12, 'ĠEarly': 12, 'Thirty': 12, 'Ġarray': 12, 'Early': 12}\n",
      "Co {'ĠAust': 13, 'ricted': 12, 'Ġdoomed': 12, 'capital': 12, 'ederation': 12, 'ĠShattered': 12}\n",
      "omen {'Ġsadness': 14, 'Ġalarms': 12, 'Ġwarmth': 12, 'ĠMcCabe': 12, 'Ġsweets': 12, 'meier': 12}\n",
      "ahu {'ĠASAP': 14, 'ĠAP': 13, 'auc': 12, 'ĠPrem': 12, 'ĠCOUR': 12, 'ĠAdvis': 12}\n",
      "sha {'Ġhilarious': 13, 'Ġmarkedly': 13, 'Ġnoticeably': 13, 'Ġdelightful': 12, 'Ġhumorous': 12, 'Ġsuited': 12}\n",
      "ious {'ĠClock': 13, 'ocard': 13, 'Ġfuner': 12, 'Ġcards': 12, 'Clock': 12, 'ĠCards': 12}\n",
      "bit {'ĠGD': 13, 'ĠEB': 13, 'Ġcoales': 13, 'GD': 12, 'Ġrul': 12, 'ĠUX': 12}\n",
      "asc {'TeX': 14, 'pic': 12, 'plates': 12, 'Ġplates': 12, 'restrial': 12, 'Ġpic': 12}\n",
      "AD {'ĠOliv': 13, 'Ġjealous': 13, 'Ġpopul': 12, 'embed': 12, 'ĠBog': 12, 'Ġetiquette': 12}\n",
      "except {'Ġunfairly': 13, 'Ġegregious': 13, 'Ġlethal': 12, 'ascal': 12, 'Ġfoul': 12, 'osexual': 12}\n",
      "rix {'Ġsegregation': 13, 'Ġstun': 13, 'balance': 13, 'Ġcorrupt': 12, 'Ġinsecurity': 12, 'Ġimprison': 12}\n",
      "Ġcoverage {'Ġprovides': 13, 'ĠProvides': 13, 'Ġprovide': 13, 'Ġoffers': 12, 'Ġprovided': 12, 'Ġpermitting': 12}\n",
      "reason {'Ġcombo': 13, 'Ġban': 13, 'Ġnorm': 13, 'ĠCombo': 12, 'ĠER': 12, 'ĠKurds': 12}\n",
      "Ġfavor {'Ġawfully': 13, 'Ġawful': 13, 'Ġnoble': 13, 'Ġawkward': 13, 'Ġoddly': 12, 'Ġshady': 12}\n",
      "dat {'ĠPes': 14, 'ĠChes': 13, 'ĠEA': 13, 'bs': 12, 'Ġpes': 12, 'ĠGD': 12}\n",
      "ev {'cert': 13, 'Ġhelmets': 13, 'Ġdams': 12, 'Ġcollaborators': 12, 'raphics': 12, 'Ġcertificates': 12}\n",
      "ding {'ĠiCloud': 12, 'Ġconserve': 12, 'Ġreinforce': 12, 'Ġresurgence': 12, 'Ġguardians': 12, 'ĠMerge': 12}\n",
      "omin {'Ġbott': 13, 'Ġpolyg': 12, 'ĠKate': 12, 'Ġwomen': 12, 'ĠWomen': 12, 'Ġgoddess': 12}\n",
      "born {'VERS': 13, 'ĠCardinals': 13, 'aspers': 12, 'AR': 12, 'finals': 12, 'BL': 12}\n",
      "Ġgrowth {'Ġcauses': 13, 'Ġcause': 13, 'ĠCauses': 13, 'Ġcausing': 13, 'cause': 12, 'Ġexper': 12}\n",
      "int {'ĠPOL': 13, 'ĠMom': 13, 'ĠMIL': 13, 'ĠGP': 12, 'ĠKob': 12, 'POL': 12}\n",
      "multipl {'Ġappeals': 13, 'Ġwolves': 13, 'Ġinsects': 12, 'inctions': 12, 'Ġfiles': 12, 'Ġsweets': 12}\n",
      "Ġcounter {'Ġhorses': 14, 'orses': 13, 'Ġfirms': 12, 'Ġlibraries': 12, 'Ġsocieties': 12, 'Ġenglish': 12}\n",
      "Ġmin {'Ġdefin': 14, 'ĠMAKE': 12, 'ĠImag': 12, 'Ġmake': 12, 'ĠAuthorization': 12, 'Ġsimulation': 12}\n",
      "ward {'Ġsilicone': 14, 'Ġadip': 13, 'ĠPLEASE': 12, 'Ġhateful': 12, 'Ġluxurious': 12, 'Ġmonstrous': 12}\n",
      "click {'ĠactionGroup': 13, 'Ġcuisine': 12, 'Ġlaws': 12, 'Ġoutfit': 12, 'Ġparents': 12, 'Ġlayouts': 12}\n",
      "antry {'Ġoccupations': 13, 'Ġwaivers': 12, 'Ġlaboratories': 12, 'Ġpapers': 12, 'Ġmigrants': 12, 'Ġpartnerships': 12}\n",
      "db {'Ġrecl': 13, 'Ġclut': 13, 'Ġsh': 12, 'Ġbarr': 12, 'Ġincrease': 12, 'Ġclam': 12}\n",
      "Future {'era': 13, 'Ġmortar': 12, 'enda': 12, 'urer': 12, 'Ġmorale': 12, 'uter': 12}\n",
      "ik {'768': 13, 'ĠAlic': 12, 'Ġ768': 12, 'ĠNewfoundland': 12, 'ĠLuffy': 12, 'ĠKens': 12}\n",
      "ver {'Ġolive': 13, 'Ġke': 13, 'Ġcell': 12, 'ĠAngel': 12, 'Ġbab': 12, 'Ġfol': 12}\n",
      "âĪ {'Ġconnections': 13, 'Ġsimilarities': 13, 'Ġrelationships': 12, 'Ġfranchises': 12, 'enses': 12, 'Ġpartnerships': 12}\n",
      "inter {'Ġsuscept': 14, 'Ġfeas': 12, 'Ġ720': 12, 'Ġrevital': 12, 'Ġinert': 12, 'Ġdiver': 12}\n",
      "lay {'Ġprototyp': 13, 'ĠScandinav': 13, 'ĠTPP': 12, 'ĠPascal': 12, 'Australian': 12, 'CRIP': 12}\n",
      "Ġch {'Ġlawfully': 14, 'Ġlawful': 13, 'Ġinitiate': 12, 'Ġlegally': 12, 'Ġlegalize': 12, 'Ġofficially': 12}\n",
      "mid {'ĠRosenberg': 13, 'ĠEnlightenment': 12, 'Saharan': 12, 'Ġemergence': 12, 'ĠKant': 12, 'femin': 12}\n",
      "oin {'Ġbalanced': 13, 'Ġgrasped': 13, 'Ġbuffet': 12, 'Ġaspir': 12, 'Ġtan': 12, 'Ġgripped': 12}\n",
      "ord {'Ġdecriminal': 13, 'Ġqualifiers': 13, 'Ġdigital': 13, 'Ġstandards': 12, 'Ġfeminine': 12, 'Ġadolesc': 12}\n",
      "bot {'ĠDres': 13, 'ĠObi': 12, 'ĠGob': 12, 'ĠWyatt': 12, 'ĠKier': 12, 'ĠYue': 12}\n",
      "bum {'ĠBF': 14, 'ĠMPH': 13, 'IRD': 13, 'ĠHH': 12, 'EH': 12, 'ĠAI': 12}\n",
      "ip {'iazep': 13, 'Ġmascul': 12, 'ĠREL': 12, 'ĠDoll': 12, 'Ġbeaut': 12, 'Ġlewd': 12}\n",
      "bas {'ĠLeague': 13, 'Ġleague': 12, 'ĠRussell': 12, 'ĠSharif': 12, 'ĠIslam': 12, 'ĠMuslim': 12}\n",
      "units {'ĠLuxembourg': 14, 'ĠHoliday': 13, 'Ġholiday': 13, 'holiday': 12, 'ĠWEEK': 12, 'ĠWeekend': 12}\n",
      "owl {'ascal': 13, 'Ġnewborn': 13, 'esley': 12, 'ĠPascal': 12, 'IZ': 12, 'ĠMSI': 12}\n",
      "IR {'Myth': 13, 'MAX': 12, 'FG': 12, 'ĠFG': 12, 'AAAA': 12, 'ĠMyth': 12}\n",
      "pp {'ĠMPEG': 13, 'ĠGob': 12, 'ĠGeoffrey': 12, 'ĠErik': 12, 'ĠIzan': 12, 'ĠLindsey': 12}\n",
      "wald {'ĠLadies': 13, 'Ġfolks': 13, 'Members': 12, 'ĠMembers': 12, 'Ġrel': 12, 'Ġmembers': 12}\n",
      "rd {'ĠKimberly': 13, 'ĠMari': 12, 'ĠKim': 12, 'ĠLal': 12, 'Ġterrestrial': 12, 'ĠKru': 12}\n",
      "name {'esters': 13, 'Ġpuzzles': 12, 'Ġcampus': 12, 'ĠSprings': 12, 'ĠWC': 12, 'Ġlact': 12}\n",
      "par {'MER': 13, 'ĠMER': 12, 'ĠFramework': 12, 'Ġdavid': 12, 'Ġpractitioner': 12, 'Ġresemb': 12}\n",
      "Param {'cook': 13, 'Ġdye': 13, 'kl': 12, 'ĠDiesel': 12, 'stick': 12, 'Ġgrill': 12}\n",
      "ass {'atern': 13, 'Ġvisually': 13, 'ĠJal': 12, 'Ġearliest': 12, 'Ġpope': 12, 'Ġactively': 12}\n",
      "ak {'ĠKob': 13, 'ĠBucs': 12, 'ĠEmerging': 12, 'xb': 12, 'ĠAwakening': 12, 'Bu': 12}\n",
      "Disc {'Ġdishes': 13, 'ĠDish': 13, 'Ġparole': 13, 'Ġdisgust': 12, 'Ġexit': 12, 'Ġcuisine': 12}\n",
      "hover {'345': 13, '341': 12, '516': 12, '557': 12, 'Ġ345': 12, '751': 12}\n",
      "write {'ĠKlaus': 14, 'Ġadequ': 13, 'ĠClark': 12, 'ĠAtlas': 12, 'lington': 12, 'ĠHayden': 12}\n",
      "tek {'ĠRican': 14, 'ĠPilgrim': 13, 'Unix': 12, 'illa': 12, 'Ġcruise': 12, 'cair': 12}\n",
      "ka {'ĠMeg': 13, 'ĠPax': 13, 'ĠGl': 12, 'ĠCanaveral': 12, 'ĠFair': 12, 'ĠSH': 12}\n",
      "Ġspecial {'Feature': 13, 'Ġwarrant': 13, 'Ġstern': 12, 'feature': 12, 'ĠWarrant': 12, 'Ġliquor': 12}\n",
      "mer {'Ġballot': 14, 'Ġfat': 13, 'Ġalgebra': 12, 'Ġappreci': 12, 'Ġartery': 12, 'Ġballots': 12}\n",
      "âĢ {'Ġcircular': 13, 'Ġsleek': 12, 'Ġnormal': 12, 'Ġdeaf': 12, 'Ġladies': 12, 'Ġhard': 12}\n",
      "flow {'ĠZionist': 14, 'Ġbisexual': 12, 'Ġadaptive': 12, 'Ġadaptation': 12, 'Ġpipeline': 12, 'isexual': 12}\n",
      "Ãº {'yahoo': 13, 'Ġamusing': 13, 'Ġbourgeoisie': 12, 'ĠShirt': 12, 'quart': 12, 'Ġgigg': 12}\n",
      "rend {'Ġvehemently': 14, 'Ġextant': 13, 'dx': 12, 'ĠAcademic': 12, 'Ġacadem': 12, 'Ġundergrad': 12}\n",
      "mark {'ĠClaud': 14, 'ĠPAL': 13, 'Ġemulate': 12, 'femin': 12, 'hl': 12, 'please': 12}\n",
      "kw {'zyk': 14, 'Ġmech': 13, 'Ġgeop': 12, 'Ġdoc': 12, 'ĠUzbek': 12, 'ĠKirin': 12}\n",
      "abi {'hillary': 14, 'Bu': 12, 'vl': 12, 'Ġprepaid': 12, 'bu': 12, 'Ġtrailed': 12}\n",
      "purpose {'Ġnipple': 13, 'Ġnipples': 13, 'Ġguests': 12, 'Ġreferees': 12, 'Ġlenses': 12, 'Ġpilots': 12}\n",
      "ger {'ĠMaj': 13, 'ĠBak': 12, 'jee': 12, 'ĠJP': 12, 'ĠGrail': 12, 'ĠLak': 12}\n",
      "cur {'Ġstarters': 13, 'ĠBers': 13, 'Ġcurrently': 13, 'Ġgel': 12, 'ĠMyers': 12, 'Ġbeers': 12}\n",
      "off {'Ġfive': 12, 'Ġthree': 12, 'ĠCaval': 12, 'Ġnine': 12, 'ixty': 12, 'Ġsixty': 12}\n",
      "Ġhardware {'forest': 13, 'vironments': 12, 'Ġscores': 12, 'Ġforest': 12, 'Ġmountains': 12, 'Ġplatforms': 12}\n",
      "multi {'Ġchampionships': 12, 'Ġtournaments': 12, 'Ġstudies': 12, 'ograms': 12, 'ĠChampions': 12, 'Ġexams': 12}\n",
      "Ġfre {'comfort': 14, 'ĠCON': 13, 'Ġcomfort': 12, 'Ġrear': 12, 'ĠComfort': 12, 'ĠMcA': 12}\n",
      "ard {'LOD': 13, 'Ġpeaked': 13, 'Ġhealth': 13, 'ĠHealth': 12, 'haired': 12, 'health': 12}\n",
      "rey {'Ġconducive': 13, 'Ġinterestingly': 13, 'Ġvenerable': 13, 'Ġdangerously': 12, 'compatible': 12, 'Ġprecarious': 12}\n",
      "opp {'ĠPrelude': 12, 'ĠMariners': 12, 'Ġhitter': 12, 'Ġstandpoint': 12, 'Ġfeder': 12, 'Ġhitters': 12}\n",
      "del {'Ġcub': 13, 'Ġcubic': 13, 'ĠNico': 12, 'ĠPascal': 12, 'ĠCub': 12, 'ĠConce': 12}\n",
      "const {'ĠKer': 13, 'Ġguides': 13, 'Ġsage': 12, 'Ġlogs': 12, 'Ġstag': 12, 'Ġcoord': 12}\n",
      "ga {'Ġegregious': 14, 'Ġbride': 12, 'Ġdomest': 12, 'ĠApplic': 12, 'Ġfest': 12, 'Ġthankfully': 12}\n",
      "Ġmul {'Ġenlight': 15, 'Ġoppress': 12, 'Ġinform': 12, 'Ġpag': 12, 'dress': 12, 'Ġstra': 12}\n",
      "bra {'Ġturrets': 13, 'Ġtits': 12, 'Ġboobs': 12, 'Ġlens': 12, 'Ġlenses': 12, 'Ġrooft': 12}\n",
      "che {'Ġvenerable': 13, 'Ġsensible': 13, 'Ġalbeit': 12, 'ĠTRE': 12, 'Ġ</': 12, '></': 12}\n",
      "nom {'Ġmeth': 13, 'Ġwives': 12, 'Ġblo': 12, 'Ġnurses': 12, 'eth': 12, 'wives': 12}\n",
      "rol {'ĠChel': 13, 'ĠRevel': 13, 'align': 12, 'ĠDol': 12, 'femin': 12, 'Hal': 12}\n",
      "mand {'ĠPrem': 14, 'Prem': 13, 'prem': 12, 'Ġprem': 12, 'Ġcel': 12, 'ĠADA': 11}\n",
      "Ġperfection {'erate': 14, 'ĠModerate': 12, 'reve': 12, 'igans': 12, 'Ġexecutes': 12, 'utes': 12}\n",
      "ai {'illi': 13, 'ĠLei': 13, 'owitz': 12, 'acqu': 12, 'ĠLey': 12, 'neg': 12}\n",
      "wise {'Ġresil': 13, 'ĠPascal': 13, 'ĠWeb': 12, 'ĠBlake': 12, 'Ġobese': 12, 'Ġbowel': 12}\n",
      "ram {'itizens': 12, 'ĠCitizens': 12, 'ĠAda': 12, 'ĠBre': 12, 'ĠCub': 12, 'Ġembr': 12}\n",
      "gra {'ĠLooks': 13, 'Looks': 13, 'ĠBitcoins': 12, 'Ġlooks': 12, 'Ġbitcoins': 12, 'Ġglances': 12}\n",
      "outer {'ĠSCHOOL': 13, 'lv': 12, 'Ġharmon': 12, 'Ġsocial': 12, 'Ġministries': 12, 'ĠLeague': 12}\n",
      "Ġreading {'ĠLewis': 13, 'ĠModest': 12, 'Lewis': 12, 'Ġfreshly': 12, 'ĠFord': 12, 'Ġf': 12}\n",
      "kel {'Ġhippocamp': 13, 'lycer': 13, 'Ġoste': 13, 'Ġlact': 12, 'Ġbourgeois': 12, 'Ġhappiest': 12}\n",
      "Ġvolume {'ĠEsper': 13, 'ĠRichards': 12, 'ĠPenguins': 12, 'ĠChevrolet': 12, 'Ġexports': 12, 'ĠCooper': 12}\n",
      "abe {'amaz': 14, 'aur': 13, 'aternal': 13, 'Ġmaternal': 12, 'ele': 12, 'Ġshar': 11}\n",
      "cross {'ĠLanguage': 13, 'weight': 13, 'ĠWeight': 13, 'ethical': 12, 'Language': 12, 'haar': 12}\n",
      "Ġunit {'Ġclocks': 13, 'ĠDock': 13, 'Ġclock': 13, 'ountain': 12, 'Ġdonkey': 12, 'Ġcharger': 12}\n",
      "ondo {'ĠJed': 13, 'vae': 12, 'Ġshared': 12, 'Ġquoted': 12, 'hua': 12, 'ĠConfeder': 12}\n",
      "uu {'ĠLIA': 13, 'Ġunexpl': 13, 'iscons': 12, 'Ġpet': 12, 'Ġhandheld': 12, 'Ġradioactive': 12}\n",
      "resident {'ĠLantern': 12, 'ĠEsper': 12, 'ĠCarib': 12, 'Ġbold': 12, 'ĠGun': 12, 'ĠSeaf': 12}\n",
      "ios {'school': 13, 'Ġnascent': 12, 'ocard': 12, 'Ġacqu': 12, 'Ġhabits': 12, 'Ġpawn': 12}\n",
      "Ġbody {'Ġwhiskey': 13, 'Ġvodka': 12, 'Ġcheerful': 12, 'Ġwhisky': 12, 'ĠLatin': 12, 'chester': 12}\n",
      "l {'Ġpixel': 13, 'pixel': 12, 'Ġexplos': 12, 'Ġlol': 12, 'Ġgasp': 12, 'Ġhorizon': 12}\n",
      "ud {'ĠGerald': 14, 'ĠMcDonnell': 12, 'ĠGreg': 12, 'ĠJP': 12, 'erald': 12, 'ĠHoll': 12}\n",
      "aug {'Ġexemptions': 13, 'Ġdesigned': 13, 'designed': 12, 'orig': 12, 'Ġdesign': 12, 'Ġdefault': 12}\n",
      "sec {'Ġobserver': 13, 'Ġpen': 12, 'ĠButt': 12, 'Ġeyel': 12, 'Ġlens': 12, 'Ġpup': 12}\n",
      "leg {'Ġfil': 13, 'ĠHail': 12, '********************************': 12, 'Ġblo': 12, 'ĠPLAY': 12, 'pack': 12}\n",
      "ubs {'Ġpriceless': 13, 'ĠMassive': 12, 'Ġprecarious': 12, 'ĠHO': 12, 'Ġnaked': 12, 'Ġobnoxious': 12}\n",
      "BI {'Ġsensibilities': 13, 'Ġimages': 13, 'Ġrevenues': 13, 'Ġbreasts': 12, 'Ġeyebrows': 11, 'Ġprimates': 11}\n",
      "lab {'Ġshowcases': 13, 'Ġintellectuals': 12, 'Ġcitizens': 12, 'Ġcorpses': 12, 'Ġfestivities': 12, 'Ġgems': 12}\n",
      "aff {'Ġrecl': 13, 'Ġbast': 13, 'Ġdens': 12, 'Ġcardboard': 12, 'Ġcarn': 12, 'Ġpot': 12}\n",
      "main {'ĠFAT': 14, 'ĠFAC': 13, 'ĠFat': 13, 'ZZ': 12, 'ĠScal': 12, 'ĠGD': 12}\n",
      "super {'Ġdens': 13, 'Ġpundits': 12, 'ĠCoyotes': 12, 'Ġweights': 12, 'Ġreferees': 12, 'Ġvec': 12}\n",
      "sl {'ĠPascal': 13, 'ĠJacqu': 12, 'ĠSatoshi': 12, 'ĠLaurel': 12, 'Lev': 12, 'ĠSaban': 12}\n",
      "/ {'Ġcent': 13, 'Ġincub': 12, 'ĠSunny': 12, 'ĠKoz': 12, 'Ġpercent': 12, 'ĠMaid': 12}\n",
      "port {'ĠLeague': 13, 'Ġbuckets': 12, 'Ġleague': 12, 'Ġvictims': 12, 'please': 12, 'Ġclassrooms': 12}\n",
      "heads {'Quest': 12, 'Ġlineup': 12, 'Ġquest': 12, 'Ġaspect': 12, 'Ġasylum': 12, 'agraph': 12}\n",
      "rough {'Ġfatig': 12, 'ĠCait': 12, 'ĠKak': 12, 'ĠHughes': 12, 'ĠAnthrop': 12, 'ĠBMI': 12}\n",
      "iff {'Ġgorgeous': 13, 'Ġobvious': 12, 'Ġawkward': 12, 'Ġvenerable': 12, 'Ġnaturally': 12, 'Ġextraordinarily': 12}\n",
      "per {'Ġinterest': 13, 'Ġinterests': 12, 'Ġbeacon': 12, 'Ġsensibilities': 12, 'Ġresemb': 12, 'Ġinterested': 12}\n",
      "Ġuntil {'Ġstayed': 13, 'Ġwaited': 12, 'Ġgard': 12, 'Ġpersisted': 12, 'Ġpersistent': 12, 'ĠWait': 12}\n",
      "iron {'script': 14, 'ript': 12, 'Script': 12, 'arag': 12, 'rel': 12, 'Tal': 12}\n",
      "range {'Ġvulnerable': 13, 'Mart': 13, 'ĠMart': 12, 'Rat': 12, 'ĠAirbnb': 12, 'Raven': 12}\n",
      "tower {'Ġschemes': 13, 'Ġfestivities': 13, 'Ġcommittees': 13, 'ĠUniversities': 12, 'Ġleagues': 12, 'Ġpregnancies': 12}\n",
      "ender {'Ġappeal': 14, 'plug': 13, 'Ġbast': 12, 'Ġappeals': 12, 'compan': 12, 'Ġkiss': 12}\n",
      "Ġyesterday {'Ġproposed': 13, 'Ġequipped': 12, 'Ġportrayed': 12, 'Ġprovided': 12, 'Ġreleased': 12, 'Ġremembered': 12}\n",
      "avis {'Ġpads': 12, 'urg': 12, 'Ġheterogeneity': 12, 'Ġhubs': 12, 'Ġvanished': 12, 'hub': 12}\n",
      "trade {'Ġindigenous': 13, 'igenous': 12, 'itizens': 12, 'ĠIndigenous': 12, 'Ġassailants': 12, 'ĠTurkish': 12}\n",
      "stem {'abis': 12, 'Ġtimelines': 12, 'ĠShia': 12, 'ĠKats': 12, 'Ġpoets': 12, 'ĠEngels': 12}\n",
      "flush {'Ġseason': 13, 'ĠLab': 13, 'Ġresemb': 13, 'ĠTEST': 12, 'ĠFUCK': 12, 'ĠDB': 12}\n",
      "my {'Ġstable': 12, 'ĠBeacon': 12, 'ĠNewfoundland': 12, 'Ġbeacon': 12, 'Ġlatt': 12, 'Ġfeder': 12}\n",
      "Ġthem {'makers': 13, 'Ġtravelers': 12, 'Ġnegotiators': 12, 'Ġbanks': 12, 'Ġinfants': 12, 'Ġgenerations': 12}\n",
      "un {'Ġremaining': 14, 'ĠSTUD': 12, 'ĠGuth': 12, 'auc': 12, 'GGGG': 12, 'ĠGob': 12}\n",
      "Ġvia {'Ġcommunicating': 14, 'Ġarriving': 13, 'Ġcommunication': 12, 'Ġemanating': 12, 'ĠCOMMUN': 12, 'Ġcommuting': 11}\n",
      "vil {'Ġfueled': 13, 'Ġfuelled': 12, 'Ġtaped': 12, 'Ġlashed': 12, 'Ġignited': 12, 'Ġsparked': 12}\n",
      "{ {'Ġmosquito': 13, 'ĠFairy': 12, 'ĠMonkey': 12, 'ĠBulgar': 12, 'angular': 12, 'Ġendot': 12}\n",
      "oct {'Ġgag': 13, 'Ġregrets': 12, 'Ġtoday': 12, 'Ġrestrictions': 12, 'Ġcripp': 12, 'mask': 12}\n",
      "art {'Ġcamps': 14, 'Ġfuner': 13, 'Ġcamp': 12, 'ĠAlice': 12, 'RIPT': 12, 'ĠSTEP': 11}\n",
      "PD {'ĠSB': 13, 'ĠKal': 12, 'ĠJUL': 12, 'Ġanx': 12, 'ĠCHR': 12, 'AE': 12}\n",
      "Ġrecently {'Ġbeen': 14, 'Ġhadn': 13, 'been': 13, 'contained': 12, 'ĠBeen': 12, 'Ġcontained': 12}\n",
      "nt {'ĠMB': 14, 'Ġbusinessmen': 13, 'ĠGB': 12, 'MB': 12, 'Ġselfies': 12, 'Ġbloggers': 12}\n",
      "string {'Ġtermination': 13, 'ĠTermin': 13, 'Ġterminate': 12, 'Ġterminating': 12, 'Ġpeak': 12, 'ĠCRC': 12}\n",
      "âĢĲ {'Ġlipid': 12, 'porate': 12, 'mother': 12, 'Ġmother': 12, 'Ġeyel': 12, 'Ġcorporate': 12}\n",
      "Ġbow {'089': 13, '083': 13, '311': 13, '411': 12, '482': 12, '587': 12}\n",
      "transfer {'Ġpatriotic': 13, 'ĠKurds': 13, 'Ġpatriot': 12, 'ĠKurdish': 12, 'ĠPacific': 12, 'asket': 12}\n",
      "she {'Ġcouncils': 13, 'Ġdifficulties': 12, 'ĠGreeks': 12, 'Ġcourts': 12, 'ĠApostles': 12, 'Ġanomalies': 12}\n",
      "ĠWhite {'ĠDisneyland': 13, 'Ġcertainly': 13, 'ĠSERV': 12, 'Ġconvenient': 12, 'ĠServ': 12, 'Ġfairly': 12}\n",
      "AC {'Ġcooks': 13, 'Ġcollaps': 12, 'Ġmates': 12, 'Ġvotes': 12, 'Ġmoderates': 12, 'Ġposes': 12}\n",
      "ht {'Ġgrizz': 15, 'Ġshar': 14, 'Ġshrew': 13, 'opol': 11, 'Ġproper': 11, 'sha': 11}\n",
      "mon {'Ġglut': 13, 'ĠRept': 12, 'ĠGut': 12, 'ĠConcent': 12, 'ĠGlob': 12, 'ĠEt': 12}\n",
      "diff {'ĠKant': 13, 'ĠCab': 13, 'Ġcasual': 12, 'Ġcel': 12, 'Ġexponent': 12, 'Ġpassport': 12}\n",
      "pun {'Ġballot': 13, 'ĠGuardians': 13, 'ĠMarco': 12, 'Ġglasses': 12, 'Ġplanets': 12, 'Ġbinaries': 12}\n",
      "Options {'Three': 12, 'ĠSix': 12, 'Department': 12, 'ĠMadrid': 12, 'ĠThree': 12, 'Four': 12}\n",
      "iku {'Ġhabits': 13, 'Ġhabit': 12, 'Ġpurchases': 12, 'abit': 12, 'mac': 12, 'Ġhires': 12}\n",
      "ail {'Ġprior': 13, 'Ġacad': 13, 'ĠFif': 12, 'Fif': 12, 'Ġpopulace': 12, 'Ġtwent': 12}\n",
      "Ġtitles {'ĠHaley': 13, 'ĠHarbour': 13, 'Ġtink': 13, 'ĠZika': 12, 'lake': 12, 'ĠNaples': 12}\n",
      "ash {'Ġremnant': 13, 'aker': 12, 'quin': 12, 'ĠSarah': 12, 'Marx': 12, 'ĠNicolas': 12}\n",
      "cha {'ĠMagn': 13, 'Ġinnoc': 13, 'ĠDoll': 12, 'ĠButt': 12, 'pl': 12, 'ĠWel': 12}\n",
      "sc {'ãĥĺ': 12, 'jit': 12, 'Ġunconscious': 12, 'udes': 12, 'Ġexplor': 12, 'Ġaging': 12}\n",
      "Ġcal {'Ġcompens': 13, 'Ġhonour': 12, 'Ġreconsider': 12, 'Ġcompensate': 12, 'Ġentitle': 12, 'Ġobey': 12}\n",
      "erer {'Ġcords': 13, 'content': 12, 'Ġcord': 12, 'Ġcontent': 12, 'Ġtissues': 12, 'Ġquir': 12}\n",
      "fly {'asket': 13, 'ĠAPPLIC': 13, 'campus': 12, 'fecture': 12, 'opot': 12, 'Ġlabyrinth': 12}\n",
      "ads {'Ġstubborn': 13, 'Ġautonom': 12, 'Ġsubconscious': 12, 'Ġunstable': 12, 'Ġbooth': 12, 'Ġleftists': 12}\n",
      "Ġduplication {'Ġgases': 13, 'Ġflavours': 12, 'Ġmusicians': 12, 'Ġsequences': 12, 'avers': 12, 'Ġsuperheroes': 12}\n",
      "Desc {'Ġdiscord': 12, 'Ġban': 12, 'Ġreject': 12, 'Ġdecline': 12, 'ĠDesert': 12, 'Ġdecay': 12}\n",
      "div {'Ġvac': 13, 'Ġfoil': 12, 'ĠSapphire': 12, 'Ġveil': 12, 'femin': 12, 'rix': 12}\n",
      "lat {'Ġlatent': 13, 'Ġaccur': 13, 'Ġfri': 12, 'Ġhot': 12, 'Ġsparkling': 12, 'Ġfuzzy': 12}\n",
      "fn {'Ġlact': 13, 'Ġrig': 13, 'Ġoriginate': 12, 'Ġcollide': 12, 'cht': 12, 'Ġinert': 12}\n",
      "seek {'Ġhumans': 13, 'ĠHumans': 12, 'ĠScholars': 12, 'Ġmillennials': 12, 'ĠTexas': 12, 'ĠJews': 12}\n",
      "bul {'Ġcamps': 13, 'Ġclo': 13, 'ĠEngels': 12, 'Ġemph': 12, 'Ġfeces': 12, 'ĠHau': 12}\n",
      "nar {'Ġvaliant': 13, 'uine': 12, 'Ġrays': 12, 'Ġgle': 12, 'Ġsalient': 12, 'Ġlegitimate': 12}\n",
      "UID {'Cool': 13, 'ĠCool': 12, 'Band': 12, 'ĠBon': 12, 'Beck': 12, 'Meta': 12}\n",
      "inner {'Ġpuberty': 13, 'OOOO': 13, 'Ġearly': 12, 'ĠReyn': 12, 'ĠLU': 12, 'Ġeleven': 11}\n",
      "form {'Ġadolescent': 13, 'Ġsufficiently': 12, 'Ġtil': 12, 'Ġchick': 12, 'Ġcampus': 12, 'ĠCLIENT': 12}\n",
      "IM {'Ġpops': 14, 'Ġejac': 12, 'anthrop': 12, 'Ġviolates': 12, 'Ġpop': 12, 'Ġacne': 12}\n",
      "gru {'Ġjury': 13, 'Ġdye': 12, 'ĠSche': 12, 'Planet': 12, 'Ġplanet': 12, 'Ġlineman': 12}\n",
      "worm {'ĠLegislature': 13, 'ĠLanguage': 12, 'ĠHungarian': 12, 'sun': 12, 'gart': 12, 'javascript': 12}\n",
      "des {'Ġmagistrate': 13, 'Ġspider': 12, 'Ġcavern': 12, 'Ġclipboard': 12, 'Ġfallout': 12, 'Ġdynasty': 12}\n",
      "tail {'ĵĺ': 13, 'Ġsandbox': 13, 'gp': 12, 'Ġcartoon': 12, 'Ġvideot': 12, 'ORPG': 12}\n",
      ": {'Ġcoffers': 12, 'Ġqueen': 12, 'Ġladies': 12, 'Ġcosmos': 12, 'Ġgentlemen': 12, 'Ġgirl': 12}\n",
      "hi {'Ġalbeit': 13, 'Graphics': 12, 'rehensible': 12, 'ì': 12, 'Ġcolourful': 12, 'ĠNSW': 12}\n",
      "vm {'ĠGob': 13, 'Ġgigantic': 12, 'Ġstricter': 12, 'ĠBrav': 12, 'ĠFest': 12, 'ĠFamous': 12}\n",
      "Ã {'artz': 12, 'Ġcollateral': 12, 'Ġtobacco': 12, 'ĠLunar': 12, 'ĠTobacco': 12, 'zbek': 12}\n",
      "-> {'ĠKer': 13, 'Ġpl': 12, 'ĠArcher': 12, 'Ġcoales': 12, 'ĠENG': 12, 'ĠMc': 12}\n",
      "Ġdaily {'make': 13, 'plays': 12, 'makes': 12, 'ĠMAKE': 12, 'Ġmileage': 12, 'akes': 12}\n",
      "Ġday {'eka': 13, 'Ġwig': 12, 'Ġsnow': 12, 'Ġwagon': 12, 'Ġprec': 12, 'Ġunderwear': 12}\n",
      "ie {'Ġbeaut': 13, 'Ġhandsome': 13, 'XM': 12, 'beaut': 12, 'Ġimmutable': 12, 'ĠLudwig': 11}\n",
      "written {'ĠVictorian': 12, 'ĠHayden': 12, 'ĠVictoria': 12, 'ĠSchneider': 12, 'ĠCris': 12, 'Ġbiologist': 12}\n",
      "Ġtomorrow {'Ġloads': 13, 'loads': 12, 'Ġunve': 12, 'ysics': 12, 'Ġunveil': 12, 'Sense': 12}\n",
      "lost {'Ġauditor': 14, 'ĠPubMed': 12, 'Ġpractitioner': 12, 'ĠAuditor': 12, 'keye': 12, 'ĠAudit': 12}\n",
      "oss {'Ġcurrently': 14, 'Currently': 13, 'ĠCurrently': 13, 'currently': 12, 'Ġvisually': 12, 'Ġantiqu': 11}\n",
      "sac {'Ġsnacks': 13, 'Ġmotives': 12, 'Ġnodes': 12, 'Ġguests': 12, 'Ġcaucuses': 12, 'idays': 12}\n",
      "nd {'ĠJapan': 13, 'Japan': 12, 'Ġindigenous': 12, 'Ġarter': 12, 'Ġambient': 12, 'ĠGilbert': 12}\n",
      "your {'ĠBRE': 13, 'ĠRevel': 12, 'ĠGrave': 12, 'Domin': 12, 'ĠDomin': 12, 'ĠBloom': 12}\n",
      "eye {'ĠConference': 14, 'Ġconference': 12, 'Ġwedding': 12, 'ĠMET': 12, 'Ġsemblance': 12, 'Ġacademy': 12}\n",
      "piece {'Ġcampus': 13, 'ĠAngel': 13, 'femin': 12, 'ĠANGEL': 12, 'Ġchick': 12, 'Ġclimax': 11}\n",
      "line {'Ġclust': 13, 'Ġclassification': 13, 'Ġparchment': 12, 'Ġconsultant': 12, 'Ġdatabase': 12, 'Ġcooperative': 12}\n",
      "hey {'REL': 13, 'EL': 13, 'ĠREL': 13, 'BIL': 12, 'ĠQuartz': 12, 'vel': 12}\n",
      "reci {'Ġaspect': 13, 'Ġaspects': 12, 'ĠThankfully': 12, 'Ġholders': 12, 'ĠConference': 12, 'Ġembarrassment': 12}\n",
      "ones {'Ġbrowsers': 13, 'ĠKurds': 12, 'Ġblankets': 12, 'Ġbeginnings': 12, 'ĠCanadiens': 12, 'ĠWells': 12}\n",
      "generated {'ĠLuxembourg': 14, 'Ġbystanders': 13, 'ĠANG': 12, 'ALT': 12, 'ĠJeff': 12, 'Ġcollaborators': 11}\n",
      "lam {'ks': 13, 'uchs': 12, 'ĠForums': 12, 'ĠLebanese': 12, 'pees': 12, 'KS': 12}\n",
      "Ġmultipl {'Ġappeals': 13, 'Ġappell': 12, 'Ġillegitimate': 12, 'Ġmisinformation': 12, 'Ġpregnancies': 12, 'Ġinteractions': 12}\n",
      "lead {'pp': 13, 'ULL': 13, 'IZE': 12, 'LL': 12, 'ĠCLICK': 12, 'LP': 12}\n",
      "acs {'Ġace': 13, 'Ġdecentral': 13, 'ĠRec': 12, 'Ġunpre': 12, 'ĠLC': 12, 'ĠIPO': 11}\n",
      "lie {'Ġkinderg': 13, 'ĠConc': 12, 'Ġprim': 12, 'Ġemph': 12, 'Prim': 12, 'ĠMig': 12}\n",
      "aper {'Ġdefic': 14, 'Ġarter': 12, 'Ġcass': 12, 'Ġpregnancies': 12, 'Ġapprehens': 12, 'ĠMyster': 12}\n",
      "Ġrecommendations {'ĠAlex': 13, 'ĠDegree': 13, 'amn': 12, 'Ġdegree': 12, 'Ġinspector': 12, 'helm': 11}\n",
      "bur {'Ġuniversity': 14, 'ĠQueensland': 12, 'ĠPEOPLE': 12, 'Ġfederation': 12, 'Ġnation': 12, 'äºº': 12}\n",
      "eps {'ierrez': 13, 'ĠValhalla': 12, 'ĠHEL': 12, 'Ġcontinental': 12, 'Saharan': 12, 'ahl': 12}\n",
      "esa {'ĠBakr': 13, 'Ġlikewise': 12, 'pic': 12, 'Certainly': 12, 'ĠBeacon': 12, 'prim': 12}\n",
      "eg {'ĠFitzpatrick': 13, 'Ġgrav': 13, 'Ġvocal': 12, 'Ġsund': 12, 'Ġelder': 12, 'Ġbast': 12}\n",
      "anes {'Ġdeck': 12, 'deck': 12, 'Ġescaping': 12, 'Ġdecks': 12, 'ĠMonteneg': 12, 'Ġreversal': 12}\n",
      "aux {'Ġpitched': 13, 'ĠPractices': 12, 'Ġstaggered': 12, 'Ġspat': 12, 'Ġshader': 12, 'Ġimportant': 12}\n",
      "iet {'Ġtrove': 13, 'ĠDVDs': 12, 'Ġconscious': 12, 'ĠImag': 12, 'ĠIvy': 12, 'Ġmosa': 12}\n",
      "choice {'Ġsquad': 12, 'ĠGuard': 12, 'Ġrim': 12, 'Ġguard': 12, 'Ġsund': 12, 'ĠGuards': 12}\n",
      "ten {'Ġballot': 14, 'Ġsmiles': 12, 'Ġballots': 12, 'Ġmarriages': 12, 'Ġapologies': 12, 'Ġapology': 12}\n",
      "comp {'Ġray': 12, 'Ġrays': 12, 'Ġweights': 12, 'Ġmammals': 12, 'Ġgay': 12, 'ĠBraves': 12}\n",
      "period {'ĠContracts': 12, 'Ġconsortium': 12, 'Ġguests': 12, 'Ġcouncil': 12, 'ĠConsortium': 12, 'Ġsinners': 12}\n",
      "Alt {'ĠTrop': 13, 'reddit': 13, 'school': 12, 'Ġrecess': 12, 'Ġcaucus': 12, 'ĠSCHOOL': 12}\n",
      "anti {'Ġlaptops': 12, 'ECD': 12, 'ĠEmbassy': 12, 'ĠCPUs': 12, 'Ġbackgrounds': 12, 'Ġmotivations': 12}\n",
      "count {'Ġcomic': 13, 'Ġcartel': 13, 'Ġmarine': 12, 'Ġpancreat': 12, 'Ġvein': 12, 'aler': 11}\n",
      "stand {'Ġconserv': 13, 'Ġviable': 13, 'atable': 12, 'Ġingestion': 12, 'Ġilliter': 11, 'Ġpregnant': 11}\n",
      "Ġ:: {'Ġpolymer': 13, 'Ġauthorization': 12, 'iculty': 12, 'Ġdifficulty': 12, 'Ġcosting': 12, 'Ġenvoy': 11}\n",
      "rid {'ĠCarib': 12, 'Ġdurable': 12, 'ĠGOLD': 12, 'Ġsizable': 12, 'quel': 12, 'Ġhappiest': 12}\n",
      "ons {'jp': 13, 'ĠKob': 12, 'PH': 12, 'ĠGi': 12, 'ĠEB': 12, 'ĠIMAGES': 12}\n",
      "ibel {'Ġyounger': 13, 'Ġwrink': 12, 'Ġfounders': 12, 'Ġolder': 12, 'Ġbelongs': 12, 'Ġyoung': 12}\n",
      "Ġourselves {'zel': 13, 'Ġdonkey': 12, 'uci': 12, 'orter': 12, 'grain': 12, 'illary': 12}\n",
      "Ġtele {'ĠWen': 13, 'Ġhome': 12, 'Home': 12, 'ĠHed': 12, 'home': 12, 'Miami': 12}\n",
      "hold {'Ġreel': 13, 'Ġprojector': 12, 'Ġhoop': 12, 'Ġstraps': 12, 'Ġgam': 12, 'Ġheaders': 12}\n",
      "fat {'ĠGrave': 12, 'live': 12, 'Ġoriginate': 12, 'Ġaudiences': 12, 'Ġhex': 12, 'Ġmortals': 12}\n",
      "Ġjoint {'ĠFarming': 13, 'forcing': 12, 'cing': 12, 'Ġfreaking': 12, 'posing': 12, 'ouncing': 12}\n",
      "eff {'Ġheights': 13, 'Ġbridges': 13, 'Ġbuttons': 12, 'Ġhots': 12, 'Ġforeground': 11, 'Ġbackgrounds': 11}\n",
      "running {'ĠTr': 14, 'Ġtr': 12, 'Ġobserv': 12, 'Tr': 12, 'ĠNotice': 12, 'Ġpneum': 12}\n",
      "eas {'Ġpu': 13, 'Ġposs': 13, 'Ġcan': 12, 'Ġkan': 12, 'Ġbourgeois': 12, 'enburg': 12}\n",
      "ieg {'ĠNept': 13, 'fml': 12, 'odd': 12, 'gly': 12, 'Ġcellul': 12, 'onew': 11}\n",
      "ois {'Ġconqu': 14, 'Ġker': 12, 'Ġgam': 12, 'Ġfusion': 12, 'Ġsavior': 12, 'Ġoutgoing': 11}\n",
      "AI {'Ġleft': 12, 'ĠKuwait': 12, 'femin': 12, 'ĠLeah': 12, 'left': 12, 'Ġleftists': 12}\n",
      "ize {'Ġnascent': 13, 'Ġbasically': 12, 'Ġminimal': 12, 'Ġsizeable': 12, 'Ġessentially': 12, 'ĠSal': 12}\n",
      "iry {'Ġunfounded': 15, 'Ġnaturally': 12, 'Naturally': 12, 'Ġfoundational': 12, 'Ġsynthetic': 12, 'Ġworthy': 11}\n",
      "č {'Ġformidable': 13, 'Ġfairly': 13, 'Ġlate': 12, 'Ġinsanely': 12, 'Ġmic': 12, 'ĠPARK': 11}\n",
      "Ġdimension {'Ġexperiments': 13, 'opers': 12, 'Ġbriefings': 12, 'Ġplots': 12, 'Ġoperations': 12, 'comings': 12}\n",
      "go {'ĠBund': 13, 'Ġausp': 13, 'Fil': 12, 'ĠBu': 12, 'ĠLag': 12, 'ĠLiga': 11}\n",
      "omb {'GGGG': 14, 'ilib': 13, 'PRES': 13, 'ĠMSM': 11, 'Ġcharcoal': 11, 'PLE': 11}\n",
      "Ġorth {'Ġindicted': 14, 'Ġwives': 12, 'Ġevidenced': 12, 'Ġsentenced': 12, 'Ġoccupations': 12, 'Ġcharges': 11}\n",
      "eno {'ĠAnchorage': 12, 'ĠFla': 12, 'ĠTorah': 12, 'Ġderiv': 12, 'Fla': 12, 'ISION': 12}\n",
      "Ġnic {'Northern': 13, 'ĠNorthern': 13, 'Clark': 12, 'espie': 12, 'ablishment': 12, 'ÂłÂłÂłÂłÂłÂłÂłÂł': 11}\n",
      "been {'Ġhasn': 12, 'Ġha': 12, 'ĠHAS': 12, 'Ġhaven': 12, 'ĠHa': 12, 'ĠHAVE': 12}\n",
      "Ġacqu {'Ġoverwrite': 13, 'Ġtherape': 12, 'Ġhealing': 12, 'Ġmodifiers': 12, 'Ġplung': 12, 'Ġpunished': 12}\n",
      "(* {'Ġreact': 13, 'Ġcooperate': 13, 'Ġvocal': 12, 'Ġarrang': 12, 'cook': 12, 'Ġsplit': 12}\n",
      "into {'ĠRCMP': 12, 'GD': 12, 'ĠSlip': 12, 'Integ': 12, 'Ġslip': 12, 'Ġbreakthrough': 12}\n",
      "ven {'vale': 14, 'ĠNB': 12, 'ĠSeaf': 12, 'marg': 12, 'Ġmindless': 12, 'Ġveiled': 12}\n",
      "iva {'ONT': 13, 'Ġpremise': 13, 'Font': 13, 'ĠTotem': 12, 'ear': 12, 'athom': 11}\n",
      "ble {'Ġgrotesque': 12, 'Ġsubconscious': 12, 'Classic': 12, 'Ġiconic': 12, 'Ġlegendary': 12, 'ĠMonstrous': 12}\n",
      "ucc {'endium': 12, 'paper': 12, 'Ġpaper': 12, 'epad': 12, 'ĠKatz': 12, 'Ġcounterpart': 12}\n",
      "cast {'Ġglasses': 14, 'ĠMariners': 12, 'ĠPrairie': 12, 'ĠBerger': 12, 'Ġanarch': 12, 'ĠPiper': 12}\n",
      "Ġovernight {'eled': 13, 'themed': 12, 'Ġmad': 12, 'Ġintensified': 12, 'Ġspirited': 12, 'Ġwarranted': 12}\n",
      "online {'Ġassociation': 13, 'ĠCouncil': 12, 'Ġcouncil': 12, 'ĠAssociation': 12, 'ĠEmpress': 12, 'Ġresembling': 11}\n",
      "mob {'ĠCup': 12, 'ĠDesmond': 12, 'ĠLeague': 12, 'Ġcoll': 12, 'league': 12, 'ĠCerberus': 12}\n",
      "Ġdial {'ĠElectronic': 13, 'ĠExcellent': 12, 'fine': 12, 'Ġelectronic': 12, 'Ġfine': 12, 'ĠFine': 12}\n",
      "voice {'ĠChampionship': 12, 'ĠTournament': 12, 'ĠSpeak': 12, 'Ġcove': 12, 'Ġchampionship': 12, 'Ġsynd': 12}\n",
      "riv {'Ġslaves': 13, 'Ġenslaved': 13, 'Ġcamoufl': 12, 'Ġensl': 12, 'alis': 12, 'Ġnightmares': 11}\n",
      "FLAG {'Posts': 14, 'ĠPosts': 13, 'ĠDoe': 12, 'Ġfleets': 12, 'ĠBundle': 11, 'Ġposes': 11}\n",
      "hab {'Ġluckily': 13, 'ĠDEC': 13, 'DEC': 12, 'Ġdecriminal': 12, 'Dec': 12, 'dec': 12}\n",
      "imb {'Ġproposals': 13, 'MENTS': 13, 'Ġsuggestions': 12, 'IONS': 12, 'Ġpronouns': 11, 'Ġconventions': 11}\n",
      "Ġcommands {'London': 13, 'ĠLondon': 12, 'ĠChocolate': 12, 'ĠEdinburgh': 12, 'Ġexcitement': 12, 'Ġpython': 12}\n",
      "Active {'Ġmanuscript': 13, 'Ġworkshop': 12, 'Ġstorage': 12, 'Ġremain': 12, 'Ġmosquit': 12, 'Ġfeet': 12}\n",
      "nil {'isse': 12, 'Ġnoises': 12, 'Ġcookies': 12, 'Ġbright': 12, 'ĠEth': 12, 'Ġfolks': 12}\n",
      "tree {'Ġglim': 14, 'Ġcuisine': 12, 'Ġvisually': 12, 'Ġbeams': 12, 'Ġgazing': 11, 'Ġbunch': 11}\n",
      "ready {'ĠBorderlands': 13, 'ĠLabyrinth': 12, 'ivals': 12, 'Ġpipeline': 12, 'Ġpipelines': 12, 'APS': 12}\n",
      "index {'ĠJewish': 12, 'ĠJews': 12, 'Jews': 12, 'Ġhref': 12, 'Ġprimer': 12, 'ĠIrish': 12}\n",
      "case {'adequ': 12, 'Ġhealthy': 12, 'Kal': 12, 'Ġfairness': 12, 'Ġopacity': 12, 'ĠThankfully': 12}\n",
      "ial {'ĠLens': 13, 'Ġcardboard': 12, 'ĠKardashian': 12, 'Ġballoon': 12, 'Ġlens': 12, 'Ġmother': 12}\n",
      "ame {'ĠEsper': 12, 'Ġviolet': 12, 'Ġcircum': 12, 'ĠBritt': 12, 'Ġlest': 12, 'Ġfolks': 12}\n",
      "sun {'iatus': 14, 'ichick': 12, 'Ġjeans': 12, 'Ġaudiences': 12, 'Ble': 11, 'Ġamb': 11}\n",
      "Ġotherwise {'Ġwrongful': 13, 'ĠFrench': 12, 'Ġger': 12, 'Ġallowing': 12, 'Ġimproperly': 12, 'Ġpreventive': 11}\n",
      "Ġconnection {'cision': 12, 'Ġinsistence': 12, 'Ġconventions': 12, 'Ġdefinitions': 12, 'Ġdecency': 12, 'Ġdefinition': 12}\n",
      "rave {'ĠLeague': 14, 'ĠLunar': 12, 'Ġleague': 12, 'Ġclassical': 12, 'ĠRomantic': 12, 'League': 11}\n",
      "ĠYourself {'ĠTie': 13, 'bone': 12, 'ĠUI': 12, 'Role': 12, 'ĠBike': 12, 'Research': 12}\n",
      "asy {'Ġcomedic': 13, 'Ġsmokers': 12, 'ĠDefensive': 12, 'Ġcoy': 12, 'Ġtensions': 12, 'femin': 11}\n",
      "Ġearlier {'Ġstyled': 13, 'Ġproposed': 12, 'ĠProvided': 12, 'Ġprovided': 12, 'Ġevidenced': 12, 'Ġpopulated': 11}\n",
      "ure {'ĠFest': 13, 'Ġfest': 12, 'ĠPatt': 12, 'Ġrightly': 12, 'Fest': 12, 'Ġcrates': 12}\n",
      "ĠCounter {'Ġpreschool': 13, 'Ġantioxidants': 12, 'Ġears': 12, 'Ġdrawer': 12, 'Ġtitles': 12, 'Ġdefenseman': 11}\n",
      "mem {'Ġbuoy': 13, 'Ġmat': 12, 'beard': 12, 'Ġrig': 12, 'ĠEsper': 12, 'Ġbeacon': 12}\n",
      "opal {'ĠPax': 13, 'Ġundrafted': 13, 'ĠMAD': 12, 'onte': 12, 'Solid': 12, 'rued': 12}\n",
      "ier {'POR': 12, 'Kar': 12, 'Ġveter': 12, 'bool': 12, 'Ġbenz': 12, 'Ġcompan': 12}\n",
      "MD {'cultural': 12, 'zx': 12, 'Ġsocial': 12, 'Ġcultural': 12, 'hair': 12, 'ĠTYPE': 12}\n",
      "den {'Ġparchment': 13, 'ĠForsaken': 12, 'Ġpersever': 12, 'ĠDec': 12, 'Ġoutcry': 12, 'Ġperipher': 12}\n",
      "other {'Ġguitar': 13, 'Ġassailant': 12, 'Ġapplicant': 12, 'Ġjoystick': 12, 'Ġdifficulty': 12, 'Ġinstructor': 12}\n",
      "lines {'ĠHaram': 12, 'ĠNordic': 12, 'ĠScandinav': 12, 'Ġunintended': 12, 'Ġprim': 12, 'ĠSch': 12}\n",
      "AAA {'ĠFaul': 13, 'Nap': 12, 'Ġflu': 12, 'Ġhoax': 12, 'Ġsweats': 12, 'Ġrequ': 12}\n",
      "Ġsafely {'latable': 13, 'Ġcan': 12, 'ABLE': 12, 'ivable': 12, 'Ġadjustable': 12, 'Ġsustainable': 12}\n",
      "OC {'Ġensure': 12, 'Ġlast': 12, 'Ġinsufficient': 12, 'ufficient': 12, 'sufficient': 12, 'Ġstricter': 12}\n",
      "ability {'ĠKrypt': 12, 'asper': 12, 'ĠTamil': 12, 'ĠKarn': 12, 'ĠKiw': 12, 'ĠKau': 12}\n",
      "Ġexchange {'sensitive': 13, 'technical': 12, 'Ġdelicate': 12, 'mental': 12, 'inition': 12, 'ippery': 12}\n",
      "ax {'Ġimperfect': 13, 'ĠMonstrous': 13, 'ĠLaksh': 12, 'iguous': 12, 'Ġawkward': 11, 'Ġsimplest': 11}\n",
      "ge {'Ġtechnical': 13, 'Ġdiscreet': 12, 'ĠPhysical': 12, 'ĠTactical': 12, 'ĠConfeder': 12, 'Physical': 12}\n",
      "existing {'Ġpencil': 15, 'Ġpen': 13, 'ingle': 12, 'Ġdictionary': 11, 'ĠADD': 11, 'paper': 11}\n",
      "role {'ĠCoun': 13, 'Ġtreaty': 12, 'cert': 12, 'ĠPARK': 12, 'ĠTreaty': 12, 'ĠSCHOOL': 12}\n",
      "old {'ĠAur': 12, 'ĠAqu': 12, 'ĠKak': 12, 'ĠKH': 12, 'ĠBj': 12, 'ĠCass': 12}\n",
      "brain {'Ġarea': 12, 'ĠArea': 12, 'bie': 12, 'ĠTactical': 12, 'Area': 12, 'ĠHayden': 12}\n",
      "ND {'gaard': 14, 'lda': 13, 'Ġresilience': 12, '.}': 11, 'Ġgravitational': 11, 'Ġreally': 11}\n",
      "uman {'âĸ¬âĸ¬': 13, 'global': 13, 'ordial': 12, 'BU': 12, 'ĠHerald': 12, 'Global': 11}\n",
      "oke {'verett': 13, 'ĠEverett': 12, 'Ġpercept': 12, 'ĠJose': 12, 'ĠMike': 12, 'ĠRafael': 11}\n",
      "Va {'ĠVentures': 13, 'Ġparticipants': 12, 'Ġdifficulties': 12, 'oggles': 12, 'ĠMoonlight': 11, 'Ġhazards': 11}\n",
      "hal {'Ġsimplest': 13, 'Ġproposals': 12, 'Ġhappiest': 12, 'Ġgreater': 12, 'Ġhighest': 12, 'Ġgreatest': 11}\n",
      "hr {'quart': 14, 'Ġbay': 13, 'Ġpopul': 12, 'bay': 12, 'Ġcockpit': 11, 'Ġrecol': 11}\n",
      "sing {'Ġseemingly': 12, 'Ġadore': 12, 'Ġdespise': 12, 'Ġcher': 12, 'Ġsymp': 12, 'Ġhateful': 12}\n",
      "easy {'ĠEEG': 13, 'ĠGoPro': 12, 'Coll': 12, 'ĠLocke': 12, 'ĠJavaScript': 12, 'aeus': 11}\n",
      "wall {'pees': 14, 'ĠBrav': 12, 'sha': 12, 'mys': 12, 'Ġbrav': 12, 'ĠFifty': 11}\n",
      "inc {'ĠNeuro': 12, 'Ġposterior': 12, 'ĠLabrador': 12, 'Ġeyes': 12, 'ĠMalays': 12, 'Ġingestion': 12}\n",
      "aba {'Ġpartnering': 12, 'Ġpreliminary': 12, 'outhern': 12, 'iminary': 12, 'irable': 12, 'isal': 11}\n",
      "Ġflow {'Ġinforming': 13, 'ĠAtlanta': 12, 'ĠGlasgow': 12, 'ĠEdinburgh': 12, 'Ġadaptations': 12, 'Ġenabling': 11}\n",
      "Tok {'BI': 13, 'PT': 13, 'ĠPAL': 12, 'LP': 12, 'ATE': 12, 'Po': 11}\n",
      "Ġcat {'Ġlending': 13, 'Ġliquids': 12, 'Ġenvironmentalists': 12, 'Ġfurnace': 12, 'Ġskinny': 12, 'Ġcalcium': 12}\n",
      "ket {'ÙĲ': 12, 'Ġ55': 12, 'Ġ60': 12, 'Ġ59': 12, 'è¡': 12, 'Ġ54': 12}\n",
      "req {'Ġcerv': 13, 'Ġsaline': 12, 'Ġnasal': 12, 'Ġanal': 12, 'ĠZy': 12, 'Ġvaginal': 12}\n",
      "care {'terior': 12, 'Ġinsiders': 12, 'Ġforeground': 12, 'ĠTurkey': 12, 'ĠArab': 12, 'Arab': 12}\n",
      "dog {'ĠBrawl': 12, 'ĠLeap': 12, 'ĠLinear': 12, 'ĠLust': 12, 'Ġgreed': 12, 'gest': 11}\n",
      "Qu {'ĠPage': 12, 'Ġerrors': 12, 'ĠJazz': 12, 'Ġqueries': 12, 'ĠJean': 12, 'Ġsheet': 12}\n",
      "cul {'Ġemerging': 13, 'Ġemerge': 12, 'Ġovertly': 12, 'Ġdisappear': 12, 'Ġemerges': 12, 'Ġconver': 12}\n",
      "chain {'Ġadherent': 13, 'Ġpurs': 12, 'Ġstrugg': 12, 'Ġampl': 12, 'Ġrebell': 12, 'Ġbab': 11}\n",
      "FI {'ĠNUM': 14, 'ĠFP': 13, 'ĠINT': 12, 'NUM': 12, 'Ġthousands': 11, 'Ġnone': 11}\n",
      "reen {'ĠUniversity': 12, 'University': 12, 'ĠTurks': 12, 'ĠHardcore': 12, 'Gr': 12, 'istle': 12}\n",
      "ork {'ĠDunn': 13, 'ĠMER': 12, 'ĠTPP': 12, 'Ġpots': 12, 'ĠCODE': 12, 'ĠCAS': 12}\n",
      "rc {'ĠEdu': 13, 'Ġcx': 12, 'Ġsolely': 12, 'ĠHyd': 12, 'Ġmainly': 12, 'ĠCorporate': 11}\n",
      "environment {'ĠReps': 13, 'ĠMothers': 12, 'ĠMinistry': 12, 'ĠPartners': 12, 'ĠFramework': 12, 'ĠLeague': 12}\n",
      "ief {'Ġbelongings': 13, 'Ġpossessions': 12, 'Ġtwent': 12, 'Ġpige': 12, 'ĠReincarn': 12, 'Raven': 12}\n",
      "ret {'Ġnoticeable': 12, 'reet': 12, 'Ġnoticeably': 12, 'Ġiconic': 12, 'Ġretirees': 12, 'ĠCup': 12}\n",
      "rote {'Ġreadings': 13, 'Ġreading': 13, 'Ġcatching': 13, 'atching': 12, 'ĠPublications': 12, 'catching': 11}\n",
      "bus {'Ġprett': 12, 'ĠkW': 12, 'Ġdiction': 12, 'Ġresemb': 12, 'Ġlatent': 12, 'Ġfootage': 12}\n",
      "oes {'Ġscept': 13, 'Ġupbeat': 12, 'Ġgorgeous': 12, 'Ġhopeless': 12, 'Ġobsc': 12, 'Ġtwent': 12}\n",
      ":/ {'Ġforgot': 13, 'Ġsung': 12, 'Ġdisappointed': 12, 'Ġsang': 12, 'erved': 12, 'Ġpolite': 12}\n",
      "enh {'arb': 13, 'carb': 12, 'ĠEXT': 12, 'Ġfoundations': 12, 'Ġhotter': 12, 'ARB': 11}\n",
      "meta {'ĠLup': 13, 'Hillary': 12, 'Columb': 12, 'Bloomberg': 12, 'ĠHillary': 12, 'Ell': 11}\n",
      "log {'Ġcozy': 14, 'ĠSons': 13, 'Ġqueer': 12, 'yx': 11, 'Ġvictims': 11, 'Ġcoales': 11}\n",
      "vr {'Ġleader': 13, 'Ġcle': 12, 'Ġlast': 12, 'Ġcu': 12, 'Ġpe': 12, 'Ġdecad': 12}\n",
      "iter {'ĠLamp': 13, 'olesc': 12, 'Ġpre': 12, 'oir': 12, 'ĠPref': 12, 'Ġstockp': 11}\n",
      "test {'dx': 13, 'Ġinnoc': 13, 'Ġdx': 12, 'Ġcrates': 12, 'Ġqueues': 11, 'Series': 11}\n",
      "star {'Ġscant': 13, 'ĠBakr': 12, 'Ġsmall': 12, 'ĠKepler': 12, 'Ġabundant': 12, 'Ġbrightly': 12}\n",
      "ded {'Ġlact': 13, 'Ġveil': 12, 'ĠBL': 12, 'boost': 12, 'Ġcraz': 12, 'ĠDomin': 11}\n",
      "Âł {'Ġready': 13, 'ĠJean': 13, 'Ġvert': 12, 'ĠClaude': 12, 'ĠBlake': 11, 'ĠAnthony': 11}\n",
      "Ut {'stage': 12, 'Ġstash': 12, 'Ġportfolio': 12, 'place': 12, 'ĠInstitute': 12, 'level': 12}\n",
      "umb {'Ġiconic': 12, 'LIST': 12, 'Ġinnate': 12, 'Ġpresence': 12, 'KK': 12, 'anth': 12}\n",
      "usha {'ĠAlc': 13, 'illo': 13, 'ĠChandler': 12, 'ĠSophia': 12, 'ĠDS': 11, 'ĠBeta': 11}\n",
      "ĠSun {'Ġhastily': 13, 'Ġjazz': 12, 'Ġvigorous': 12, 'Ġsolely': 12, 'Ġattic': 12, 'Ġfurnace': 11}\n",
      "Ċ {'Ġinternet': 12, 'ĠFairy': 12, 'ĠInternet': 12, 'Ġgrid': 12, 'Ġlaboratory': 12, 'Ġladies': 12}\n",
      "u {'ĠBahamas': 13, 'Ġimpractical': 12, 'Ġunrealistic': 12, 'Ġdiscreet': 12, 'Ġhorizon': 12, 'Ġobvious': 12}\n",
      "san {'ĠBugs': 12, 'ĠWiki': 12, 'Ġaudience': 12, 'ĠClojure': 12, 'Ġaudiences': 12, 'Ġstudies': 12}\n",
      "sense {'ĠBakr': 14, 'Ġlact': 14, '970': 12, 'ĠKuwait': 12, 'Ġsteak': 11, 'Ġ115': 11}\n",
      "ates {'ĠWhereas': 12, 'Ġunfamiliar': 12, 'Compar': 12, 'Ġartificial': 12, 'amiliar': 12, 'Ġnonexistent': 12}\n",
      "lif {'ĠMyth': 14, 'ĠTet': 12, 'Ġmixture': 12, 'Ġclut': 12, 'Mut': 12, 'ĠTol': 12}\n",
      "vs {'Ġimportant': 13, 'Ġhappiest': 12, 'Ġbu': 12, 'ĠNost': 12, 'initial': 12, 'Ġsatisf': 11}\n",
      "bowl {'DES': 13, 'ANN': 12, 'ĠPascal': 12, 'GU': 12, 'ĠREC': 12, 'ĠGU': 12}\n",
      "kh {'lass': 12, 'ĠTSA': 12, 'Ġhuman': 12, 'Ġcharter': 12, 'Ġhumans': 12, 'Ġfrontier': 12}\n",
      "order {'camp': 13, 'ĠCamp': 13, 'Ġsubscrib': 12, 'Ġoblig': 12, 'Ġambassadors': 11, 'Ġbun': 11}\n",
      "imi {'Ġclustered': 14, 'Ġstrapped': 13, 'Ġembedded': 12, 'Ġstereotypical': 12, 'Ġtagged': 12, 'Ġartif': 11}\n",
      "ana {'ĠSaudi': 12, 'Saudi': 12, 'Ġpregn': 12, 'ĠRei': 12, 'anmar': 12, 'ĠHuma': 12}\n",
      "ange {'arters': 12, 'Ġlacked': 12, 'ĠNightmares': 12, 'ĠWilderness': 12, 'Ġanomalies': 12, 'Ġlacking': 12}\n",
      "craft {'Ġrehearsal': 12, 'Ġreinforce': 12, 'ĠJung': 12, 'Ġgain': 12, 'interest': 12, 'Ġaffirm': 12}\n",
      "side {'Ġfeast': 12, 'parent': 12, 'Ġadherents': 12, 'Ġphylogen': 12, 'Ġcuisine': 12, 'Ġgrandparents': 12}\n",
      "wave {'ĠKurds': 12, 'ĠDACA': 12, 'Ġstandards': 12, 'Ġcasualties': 12, 'Ġhardships': 12, 'Ġbishops': 12}\n",
      "R {'Ġforest': 13, 'Ġvert': 13, 'Ġmosquit': 13, 'Ġforests': 12, 'Ġairport': 12, 'forest': 11}\n",
      "har {'Ġcomple': 13, 'Ġreference': 12, 'ĠPixel': 12, 'ĠTaj': 12, 'Ġqueer': 12, 'Ġpeach': 12}\n",
      "Ġfl {'ĠRestore': 12, 'Ġpromot': 12, 'Ġinsur': 12, 'Ġrestore': 12, 'driving': 12, 'Ġdriving': 12}\n",
      "chi {'ĠBrave': 13, 'ĠPER': 13, 'Ġboarding': 12, 'ĠMB': 12, 'Ġboarded': 12, 'PER': 12}\n",
      "oom {'ubb': 14, 'FOX': 13, 'ĠXIII': 12, 'ĠSX': 12, 'VC': 11, 'ĠTories': 11}\n",
      "oca {'ett': 14, 'ETS': 13, 'ets': 12, 'et': 12, 'nox': 11, 'auc': 11}\n",
      "sa {'shr': 13, 'ĠShim': 12, 'ĠKum': 12, 'Ġheter': 12, 'wal': 12, 'Ġqueer': 11}\n",
      "dem {'Ġprud': 13, 'BL': 12, 'ex': 12, 'ĠBL': 12, 'Ġex': 11, 'Ġbl': 11}\n",
      "Ġlit {'pay': 13, 'ĠPay': 13, 'Ġpay': 12, 'ĠGive': 12, 'ĠPaid': 11, 'ĠIdle': 11}\n",
      "Ġrum {'uberty': 13, 'biology': 12, 'Ġbiologists': 12, 'Ġscientists': 11, 'ublic': 11, 'Ġrefund': 11}\n",
      "slow {'ĠChile': 12, 'ĠReact': 12, 'mber': 12, 'ĠBahrain': 12, 'ĠChaser': 12, 'Bloom': 12}\n",
      "Ġdemand {'helle': 12, 'ĠCastle': 12, 'ĠBelle': 12, 'Andy': 12, 'ĠAndy': 12, 'ĠBurton': 12}\n",
      "pc {'ĠGlover': 13, 'ĠJaguars': 12, 'wolves': 12, 'ĠTimbers': 12, 'Ġrenders': 12, 'ĠHughes': 12}\n",
      "Ġy {'Ġpaying': 12, 'Ġrepaid': 12, 'Ġgentlemen': 12, 'Ġrestoring': 12, 'Ġresponding': 12, 'Ġequitable': 12}\n",
      "Qual {'bag': 14, 'Ġbag': 13, 'Ġveil': 12, 'ĠBag': 12, 'Ġeve': 12, 'Label': 11}\n",
      "param {'Ġdram': 13, 'İĭ': 13, 'ĠBurnett': 12, 'ĠGranger': 12, 'Ġdeliber': 11, 'ĠBecker': 11}\n",
      "cry {'Ġguests': 13, 'Ġcompanions': 13, 'ĠFal': 12, 'Ġclusters': 12, 'files': 12, 'Ġfilms': 11}\n",
      "pe {'ĠMalays': 13, 'Ġmice': 12, 'ĠIsraelis': 12, 'Ġreefs': 12, 'Ġbiscuits': 11, 'ĠScots': 11}\n",
      "SA {'Ġphot': 13, 'femin': 12, 'Ġhinted': 12, 'ĠGawker': 12, 'ĠFemales': 11, 'ampires': 11}\n",
      "psy {'dyl': 13, 'ĠCovenant': 13, 'ĠLily': 12, 'Ġdick': 12, 'bil': 11, 'ĠDad': 11}\n",
      "fire {'1007': 12, 'ĠEmma': 12, 'Ġtwelve': 12, 'Ġ136': 12, 'ĠASCII': 12, 'ĠXML': 12}\n",
      "pse {'quet': 13, 'Ġliver': 13, 'ĠJasper': 12, 'Ġdens': 12, 'Ġdiving': 11, 'gment': 11}\n",
      "sent {'ĠBalance': 12, 'Ġcushion': 12, 'balance': 12, 'ĠREL': 12, 'Ġbalance': 12, 'REL': 12}\n",
      "appro {'Ġreluctance': 12, 'Ġlovers': 12, 'perors': 12, 'Ġperceptions': 12, 'acons': 11, 'Ġcosmetics': 11}\n",
      "vic {'Ġprecious': 12, 'Ġfounders': 12, 'Ġminors': 12, 'Ġvaluable': 12, 'Ġsurprisingly': 12, 'Ġscholarly': 12}\n",
      "eth {'EL': 13, 'IST': 12, 'ĠHOR': 12, 'bor': 12, 'ById': 12, 'ĠLEVEL': 11}\n",
      "cm {'Ġveget': 12, 'Ġterrestrial': 12, 'Ġland': 12, 'ĠKahn': 12, 'ĠGlass': 11, 'ĠGur': 11}\n",
      "or {'Ġappre': 13, 'ĠFIL': 12, 'ĠCOP': 12, 'Ġimper': 12, 'Ġbikini': 12, 'Ġappreci': 11}\n",
      "DP {'Tes': 12, 'ĠNEC': 12, 'ĠTes': 12, 'isal': 12, 'ĠVaj': 12, 'ĠSEC': 12}\n",
      "ale {'Ġdefinitive': 12, 'Ġarithmetic': 12, 'Ġsurely': 12, 'Ġcertainly': 12, 'Ġdevelopments': 12, 'ettlement': 12}\n",
      "search {'please': 13, 'FIL': 12, 'VL': 12, 'ĠFIL': 12, 'ĠWebb': 11, 'cl': 11}\n",
      ">( {'ureen': 13, 'arie': 12, 'Larry': 12, 'ĠLarry': 12, 'Susan': 12, 'ĠLiz': 12}\n",
      "uses {'Ġisland': 12, 'ĠSpani': 12, 'Ġbrist': 12, 'Ġsadd': 12, 'ĠLeague': 12, 'Ġdissu': 11}\n",
      "gs {'Ġhumankind': 13, 'Ġfreshman': 12, 'ĠMankind': 12, 'ĠJavier': 12, 'ĠJacksonville': 12, 'ĠMAN': 12}\n",
      "pen {'ĠLU': 13, 'ĠBUR': 12, 'ĠHUN': 12, 'ĠLAPD': 12, 'BUR': 11, 'ĠGL': 11}\n",
      "cycles {'ĠBlend': 13, 'Ġblend': 13, 'Ġjoint': 12, 'Ġblends': 12, 'Ġherd': 12, 'Ġmixture': 11}\n",
      "vind {'Ġseem': 13, 'Ġseems': 13, 'Ġclips': 12, 'Ġclimax': 12, 'ĠClip': 12, 'ĠSeems': 12}\n",
      "ital {'ĠTelevision': 13, 'ĠVert': 13, 'Ġvert': 13, 'Ġbelong': 11, 'Ġbelongs': 11, 'Ġvictims': 11}\n",
      "van {'Ġvenerable': 13, 'Ġbenef': 12, 'Ġpast': 12, 'Ġoxygen': 12, 'igham': 12, 'ptic': 11}\n",
      "Ġsurface {'agons': 12, 'Ġembassy': 12, 'Ġgardens': 12, 'Ġkitchens': 12, 'ĠBridges': 12, 'assies': 12}\n",
      "est {'Ġpract': 13, 'Ġfil': 13, 'Ġconce': 12, 'ĠSpr': 12, 'Ġadherent': 12, 'Ġappl': 11}\n",
      "ead {'Ġemerging': 14, 'Ġacknowled': 13, 'Ġende': 12, 'Ġemerge': 12, 'Ġmention': 11, 'Ġrecogn': 11}\n",
      "wat {'Ġensu': 13, 'ĠLu': 12, 'isexual': 12, 'ĠKurds': 12, 'ĠEllis': 12, 'Ġoverweight': 12}\n",
      "ire {'ĠIX': 13, 'Thirty': 13, 'ixty': 12, 'Ġninth': 12, 'ĠThirty': 12, 'KY': 11}\n",
      "pill {'ĠPets': 12, 'ĠEB': 12, 'ĠGuests': 12, 'Ġguests': 12, 'gs': 12, 'ĠBanks': 12}\n",
      "ill {'Ġgigg': 13, 'Ġrelaxation': 13, 'Ġpurse': 12, 'Ġjuxtap': 11, 'ĠFG': 11, 'ilipp': 11}\n",
      "dor {'Ġseconds': 13, 'Ġthirds': 12, 'Ġbatters': 12, 'seconds': 12, 'Ġdoubles': 11, 'Ġballs': 11}\n",
      "ions {'ĠFernandez': 12, 'ĠStefan': 12, 'ĠJuliet': 12, 'ĠTeresa': 12, 'ĠSister': 12, 'ĠSophie': 12}\n",
      "Ġspaces {'Ġfools': 13, 'Ġterritories': 12, 'Ġsurrounds': 12, 'Ġvillages': 12, 'Ġtroop': 11, 'Ġneighbours': 11}\n",
      "ep {'ĠBeacon': 12, 'ĠHopkins': 12, 'Ġguardians': 12, 'spot': 12, 'Ġpoised': 12, 'Spot': 11}\n",
      "dep {'ĠLive': 12, 'live': 12, 'Live': 12, 'ĠLIVE': 12, 'Ġlive': 12, 'Ġlives': 12}\n",
      "iers {'complex': 12, 'Ġolig': 12, 'Ġguys': 12, 'ĠRodrigo': 12, 'Ġcomplex': 12, 'Ġcolossal': 11}\n",
      "cap {'ĠLEG': 12, 'ĠGD': 12, 'Eth': 12, 'Ġgay': 12, 'ĠLeague': 12, 'ĠGlover': 11}\n",
      "Ġdesc {'Ġderog': 12, 'science': 12, 'Ġsatir': 12, 'Ġray': 12, 'Ġmul': 12, 'Ġblasp': 12}\n",
      "Mon {'Ġmonks': 12, 'ZE': 12, 'roup': 12, 'Ġblo': 12, 'ĠGAM': 12, 'Ġnetwork': 12}\n",
      "ĠLy {'quad': 12, 'asu': 12, 'Ġcomfortable': 12, 'Ġcumbersome': 12, 'Ġattended': 11, 'Ġpreferable': 11}\n",
      "request {'Ġhumor': 13, 'Ġprud': 12, 'ĠCoff': 12, 'Special': 12, 'Ġbold': 12, 'Ġobst': 11}\n",
      "zen {'DVD': 12, 'ĠInstagram': 12, 'ĠFACE': 12, 'Age': 12, '713': 12, 'USE': 11}\n",
      "keys {'ĠMeng': 13, 'ĠGulf': 12, 'ĠLey': 12, 'ĠGrail': 12, 'ĠAmpl': 12, 'Ġfifth': 11}\n",
      "soft {'ĠTS': 13, 'Ġvers': 12, 'Ġts': 12, 'ĠHorde': 12, 'LCS': 11, 'ĠKats': 11}\n",
      "arm {'Ġsevent': 12, 'Ġrooft': 12, 'Ġscreenplay': 12, 'Ġplugins': 12, 'Ġwidespread': 12, 'Ġabundant': 11}\n",
      "round {'school': 13, 'Mat': 12, 'fram': 12, 'frame': 12, 'ĠBraz': 11, 'apult': 11}\n",
      "s {'Ġzone': 12, 'Ġtimeout': 12, 'Ġbikini': 12, 'Ġseismic': 12, 'Ġwaterfall': 12, 'Ġresilient': 11}\n",
      "ives {'Ġoutsiders': 12, 'Researchers': 12, 'Ġoutsider': 12, 'Ġcapacitor': 12, 'workers': 11, 'ĠResearchers': 11}\n",
      "ase {'Ġmothers': 12, 'ĠCoinbase': 12, 'ĠAugusta': 12, 'Ġsisters': 12, 'Ġactresses': 11, 'Ġbankers': 11}\n",
      "hered {'BILL': 12, 'UME': 12, 'ĠDate': 12, 'NBC': 12, 'UX': 11, 'BU': 11}\n",
      "stead {'Ġcool': 12, 'Ġsafeguards': 12, 'Ġshops': 12, 'Ġknowledgeable': 12, 'ĠCountdown': 12, 'Ġgcc': 11}\n",
      "fee {'ĠLac': 13, 'Ġvac': 12, 'ĠBreast': 12, 'ĠLap': 12, 'ĠKling': 12, 'ĠLag': 12}\n",
      "Ġend {'Ġillusions': 12, 'ĠFrances': 12, 'ĠNeville': 12, 'Ġcares': 12, 'Ġdesolate': 12, 'Ġframework': 11}\n",
      "Ãł {'Ġank': 13, 'illi': 13, 'Ġdetainees': 12, 'ĠMari': 12, 'ĠBanks': 11, 'Ġchimpanzees': 11}\n",
      "ador {'Ġreceptive': 12, 'Ġmoderators': 12, 'Ġops': 12, 'Ġpret': 12, 'Ġexce': 11, 'ĠPediatrics': 11}\n",
      "uto {'ĠTele': 12, 'Ġtele': 12, 'ĠHB': 12, 'Http': 12, 'ĠSNAP': 12, 'ĠLing': 12}\n",
      "Ġvolley {'ĠSend': 12, 'Send': 12, 'send': 12, 'ĠFIRE': 12, 'Ġcough': 12, 'ĠSending': 11}\n",
      "ock {'ĠKats': 12, 'wcsstore': 12, 'Ġappearances': 12, 'lbs': 12, 'acons': 12, 'ĠMariners': 12}\n",
      "ops {'Ġbikini': 12, 'ĠLaurie': 12, 'ĠKuala': 12, 'ĠYellowstone': 12, 'ĠBeh': 12, 'Ġkilomet': 12}\n",
      "sample {'ĠFisher': 14, 'Ġincidental': 12, 'ĠIncident': 12, 'ĠTest': 12, 'Interest': 12, 'ĠBooth': 11}\n",
      "Ġretro {'Women': 12, 'ĠWomen': 12, 'ĠGirls': 12, 'Girls': 12, 'ĠAdds': 12, 'ĠMakes': 12}\n",
      "rav {'Ġconspicuous': 12, 'Ġnoticeable': 12, 'Ġclueless': 12, 'Ġknowledgeable': 12, 'Ġcomplaining': 12, 'ĠMalays': 12}\n",
      "physical {'Ġpens': 12, 'Ġpen': 12, 'ĠQUEST': 12, 'ĠFortress': 12, 'Ġdifficulties': 11, 'ĠLabyrinth': 11}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "het {'Ġwidespread': 14, 'idespread': 12, 'Ġample': 12, 'ĠDozens': 11, 'ĠGrimm': 11, 'ĠDepot': 11}\n",
      "gen {'Ġfederation': 12, 'Ġmodular': 12, 'Ġsizable': 12, 'Council': 12, 'ĠCouncil': 12, 'ĠLU': 11}\n",
      "acks {'Ġtwenty': 12, 'Ġ08': 12, 'Ġ1': 12, 'Ġ03': 12, 'Ġ07': 12, 'Ġ05': 12}\n",
      "ume {'Ġsl': 12, 'school': 12, 'pler': 12, 'Ġmoms': 12, 'eteria': 12, 'ĠTyler': 12}\n",
      "Ġcomparison {'Ġbears': 13, 'Ġwarrants': 12, 'Ġlawful': 12, 'Ġlions': 12, 'Ġlicences': 12, 'Ġbear': 11}\n",
      "most {'Ġlust': 12, 'ĠARE': 12, 'Ġnorms': 12, 'Ġnorm': 12, 'ĠDHS': 12, 'ĠLust': 12}\n",
      "Ã© {'artz': 12, 'Ġalk': 12, 'ethyst': 12, 'Ġpanties': 12, 'Ġthankfully': 12, 'Ġanesthesia': 12}\n",
      "oint {'Ġadip': 13, 'Ġerad': 12, 'Ġdissu': 12, 'ĠMPEG': 11, 'ĠCES': 11, 'Ġrecept': 11}\n",
      "zz {'jac': 12, 'ĠGlac': 12, 'ĠTac': 12, 'ĠVac': 12, 'gob': 12, 'ĠButt': 12}\n",
      "Ġbulk {'ĠAuthorization': 14, 'ĠAppropri': 13, 'ĠCooper': 12, 'Ġresources': 12, 'ĠChevrolet': 12, 'Ġcontribut': 11}\n",
      "ende {'ĠLegion': 13, 'Ġgarlic': 12, 'LP': 12, 'ĠFIL': 12, 'FIL': 12, 'Ġempathy': 11}\n",
      "ANT {'Ġaz': 13, 'Ġsquads': 12, 'Az': 12, 'Ġteams': 12, 'ĠTeams': 12, 'Users': 11}\n",
      "ner {'Ġearliest': 13, 'ĠAP': 12, 'umblr': 12, 'MAC': 12, 'ĠASCII': 11, 'ĠMAC': 11}\n",
      "onder {'Ġemergence': 13, 'Ġemerge': 12, 'Ġemerges': 12, 'ĠKier': 12, 'Dou': 11, 'Ġcomple': 11}\n",
      "et {'ĠLEG': 13, 'Ġmuch': 12, 'Leg': 12, 'ĠLeg': 12, 'ĠMUCH': 12, 'Ġmeg': 11}\n",
      "hod {'Ġagile': 12, 'ĠDebian': 12, 'Ġparties': 12, 'Ġhotels': 12, 'ĠParties': 11, 'Ġgays': 11}\n",
      "proof {'ĠTight': 13, 'Ġcrisp': 12, 'ĠMormonism': 12, 'ĠSlim': 12, 'Ġquirky': 11, 'ĠSavior': 11}\n",
      "Ġstable {'Ġencouraging': 13, 'Ġletting': 12, 'Ġempowering': 12, 'Ġinspiring': 12, 'Ġinciting': 12, 'Ġoptimizing': 11}\n",
      "stall {'ĠSchools': 13, 'ĠHunters': 12, 'Ġsunglasses': 12, 'Ġadore': 12, 'Ġshields': 11, 'Ġdread': 11}\n",
      "rain {'ĠREL': 12, 'Ġaspir': 12, 'abe': 12, 'Cub': 12, 'Ġdudes': 12, '¸': 12}\n",
      "Ġmicro {'Ġinsurance': 13, 'Ġworrisome': 12, 'Ġsterling': 12, 'giene': 12, 'Ġpursuant': 12, 'kin': 11}\n",
      "yo {'ĠTPP': 13, 'ĠDS': 12, 'ĠCalder': 12, 'HK': 12, 'ĠCohen': 12, 'ĠDh': 11}\n",
      "Ġeye {'Ġcarbohydrate': 13, 'Ġcarbohydrates': 12, 'Ġmusic': 12, 'music': 12, 'Ġsemblance': 11, 'Ġsoftware': 11}\n",
      "abase {'Ġpaternal': 12, 'api': 12, 'ĠProphe': 12, 'urches': 12, 'pins': 12, 'Ġsubmissions': 12}\n",
      "ile {'Ġnegoti': 12, 'Ġscrolling': 12, 'Ġunderwear': 12, 'Ġscrolls': 12, 'Ġaggrav': 12, 'Ġinhal': 11}\n",
      "als {'Ġinitially': 13, 'Ġinitial': 12, 'Ġinvariably': 12, 'Ġprior': 12, 'ĠInitially': 11, 'Ġdeeply': 11}\n",
      "Tom {'ĠFP': 12, 'FP': 12, 'Ġveil': 12, 'Ġveiled': 12, 'Ġinsecure': 12, 'fuel': 12}\n",
      "stad {'Ġfastest': 13, 'Ġweakest': 12, 'Ġdecent': 12, 'Ġsafest': 12, 'Ġcrude': 12, 'ĠAsians': 12}\n",
      "irs {'Ġareas': 13, 'Ġbrass': 12, 'ORS': 12, 'ARDS': 12, 'BOX': 12, 'Ġboxes': 12}\n",
      "ulin {'FIL': 12, 'PET': 12, 'Ġmoms': 12, 'LB': 12, 'Ġholders': 12, 'Ġmothers': 12}\n",
      "ien {'Ġworldwide': 12, 'Ġindigenous': 12, 'Ġpersonally': 12, 'ĠMediterranean': 12, 'Ġlucrative': 12, 'Ġglobally': 11}\n",
      "ades {'Ġtransitional': 12, 'Ġconceptual': 12, 'Ġcustomary': 12, 'Ġincapac': 11, 'Ġwaiver': 11, 'Ġfearsome': 11}\n",
      "perfect {'ĠHat': 12, 'des': 12, 'Ġpilgrims': 12, 'amd': 12, 'ĠTud': 11, 'ĠVive': 11}\n",
      "VD {'fac': 13, 'ĠJac': 12, 'ĠFac': 12, 'pac': 11, 'Fac': 11, 'dead': 11}\n",
      "overs {'ĠGar': 12, 'Compan': 12, 'Ġgar': 12, 'ĠMB': 12, 'ĠDARK': 12, 'ĠGob': 12}\n",
      "worthy {'Am': 14, 'ĠAm': 14, 'ĠIND': 12, 'ĠARE': 11, 'Ġam': 11, 'ĠBelgian': 11}\n",
      "sw {'ĠSolar': 12, 'Ġsolar': 12, 'imaru': 12, 'Ġdiaper': 12, 'Solar': 12, 'Ġausp': 12}\n",
      "Ġpel {'Ġadvantages': 12, 'Ġstake': 12, 'aunts': 12, 'ĠMaritime': 12, 'Ġattitudes': 12, 'Ġcaveats': 11}\n",
      "Ġsu {'Ġdeduct': 13, 'Ġchains': 12, 'Ġterms': 12, 'Ġaward': 11, 'Ġpays': 11, 'Ġshorten': 11}\n",
      "market {'Ġwillpower': 12, 'Ġpractice': 12, 'practice': 12, 'ĠPractice': 12, 'ĠPascal': 11, 'Ġfriendship': 11}\n",
      "cc {'ĠPartnership': 12, 'Ġfeder': 12, 'ĠHandbook': 12, 'ĠConstitution': 12, 'ĠBab': 12, 'Ġconstitution': 11}\n",
      "Ġpreference {'Ġelecting': 13, 'Ġelected': 12, 'Ġaward': 12, 'Ġgranting': 12, 'Ġawarding': 11, 'Ġattribution': 11}\n",
      "secret {'ĠUlt': 12, 'Sun': 12, 'ĠIBM': 12, 'Pot': 12, 'ĠKant': 12, 'umblr': 11}\n",
      "ars {'ELF': 13, 'abb': 13, 'Early': 12, 'ĠVaj': 12, 'Pinterest': 11, 'annabin': 11}\n",
      "ending {'ĠAdamant': 12, 'Ġacceler': 12, 'Ġeager': 12, 'Ġfatigue': 12, 'Ġimperfect': 11, 'ĠDARK': 11}\n",
      "access {'Ġinvincible': 12, 'æľ': 12, 'Ġfav': 12, 'ĠPOV': 12, 'ĠDomin': 11, 'Ġvacations': 11}\n",
      "amen {'eur': 13, 'onut': 13, 'Ġglitch': 12, 'itizens': 12, 'Ġpals': 11, 'Ġloaf': 11}\n",
      "ify {'ĠPAL': 13, 'arthy': 12, 'Golden': 12, 'pal': 12, 'ĠPal': 12, 'lated': 12}\n",
      "cel {'ĠAbrams': 12, 'ĠChel': 12, 'ayette': 12, 'ĠBates': 12, 'Ġscant': 11, 'ĠDozens': 11}\n",
      "roy {'Ġadolescence': 13, 'Ġimprisonment': 12, 'Ġfeminism': 12, 'Ġhappiness': 12, 'krit': 11, 'beaut': 11}\n",
      "a {'Ġvac': 14, 'Ġdrastically': 12, 'Ġdere': 12, 'Ġhoop': 12, 'fif': 11, 'Ġthirty': 11}\n",
      "fixed {'ĠStud': 13, 'Stud': 12, 'Ġstill': 12, 'Ġaff': 11, 'Hug': 11, 'ĠThrust': 11}\n",
      "state {'ĠBret': 12, 'opal': 12, 'ĠHelmet': 12, 'ĠCelest': 12, 'Ash': 12, 'ĠBeacon': 12}\n",
      "ang {'Ġavoids': 13, 'Ġtissues': 12, 'ĠSprings': 12, 'ĠBre': 12, 'POR': 11, 'LOD': 11}\n",
      "Ġt {'LINE': 12, 'WIND': 12, 'Ġassay': 12, 'Ġwording': 12, 'Ġnotation': 12, 'Ġwisdom': 11}\n",
      "reed {'ĠPolar': 13, 'ĠSoci': 12, 'ĠJal': 12, 'Secure': 12, 'ĠPun': 11, 'ĠSecure': 11}\n",
      "ce {'Ġlad': 12, 'bons': 12, 'Ġautop': 12, 'Ġb': 12, 'Ġpr': 12, 'Ġborder': 12}\n",
      "oth {'Ġfolklore': 13, 'Ġmasculine': 12, 'ĠBrave': 12, 'Ġstruggling': 12, 'ecd': 12, 'Ġsexy': 11}\n",
      "ice {'Ġpept': 13, 'ĠTerminal': 12, 'Ġdivision': 12, 'Ġadditionally': 12, 'ĠPositive': 11, 'Ġequitable': 11}\n",
      "rit {'ĠAlpine': 12, 'ĠCrest': 12, 'ĠMiddle': 12, 'ĠHispanics': 12, 'ĠLip': 12, 'Ġpayable': 11}\n",
      "select {'ĠREST': 12, 'Ġbystanders': 12, 'Ġremnant': 12, 'ĠRest': 12, 'Rest': 12, 'ĠRelic': 12}\n",
      "container {'Pand': 13, 'Ġpand': 12, 'ĠPand': 12, 'Ġoffseason': 12, 'Div': 11, 'ĠSpons': 11}\n",
      "der {'ĠDARK': 12, 'ĠPaladin': 12, 'Ġsafeguard': 12, 'Ġtouchscreen': 12, 'ĠFramework': 12, 'Ġphantom': 12}\n",
      "iv {'akers': 12, 'ĠKens': 12, 'Ġentrepreneurs': 12, 'Ġpregnancies': 11, 'Ġheadphones': 11, 'Ġpens': 11}\n",
      "ne {'Ġke': 12, 'ĠFat': 12, 'ĠSD': 12, 'Ġfrontier': 12, 'Ġfetal': 12, 'Ġvein': 12}\n",
      "ben {'Ġvanish': 12, 'Ġweak': 12, 'Ġleak': 12, 'Ġbreast': 12, 'Ġlewd': 12, 'Ġnecklace': 11}\n",
      "ro {'Ġtagging': 13, 'ĠTags': 12, 'Tags': 12, 'Ġassoci': 12, 'ĠApplic': 11, 'tag': 11}\n",
      "ĠSne {'ĠSouth': 13, 'ĠAT': 12, 'ĠNorth': 12, 'East': 12, 'ĠEast': 11, 'North': 11}\n",
      "gro {'ĠGuys': 12, 'Ġhom': 12, 'ĠKurds': 12, 'Ġemployers': 12, 'Ġconspir': 12, 'Ġantiqu': 12}\n",
      "Ġstructure {'Ġvillages': 13, 'Ġkitchens': 12, 'Ġmountains': 12, 'Ġhospitals': 12, 'ĠKats': 11, 'ĠVes': 11}\n",
      "Liber {'Ġconfused': 12, 'used': 12, 'Ġviewed': 12, 'Ġresulted': 11, 'Ġinduced': 11, 'Ġdoubted': 11}\n",
      "entry {'Ġdisqual': 14, 'Ġmaterial': 12, 'Ġlogic': 12, 'Ġclust': 11, 'Ġpen': 11, 'Ġseries': 11}\n",
      "sel {'akuya': 13, 'Ġaliens': 12, 'irty': 12, 'Ġarchaic': 11, 'Ġintegers': 11, 'Ġtoddler': 11}\n",
      "SW {'Ġausp': 13, 'ãĤŃ': 13, 'Ġrooftop': 12, 'JP': 11, 'Ġrooft': 11, 'Ġter': 11}\n",
      "Ġcens {'abus': 13, 'ĠCross': 12, 'ĠVeget': 12, 'skirts': 12, 'Ġspare': 11, 'ĠEssex': 11}\n",
      "iler {'Ġmaximal': 13, 'Ġsustainable': 12, 'ĠSAF': 12, 'ĠVital': 12, 'Ġattainment': 12, 'ĠUnreal': 11}\n",
      "strip {'Ġtw': 12, 'LGBT': 12, 'wt': 12, 'math': 12, 'Ġshades': 12, 'ĠRenaissance': 11}\n",
      "ioch {'Ġagain': 13, 'ĠBond': 13, 'ĠSure': 12, 'Sure': 12, 'ĠEsper': 11, 'ĠGrowth': 11}\n",
      "to {'ĠLaurel': 12, 'ĠKuala': 12, 'ĠEsper': 12, 'ĠLag': 12, 'jp': 12, 'ĠPal': 12}\n",
      "Ġwheels {'ĠMilwaukee': 13, 'waukee': 12, 'Ġkilometres': 12, 'ĠAnfield': 12, 'Ġkilometers': 11, 'Ġmillion': 11}\n",
      "adel {'ahi': 13, 'Bon': 12, 'ĠBon': 12, 'vacc': 12, 'ĠPARK': 11, 'ĠSind': 11}\n",
      "lies {'ĠDign': 12, 'ĠMig': 12, 'Ġausp': 12, 'ĠUnsure': 12, 'Ġpian': 11, 'ĠProm': 11}\n",
      "ĠV {'Ġawkward': 12, 'azaki': 12, 'Ġnegligible': 12, 'traditional': 12, 'ĠGermans': 12, 'awei': 11}\n",
      "rich {'dx': 13, 'Ġdaylight': 12, 'Ġsupper': 12, 'Ġdinner': 12, 'ĠPsal': 11, 'ĠGulf': 11}\n",
      "rift {'ĠExpo': 12, 'ĠCemetery': 12, 'ĠMessi': 12, 'Ġcemetery': 12, 'ĠJay': 11, 'Cat': 11}\n",
      "HK {'ÃŃa': 13, 'uble': 13, 'aba': 12, 'Ġsoluble': 12, 'ut': 11, 'needed': 11}\n",
      "negative {'ĠGators': 12, 'ĠContract': 12, 'Ġmotif': 12, 'ĠTexans': 11, 'ĠCanadiens': 11, 'Ġmiscon': 11}\n",
      "Ġalready {'writing': 13, 'Ġadding': 12, 'ĠHelsinki': 12, 'Ġintegrating': 12, 'Ġserving': 11, 'Ġinserting': 11}\n",
      "stable {'Ġtumors': 12, 'Ġcardiovascular': 12, 'Ġgrids': 12, 'ados': 12, 'Ġclassrooms': 12, 'ĠTABLE': 11}\n",
      "Ġu {'Ġexacerbate': 12, 'Ġimprobable': 12, 'ĠRedmond': 12, 'Ġconced': 12, 'Ġinaccurate': 12, 'Ġrebellious': 11}\n",
      "aging {'ĠBrave': 14, 'ĠSikh': 12, 'ĠEmpress': 12, 'Brave': 12, 'Ġke': 11, 'ĠBai': 11}\n",
      "sle {'Ġlightweight': 12, 'acht': 12, 'Ġroster': 12, 'OOL': 12, 'ĠZhang': 12, 'ĠSquid': 11}\n",
      "internal {'ĠTrop': 12, 'ĠLOW': 12, 'ĠGregg': 12, 'Ġhyper': 11, 'ĠSab': 11, 'ĠTrog': 11}\n",
      "Ġmemory {'Ġprograms': 12, 'Ġgardens': 12, 'Ġresidences': 12, 'Ġbegins': 12, 'Ġproperties': 11, 'Ġloads': 11}\n",
      "heat {'ĠFunk': 13, 'ĠNag': 12, 'ĠGob': 12, 'ĠKak': 12, 'ĠMisty': 12, 'Äį': 11}\n",
      "Ġpurpose {'Ġadapters': 12, 'Ġnipples': 12, 'Ġcontrollers': 12, 'Ġdebts': 12, 'Ġinterfaces': 12, 'Ġservers': 12}\n",
      "lot {'ĠReps': 12, 'Ġtorso': 12, 'ĠBW': 12, 'Ġreq': 12, 'ĠChest': 12, 'Ġpalate': 11}\n",
      "osc {'Ġobvious': 13, 'coll': 12, 'ĠGloss': 12, 'ĠSapp': 12, 'Ġobviously': 12, 'ĠGamb': 11}\n",
      "blocks {'ĠSurvey': 13, 'Ġsects': 12, 'ser': 12, 'krit': 12, 'Ġsurveys': 12, 'ĠProjects': 12}\n",
      "lim {'ceptive': 12, 'Ġsatur': 12, 'Ġclust': 12, 'ĠCemetery': 12, 'Ġrepressive': 12, 'Ġtens': 11}\n",
      "eat {'ĠCanadiens': 14, 'Ġsettlers': 12, 'Ġlinemen': 12, 'ĠMalays': 11, 'edar': 11, 'guards': 11}\n",
      "py {'Ġislands': 12, 'ĠHiroshima': 12, 'Ġbatteries': 12, 'Ġheadquartered': 12, 'ids': 11, 'according': 11}\n",
      "green {'ĠCubs': 12, 'ĠSapphire': 12, 'ĠBraves': 12, 'Ġcannabis': 12, 'Ġcoales': 11, 'ĠComics': 11}\n",
      "Ġtag {'Ġmodeling': 14, 'Ġmodelling': 13, 'Ġletting': 12, 'ott': 11, 'ĠElection': 11, 'Ġelection': 11}\n",
      "aval {'ĠNCAA': 13, 'ĠColleges': 12, 'Ġsolutions': 12, 'ĠApplications': 12, 'ĠDeadly': 11, 'Ġegregious': 11}\n",
      "iri {'ĠUCH': 13, 'Ġdomest': 12, 'Ġregul': 12, 'Ġveter': 12, 'ĠSomew': 12, 'Ġbalanced': 12}\n",
      "yet {'ĠNEVER': 12, 'ĠNost': 12, 'never': 12, 'ĠBever': 12, 'ĠLaurie': 12, 'ĠTant': 11}\n",
      "clear {'Ġmassively': 13, 'ĠMassive': 12, 'Ġcomedic': 12, 'Ġillustrious': 11, 'ĠFey': 11, 'Ġmassive': 11}\n",
      "De {'ĠDa': 13, 'Ġda': 13, 'Ġmembr': 12, 'Da': 12, 'Ġta': 11, 'Ġdat': 11}\n",
      "pos {'Ġprotocols': 12, 'Ġbrewers': 12, 'Ġmerchants': 12, 'Ġpsychologists': 12, 'Ġauthors': 11, 'ĠScholars': 11}\n",
      "& {'Marie': 13, 'Ġherds': 12, 'aby': 12, 'Ġplenty': 12, 'ĠKatherine': 11, 'Ġfem': 11}\n",
      "wards {'Ġcompens': 12, 'Ġalong': 12, 'ĠAlong': 12, 'Ġpreced': 12, 'ĠScorp': 11, 'Ġplaybook': 11}\n",
      "rak {'ĠKay': 12, 'ĠYorkers': 12, 'HCR': 12, 'Ġrobust': 12, 'Ġothers': 12, 'cair': 11}\n",
      "joy {'ĠReplay': 13, 'watch': 12, 'Ġsab': 12, 'Ġauditory': 11, 'Ġaccess': 11, 'Race': 11}\n",
      "nature {'ĠJump': 13, 'Ġzones': 12, 'Ġpeek': 12, 'ĠConsent': 12, 'Ġzone': 11, 'ĠHots': 11}\n",
      "NG {'Ġther': 12, 'femin': 12, 'ĠZo': 12, 'Boo': 12, 'Dark': 11, 'Flo': 11}\n",
      "sp {'Ġsimplest': 14, 'Ob': 12, 'Ġqueer': 12, 'Mist': 12, 'Ġsimpler': 11, 'Ġoptic': 11}\n",
      "Ġheter {'Ġdistinguish': 13, 'Ġillustrating': 12, 'Ġacknowledge': 12, 'Ġdistinguishes': 12, 'Ġrespective': 11, 'Ġacknowledging': 11}\n",
      "ese {'Ġja': 13, 'cod': 12, 'Ġcod': 12, 'Ġjo': 11, 'ĠLoyal': 11, 'jad': 11}\n",
      "plan {'ĠCoh': 13, 'ĠPOP': 12, 'ĠSocial': 12, 'ĠHealth': 11, 'ĠPopulation': 11, 'ĠLot': 11}\n",
      "Ġmy {'Ġstiff': 12, 'Ġbeacon': 12, 'ĠChevy': 12, 'ĠCarlo': 12, 'Ġaccredited': 12, 'Ġid': 11}\n",
      "gar {'ĠMarriage': 13, 'Ġmarriage': 12, 'ĠCLASS': 12, 'ĠSCHOOL': 12, 'Ġcandidacy': 11, 'Ġcomple': 11}\n",
      "Ġform {'ĠCorporate': 14, 'Ġcorporate': 13, 'ĠMolecular': 12, 'Ġmolecular': 12, 'Ġwedd': 11, 'porate': 11}\n",
      "tun {'Ġviable': 12, 'ĠMoj': 12, 'ĠEmber': 12, 'ĠRecession': 12, 'Ġrejuven': 11, 'ĠTw': 11}\n"
     ]
    }
   ],
   "source": [
    "show_topk.indices_fn = tokenizer.convert_ids_to_tokens\n",
    "for i in values.mean(1).topk(1000).indices.tolist():\n",
    "    print(tokenizer.convert_ids_to_tokens(i), show_topk(values[i][:6].long(), indices[i][:6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "d7da0142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ġbut\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Ġmedal': 163.481,\n",
       " 'umbing': 162.33,\n",
       " 'Ð´': 160.736,\n",
       " 'Ġfate': 159.438,\n",
       " 'Ðº': 157.868,\n",
       " 'ÑĢ': 156.459,\n",
       " 'Ġtill': 156.24,\n",
       " 'Ġmastery': 155.714,\n",
       " 'ung': 155.683,\n",
       " 'Ġ1985': 155.392,\n",
       " 'Ġ1967': 155.38,\n",
       " 'ĠAppeals': 155.32,\n",
       " 'Ġany': 154.876,\n",
       " 'urch': 154.739,\n",
       " 'Ġprecedent': 154.583,\n",
       " 'Ġwhom': 154.148,\n",
       " 'Ġmail': 153.655,\n",
       " 'Ġanything': 153.229,\n",
       " 'ired': 153.093,\n",
       " 'otion': 153.055}"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = tokenizer.encode(' but')[0]; print(tokenizer.convert_ids_to_tokens(i))\n",
    "show_topk(*m[i].topk(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c168801f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "052c1e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_token = 'Ġ!'; prompt_id = tokenizer._convert_token_to_id(prompt_token)\n",
    "bop_str = 'Instruction: '; bop_id = tokenizer.encode(bop_str)[0]  # 'Inst'\n",
    "eop_str = '. For example:'; eop_id = tokenizer.encode(eop_str)[2] # 'Ġexample'\n",
    "bos_id = tokenizer._convert_token_to_id('Ġ->')\n",
    "eos_id = tokenizer._convert_token_to_id('Ċ')\n",
    "\n",
    "\n",
    "class CHILDDataset(Dataset):\n",
    "    def __init__(self, input_strs, tokenizer):\n",
    "        if tokenizer.pad_token is None: tokenizer.pad_token = '!'\n",
    "        self.inputs = tokenizer.batch_encode_plus(input_strs, add_special_tokens=False, padding=True, return_tensors='pt')#长的截，短的补\n",
    "        input_ids = self.inputs.input_ids\n",
    "        self.labels = torch.ones_like(input_ids) * (-100)\n",
    "\n",
    "        for bi in range(input_ids.size(0)): \n",
    "            bop_idx = (input_ids[bi] == bop_id).nonzero().squeeze(1) #prompt\n",
    "            eop_idx = (input_ids[bi] == eop_id).nonzero().squeeze(1) #context\n",
    "\n",
    "            if len(bop_idx) > 0:\n",
    "                assert len(bop_idx) == 1 and len(eop_idx) == 1\n",
    "                bop_idx, eop_idx = bop_idx.item(), eop_idx.item() #取出单元素张量的元素值并返回该值，保持原元素类型不变\n",
    "                #bop: 0   eop:6\n",
    "                input_ids[bi, bop_idx: eop_idx + 2] *= -1  # use prompt embedding for prompt tokens\n",
    "  \n",
    "            bos_indices = (input_ids[bi] == bos_id).nonzero().squeeze(1)\n",
    "#             print(\"bos_indices:\",bos_indices)\n",
    "            eos_indices = (input_ids[bi] == eos_id).nonzero()[-len(bos_indices):].squeeze(1) #每一位 eos都比bos大2\n",
    "#             print(\"eos_indices:\",eos_indices)\n",
    "            for i, (bos_i, eos_i) in enumerate(zip(bos_indices.tolist(), eos_indices.tolist())):\n",
    "                assert eos_i > bos_i + 1\n",
    "                if i >= 0:  #zero-shot\n",
    "                    self.labels[bi, bos_i + 1: eos_i] = input_ids[bi, bos_i + 1: eos_i] \n",
    "        \n",
    "        \n",
    "    def re_input(self):\n",
    "        return self.inputs['input_ids']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputs['input_ids'])\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {'input_ids': self.inputs['input_ids'][i],  #输入\n",
    "                'attention_mask': self.inputs['attention_mask'][i],\n",
    "                'labels': self.labels[i]}   #结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b322160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4613, 198)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_id,eos_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "696ea332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from child_utils import *\n",
    "torch.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56fcd441",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedEmbedding(nn.Module):\n",
    "    def __init__(self,  \n",
    "                wte: nn.Embedding,  #正常向量\n",
    "                prompt_id: int = None,\n",
    "                prompt_len: int = 10, \n",
    "                random_range: float = 0.5,\n",
    "                initialize_from_vocab: bool = True):\n",
    "        super(WrappedEmbedding, self).__init__()\n",
    "#         self.wte = wte\n",
    "#         self.prompt_id = prompt_id\n",
    "#         self.prompt_len = prompt_len\n",
    "        self.__dict__.update(locals()); del self.self #locals()以字典类型返回当前位置的全部局部变量\n",
    "        if self.prompt_id is not None: #prompt_embedding prompt词向量\n",
    "            self.prompt_embedding = nn.parameter.Parameter( #将一个不可训练的类型Tensor转换成可以训练的类型parameter\n",
    "                self.initialize_embedding(random_range, initialize_from_vocab)).to(self.wte.weight.device) #在-0.5-0.5中随机取值初始化\n",
    "        else:\n",
    "            self.prompt_embedding = nn.Embedding(self.prompt_len, self.wte.weight.size(1)).to(self.wte.weight.device)\n",
    "                                        #词典大小（总共输入多少词） 嵌入向量维度（多少维表示一个符号）\n",
    "            \n",
    "            assert initialize_from_vocab\n",
    "            self.init_prompt_embedding_()  #将wte的weight值作为初始化\n",
    "#             self.prompt_embedding.weight.data = self.initialize_embedding(random_range, initialize_from_vocab)     \n",
    " \n",
    "    def initialize_embedding(self, random_range: float = 0.5, initialize_from_vocab: bool = True):\n",
    "        if initialize_from_vocab: return self.wte.weight[:self.prompt_len].clone().detach() #返回一个新的tensor，新的tensor和原来的tensor共享数据内存，但不涉及梯度计算\n",
    "        return torch.FloatTensor(self.prompt_len, self.wte.weight.size(1)).uniform_(-random_range, random_range) #产生随机数\n",
    "    \n",
    "    def init_prompt_embedding_(self):\n",
    "#         print(self.wte.weight)\n",
    "        self.prompt_embedding.weight.data[:] = self.wte.weight[:self.prompt_len]\n",
    "\n",
    "        \n",
    "    def forward(self, input_ids):\n",
    "        if self.prompt_id is not None:\n",
    "            input_embeds = self.wte(input_ids)\n",
    "            input_embeds[input_ids == self.prompt_id] = self.prompt_embedding.expand(input_embeds.size(0), -1, -1)\n",
    "        else: # adapted from cpm-2\n",
    "            prompt_mask = input_ids < 0  #返回bool类型\n",
    "#             print(\"prompt_mask:\",prompt_mask.shape)\n",
    "            prompt_ids = -input_ids * prompt_mask #将prompt的值变为正数，其他置零\n",
    "#             print(\"prompt_ids:\",prompt_ids)\n",
    "#             print(prompt_ids < self.prompt_len)\n",
    "#             print(prompt_ids)\n",
    "            assert torch.all(prompt_ids < self.prompt_len)\n",
    "#             print(self.prompt_embedding(prompt_ids).shape)\n",
    "            p_embeds = self.prompt_embedding(prompt_ids) * prompt_mask.float().unsqueeze(-1)\n",
    "#             print(\"p_embeds:\",p_embeds.shape)\n",
    "            input_ids = input_ids * ~prompt_mask\n",
    "            w_embeds = self.wte(input_ids) * (~prompt_mask).float().unsqueeze(-1)\n",
    "#             print(\"w_embeds:\",w_embeds.shape)\n",
    "            input_embeds = w_embeds + p_embeds \n",
    "#         print(input_embeds)\n",
    "        return input_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44b17b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from cpm-2: https://github.com/TsinghuaAI/CPM-2-Finetune/blob/master/utils.py#L133-L164    #不训练模型参数，只训练prompt_embading，这个函数是取这些参数\n",
    "def get_params_for_prompt_optimization(module: nn.Module): \n",
    "    params = []\n",
    "    for t in module.named_modules():\n",
    "        if \"prompt_embedding\" in t[0]:\n",
    "            params.append({'params': [p for p in list(t[1]._parameters.values()) if p is not None]})\n",
    "    for t in module.named_parameters():\n",
    "        if \"prompt\" not in t[0]:\n",
    "            t[1].requires_grad_(False)    \n",
    "    return params\n",
    "\n",
    "def create_optimizer(model, training_args):\n",
    "    from torch.nn.parallel.distributed import DistributedDataParallel as DDP\n",
    "    while isinstance(model, (DDP, )): model = model.module\n",
    "        \n",
    "    we.init_prompt_embedding_()\n",
    "    param_groups = get_params_for_prompt_optimization(model)\n",
    "    optimizer = AdamW(param_groups, lr=training_args.learning_rate, \n",
    "                      betas=(training_args.adam_beta1, training_args.adam_beta2),eps=training_args.adam_epsilon)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39b4f350",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# wte = model.get_input_embeddings() #提取 embedding 中的 词向量部分\n",
    "# if hasattr(wte, 'wte'): wte = wte.wte  # already been wrapped\n",
    "# we = WrappedEmbedding(wte, prompt_len=20000)\n",
    "# model.set_input_embeddings(we) #为词向量赋值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae3bb45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbalize(obj):\n",
    "    if type(obj) == bool: return 'Yes' if obj else 'No'\n",
    "    return str(obj)\n",
    "\n",
    "def list2str(l): return ' '.join(str(i) for i in l)\n",
    "def pairs2str(pairs): return ', '.join(str(k) + ': ' + str(v) for k, v in pairs)\n",
    "\n",
    "def make_context_str(cxt):\n",
    "    if type(cxt) == list:\n",
    "        return pairs2str(cxt) if type(cxt[0]) == tuple and len(cxt[0]) == 2 else list2str(cxt)\n",
    "    if type(cxt) == tuple:\n",
    "        return '; '.join(make_context_str(c) for c in cxt)  # 用分号分隔context的不同部分\n",
    "    \n",
    "def make_query_str(instruction, query):\n",
    "    if instruction is None and query is None: return ''\n",
    "    s = '.'\n",
    "    if instruction is not None: s = s + ' ' + instruction\n",
    "    if query is not None:\n",
    "        if type(query) in [int, bool, str]: query = [query]\n",
    "        if type(query) == dict:# and list(query.keys())[0] != \"CS\"):  # by nrk\n",
    "            s = s + ' ' + '{' + ','.join([' replace %s with %s' % (str(k), str(v)) for k, v in query.items()]) + ' }'\n",
    "        if type(query) in [list, tuple]:\n",
    "            s = s + ' ' + ' '.join([list2str(i) if type(i) == list else str(i) for i in query])\n",
    "    return s\n",
    "\n",
    "def make_example_str(example, query2str):\n",
    "    instruction, cxt, query, ans = example\n",
    "    if type(ans) not in [Sequence, list]: ans = [ans]\n",
    "    ans = [verbalize(a) for a in ans]\n",
    "#     return '%s -> %s' % (''.join(l[0]) + make_query_str(instruction if with_instruction else None, query), ' '.join(ans))  # by nrk\n",
    "#     return '%s -> %s' % (' '.join(l) + make_query_str(instruction if with_instruction else None, query), ' '.join(ans))  # by XD\n",
    "#     return '%s -> %s' % (make_context_str(cxt) + make_query_str(instruction if with_instruction else None, query[0]), ' '.join(ans))\n",
    "    return '%s -> %s' % (make_context_str(cxt) + query2str(query), ' '.join(ans))\n",
    "\n",
    "\n",
    "def sample_rand_len(vocab, k): return sample(vocab, k=randint(1, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df63ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def promptize(s):\n",
    "#     return prompt_token * len(s.split())\n",
    "    return bop_str + s + eop_str\n",
    "\n",
    "courses_vocab=[\"Sql\",\"Math\",\"English\",\"Chinese\",\"Art\",\"Music\",\"History\",\"Biology\",\"Chemistry\",\"Physics\",\"Geography\"]\n",
    "all_vocab = [\"apple\",\"pear\",\"peach\",\"grape\",\"banana\",\"pineapple\",\"lemon\",\"strawberry\",\"cola\",\"juice\",\"coffee\",\"milk\",\"wine\",\"beer\",\"whisky\",\"vodka\",\"brandy\"]\n",
    "solid_vocab=[\"apple\",\"pear\",\"peach\",\"grape\",\"banana\",\"pineapple\",\"lemon\",\"strawberry\"]\n",
    "liquid_vocab=[\"cola\",\"juice\",\"coffee\",\"milk\",\"wine\",\"beer\",\"whisky\",\"vodka\",\"brandy\"]\n",
    "names_vocab =  [i for i in string.ascii_uppercase]\n",
    "depts_vocab = [\"CS\",\"Chi\",\"Eng\",\"Mat\"]\n",
    "sl = [\"solid\"]*len(solid_vocab)+[\"liquid\"]*len(liquid_vocab)\n",
    "sl_vocab = dict(zip(all_vocab,sl))\n",
    "toys = [\"ball\",\"doll\",\"puppet\",\"weiqi\",\"chess\",\"slide\",\"diabolo\",\"plasticine\",\"tumbler\"]\n",
    "                                              #滑梯     空竹      橡皮泥      不倒翁\n",
    "boys = [\"Alex\",\"Dylan\",\"Daniel\",\"Patrick\",\"Austin\",\"Harrison\",\"Tom\",\"Neil\"]\n",
    "girls = [\"Ashley\",\"jessica\",\"Sarah\",\"Amanda\",\"Nicole\",\"Katherine\",\"Anne\",\"Eva\"]\n",
    "all = boys+girls\n",
    "bg = [\"boys\"]*len(boys)+[\"girls\"]*len(girls)\n",
    "bg_vocab = dict(zip(all,bg))\n",
    "\n",
    "all = solid_vocab+toys\n",
    "ft = [\"fruits\"]*len(solid_vocab)+[\"toys\"]*len(toys)\n",
    "ft_vocab = dict(zip(all,ft))\n",
    "\n",
    "def make_input_str(task, nrows=4, ncols=4, full_vocab=None, ans_vocab=[True, False]):\n",
    "    if full_vocab is None: full_vocab = string.ascii_uppercase + string.digits\n",
    "    transform_fn, vocab_fn, sample_fn, query_fn, query2str = task\n",
    "    instruction = transform_fn.__name__.replace('_', ' ')\n",
    "    if vocab_fn is None: vocab_fn = lambda: full_vocab\n",
    "    if query_fn is None: query_fn = lambda *_: None\n",
    "        \n",
    "    examples = []\n",
    "    query = None\n",
    "    for i in range(nrows):\n",
    "        vocab = vocab_fn()\n",
    "        l = sample_fn(vocab, k=ncols)\n",
    "        query = query_fn(l, vocab, ncols)\n",
    "        examples.append([instruction, l, query, transform_fn(l, query=query)])\n",
    "#     examples = balance(examples,ans_vocab)\n",
    "\n",
    "    desc = promptize(instruction) if True else ''\n",
    "    text = '\\n'.join([make_example_str(e, query2str) for e in examples])\n",
    "    text = desc + '\\n' + text + '\\n'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd0c286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def balance(examples, ans_vocab=[True, False]):\n",
    "# def balance1(examples, ans_vocab):\n",
    "#     groups = seq(examples).group_by(_[-1]).map(_[1])  # 按ans分组\n",
    "# #     assert groups.len() == len(ans_vocab), '%d < %d' % (groups.len(), len(ans_vocab))  # 保证每种ans都出现\n",
    "#     min_cnt = groups.map(lambda x: len(x)).min()\n",
    "#     examples = groups.map(lambda x: sample(x, min_cnt)).flatten().list() # 每组都采样最小个数后去分组\n",
    "#     return sample(examples, len(examples))  # 重新打乱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d664342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(examples, ans_vocab):\n",
    "    groups = seq(examples).group_by(_[-1]).map(_[1])  # 按ans分组\n",
    "#     min_cnt = groups.map(lambda x: len(x)).min()\n",
    "    min_cnt =3\n",
    "    if(groups.len()>3):\n",
    "        min_cnt = 3\n",
    "    elif(groups.len()==3):\n",
    "        min_cnt = 3\n",
    "    if(min_cnt > 2):\n",
    "        examples = groups.map(lambda x: sample(x, 3)).flatten().list() # 每组都采样最小个数后去分组\n",
    "        return sample(examples, len(examples))  # 重新打乱\n",
    "    else:\n",
    "        examples = groups.map(lambda x: sample(x, min_cnt)).flatten().list() # 每组都采样最小个数后去分组\n",
    "        return sample(examples, len(examples))  # 重新打乱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab80cfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools  \n",
    "def Do_all_students_choose_courses_in_a_department(cxt, query):\n",
    "    SC, CD = cxt  # SC paris: studeng-course relation, CD pairs: course-department function\n",
    "    ss, d = query  # ss: 学生子集（可以*不止两个学生*），d: 课程\n",
    "#     return seq(ss).map(lambda s: seq(SC).filter(_[0] == s).map(_[1]).intersection(CD.filter(_.[1] == d).map(_.[0])).non_empty()).all()\n",
    "    return (seq(ss)\n",
    "            .map(lambda s: seq(SC).filter(_[0] == s).map(_[1])  # 学生s选的所有课程\n",
    "                 .intersection(\n",
    "                     seq(CD).filter(_[1] == d).map(_[0])) # d系的课程\n",
    "                 .non_empty())  # s选了d系的课程\n",
    "            .all())  # 学生子集ss都选了d系的课程\n",
    "\n",
    "def all_a_sample(vocab, k):\n",
    "    S_vocab, C_vocab, D_vocab = vocab  # vocabs of students, courses, departments\n",
    "    k_S, k_C, k_D, k_SC = k  # default values: k_S = 3, k_C = 3, k_D = 2, k_SC = 5\n",
    "    S, C, D = sample(S_vocab, k_S), sample(C_vocab, k_C), sample(D_vocab, k_D)\n",
    "    \n",
    "    while len(set(CD := choices(D, k=k_C))) < k_D: continue  # ds里每个系的课都要出现\n",
    "    CD = list(zip(C, CD))  # 得到每门课所属的系\n",
    "    \n",
    "    all_SC = list(itertools.product(S, C))  # or seq(S).cartesian(C).list()\n",
    "    while seq(SC := sample(all_SC, k_SC)).map(_[0]).distinct().len() < k_S: continue  # ss里每个学生都要选课\n",
    "    return SC, CD\n",
    "\n",
    "def select_distinct(tuples, col): return seq(tuples).map(_[col]).distinct().list()\n",
    "    \n",
    "def all_a_query(cxt,vocab,k):\n",
    "    SC, CD = cxt\n",
    "    k_S, k_C, k_D, k_SC = k\n",
    "    S, D = select_distinct(SC, 0), select_distinct(CD, 1)\n",
    "#     k_ss = randint(2, len(S))\n",
    "    ss = sample(S, 2)\n",
    "    d = choice(D)\n",
    "    return ss, d\n",
    "\n",
    "def all_a_query2str(query):\n",
    "    ss, d = query\n",
    "    query_str = '%s,%s?' % (', '.join(ss[:-1]) + ' and ' + ss[-1], d)\n",
    "    return '. ' + query_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8103db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_b(cxt, query):\n",
    "    SC, CD = cxt\n",
    "    ss,d = query\n",
    "    return (seq(CD).filter(_[1] == d).map(_[0])\n",
    "                 .difference(\n",
    "                     seq(SC).filter(_[0] == ss).map(_[1]))\n",
    "                 .empty())\n",
    "\n",
    "def all_b_sample(vocab, k):\n",
    "    S_vocab, C_vocab, D_vocab = vocab  \n",
    "    k_S, k_C, k_D, k_SC = k  # default values: k_S = 2, k_C = 3, k_D = 2, k_SC = 5\n",
    "    S, C, D = sample(S_vocab, k_S), sample(C_vocab, k_C), sample(D_vocab, k_D)\n",
    "    \n",
    "    while len(set(CD := choices(D, k=k_C))) < k_D: continue  \n",
    "    CD = list(zip(C, CD)) \n",
    "    \n",
    "    all_SC = list(itertools.product(S, C))  \n",
    "    while seq(SC := sample(all_SC, k_SC)).map(_[0]).distinct().len() < k_S: continue  # ss里每个学生都要选课\n",
    "    return SC, CD\n",
    "   \n",
    "def all_b_query(cxt,vocab,k):  # XD: 不要给qeury_fn加st参数\n",
    "    SC, CD = cxt\n",
    "    k_S, k_C, k_D, k_SC = k\n",
    "    S, D = select_distinct(SC, 0), select_distinct(CD, 1)\n",
    "#     k_ss = randint(2, len(S))  # XD: k_ss unused\n",
    "    ss = choice(S)\n",
    "    d = choice(D)\n",
    "    return ss, d\n",
    "    # XD: 不要在query_fn里转str！！这里转str，transform_fn里再解析回来，两边不是白折腾吗！\n",
    "\n",
    "def all_b_query2str(query):\n",
    "    ss, d = query\n",
    "    query_str = 'Does %s take all %s courses?' % (ss, d)\n",
    "    return '. ' + query_str\n",
    "\n",
    "\n",
    "def Is_the_intersection_of_two_sets_empty(cxt, query):\n",
    "    SC= cxt\n",
    "    s,d = query\n",
    "    return (seq(SC).filter(_[0] == s).map(_[1])\n",
    "                 .intersection(\n",
    "                     seq(SC).filter(_[0] == d).map(_[1]))\n",
    "                 .non_empty())\n",
    "\n",
    "def intersection_query(cxt,vocab,k):\n",
    "    SC= cxt\n",
    "    k_S, k_C, k_SC = k #k_s = 3, k_C = 5 , k_sc = 6\n",
    "    S = select_distinct(SC, 0)\n",
    "    s,d = sample(S,2)\n",
    "    return s, d\n",
    "\n",
    "def intersection_query2str(query):\n",
    "    s, d = query\n",
    "    query_str = \"%s,%s?\" % (s, d)\n",
    "    return '. ' + query_str\n",
    "\n",
    "def intersection_sample(vocab, k):\n",
    "    S_vocab, C_vocab = vocab  \n",
    "    k_S, k_C, k_SC = k  # k_S = 3, k_C = 5, , k_SC = 6\n",
    "    S, C= sample(S_vocab, k_S), sample(C_vocab, k_C)\n",
    "    all_SC = list(itertools.product(S, C))  \n",
    "    while seq(SC := sample(all_SC, k_SC)).map(_[0]).distinct().len() < k_S: continue \n",
    "    return SC\n",
    "\n",
    "def Is_the_first_set_a_subset_of_the_second_one(cxt, query):\n",
    "    SC= cxt\n",
    "    s,d = query\n",
    "    return (seq(SC).filter(_[0] == d).map(_[1])\n",
    "                 .union(\n",
    "                     seq(SC).filter(_[0] == s).map(_[1]))\n",
    "                 ).distinct().len()== seq(SC).filter(_[0] == d).map(_[1]).distinct().len()\n",
    "\n",
    "def complement_query(cxt,vocab,k):\n",
    "    SC= cxt\n",
    "    k_S, k_C, k_SC = k #k_s = 3, k_C = 5 , k_sc = 6\n",
    "    S = select_distinct(SC, 0)\n",
    "    s,d = sample(S,2)\n",
    "    return s, d\n",
    "\n",
    "def complement_query2str(query):\n",
    "    s, d = query\n",
    "    query_str = \"%s,%s?\" % (s, d)\n",
    "    return '. ' + query_str\n",
    "\n",
    "def complement_sample(vocab, k):\n",
    "    S_vocab, C_vocab = vocab  \n",
    "    k_S, k_C, k_SC = k  # k_S = 3, k_C = 4, k_SC = 5\n",
    "    S, C= sample(S_vocab, k_S), sample(C_vocab, k_C)\n",
    "    all_SC = list(itertools.product(S, C))  \n",
    "    while seq(SC := sample(all_SC, k_SC)).map(_[0]).distinct().len() < k_S: continue \n",
    "    return SC\n",
    "\n",
    "def Are_they_the_union_of_the_last_element(cxt, query):\n",
    "    SC, DC = cxt\n",
    "    ss,d = query\n",
    "    return (seq(ss)\n",
    "            .map(lambda s: seq(SC).filter(_[0] == s).map(_[1]) \n",
    "                 .union(\n",
    "                     seq(DC).filter(_[0] == d).map(_[1])) \n",
    "                 .distinct().len() == seq(DC).filter(_[0] == d).map(_[1]).distinct().len())  \n",
    "            .all()) \n",
    "\n",
    "def union_sample(vocab, k):\n",
    "    S_vocab, C_vocab, D_vocab = vocab  \n",
    "    k_S, k_C, k_D, k_SC = k  # k_S = 3, k_C = 4, k_D = 2, k_SC = 6\n",
    "    S, C, D = sample(S_vocab, k_S), sample(C_vocab, k_C), sample(D_vocab, k_D)\n",
    "    \n",
    "    while len(set(DC := choices(D, k=k_C))) < k_D: continue  \n",
    "    DC = list(zip(DC,C)) \n",
    "    \n",
    "    all_SC = list(itertools.product(S, C))  \n",
    "    while seq(SC := sample(all_SC, k_SC)).map(_[0]).distinct().len() < k_S: continue  \n",
    "    return SC, DC\n",
    "   \n",
    "def union_query(cxt,vocab,k): \n",
    "    SC, DC = cxt\n",
    "    k_S, k_C, k_D, k_SC = k\n",
    "    S, D = select_distinct(SC, 0), select_distinct(DC, 0)\n",
    "    k_ss = randint(2, len(S))\n",
    "    ss = sample(S, k_ss)\n",
    "    d = choice(D)\n",
    "    return ss, d\n",
    "\n",
    "def union_query2str(query):\n",
    "    ss, d = query\n",
    "    query_str = '%s,%s?' % (', '.join(ss[:-1]) + ' and ' + ss[-1], d)\n",
    "    return '. ' + query_str\n",
    "\n",
    "def Are_there_elements_belonging_to_the_same_class(cxt, query): #新建联系，把vocab和属性连起来形成新集合\n",
    "    NA, DA = cxt\n",
    "    s,d = query\n",
    "    D = seq(DA).filter(_[0] == d).map(_[1])\n",
    "    return (seq(NA).filter(_[0] == s).map(_[1]).select(lambda x: sl_vocab[x] == sl_vocab[D[0]]).any())\n",
    "      \n",
    "    \n",
    "def find_sample(vocab, k): \n",
    "    name_vocab, all_vocab = vocab\n",
    "    k_name, k_all, k_D, k_SA = k  # k_name = 3, k_all = 4, k_D = 2, k_SA = 6\n",
    "    S = list(all_vocab.keys())\n",
    "    N, A, D = sample(name_vocab, k_name), sample(S, k_all), sample(string.ascii_lowercase, k_D)\n",
    "#     D = sample(d := name_vocab.pop(name_vocab.index(a) for a in N),k_D)\n",
    "    A1 = sample(S, k_D)\n",
    "    DA = list(zip(D,A1)) \n",
    "    \n",
    "    all_NA = list(itertools.product(N, A))  \n",
    "    while seq(NA := sample(all_NA, k_SA)).map(_[0]).distinct().len() < k_name: continue  \n",
    "    return NA, DA\n",
    "   \n",
    "def find_query(cxt,vocab,k): \n",
    "    NA, DA = cxt\n",
    "    k_name, k_all, k_D, k_SA = k\n",
    "    S,D = select_distinct(NA, 0), select_distinct(DA, 0)\n",
    "    s,d = choice(S), choice(D)\n",
    "    return s, d\n",
    "\n",
    "def find_query2str(query):\n",
    "    s, d = query\n",
    "    query_str = '%s,%s?' % (s, d)\n",
    "    return '. ' + query_str\n",
    "\n",
    "\n",
    "def Are_there_any_elements_different_from_other_elements(cxt, query):\n",
    "    NA = cxt\n",
    "    ss = query\n",
    "    return (seq(ss).map(lambda s: seq(NA).filter(_[0] == s).map(_[1])\n",
    "                        .select(lambda x: sl_vocab[x])[0])\n",
    "            .distinct().len( ) == 2)\n",
    "               \n",
    "def find_dif_sample(vocab, k):\n",
    "    name_vocab, all_vocab = vocab\n",
    "    k_name, k_all, k_SA = k  # k_name = 4, k_all = 4, k_SA= 3\n",
    "    N, A = sample(name_vocab, k_name), sample(list(all_vocab.keys()), k_all) \n",
    "    NA = list(zip(N,A)) \n",
    "    return NA\n",
    "   \n",
    "def find_dif_query(cxt,vocab,k): \n",
    "    NA = cxt\n",
    "    k_name, k_all, k_NA = k\n",
    "    S = select_distinct(NA, 0)\n",
    "    ss = sample(S,k_NA)\n",
    "    return ss\n",
    "\n",
    "\n",
    "def find_dif_query2str(query):\n",
    "    ss = query\n",
    "    query_str = '%s?' % (', '.join(ss[:-1]) + ' and ' + ss[-1])\n",
    "    return '. ' + query_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "464efbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def How_many_elements_are_similar_to_the_case(cxt, query):\n",
    "    s = cxt\n",
    "    q = query\n",
    "    return seq(s).filter(lambda x: sl_vocab[x] == sl_vocab[q[0]]).len()\n",
    "                     \n",
    "def count_sample(vocab, k):\n",
    "    all_vocab = vocab\n",
    "    k_cxt,k_query = k  # k_cxt = 4 ,k_query =1\n",
    "    N = list(all_vocab.keys())\n",
    "    s = sample(N, k_cxt) \n",
    "    return s\n",
    "   \n",
    "def count_query(cxt,vocab,k): \n",
    "    NA = cxt\n",
    "    k_cxt,k_query = k\n",
    "    N = list(vocab.keys())\n",
    "    q = sample(N,k_query)\n",
    "    return q\n",
    "\n",
    "def count_query2str(query):\n",
    "    q = query\n",
    "    query_str = '%s?' % (q[0])\n",
    "    return '. ' + query_str\n",
    "\n",
    "def Is_the_number_of_first_elements_greater_than_the_second_one(cxt, query):\n",
    "    s = cxt\n",
    "    q = query\n",
    "    return (seq(s).filter(lambda x: sl_vocab[x] == sl_vocab[q[0]]).len() >= len(s)/2)\n",
    "                     \n",
    "def compare_sample(vocab, k):\n",
    "    all_vocab,s_vocab,l_vocab = vocab\n",
    "    k_cxt,k_query = k  # k_cxt = 5 ,k_query =2\n",
    "    N = list(all_vocab.keys())\n",
    "    s = sample(N, k_cxt) \n",
    "    return s\n",
    "   \n",
    "def compare_query(cxt,vocab,k): \n",
    "    NA = cxt\n",
    "    all_vocab,s_vocab,l_vocab = vocab\n",
    "    k_cxt,k_query = k\n",
    "    q = sample(s_vocab,1)+sample(l_vocab,1)\n",
    "    random.shuffle(q)\n",
    "    return q\n",
    "\n",
    "def compare_query2str(query):\n",
    "    ss,q = query\n",
    "    query_str = '%s,%s?' % (ss,q)\n",
    "    return '. ' + query_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62aee837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ascii_size_existence(l, query): return seq(l).map(_[0] > query).any()\n",
    "def Ascii_size_all(l, query): return seq(l).map(_[0] > query).all()\n",
    "def Ascii_size_None(l, query): return seq(l).filter(_[0] > query).empty()\n",
    "def ith_element(l, query=None): return seq(l).slice(1, 2)\n",
    "def ith_group(l, query=None): return seq(l).group_by(_).select(_[1]).slice(1, 2).flatten()#.distinct()# davinci F w/ and wo dist\n",
    "# def element_at_index(l, query): return seq(l).slice(query, query + 1) # davinci F\n",
    "def element_at_index(l, query): return seq(l).enumerate().filter(_[0] == query).select(_[1])\n",
    "def replace(l, query): return seq(l).map(lambda x: query.get(x, x))\n",
    "def replace_with_the_other(l, query): # davinci F\n",
    "    query = {k: (set(l) - {k}).pop() for k in l}\n",
    "    return replace(l, query)\n",
    "def replace_all_with(l, query): return seq(l).map(lambda x: query)  # davinci F?!\n",
    "def interleave_with(l, query): return seq(l).flat_map(lambda x: [x, query])  # davinci T!!\n",
    "def unique_elements(l, query=None): return seq(l).distinct() # davinci F\n",
    "def how_many_unique_elements(l, query=None): return seq(l).distinct().len()  # davinci F\n",
    "def how_many(l, query): return seq(l).filter(_ == query).len() # davinci F\n",
    "def select_same_as(l, query): return seq(l).filter(_ == query) # simpler version of how_many. davinci F\n",
    "def select_same_number_as(l, query): return seq(l).group_by(_).select(_[1]).filter(lambda x: len(x) == len(query)).flatten() # F\n",
    "def includes(l, query): return seq(l).union(seq(query)).distinct().len() == seq(l).distinct().len() # davinci F\n",
    "def is_included_by(l, query): return seq(l).difference(seq(query)).empty() # davinci F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "388dd77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compare_the_values_of_two_sets(cxt, query):\n",
    "    s = cxt\n",
    "    q = query\n",
    "    if(seq(s).filter(lambda x: sl_vocab[x] == sl_vocab[q[0]]).len() > len(s)/2):\n",
    "        return \">\"\n",
    "    elif(seq(s).filter(lambda x: sl_vocab[x] == sl_vocab[q[0]]).len() < len(s)/2):\n",
    "        return \"<\"\n",
    "    else:\n",
    "        return \"=\"\n",
    "\n",
    "def Compare_sample(vocab, k):\n",
    "    all_vocab,s_vocab,l_vocab = vocab\n",
    "    k_cxt,k_query = k  # k_cxt = 5 ,k_query =2\n",
    "    N = list(all_vocab.keys())\n",
    "    s = sample(N, k_cxt) \n",
    "    return s\n",
    "   \n",
    "def Compare_query(cxt,vocab,k): \n",
    "    NA = cxt\n",
    "    all_vocab,s_vocab,l_vocab = vocab\n",
    "    k_cxt,k_query = k\n",
    "    q = sample(s_vocab,1)+sample(l_vocab,1)\n",
    "    random.shuffle(q)\n",
    "    return q\n",
    "\n",
    "def Compare_query2str(query):\n",
    "    ss,q = query\n",
    "    query_str = '%s,%s?' % (ss,q)\n",
    "    return '. ' + query_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48028352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Relationship_between_two_sets(cxt, query): #新建联系，把vocab和属性连起来形成新集合\n",
    "    NA = cxt\n",
    "    s,q= query   #s:boys/girls  q:fruits/toys\n",
    "    name = seq(NA).filter(lambda x: bg_vocab[x[0]] == s)\n",
    "    if(seq(name).map(_[1]).filter(lambda x: ft_vocab[x] == q).len() == seq(name).len()):\n",
    "        return \"all\"\n",
    "    elif(seq(name).map(_[1]).filter(lambda x: ft_vocab[x] == q).empty()):\n",
    "        return \"none\"\n",
    "    else:\n",
    "        return \"some\"\n",
    "    \n",
    "def Relationship_sample(vocab, k): \n",
    "    name_vocab, all_vocab = vocab\n",
    "    k_name, k_all, k_SA = k  # k_name = 4, k_all = 4, k_SA = 4\n",
    "    Name = list(name_vocab.keys())\n",
    "    S = list(all_vocab.keys())\n",
    "    N, A = sample(Name, k_name), sample(S, k_all)\n",
    "#     D = sample(d := name_vocab.pop(name_vocab.index(a) for a in N),k_D)\n",
    "    \n",
    "    all_NA = list(itertools.product(N, A))  \n",
    "    while seq(NA := sample(all_NA, k_SA)).map(_[0]).distinct().len() < k_name: continue  \n",
    "    return NA\n",
    "   \n",
    "def Relationship_query(cxt,vocab,k): \n",
    "    NA = cxt\n",
    "    name_vocab, all_vocab = vocab\n",
    "    k_name, k_all, k_SA = k\n",
    "    S,D = select_distinct(NA, 0),select_distinct(NA, 1)\n",
    "    s,d = choice(S),choice(D)\n",
    "    s1,d1 = name_vocab[s],all_vocab[d]\n",
    "    return s1,d1\n",
    "\n",
    "def Relationship_query2str(query):\n",
    "    s,q = query\n",
    "    query_str = '[] %s have %s. [all / some / none]?' % (s,q)\n",
    "    return '. ' + query_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f199b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\n",
    "    (ith_element,            None,                               sample,    None,None),\n",
    "    (ith_group,              None, lambda vocab, k: seq(sample(vocab, k)).map(lambda x:[x]*randint(1, 3)).flatten().list(),None,None),\n",
    "    (element_at_index,       lambda: upper_letters,              sample,    lambda l,vocab,k: randint(0, min(2,len(l)-1))),\n",
    "    (replace,                None,                               sample,    lambda l,vocab,k: {choice(l): choice(vocab)}),\n",
    "    (replace_with_the_other, lambda: sample(full_vocab, 2),   lambda vocab,k: sample(vocab+choices(vocab, k=k-2),k), None),\n",
    "    (replace_all_with,       None,                               sample_rand_len, lambda l,vocab,k: choice(vocab)),\n",
    "    (interleave_with,        None,                               sample_rand_len, lambda l,vocab,k: choice(vocab)),\n",
    "    (unique_elements,        lambda: sample(upper_letters, 3),   choices,   None),\n",
    "    (how_many_unique_elements,lambda: sample(upper_letters, 3),  choices,   None),\n",
    "    (how_many,               lambda: sample(upper_letters, 3),   choices,   lambda l,vocab,k: choice(list(set(l)))),\n",
    "    (select_same_as,         lambda: sample(upper_letters, 3),   choices,   lambda l,vocab,k: choice(list(set(l)))),\n",
    "    (select_same_number_as,  None, lambda vocab, k: seq(sample(vocab, k)).map(lambda x:[x]*randint(1, 3)).flatten().list(),   \n",
    "     lambda l,vocab,k: [choice(vocab)]*randint(1, 3)),\n",
    "    (includes,               lambda: sample(upper_letters, 6),   sample,    lambda l,vocab,k: sample(vocab, 3)),\n",
    "    (is_included_by,         lambda: sample(upper_letters, 6),   sample,    lambda l,vocab,k: sample(vocab, 5)),\n",
    "    \n",
    "    (Ascii_size_None,        lambda: string.ascii_uppercase,              sample,    lambda l,vocab,k: \"Is there no element greater than %s?\" % choice(list(set(l)))),\n",
    "    (Ascii_size_all,         lambda: string.ascii_uppercase,              sample,    lambda l,vocab,k: \"Are all elements greater than %s?\" % choice(list(set(l)))),\n",
    "    (Ascii_size_existence,   lambda: string.ascii_uppercase,              sample,    lambda l,vocab,k: \"Is there an element greater than %s?\" % choice(list(set(l)))),\n",
    "    \n",
    "#     (all_a,                  lambda: [names_vocab,courses_vocab,depts_vocab],     all_a_sample,    all_a_query, all_a_query2str),\n",
    "    (Do_all_students_choose_courses_in_a_department,    lambda: [names_vocab,courses_vocab,depts_vocab],     all_a_sample,    all_a_query, all_a_query2str),\n",
    "    (Compare_the_values_of_two_sets,  lambda: [sl_vocab,solid_vocab,liquid_vocab],  Compare_sample,    Compare_query, Compare_query2str),\n",
    "    (Relationship_between_two_sets,   lambda: [bg_vocab,ft_vocab],               Relationship_sample,    Relationship_query, Relationship_query2str),\n",
    "    (Is_the_intersection_of_two_sets_empty,           lambda: [string.ascii_uppercase,string.ascii_lowercase],     intersection_sample,    intersection_query, intersection_query2str),\n",
    "    (Is_the_first_set_a_subset_of_the_second_one,           lambda: [string.ascii_uppercase,string.ascii_lowercase],     complement_sample,    complement_query, complement_query2str),\n",
    "    (Are_they_the_union_of_the_last_element,                lambda: [string.ascii_uppercase,string.ascii_lowercase,depts_vocab],     union_sample,    union_query, union_query2str),\n",
    "    (Are_there_elements_belonging_to_the_same_class,            lambda: [string.ascii_uppercase,sl_vocab],      find_sample,    find_query, find_query2str ),\n",
    "    (Are_there_any_elements_different_from_other_elements,          lambda: [string.ascii_uppercase,sl_vocab],      find_dif_sample,  find_dif_query, find_dif_query2str ),\n",
    "    (How_many_elements_are_similar_to_the_case,                lambda: sl_vocab,                                      count_sample,            count_query,count_query2str),\n",
    "    (Is_the_number_of_first_elements_greater_than_the_second_one,              lambda: [sl_vocab,solid_vocab,liquid_vocab],          compare_sample,            compare_query,compare_query2str),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1365,
   "id": "105e915f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-8], nrows=30, ncols=(4, 4, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "91683062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-9], nrows=8, ncols=(4,2))) #比较，query中给了两个元素（固体、液体），\n",
    "                                                        #若前一个元素的类型数目大于后一个，就输出YES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "dc45005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-9], nrows=80, ncols=(2, 3, 2, 5))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "e98e87d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Are there any elements different from other elements. For example:\n",
      "M: beer, N: pear, B: milk, G: peach. N, B and G? -> Yes\n",
      "F: juice, P: cola, E: coffee, G: pineapple. F, P and E? -> No\n",
      "U: grape, C: whisky, Z: juice, T: beer. Z, C and T? -> No\n",
      "H: whisky, R: apple, L: strawberry, O: brandy. R, L and O? -> Yes\n",
      "V: juice, W: brandy, P: coffee, O: banana. O, W and P? -> Yes\n",
      "H: banana, J: pineapple, E: coffee, G: grape. H, G and J? -> No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(make_input_str(tasks[-3], nrows=80, ncols=(4,4,3))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "6fb4988c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Are there elements belonging to the same class. For example:\n",
      "P: banana, P: brandy, I: brandy, U: peach; v: grape, b: wine. I,b? -> Yes\n",
      "K: whisky, P: apple, K: cola, L: apple; v: whisky, a: strawberry. K,a? -> No\n",
      "R: pear, R: cola, E: strawberry, M: cola; q: pear, h: vodka. E,h? -> No\n",
      "N: pineapple, Z: pineapple, C: coffee, C: juice; p: lemon, j: milk. N,p? -> Yes\n",
      "E: beer, J: milk, I: peach, I: beer; j: peach, n: banana. E,j? -> No\n",
      "R: grape, P: grape, P: juice, N: grape; k: milk, n: vodka. P,k? -> Yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(make_input_str(tasks[-4], nrows=100, ncols=(3,4,2,4)))  #找相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "f4070da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-1], nrows=8, ncols=(5,2))) #比较，query中给了两个元素（固体、液体），\n",
    "                                                        #若前一个元素的类型数目大于后一个，就输出YES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "4f3668d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-2], nrows=30, ncols=(3,1), ans_vocab=[0,1,2,3]))    #数数，数cxt中与query中元素同类的个数\n",
    "                                                                                  #这里修改了balance函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "db442a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-5], nrows=10, ncols=(3,4,2,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "eadf0bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-6], nrows=18, ncols=(3,11,5))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "c8c59a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-7], nrows=4, ncols=(3,4,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1377,
   "id": "c3df9c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Do all students choose courses in a department. For example:\n",
      "L: Geography, L: English, B: Chemistry, L: Chemistry, Z: Chemistry; English: Eng, Geography: Eng, Chemistry: Mat. B and L,Eng? -> No\n",
      "J: History, O: Art, O: History, J: Math, D: History; History: CS, Art: Mat, Math: Mat. D and O,CS? -> Yes\n",
      "Z: Sql, Z: Music, P: Chemistry, P: Sql, T: Music; Sql: Eng, Music: Eng, Chemistry: Chi. P and Z,Chi? -> No\n",
      "J: Chinese, J: Music, U: Music, J: Sql, H: Chinese; Chinese: CS, Sql: Eng, Music: Eng. J and H,CS? -> Yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(make_input_str(tasks[-10], nrows=100, ncols=(3, 3, 2, 5))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "06d90c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-2], nrows=8, ncols=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "3185653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if n_total == 1:\n",
    "#     inputs = tokenizer.encode_plus(text, return_tensors='pt')\n",
    "#     inputs = prepare_inputs(inputs, model.device)\n",
    "#     outputs = model(**inputs, output_attentions=False)\n",
    "\n",
    "#     # assert inputs.input_ids.size(0) == 1\n",
    "#     input_ids = inputs.input_ids\n",
    "#     logits = outputs.logits\n",
    "\n",
    "#     bsz = input_ids.size(0); assert bsz == 1\n",
    "#     labels = torch.ones_like(input_ids) * (-100)\n",
    "#     for bi in range(bsz):\n",
    "#         bos_indices = (input_ids[bi] == bos_id).nonzero().squeeze(1)\n",
    "#         eos_indices = (input_ids[bi] == eos_id).nonzero()[-nrows:].squeeze(1)\n",
    "#         for i, (example, bos_i, eos_i) in enumerate(zip(examples, bos_indices.tolist(), eos_indices.tolist())):\n",
    "#             print(' ' + make_example_str(example))\n",
    "#             ans_ids = input_ids[bi, bos_i + 1: eos_i]\n",
    "#             if i >= 2: labels[bi, bos_i: eos_i - 1] = ans_ids\n",
    "#             ans_prob_dist = logits[bi, bos_i: eos_i - 1].softmax(-1)\n",
    "#             ans_probs = ans_prob_dist[torch.arange(ans_prob_dist.size(0)), ans_ids]\n",
    "#             ans_tokens = tokenizer.convert_ids_to_tokens(ans_ids)\n",
    "#             for ans_id, ans_token, ans_prob, dist in zip(ans_ids, ans_tokens, numpy(ans_probs, decimals=3), ans_prob_dist):\n",
    "#                 top1_correct = (dist.argmax() == ans_id).item()\n",
    "#                 print(('*' if top1_correct else ' ') + ans_token, ans_prob, \n",
    "#                       show_topk(*dist.topk(5), indices_fn=tokenizer.convert_ids_to_tokens)) \n",
    "#     loss = nn.CrossEntropyLoss()(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "#     loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "6b5d2b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.convert_ids_to_tokens(617)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "f7d6edbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(s.count('Yes') for s in input_strs)\n",
    "# sum(s.count('No') for s in input_strs)\n",
    "# sum(s.count('all') for s in input_strs)\n",
    "# sum(s.count('none') for s in input_strs)\n",
    "# sum(s.count('some') for s in input_strs)\n",
    "# sum(s.count('3') for s in input_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d64330f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [e['input_ids'] for e in train_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ee181c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.convert_ids_to_tokens(([e['input_ids'] for e in train_dataset][0]).numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4ff9a2be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(eval_dataset.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c759bca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f588b59",
   "metadata": {},
   "source": [
    "# 请从这里开始,肖老师"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "17373019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Relationship between two sets. For example:\n",
      "Daniel: lemon, Ashley: grape, Amanda: grape, Harrison: pear. [] boys have fruits. [all / some / none]? -> all\n",
      "\n",
      "Instruction: Relationship between two sets. For example:\n",
      "Sarah: lemon, Alex: peach, Harrison: grape, Eva: plasticine. [] boys have toys. [all / some / none]? -> none\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# n_total, n_valid = 500, 100  #全部数目，测试数目\n",
    "# n_total, n_valid = 800, 200\n",
    "n_total, n_valid = 180, 30\n",
    "# n_total, n_valid =4,2\n",
    "n_train = n_total - n_valid\n",
    "# input_strs = [make_input_str(tasks[-7], nrows=1, ncols=(3,4,5)) for __ in range(n_total)]# Is the intersection of two sets empty.\n",
    "# input_strs = [make_input_str(tasks[-3], nrows=1, ncols=(4,4,3)) for __ in range(n_total)]# Are there any elements different from other elements\n",
    "# input_strs = [make_input_str(tasks[-4], nrows=1, ncols=(3,4,2,4)) for __ in range(n_total)]# Are_there_elements_belonging_to_the_same_class\n",
    "# input_strs = [make_input_str(tasks[-1], nrows=1, ncols=(5,2)) for __ in range(n_total)]#Is_the_number_of_first_elements_greater_than_the_second_one\n",
    "# input_strs = [make_input_str(tasks[-2], nrows=1, ncols=(3,1), ans_vocab=[0,1,2,3]) for __ in range(n_total)] #How_many_elements_are_similar_to_the_example\n",
    "# input_strs = [make_input_str(tasks[-5], nrows=1, ncols=(3,4,2,4)) for __ in range(n_total)] #Are_they_the_union_of_the_last_element\n",
    "# input_strs = [make_input_str(tasks[-6], nrows=1, ncols=(3,11,5)) for __ in range(n_total)]#Is the first set a subset of the second one\n",
    "# input_strs = [make_input_str(tasks[-10], nrows=1, ncols=(3, 3, 2, 5)) for __ in range(n_total)]\n",
    "# input_strs = [make_input_str(tasks[-9], nrows=1, ncols=(4,2)) for __ in range(n_total)] #Compare the values of two sets.\n",
    "input_strs = [make_input_str(tasks[-8], nrows=1, ncols=(4, 4, 4)) for __ in range(n_total)] #Relationship between two sets.\n",
    "\n",
    "for s in sample(input_strs, 2): print(s)\n",
    "# print(input_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "58f1d494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s,end = input_strs[0].index(\":\"),input_strs[0].index(\"For\")\n",
    "# name = input_strs[0][s+2:end]\n",
    "# import json\n",
    "# filename = './nrk/'+name\n",
    "# with open(filename,\"w\") as file_obj:\n",
    "#     json.dump(input_strs,file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "2e64ee95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Is this sentence correct. For example:\n",
      "A is less difficult to carry than B because A is smaller. Is that right? -> Yes\n",
      "\n",
      "Instruction: Is this sentence correct. For example:\n",
      "A is more dangerous to look at than B because A is less luminous. Is that right? -> No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in sample(text, 2): print(s)\n",
    "n_total, n_valid = 180, 30\n",
    "n_train = n_total - n_valid\n",
    "text = text[:180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "e2f80b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "# train_dataset = CHILDDataset(input_strs[:-n_valid], tokenizer)\n",
    "# eval_dataset = CHILDDataset(input_strs[-n_valid:], tokenizer)\n",
    "train_dataset = CHILDDataset(text[:-n_valid], tokenizer)\n",
    "eval_dataset = CHILDDataset(text[-n_valid:], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "82ad27d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wte = model.get_input_embeddings() #提取 embedding 中的 词向量部分\n",
    "if hasattr(wte, 'wte'): wte = wte.wte  # already been wrapped\n",
    "we = WrappedEmbedding(wte, prompt_len=40000)\n",
    "model.set_input_embeddings(we) #为词向量赋值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "416bbc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = []\n",
    "    bos_indices = []\n",
    "    eos_indices = []\n",
    "    preds = []\n",
    "    m = nn.Softmax(dim = -1)\n",
    "    labels_loc = pred.label_ids.argmax(-1)\n",
    "    for i in range(len(labels_loc)):\n",
    "        labels.append(pred.label_ids[i][labels_loc[i]])\n",
    "                                                                                 #     arraypre = pred.predictions[0] # 6B\n",
    "    arraypre = pred.predictions                                                                              # 1.3B\n",
    "    predss = arraypre.argmax(-1)\n",
    "    num = \"\"\n",
    "   \n",
    "    for bi in range(predss.shape[0]):\n",
    "        num = labels_loc[bi]\n",
    "        preds.append(predss[bi, num-1:num]) \n",
    "        t = torch.from_numpy(pred.predictions[bi,num-1:num])                        #1.3B\n",
    "                                                                                    #         t = torch.from_numpy(pred.predictions[0][bi,num-1:num])  #6B\n",
    "        n = m(t)\n",
    "        ids = torch.topk(n,3)[1].numpy().tolist()                                              #ids   /[0] 概率\n",
    "        loc = torch.topk(n,3)[0].numpy().tolist()\n",
    "                                                                                                 #         print(ids)\n",
    "        ids = tokenizer.convert_ids_to_tokens(ids[0])\n",
    "        loc = [float('{:.4f}'.format(i)) for i in loc[0]]\n",
    "        precision = [i+\" : \"+str(j) for i,j in zip(ids,loc)]\n",
    "    acc = accuracy_score(labels, list(preds))    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "d34fd7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, 3363, -100, -100, -100, -100,\n",
       "        -100, -100])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset[0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "eb7bf973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_metrics(pred):\n",
    "#     labels = []\n",
    "#     bos_indices = []\n",
    "#     preds = []\n",
    "#     labels_loc = pred.label_ids.argmax(-1)\n",
    "#     for i in range(len(labels_loc)):\n",
    "#         labels.append(pred.label_ids[i][labels_loc[i]])\n",
    "# #     print(labels)\n",
    "#     arraypre = pred.predictions[0] # 6B\n",
    "# # #     arraypre = pred.predictions # 1.3B\n",
    "#     print(arraypre)\n",
    "#     predss = arraypre.argmax(-1)\n",
    "#     sent = tokenizer.convert_ids_to_tokens(predss[0])\n",
    "#     sent1 = \" \".join(sent)\n",
    "#     sent1=sent1.replace(\"Ġ\",\"\")\n",
    "#     sent1=sent1.replace(\"Ċ\",\"\\n\")\n",
    "#     print(sent1)\n",
    "#     for bi in range(predss.shape[0]):\n",
    "#         for j in range(predss.shape[1]):\n",
    "#             if(predss[bi][j] == bos_id):\n",
    "#                 bos_indices.append(j)\n",
    "#         bos_i = bos_indices[-1]\n",
    "#         preds.append(predss[bi, bos_i + 1:bos_i + 2])\n",
    "    \n",
    "#     acc = accuracy_score(labels, list(preds))\n",
    "#     return {\n",
    "# #         'accuracy': acc,\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "6ebf074a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(output_dir=\"./models/model_name\",                                                             #模型预测和检查点的输出目录\n",
    "    overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=True, \n",
    "    per_device_train_batch_size=1, per_device_eval_batch_size=1,                                                  #每个GPU / TPU内核/ CPU的批处理大小\n",
    "    gradient_accumulation_steps=6,eval_steps=5, \n",
    "    weight_decay=0.001, adam_beta2=0.98, adam_epsilon=1e-6,                                      #weight_decay要应用的权重衰减,adam_epsilon AdamW优化器的ε超参数\n",
    "    lr_scheduler_type='constant', learning_rate=0.001, num_train_epochs=5,                                  #learning_rate:Adam初始学习率\n",
    "    logging_strategy ='epoch',  save_steps=0,                                             #save_steps保存两个检查点之前的更新步骤数\n",
    "    no_cuda=True, report_to='none',                                                         # to avoid report to wandb\n",
    "    evaluation_strategy ='steps',\n",
    "#     evaluation_strategy ='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "ff25273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(filename,\"a\") as f:\n",
    "#         f.write(str(training_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "d89c7d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/xd/projects/transformers/src/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, training_args, train_dataset=train_dataset, eval_dataset=eval_dataset,compute_metrics=compute_metrics,\n",
    "                  optimizers=(create_optimizer(model, training_args), None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "0aa95c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 01:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.5578513145446777,\n",
       " 'eval_accuracy': 0.0,\n",
       " 'eval_precision': ['ĠA : 0.1883', 'ĠIs : 0.059', 'ĠB : 0.0472'],\n",
       " 'eval_runtime': 9.2024,\n",
       " 'eval_samples_per_second': 3.26,\n",
       " 'eval_steps_per_second': 3.26}"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "c5b8d21d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 150\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 750\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 09:14, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.616900</td>\n",
       "      <td>1.304838</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>['ĠYes : 0.6459', 'ĠNo : 0.1877', 'Ġ[ : 0.0194']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.889400</td>\n",
       "      <td>13.196543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>['ĊĊ : 0.1545', 'Ċ : 0.1327', '\\\\ : 0.0873']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10.558700</td>\n",
       "      <td>12.672831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>['Ġthe : 0.1758', 'Ġof : 0.0498', '- : 0.0434']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9.712600</td>\n",
       "      <td>9.770533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>['Ġ : 0.273', 'Ġthe : 0.0731', 'Ġlike : 0.035']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.668000</td>\n",
       "      <td>2.120934</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>['ĠNo : 0.1628', 'ĠYes : 0.1345', 'Ġthe : 0.0488']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=750, training_loss=5.889138916015625, metrics={'train_runtime': 554.7103, 'train_samples_per_second': 1.352, 'train_steps_per_second': 1.352, 'total_flos': 224246237184000.0, 'train_loss': 5.889138916015625, 'epoch': 5.0})"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "90777ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 10\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.735599160194397, 'test_accuracy': 0.5, 'test_precision': ['ĠYes : 0.6578', 'ĠNo : 0.3009', 'Ġyes : 0.0071'], 'test_runtime': 3.1062, 'test_samples_per_second': 3.219, 'test_steps_per_second': 3.219}\n"
     ]
    }
   ],
   "source": [
    "test_dataset = CHILDDataset(text[:10], tokenizer)\n",
    "a = trainer.predict(test_dataset) #此处新生成了测试集\n",
    "print(a.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8d29120e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 30\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.0003098619054071605, 'test_accuracy': 1.0, 'test_precision': ['ĠNo : 0.9999', 'No : 0.0', 'Ġ : 0.0'], 'test_runtime': 50.5283, 'test_samples_per_second': 0.594, 'test_steps_per_second': 0.594}\n"
     ]
    }
   ],
   "source": [
    "# input_strs = [make_input_str(tasks[-7], nrows=100, ncols=(3,4,5)) for __ in range(30)]# Is the intersection of two sets empty.\n",
    "# input_strs = [make_input_str(tasks[-3], nrows=100, ncols=(4,4,3)) for __ in range(30)]# Are there any elements different from other elements\n",
    "# input_strs = [make_input_str(tasks[-4], nrows=100, ncols=(3,4,2,4)) for __ in range(30)]# Are_there_elements_belonging_to_the_same_class\n",
    "# input_strs = [make_input_str(tasks[-1], nrows=120, ncols=(5,2)) for __ in range(30)]#Is_the_number_of_first_elements_greater_than_the_second_one\n",
    "# input_strs = [make_input_str(tasks[-2], nrows=80, ncols=(3,1), ans_vocab=[0,1,2,3]) for __ in range(30)] #How_many_elements_are_similar_to_the_example\n",
    "# input_strs = [make_input_str(tasks[-5], nrows=100, ncols=(3,4,2,4)) for __ in range(30)] #Are_they_the_union_of_the_last_element\n",
    "# input_strs = [make_input_str(tasks[-6], nrows=100, ncols=(3,11,5)) for __ in range(30)]#Is the first set a subset of the second one\n",
    "# input_strs = [make_input_str(tasks[-10], nrows=100, ncols=(3, 3, 2, 5)) for __ in range(30)]\n",
    "# input_strs = [make_input_str(tasks[-9], nrows=100, ncols=(4,2)) for __ in range(30)] #Compare the values of two sets.\n",
    "# input_strs = [make_input_str(tasks[-8], nrows=100, ncols=(4, 4, 4)) for __ in range(30)] #Relationship between two sets.\n",
    "test_dataset = CHILDDataset(input_strs[:], tokenizer)\n",
    "a = trainer.predict(test_dataset) #此处新生成了测试集\n",
    "print(a.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d1961b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ef98c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedb8237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4622d39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a194cd0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afa17cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e6b876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b37a9874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.place_model_on_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9b4b3eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prev(elem):\n",
    "    i, v = elem\n",
    "    return _l[i - 1] if i > 0 else None\n",
    "\n",
    "false = lambda *_: False\n",
    "true  = lambda *_: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "721cb66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Element = namedtuple('Element', 'index value')\n",
    "_l = 'A B C B'.split()\n",
    "n = len(_l)\n",
    "# l = [Element._make(e) for e in enumerate(l)]\n",
    "l = seq(_l)\n",
    "l = l.enumerate().map(Element._make)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9f22f664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  index</th><th>value  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">      0</td><td>A      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      1</td><td>B      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      2</td><td>C      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      3</td><td>B      </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[Element(index=0, value='A'), Element(index=1, value='B'), Element(index=2, value='C'), Element(index=3, value='B')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['C']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['b']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['C', 'A', 'B', 'B']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['B', 'B', 'C', 'A']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  index</th><th>value  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">      0</td><td>A      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      1</td><td>A      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      2</td><td>C      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      3</td><td>B      </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[Element(index=0, value='A'), Element(index=1, value='A'), Element(index=2, value='C'), Element(index=3, value='B')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'B', 'C', 'C']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 1, 2, 3]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['B']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['B']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.map(lambda x: {'B': 'D'}.get(x, x))\n",
    "\n",
    "l.filter(lambda x: get_prev(x) == 'B').select(_.value)\n",
    "\n",
    "find_fn = _.index == 1\n",
    "l.filter(find_fn).select(_.value).map(lower)\n",
    "\n",
    "find_fn = _.value == 'C'\n",
    "l.filter(find_fn).select(_.index)\n",
    "\n",
    "# move x to first\n",
    "update_filter = _.value == 'C'\n",
    "get_new = lambda x: -1\n",
    "l.map(lambda x: Element(update_fn(x, 'index'), x.value)).order_by(_.index).select(_.value)\n",
    "\n",
    "# swap first and last\n",
    "update_filter = true\n",
    "get_new = lambda x: {0: n - 1, n - 1: 0}.get(x.index, x.index)\n",
    "l.map(lambda x: Element(update_fn(x, 'index'), x.value)).order_by(_.index).select(_.value)\n",
    "\n",
    "# get inbetween == drop_while + take_while?\n",
    "\n",
    "# update by index to its prev\n",
    "update_filter = _.index == 1\n",
    "get_new = lambda x: get_prev(x)\n",
    "def update_fn(x, update_field): return get_new(x) if update_filter(x) else getattr(x, update_field)\n",
    "l.map(lambda x: Element(x.index, update_fn(x, 'value')))\n",
    "\n",
    "# if two adjacent elements by indices are equal\n",
    "l.filter(lambda x: x.index in [0, 1]).select(_.value).distinct().len() == 1\n",
    "\n",
    "seq('A B C B C'.split()).group_by(_).select(_[1]).flatten()\n",
    "\n",
    "# count occurance till current\n",
    "seq('A B A C B A'.split()).inits().reverse().tail().map(lambda x: x.filter(_ == x.last()).len())\n",
    "\n",
    "# find special\n",
    "seq('A B A A'.split()).count_by_value().filter(_[1] == 1).select(_[0])\n",
    "\n",
    "# generalized find special\n",
    "seq('A A B C C D D'.split()).group_by(_).map(lambda x: (x[0], len(x[1]))).filter(_[1] == 1).select(_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b3e124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
