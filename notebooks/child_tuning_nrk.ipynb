{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6ea7a72",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (4.17.0)\n",
      "Requirement already satisfied: sacremoses in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: filelock in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (2021.10.8)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/xd/.local/lib/python3.8/site-packages (from transformers) (4.60.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (0.11.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/xd/.local/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages/PyYAML-6.0-py3.8-linux-x86_64.egg (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (1.21.2)\n",
      "Requirement already satisfied: requests in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/xd/.local/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: six in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e11bc1d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pyfunctional\n",
      "  Using cached PyFunctional-1.4.3-py3-none-any.whl (49 kB)\n",
      "Requirement already satisfied: dill>=0.2.5 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from pyfunctional) (0.3.4)\n",
      "Requirement already satisfied: tabulate<=1.0.0 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from pyfunctional) (0.8.9)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pyfunctional\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed pyfunctional-1.4.3\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pyfunctional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "367b7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run \"context_learning_nrk.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9398a888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Is this sentence correct. For example:\n",
      "A is harder to discern in water than B because A is more soluble. Is that right? -> Yes\n",
      "A is more comfortable than B because B is easier. Is that right? -> No\n",
      "A finds it easier to displace liquid in a tub than B because A is bigger. Is that right? -> Yes\n",
      "A is worse at withstanding additional force than B because A is more taut. Is that right? -> Yes\n",
      "A is less financially secure than B because B has a lot less money. Is that right? -> No\n",
      "A finds it easier to displace liquid in a tub than B because B is bigger. Is that right? -> No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text1 = text\n",
    "print(text1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7292808a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from IPython import get_ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "54a886cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ['HF_HOME'] = '/raid/xd/.cache/torch'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from types import MethodType\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, OrderedDict, Counter\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "from itertools import chain\n",
    "import math\n",
    "from functools import reduce\n",
    "import numpy as np \n",
    "# np.set_printoptions(threshold=np.inf)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data.sampler import RandomSampler, Sampler, SequentialSampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from transformers.data.data_collator import DataCollator, default_data_collator\n",
    "from transformers import AutoConfig, pipeline\n",
    "from transformers import RobertaForMaskedLM, RobertaTokenizer, GPT2LMHeadModel, GPT2Tokenizer, GPTNeoForCausalLM\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import HfArgumentParser, Trainer, TrainingArguments, set_seed, AdamW\n",
    "# from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "# from transformers.trainer_utils import EvaluationStrategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7f54c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPTNeoForCausalLM, GPTJForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dd287822",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/nas/xd/projects/PyFunctional')\n",
    "from functional import seq\n",
    "from functional.pipeline import Sequence\n",
    "from fn import _\n",
    "from collections import namedtuple \n",
    "import sys\n",
    "# sys.path.insert(0, '/nas/xd/projects/transformers/src/transformers')\n",
    "import os\n",
    "# device_mappings = {0: 1, 1: 5, 2: 6, 3: 7, 4: 2, 5: 3, 6: 0, 1: 4}\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(device_mappings[2])\n",
    "\n",
    "import random\n",
    "import string\n",
    "from collections import defaultdict, OrderedDict\n",
    "from itertools import product, chain\n",
    "import math\n",
    "import numpy as np\n",
    "from pattern.en import comparative\n",
    "import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a2a577ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/nas/xd/projects/PyFunctional')\n",
    "from functional import seq\n",
    "from functional.pipeline import Sequence\n",
    "from fn import _\n",
    "from collections import namedtuple \n",
    "import sys\n",
    "# sys.path.insert(0, '/nas/xd/projects/transformers/src/transformers')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7d5907ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "import openai\n",
    "openai.api_key = open('/nas/xd/projects/openai_api_keys.txt').readlines()[-1].split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "86a17aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Do all students choose courses in a department. For example:\n",
      "Q: Biology, X: Biology, L: History, X: History, Q: History; Chinese: Mat, Biology: Mat, History: Chi. X and Q,Chi? -> Yes\n",
      "\n",
      "Instruction: Do all students choose courses in a department. For example:\n",
      "I: Chemistry, B: Chemistry, R: Physics, B: History, R: History; History: Chi, Chemistry: Chi, Physics: CS. I and R,CS? -> No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_total, n_valid =30,2\n",
    "n_train = n_total - n_valid\n",
    "# input_strs = [make_input_str(tasks[-7], nrows=1, ncols=(3,4,5)) for __ in range(n_total)]# Is the intersection of two sets empty.\n",
    "# input_strs = [make_input_str(tasks[-3], nrows=1, ncols=(4,4,3)) for __ in range(n_total)]# Are there any elements different from other elements\n",
    "# input_strs = [make_input_str(tasks[-4], nrows=1, ncols=(3,4,2,4)) for __ in range(n_total)]# Are_there_elements_belonging_to_the_same_class\n",
    "# input_strs = [make_input_str(tasks[-1], nrows=1, ncols=(5,2)) for __ in range(n_total)]#Is_the_number_of_first_elements_greater_than_the_second_one\n",
    "# input_strs = [make_input_str(tasks[-2], nrows=1, ncols=(3,1), ans_vocab=[0,1,2,3]) for __ in range(n_total)] #How_many_elements_are_similar_to_the_example\n",
    "# input_strs = [make_input_str(tasks[-5], nrows=1, ncols=(3,4,2,4)) for __ in range(n_total)] #Are_they_the_union_of_the_last_element\n",
    "# input_strs = [make_input_str(tasks[-6], nrows=1, ncols=(3,11,5)) for __ in range(n_total)]#Is the first set a subset of the second one\n",
    "input_strs = [make_input_str(tasks[-10], nrows=1, ncols=(3, 3, 2, 5)) for __ in range(n_total)]\n",
    "# input_strs = [make_input_str(tasks[-9], nrows=1, ncols=(4,2)) for __ in range(n_total)] #Compare the values of two sets.\n",
    "# input_strs = [make_input_str(tasks[-8], nrows=1, ncols=(4, 4, 4)) for __ in range(n_total)] #Relationship between two sets.\n",
    "\n",
    "for s in sample(input_strs, 2): print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "21465a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_fn(engine):  # XD\n",
    "    def fn(text):\n",
    "        return openai.Completion.create(engine=engine, prompt=text, max_tokens=1, echo=True, logprobs=5).choices[0]\n",
    "    return fn\n",
    "\n",
    "engines = ['davinci', 'curie']\n",
    "for engine in engines:\n",
    "    model_name = 'openai_api_' + engine\n",
    "#     model = lambda x: openai.Completion.create(engine=engine, prompt=x, max_tokens=0, echo=True, logprobs=5).choices[0]\n",
    "    model = get_model_fn(engine)\n",
    "    models[model_name] = model, tokenizer\n",
    "    \n",
    "# model_name = 'openai_api_davinci'\n",
    "model_name = 'openai_api_curie'\n",
    "model, tokenizer = models[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "bf3af01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['EleutherAI/gpt-neo-1.3B', 'openai_api_davinci', 'openai_api_curie'])"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "693f563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_dist(d, topk=5): return {k: round(math.exp(v), 3) for k, v in sorted(d.items(), key=lambda x: x[1], reverse=True)[:topk]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "77d1817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ans_indices0(input_ids):\n",
    "    bos_id = tokenizer._convert_token_to_id('Ġ->')\n",
    "    eos_id = tokenizer._convert_token_to_id('Ċ')\n",
    "    bos_indices = (input_ids == bos_id).nonzero().squeeze(1).tolist()\n",
    "    eos_indices = (input_ids == eos_id).nonzero()[-len(bos_indices):].squeeze(1).tolist()\n",
    "    return bos_indices, eos_indices\n",
    "\n",
    "# def get_ans_indices1(input_ids):\n",
    "#     bos_id = tokenizer._convert_token_to_id('?')\n",
    "# #     print(\"bos_id\",bos_id)\n",
    "#     eos_id = tokenizer._convert_token_to_id('Ċ')\n",
    "#     period_ids = [tokenizer._convert_token_to_id('.'), tokenizer._convert_token_to_id('Ġ.')]\n",
    "# #     print(\"period_ids:\",period_ids)\n",
    "# #     l_bracket_id, r_bracket_id = tokenizer._convert_token_to_id('Ġ['), tokenizer._convert_token_to_id('Ġ]')\n",
    "# #     print(\"l_bracket_id\",l_bracket_id)\n",
    "# #     print(\"r_bracket_id:\",r_bracket_id)\n",
    "#     eos_indices = (input_ids == eos_id).nonzero().squeeze(1).tolist() #.nonezero()取非零元素坐标\n",
    "# #     print(\"eos_indices0:\",eos_indices)\n",
    "#     eos_indices = [i - 1 if input_ids[i - 1] in period_ids else i for i in eos_indices]\n",
    "# #     print(\"eos_indices1:\",eos_indices)\n",
    "# #     eos_indices = [i - 1 if input_ids[i - 1] == r_bracket_id else i for i in eos_indices]\n",
    "# #     print(\"eos_indices2:\",eos_indices)\n",
    "    \n",
    "#     def find_bos_index(start_i):\n",
    "#         for bos_i in range(start_i, start_i - 3, -1):\n",
    "# #             if input_ids[bos_i] == bos_id or input_ids[bos_i] == l_bracket_id and input_ids[bos_i - 1] == bos_id:\n",
    "#             if input_ids[bos_i] == bos_id:\n",
    "#                 if bos_i != start_i: print('subtokens:', tokenizer.convert_ids_to_tokens(input_ids[bos_i + 1: start_i + 2]))\n",
    "#                 return bos_i\n",
    "#         assert False\n",
    "#     bos_indices = [find_bos_index(i - 2) for i in eos_indices]\n",
    "# #     print(\"bos:\",bos_indices)\n",
    "# #     print(\"eos:\",eos_indices)\n",
    "#     return bos_indices, eos_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "bb474e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_num = 0\n",
    "def predict(model, text, ans_indices_fn, topk=3, return_reduced_loss=False, verbose=True):\n",
    "    use_openai_api = type(model) in [types.MethodType, types.FunctionType]  # openai.Completion.create\n",
    "    inputs = tokenizer.encode_plus(text, return_tensors='pt')\n",
    "#     print(inputs)\n",
    "    input_ids = inputs.input_ids\n",
    "#     print(input_ids)\n",
    "    bsz = input_ids.size(0)\n",
    "#     print(\"bsz = \",bsz)\n",
    "    labels = torch.ones_like(input_ids) * (-100)\n",
    "    if use_openai_api:\n",
    "        assert bsz == 1\n",
    "#         outputs = model(engine=engine, prompt=text, max_tokens=0, echo=True, logprobs=5).choices[0].logprobs\n",
    "        outputs = model(text).logprobs  # XD\n",
    "        ans_nlls = []\n",
    "    else:\n",
    "        inputs = prepare_inputs(inputs, model.device)\n",
    "        outputs = model(**inputs, output_attentions=False)\n",
    "        logits = outputs.logits\n",
    "    for bi in range(bsz):\n",
    "\n",
    "        bos_indices, eos_indices = ans_indices_fn(input_ids[bi])\n",
    "#         print(\"input_ids :\",input_ids[bi])\n",
    "#         print(\"ans_indices_fn:\",ans_indices_fn(input_ids[bi]))\n",
    "#         print(\"bos_indices:\",bos_indices)\n",
    "#         print(\"eos_indices:\",eos_indices)\n",
    "        examples = text.strip().split('\\n')\n",
    "#         print(\"bos_indices:\",bos_indices)\n",
    "        print(\"examples:\",examples)\n",
    "        assert len(bos_indices) == len(examples)-1, '%d != %d' % (len(bos_indices), len(examples))\n",
    "        num = 0\n",
    "        for i, (example, bos_i, eos_i) in enumerate(zip(examples, bos_indices, eos_indices)):\n",
    "#             if verbose: print(' ' + example, end='\\t')\n",
    "            ans_ids = input_ids[bi, bos_i + 1: eos_i]\n",
    "            print(\"ans_ids:\",ans_ids)\n",
    "            labels[bi, bos_i: eos_i - 1] = ans_ids\n",
    "            if use_openai_api:\n",
    "                ans_prob_dist = [get_prob_dist(d, topk=topk) for d in outputs.top_logprobs[bos_i + 1: eos_i]]\n",
    "                ans_probs = [math.exp(lp) for lp in outputs.token_logprobs[bos_i + 1: eos_i]]\n",
    "                ans_nlls += [-lp for lp in outputs.token_logprobs[bos_i + 1: eos_i]]\n",
    "            else:\n",
    "                ans_prob_dist = logits[bi, bos_i: eos_i - 1].softmax(-1)\n",
    "                ans_probs = ans_prob_dist[torch.arange(ans_prob_dist.size(0)), ans_ids]\n",
    "            ans_tokens = tokenizer.convert_ids_to_tokens(ans_ids)\n",
    "            num += 1\n",
    "            for ans_id, ans_token, ans_prob, dist in zip(ans_ids, ans_tokens, numpy(ans_probs, decimals=3), ans_prob_dist):\n",
    "                top1_correct = max(dist.items(), key=lambda x: x[1])[0] == ans_token.replace('Ġ', ' ') \\\n",
    "                    if use_openai_api else (dist.argmax() == ans_id).item()  \n",
    "                \n",
    "                if verbose:\n",
    "                    if(num == 1 and top1_correct):\n",
    "                        global correct_num\n",
    "                        correct_num += 1\n",
    "                    if(len(ans_tokens) <= 1):\n",
    "#                         if(top1_correct):\n",
    "#                             dictlocation1[example] = 1\n",
    "                        print(('！！！' if top1_correct else ' ') + ans_token, ans_prob, \n",
    "                              dist if use_openai_api else show_topk(*dist.topk(topk), indices_fn=tokenizer.convert_ids_to_tokens)) \n",
    "                        \n",
    "                    else:\n",
    "                        pass\n",
    "    if use_openai_api:\n",
    "        loss = ans_nlls if return_reduced_loss else sum(ans_nlls) / len(ans_nlls)\n",
    "    else:\n",
    "        loss = nn.CrossEntropyLoss()(logits.view(-1, logits.size(-1)), labels.view(-1)) if return_reduced_loss \\\n",
    "            else nn.CrossEntropyLoss(reduction='none')(logits.view(-1, logits.size(-1)), labels.view(-1))[labels.view(-1)>=0].tolist()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "f49b21a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "Instruction: Do all students choose courses in a department. For example:\n",
      "B: History, R: Sql, R: History, F: Art, B: Art; Sql: Mat, History: Eng, Art: Eng. F and B,Eng? -> Yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(input_strs))\n",
    "print(input_strs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "490ff768",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'B: History, R: Sql, R: History, F: Art, B: Art; Sql: Mat, History: Eng, Art: Eng. F and B,Eng? -> Yes']\n",
      "ans_ids: tensor([3363])\n",
      " ĠYes 0.04 {' F': 0.099, ' B': 0.083, ' No': 0.046, ' Yes': 0.04, ' Eng': 0.026}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.2294643"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'W: English, N: English, W: Sql, Z: English, Z: Sql; Geography: Eng, Sql: CS, English: CS. W and N,CS? -> Yes']\n",
      "ans_ids: tensor([3363])\n",
      " ĠYes 0.025 {' W': 0.134, ' CS': 0.06, ' English': 0.049, ' Yes': 0.025, ' No': 0.02}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.7054539"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'H: English, L: Chinese, L: Physics, Z: Chinese, H: Chinese; Physics: CS, English: CS, Chinese: Mat. H and Z,CS? -> No']\n",
      "ans_ids: tensor([1400])\n",
      " ĠNo 0.039 {' H': 0.087, ' CS': 0.07, ' Yes': 0.05, ' No': 0.039, ' Z': 0.025}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.2459452"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'A: History, A: Art, G: Art, R: Biology, G: History; Art: Chi, History: Mat, Biology: Mat. A and R,Chi? -> No']\n",
      "ans_ids: tensor([1400])\n",
      " ĠNo 0.022 {' A': 0.095, ' R': 0.034, ' Art': 0.033, ' B': 0.032, ' History': 0.024}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.8170967"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'M: Physics, J: Physics, F: Physics, F: Math, J: Math; Math: Chi, Biology: Eng, Physics: Chi. F and M,Eng? -> No']\n",
      "ans_ids: tensor([1400])\n",
      " ĠNo 0.033 {' F': 0.14, ' M': 0.047, ' No': 0.033, ' Yes': 0.031, ' Eng': 0.031}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.4081461"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'D: Art, R: Art, D: Sql, Y: Physics, Y: Art; Art: Chi, Sql: Mat, Physics: Chi. Y and R,Mat? -> No']\n",
      "ans_ids: tensor([1400])\n",
      " ĠNo 0.026 {' Y': 0.129, ' Yes': 0.05, ' R': 0.039, ' Chi': 0.032, ' Art': 0.026}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.6633525"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'K: Math, D: Biology, R: Chemistry, K: Chemistry, R: Biology; Chemistry: Chi, Math: Eng, Biology: Eng. R and K,Chi? -> Yes']\n",
      "ans_ids: tensor([3363])\n",
      " ĠYes 0.011 {' R': 0.142, ' K': 0.049, ' Chemistry': 0.04, ' Eng': 0.024, ' Chi': 0.021}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.5446343"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'Q: Biology, X: Biology, L: History, X: History, Q: History; Chinese: Mat, Biology: Mat, History: Chi. X and Q,Chi? -> Yes']\n",
      "ans_ids: tensor([3363])\n",
      " ĠYes 0.019 {' X': 0.107, ' No': 0.027, ' Q': 0.027, ' Yes': 0.019, ' Chi': 0.015}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.9736772"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'J: Physics, K: Physics, R: Physics, R: Art, K: Biology; Biology: Mat, Physics: CS, Art: Mat. K and J,Mat? -> No']\n",
      "ans_ids: tensor([1400])\n",
      " ĠNo 0.033 {' K': 0.124, ' Yes': 0.048, ' J': 0.047, ' No': 0.033, ' Mat': 0.027}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.4157999"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'I: English, Y: Geography, T: English, I: Music, Y: English; Music: Chi, Geography: Eng, English: Eng. T and I,Chi? -> No']\n",
      "ans_ids: tensor([1400])\n",
      " ĠNo 0.024 {' T': 0.075, ' I': 0.056, ' Chi': 0.034, ' Eng': 0.028, ' No': 0.024}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.7360075"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'O: Art, A: Art, M: Chinese, A: Chinese, A: Geography; Geography: Mat, Chinese: CS, Art: CS. M and O,Mat? -> No']\n",
      "ans_ids: tensor([1400])\n",
      " ĠNo 0.03 {' M': 0.085, ' CS': 0.069, ' Mat': 0.043, ' O': 0.038, ' A': 0.035}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.5119023"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'U: Physics, U: Art, Q: Physics, Q: Art, Y: Art; Sql: CS, Art: CS, Physics: Chi. Q and Y,CS? -> Yes']\n",
      "ans_ids: tensor([3363])\n",
      " ĠYes 0.023 {' CS': 0.054, ' Q': 0.044, ' Y': 0.037, ' No': 0.026, ' Yes': 0.023}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.7928112"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'Y: Biology, A: Physics, M: Chemistry, A: Chemistry, A: Biology; Physics: CS, Biology: Chi, Chemistry: CS. Y and A,CS? -> No']\n",
      "ans_ids: tensor([1400])\n",
      " ĠNo 0.031 {' Y': 0.143, ' A': 0.067, ' CS': 0.061, ' Yes': 0.056, ' No': 0.031}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.4713967"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'O: Geography, H: Geography, O: Art, R: English, O: English; English: Eng, Art: Mat, Geography: Mat. H and R,Eng? -> No']\n",
      "ans_ids: tensor([1400])\n",
      " ĠNo 0.044 {' H': 0.115, ' O': 0.069, ' Eng': 0.052, ' Yes': 0.046, ' No': 0.044}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.127809"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'K: Geography, L: Geography, K: Chinese, I: Biology, L: Chinese; Geography: CS, Chinese: Eng, Biology: CS. I and K,CS? -> Yes']\n",
      "ans_ids: tensor([3363])\n",
      " ĠYes 0.025 {' CS': 0.109, ' I': 0.072, ' K': 0.043, ' L': 0.035, ' No': 0.028}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.6733565"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'H: English, Z: Math, J: English, J: History, Z: English; English: Eng, Math: Eng, History: Mat. Z and H,Mat? -> No']\n",
      "ans_ids: tensor([1400])\n",
      " ĠNo 0.016 {' Z': 0.138, ' Eng': 0.061, ' English': 0.048, ' H': 0.028, ' J': 0.027}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.1510186"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'I: Sql, C: History, C: Music, I: Music, G: History; Music: Eng, History: Mat, Sql: Eng. I and G,Eng? -> No']\n",
      "ans_ids: tensor([1400])\n",
      " ĠNo 0.033 {' I': 0.08, ' Yes': 0.052, ' Eng': 0.044, ' No': 0.033, ' G': 0.032}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.4193516"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'H: Biology, L: Biology, H: Sql, L: Sql, M: Chemistry; Sql: Mat, Chemistry: Chi, Biology: Mat. M and L,Mat? -> No']\n",
      "ans_ids: tensor([1400])\n",
      " ĠNo 0.045 {' M': 0.103, ' Yes': 0.051, ' No': 0.045, ' Mat': 0.04, ' S': 0.026}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.1098552"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'J: Biology, X: Biology, X: Physics, I: Physics, J: English; Physics: Eng, Biology: Chi, English: Chi. J and I,Eng? -> No']\n",
      "ans_ids: tensor([1400])\n",
      " ĠNo 0.039 {' J': 0.076, ' Eng': 0.048, ' Yes': 0.045, ' I': 0.044, ' No': 0.039}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.2420323"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'N: Geography, Q: Geography, Q: Biology, N: Music, W: Geography; Music: CS, Geography: Mat, Biology: CS. Q and N,Mat? -> Yes']\n",
      "ans_ids: tensor([3363])\n",
      " ĠYes 0.019 {' Q': 0.207, ' CS': 0.054, ' N': 0.042, ' W': 0.033, ' No': 0.028}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.944714"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'K: Chemistry, M: Music, M: English, K: Music, Q: English; English: CS, Chemistry: Eng, Music: Eng. K and Q,Eng? -> No']\n",
      "ans_ids: tensor([1400])\n",
      " ĠNo 0.038 {' K': 0.097, ' CS': 0.058, ' English': 0.047, ' Yes': 0.044, ' No': 0.038}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.2752252"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'N: Art, E: Geography, E: Physics, N: Physics, G: Art; Physics: Chi, Geography: Mat, Art: Chi. G and E,Mat? -> No']\n",
      "ans_ids: tensor([1400])\n",
      " ĠNo 0.041 {' Chi': 0.058, ' G': 0.056, ' No': 0.041, ' E': 0.041, ' Yes': 0.039}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.1886263"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'B: English, R: Physics, K: Physics, K: English, B: Physics; Physics: Eng, Math: Mat, English: Eng. B and R,Eng? -> Yes']\n",
      "ans_ids: tensor([3363])\n",
      " ĠYes 0.048 {' B': 0.161, ' Yes': 0.048, ' No': 0.039, ' R': 0.037, ' Eng': 0.036}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.0290446"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'S: English, K: English, P: English, K: Art, K: Geography; Art: Mat, English: CS, Geography: CS. P and S,Mat? -> No']\n",
      "ans_ids: tensor([1400])\n",
      " ĠNo 0.027 {' P': 0.102, ' CS': 0.066, ' Mat': 0.045, ' S': 0.03, ' K': 0.028}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.6178932"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'M: Physics, X: History, M: Chinese, J: Physics, J: History; Chinese: CS, History: Eng, Physics: Eng. M and X,CS? -> No']\n",
      "ans_ids: tensor([1400])\n",
      " ĠNo 0.033 {' M': 0.097, ' CS': 0.089, ' Yes': 0.034, ' No': 0.033, ' Physics': 0.028}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.4114916"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'Q: Geography, U: Math, Q: Physics, U: Geography, X: Geography; Physics: Eng, Geography: CS, Math: CS. U and X,CS? -> Yes']\n",
      "ans_ids: tensor([3363])\n",
      " ĠYes 0.053 {' U': 0.074, ' Yes': 0.053, ' CS': 0.05, ' No': 0.049, ' X': 0.037}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.9343772"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'H: Chinese, W: Geography, T: Geography, T: Chinese, H: Sql; Sql: Chi, Geography: Chi, Chinese: CS. H and T,CS? -> Yes']\n",
      "ans_ids: tensor([3363])\n",
      " ĠYes 0.016 {' H': 0.139, ' CS': 0.084, ' T': 0.03, ' S': 0.026, ' W': 0.024}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.12379"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'O: Biology, P: Physics, O: Physics, C: Geography, O: Geography; Geography: Eng, Physics: Eng, Biology: Chi. C and P,Chi? -> No']\n",
      "ans_ids: tensor([1400])\n",
      " ĠNo 0.013 {' O': 0.054, ' C': 0.038, ' Eng': 0.037, ' P': 0.022, ' Chi': 0.017}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.3281345"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'U: Chemistry, U: Math, L: Chemistry, H: Math, L: Music; Music: Mat, Chemistry: Mat, Math: Chi. H and U,Mat? -> No']\n",
      "ans_ids: tensor([1400])\n",
      " ĠNo 0.031 {' H': 0.086, ' U': 0.057, ' Yes': 0.039, ' No': 0.031, ' Chemistry': 0.028}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.4841933"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'I: Chemistry, B: Chemistry, R: Physics, B: History, R: History; History: Chi, Chemistry: Chi, Physics: CS. I and R,CS? -> No']\n",
      "ans_ids: tensor([1400])\n",
      " ĠNo 0.022 {' I': 0.078, ' CS': 0.068, ' R': 0.041, ' Chemistry': 0.037, ' B': 0.032}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.8389473"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_num = 0\n",
    "for i in input_strs:\n",
    "# for i in text1:\n",
    "    text = i\n",
    "    predict(model, text, get_ans_indices0, verbose=True, topk=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "11e1569a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_num/len(input_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c28db7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1722,
   "id": "f14f83c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = [('a', 1), ('b', 2), ('a', 3), ('c', 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1723,
   "id": "3e3fb3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq(l).dom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1724,
   "id": "97c16cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq(l).codom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1725,
   "id": "b27075a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq(l).image('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1726,
   "id": "167173b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq(l).image(['a', 'c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1727,
   "id": "994d4e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq(l).preimage([3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58cba5e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from child_utils import *\n",
    "from common_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30243f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90f62ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "cache_dir = '/nas/xd/.cache/torch/transformers/'  # for models besides t5-3b/11b\n",
    "proxies = {'http': '192.168.50.1:1081'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "520d34a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_name = \"EleutherAI/gpt-j-6B\"\n",
    "model_name = \"EleutherAI/gpt-neo-1.3B\"\n",
    "# model = GPTJForCausalLM.from_pretrained(model_name, proxies=proxies, cache_dir=cache_dir)\n",
    "model = GPTNeoForCausalLM.from_pretrained(model_name, proxies=proxies, cache_dir=cache_dir)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', cache_dir=cache_dir)\n",
    "models[model_name] = model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "052c1e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_token = 'Ġ!'; prompt_id = tokenizer._convert_token_to_id(prompt_token)\n",
    "bop_str = 'Instruction: '; bop_id = tokenizer.encode(bop_str)[0]  # 'Inst'\n",
    "eop_str = '. For example:'; eop_id = tokenizer.encode(eop_str)[2] # 'Ġexample'\n",
    "bos_id = tokenizer._convert_token_to_id('Ġ->')\n",
    "eos_id = tokenizer._convert_token_to_id('Ċ')\n",
    "\n",
    "\n",
    "class CHILDDataset(Dataset):\n",
    "    def __init__(self, input_strs, tokenizer):\n",
    "        if tokenizer.pad_token is None: tokenizer.pad_token = '!'\n",
    "        self.inputs = tokenizer.batch_encode_plus(input_strs, add_special_tokens=False, padding=True, return_tensors='pt')#长的截，短的补\n",
    "        input_ids = self.inputs.input_ids\n",
    "        self.labels = torch.ones_like(input_ids) * (-100)\n",
    "\n",
    "        for bi in range(input_ids.size(0)): \n",
    "            bop_idx = (input_ids[bi] == bop_id).nonzero().squeeze(1) #prompt\n",
    "            eop_idx = (input_ids[bi] == eop_id).nonzero().squeeze(1) #context\n",
    "\n",
    "            if len(bop_idx) > 0:\n",
    "                assert len(bop_idx) == 1 and len(eop_idx) == 1\n",
    "                bop_idx, eop_idx = bop_idx.item(), eop_idx.item() #取出单元素张量的元素值并返回该值，保持原元素类型不变\n",
    "                #bop: 0   eop:6\n",
    "                input_ids[bi, bop_idx: eop_idx + 2] *= -1  # use prompt embedding for prompt tokens\n",
    "  \n",
    "            bos_indices = (input_ids[bi] == bos_id).nonzero().squeeze(1)\n",
    "#             print(\"bos_indices:\",bos_indices)\n",
    "            eos_indices = (input_ids[bi] == eos_id).nonzero()[-len(bos_indices):].squeeze(1) #每一位 eos都比bos大2\n",
    "#             print(\"eos_indices:\",eos_indices)\n",
    "            for i, (bos_i, eos_i) in enumerate(zip(bos_indices.tolist(), eos_indices.tolist())):\n",
    "                assert eos_i > bos_i + 1\n",
    "                if i >= 0:  #zero-shot\n",
    "                    self.labels[bi, bos_i + 1: eos_i] = input_ids[bi, bos_i + 1: eos_i] \n",
    "        \n",
    "        \n",
    "    def re_input(self):\n",
    "        return self.inputs['input_ids']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputs['input_ids'])\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {'input_ids': self.inputs['input_ids'][i],  #输入\n",
    "                'attention_mask': self.inputs['attention_mask'][i],\n",
    "                'labels': self.labels[i]}   #结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b322160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4613, 198)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_id,eos_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "696ea332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from child_utils import *\n",
    "torch.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56fcd441",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedEmbedding(nn.Module):\n",
    "    def __init__(self,  \n",
    "                wte: nn.Embedding,  #正常向量\n",
    "                prompt_id: int = None,\n",
    "                prompt_len: int = 10, \n",
    "                random_range: float = 0.5,\n",
    "                initialize_from_vocab: bool = True):\n",
    "        super(WrappedEmbedding, self).__init__()\n",
    "#         self.wte = wte\n",
    "#         self.prompt_id = prompt_id\n",
    "#         self.prompt_len = prompt_len\n",
    "        self.__dict__.update(locals()); del self.self #locals()以字典类型返回当前位置的全部局部变量\n",
    "        if self.prompt_id is not None: #prompt_embedding prompt词向量\n",
    "            self.prompt_embedding = nn.parameter.Parameter( #将一个不可训练的类型Tensor转换成可以训练的类型parameter\n",
    "                self.initialize_embedding(random_range, initialize_from_vocab)).to(self.wte.weight.device) #在-0.5-0.5中随机取值初始化\n",
    "        else:\n",
    "            self.prompt_embedding = nn.Embedding(self.prompt_len, self.wte.weight.size(1)).to(self.wte.weight.device)\n",
    "                                        #词典大小（总共输入多少词） 嵌入向量维度（多少维表示一个符号）\n",
    "            \n",
    "            assert initialize_from_vocab\n",
    "            self.init_prompt_embedding_()  #将wte的weight值作为初始化\n",
    "#             self.prompt_embedding.weight.data = self.initialize_embedding(random_range, initialize_from_vocab)     \n",
    " \n",
    "    def initialize_embedding(self, random_range: float = 0.5, initialize_from_vocab: bool = True):\n",
    "        if initialize_from_vocab: return self.wte.weight[:self.prompt_len].clone().detach() #返回一个新的tensor，新的tensor和原来的tensor共享数据内存，但不涉及梯度计算\n",
    "        return torch.FloatTensor(self.prompt_len, self.wte.weight.size(1)).uniform_(-random_range, random_range) #产生随机数\n",
    "    \n",
    "    def init_prompt_embedding_(self):\n",
    "#         print(self.wte.weight)\n",
    "        self.prompt_embedding.weight.data[:] = self.wte.weight[:self.prompt_len]\n",
    "\n",
    "        \n",
    "    def forward(self, input_ids):\n",
    "        if self.prompt_id is not None:\n",
    "            input_embeds = self.wte(input_ids)\n",
    "            input_embeds[input_ids == self.prompt_id] = self.prompt_embedding.expand(input_embeds.size(0), -1, -1)\n",
    "        else: # adapted from cpm-2\n",
    "            prompt_mask = input_ids < 0  #返回bool类型\n",
    "#             print(\"prompt_mask:\",prompt_mask.shape)\n",
    "            prompt_ids = -input_ids * prompt_mask #将prompt的值变为正数，其他置零\n",
    "#             print(\"prompt_ids:\",prompt_ids)\n",
    "#             print(prompt_ids < self.prompt_len)\n",
    "#             print(prompt_ids)\n",
    "            assert torch.all(prompt_ids < self.prompt_len)\n",
    "#             print(self.prompt_embedding(prompt_ids).shape)\n",
    "            p_embeds = self.prompt_embedding(prompt_ids) * prompt_mask.float().unsqueeze(-1)\n",
    "#             print(\"p_embeds:\",p_embeds.shape)\n",
    "            input_ids = input_ids * ~prompt_mask\n",
    "            w_embeds = self.wte(input_ids) * (~prompt_mask).float().unsqueeze(-1)\n",
    "#             print(\"w_embeds:\",w_embeds.shape)\n",
    "            input_embeds = w_embeds + p_embeds \n",
    "#         print(input_embeds)\n",
    "        return input_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44b17b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from cpm-2: https://github.com/TsinghuaAI/CPM-2-Finetune/blob/master/utils.py#L133-L164\n",
    "def get_params_for_prompt_optimization(module: nn.Module): #不训练模型参数，只训练prompt_embading，这个函数是取这些参数\n",
    "    params = []\n",
    "    for t in module.named_modules():\n",
    "        if \"prompt_embedding\" in t[0]:\n",
    "            params.append({'params': [p for p in list(t[1]._parameters.values()) if p is not None]})\n",
    "    for t in module.named_parameters():\n",
    "        if \"prompt\" not in t[0]:\n",
    "            t[1].requires_grad_(False)    \n",
    "    return params\n",
    "\n",
    "def create_optimizer(model, training_args):\n",
    "    from torch.nn.parallel.distributed import DistributedDataParallel as DDP\n",
    "    while isinstance(model, (DDP, )): model = model.module\n",
    "        \n",
    "    we.init_prompt_embedding_()\n",
    "    param_groups = get_params_for_prompt_optimization(model)\n",
    "    optimizer = AdamW(param_groups, lr=training_args.learning_rate, \n",
    "                      betas=(training_args.adam_beta1, training_args.adam_beta2),eps=training_args.adam_epsilon)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39b4f350",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# wte = model.get_input_embeddings() #提取 embedding 中的 词向量部分\n",
    "# if hasattr(wte, 'wte'): wte = wte.wte  # already been wrapped\n",
    "# we = WrappedEmbedding(wte, prompt_len=20000)\n",
    "# model.set_input_embeddings(we) #为词向量赋值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae3bb45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbalize(obj):\n",
    "    if type(obj) == bool: return 'Yes' if obj else 'No'\n",
    "    return str(obj)\n",
    "\n",
    "def list2str(l): return ' '.join(str(i) for i in l)\n",
    "def pairs2str(pairs): return ', '.join(str(k) + ': ' + str(v) for k, v in pairs)\n",
    "\n",
    "def make_context_str(cxt):\n",
    "    if type(cxt) == list:\n",
    "        return pairs2str(cxt) if type(cxt[0]) == tuple and len(cxt[0]) == 2 else list2str(cxt)\n",
    "    if type(cxt) == tuple:\n",
    "        return '; '.join(make_context_str(c) for c in cxt)  # 用分号分隔context的不同部分\n",
    "    \n",
    "def make_query_str(instruction, query):\n",
    "    if instruction is None and query is None: return ''\n",
    "    s = '.'\n",
    "    if instruction is not None: s = s + ' ' + instruction\n",
    "    if query is not None:\n",
    "        if type(query) in [int, bool, str]: query = [query]\n",
    "        if type(query) == dict:# and list(query.keys())[0] != \"CS\"):  # by nrk\n",
    "            s = s + ' ' + '{' + ','.join([' replace %s with %s' % (str(k), str(v)) for k, v in query.items()]) + ' }'\n",
    "        if type(query) in [list, tuple]:\n",
    "            s = s + ' ' + ' '.join([list2str(i) if type(i) == list else str(i) for i in query])\n",
    "    return s\n",
    "\n",
    "def make_example_str(example, query2str):\n",
    "    instruction, cxt, query, ans = example\n",
    "    if type(ans) not in [Sequence, list]: ans = [ans]\n",
    "    ans = [verbalize(a) for a in ans]\n",
    "#     return '%s -> %s' % (''.join(l[0]) + make_query_str(instruction if with_instruction else None, query), ' '.join(ans))  # by nrk\n",
    "#     return '%s -> %s' % (' '.join(l) + make_query_str(instruction if with_instruction else None, query), ' '.join(ans))  # by XD\n",
    "#     return '%s -> %s' % (make_context_str(cxt) + make_query_str(instruction if with_instruction else None, query[0]), ' '.join(ans))\n",
    "    return '%s -> %s' % (make_context_str(cxt) + query2str(query), ' '.join(ans))\n",
    "\n",
    "\n",
    "def sample_rand_len(vocab, k): return sample(vocab, k=randint(1, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "df63ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def promptize(s):\n",
    "#     return prompt_token * len(s.split())\n",
    "    return bop_str + s + eop_str\n",
    "\n",
    "courses_vocab=[\"Sql\",\"Math\",\"English\",\"Chinese\",\"Art\",\"Music\",\"History\",\"Biology\",\"Chemistry\",\"Physics\",\"Geography\"]\n",
    "all_vocab = [\"apple\",\"pear\",\"peach\",\"grape\",\"banana\",\"pineapple\",\"lemon\",\"strawberry\",\"cola\",\"juice\",\"coffee\",\"milk\",\"wine\",\"beer\",\"whisky\",\"vodka\",\"brandy\"]\n",
    "solid_vocab=[\"apple\",\"pear\",\"peach\",\"grape\",\"banana\",\"pineapple\",\"lemon\",\"strawberry\"]\n",
    "liquid_vocab=[\"cola\",\"juice\",\"coffee\",\"milk\",\"wine\",\"beer\",\"whisky\",\"vodka\",\"brandy\"]\n",
    "names_vocab =  [i for i in string.ascii_uppercase]\n",
    "depts_vocab = [\"CS\",\"Chi\",\"Eng\",\"Mat\"]\n",
    "sl = [\"solid\"]*len(solid_vocab)+[\"liquid\"]*len(liquid_vocab)\n",
    "sl_vocab = dict(zip(all_vocab,sl))\n",
    "toys = [\"ball\",\"doll\",\"puppet\",\"weiqi\",\"chess\",\"slide\",\"diabolo\",\"plasticine\",\"tumbler\"]\n",
    "                                              #滑梯     空竹      橡皮泥      不倒翁\n",
    "boys = [\"Alex\",\"Dylan\",\"Daniel\",\"Patrick\",\"Austin\",\"Harrison\",\"Tom\",\"Neil\"]\n",
    "girls = [\"Ashley\",\"jessica\",\"Sarah\",\"Amanda\",\"Nicole\",\"Katherine\",\"Anne\",\"Eva\"]\n",
    "all = boys+girls\n",
    "bg = [\"boys\"]*len(boys)+[\"girls\"]*len(girls)\n",
    "bg_vocab = dict(zip(all,bg))\n",
    "\n",
    "all = solid_vocab+toys\n",
    "ft = [\"fruits\"]*len(solid_vocab)+[\"toys\"]*len(toys)\n",
    "ft_vocab = dict(zip(all,ft))\n",
    "\n",
    "def make_input_str(task, nrows=4, ncols=4, full_vocab=None, ans_vocab=[True, False]):\n",
    "    if full_vocab is None: full_vocab = string.ascii_uppercase + string.digits\n",
    "    transform_fn, vocab_fn, sample_fn, query_fn, query2str = task\n",
    "    instruction = transform_fn.__name__.replace('_', ' ')\n",
    "    if vocab_fn is None: vocab_fn = lambda: full_vocab\n",
    "    if query_fn is None: query_fn = lambda *_: None\n",
    "        \n",
    "    examples = []\n",
    "    query = None\n",
    "    for i in range(nrows):\n",
    "        vocab = vocab_fn()\n",
    "        l = sample_fn(vocab, k=ncols)\n",
    "        query = query_fn(l, vocab, ncols)\n",
    "        examples.append([instruction, l, query, transform_fn(l, query=query)])\n",
    "    examples = balance(examples,ans_vocab)\n",
    "\n",
    "    desc = promptize(instruction) if True else ''\n",
    "    text = '\\n'.join([make_example_str(e, query2str) for e in examples])\n",
    "    text = desc + '\\n' + text + '\\n'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd0c286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def balance(examples, ans_vocab=[True, False]):\n",
    "# def balance1(examples, ans_vocab):\n",
    "#     groups = seq(examples).group_by(_[-1]).map(_[1])  # 按ans分组\n",
    "# #     assert groups.len() == len(ans_vocab), '%d < %d' % (groups.len(), len(ans_vocab))  # 保证每种ans都出现\n",
    "#     min_cnt = groups.map(lambda x: len(x)).min()\n",
    "#     examples = groups.map(lambda x: sample(x, min_cnt)).flatten().list() # 每组都采样最小个数后去分组\n",
    "#     return sample(examples, len(examples))  # 重新打乱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "2d664342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(examples, ans_vocab):\n",
    "    groups = seq(examples).group_by(_[-1]).map(_[1])  # 按ans分组\n",
    "#     min_cnt = groups.map(lambda x: len(x)).min()\n",
    "    min_cnt =3\n",
    "    if(groups.len()>3):\n",
    "        min_cnt = 3\n",
    "    elif(groups.len()==3):\n",
    "        min_cnt = 3\n",
    "    if(min_cnt > 2):\n",
    "        examples = groups.map(lambda x: sample(x, 3)).flatten().list() # 每组都采样最小个数后去分组\n",
    "        return sample(examples, len(examples))  # 重新打乱\n",
    "    else:\n",
    "        examples = groups.map(lambda x: sample(x, min_cnt)).flatten().list() # 每组都采样最小个数后去分组\n",
    "        return sample(examples, len(examples))  # 重新打乱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab80cfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools  \n",
    "def Do_all_students_choose_courses_in_a_department(cxt, query):\n",
    "    SC, CD = cxt  # SC paris: studeng-course relation, CD pairs: course-department function\n",
    "    ss, d = query  # ss: 学生子集（可以*不止两个学生*），d: 课程\n",
    "#     return seq(ss).map(lambda s: seq(SC).filter(_[0] == s).map(_[1]).intersection(CD.filter(_.[1] == d).map(_.[0])).non_empty()).all()\n",
    "    return (seq(ss)\n",
    "            .map(lambda s: seq(SC).filter(_[0] == s).map(_[1])  # 学生s选的所有课程\n",
    "                 .intersection(\n",
    "                     seq(CD).filter(_[1] == d).map(_[0])) # d系的课程\n",
    "                 .non_empty())  # s选了d系的课程\n",
    "            .all())  # 学生子集ss都选了d系的课程\n",
    "\n",
    "def all_a_sample(vocab, k):\n",
    "    S_vocab, C_vocab, D_vocab = vocab  # vocabs of students, courses, departments\n",
    "    k_S, k_C, k_D, k_SC = k  # default values: k_S = 3, k_C = 3, k_D = 2, k_SC = 5\n",
    "    S, C, D = sample(S_vocab, k_S), sample(C_vocab, k_C), sample(D_vocab, k_D)\n",
    "    \n",
    "    while len(set(CD := choices(D, k=k_C))) < k_D: continue  # ds里每个系的课都要出现\n",
    "    CD = list(zip(C, CD))  # 得到每门课所属的系\n",
    "    \n",
    "    all_SC = list(itertools.product(S, C))  # or seq(S).cartesian(C).list()\n",
    "    while seq(SC := sample(all_SC, k_SC)).map(_[0]).distinct().len() < k_S: continue  # ss里每个学生都要选课\n",
    "    return SC, CD\n",
    "\n",
    "def select_distinct(tuples, col): return seq(tuples).map(_[col]).distinct().list()\n",
    "    \n",
    "def all_a_query(cxt,vocab,k):\n",
    "    SC, CD = cxt\n",
    "    k_S, k_C, k_D, k_SC = k\n",
    "    S, D = select_distinct(SC, 0), select_distinct(CD, 1)\n",
    "#     k_ss = randint(2, len(S))\n",
    "    ss = sample(S, 2)\n",
    "    d = choice(D)\n",
    "    return ss, d\n",
    "\n",
    "def all_a_query2str(query):\n",
    "    ss, d = query\n",
    "    query_str = '%s,%s?' % (', '.join(ss[:-1]) + ' and ' + ss[-1], d)\n",
    "    return '. ' + query_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8103db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_b(cxt, query):\n",
    "    SC, CD = cxt\n",
    "    ss,d = query\n",
    "    return (seq(CD).filter(_[1] == d).map(_[0])\n",
    "                 .difference(\n",
    "                     seq(SC).filter(_[0] == ss).map(_[1]))\n",
    "                 .empty())\n",
    "\n",
    "def all_b_sample(vocab, k):\n",
    "    S_vocab, C_vocab, D_vocab = vocab  \n",
    "    k_S, k_C, k_D, k_SC = k  # default values: k_S = 2, k_C = 3, k_D = 2, k_SC = 5\n",
    "    S, C, D = sample(S_vocab, k_S), sample(C_vocab, k_C), sample(D_vocab, k_D)\n",
    "    \n",
    "    while len(set(CD := choices(D, k=k_C))) < k_D: continue  \n",
    "    CD = list(zip(C, CD)) \n",
    "    \n",
    "    all_SC = list(itertools.product(S, C))  \n",
    "    while seq(SC := sample(all_SC, k_SC)).map(_[0]).distinct().len() < k_S: continue  # ss里每个学生都要选课\n",
    "    return SC, CD\n",
    "   \n",
    "def all_b_query(cxt,vocab,k):  # XD: 不要给qeury_fn加st参数\n",
    "    SC, CD = cxt\n",
    "    k_S, k_C, k_D, k_SC = k\n",
    "    S, D = select_distinct(SC, 0), select_distinct(CD, 1)\n",
    "#     k_ss = randint(2, len(S))  # XD: k_ss unused\n",
    "    ss = choice(S)\n",
    "    d = choice(D)\n",
    "    return ss, d\n",
    "    # XD: 不要在query_fn里转str！！这里转str，transform_fn里再解析回来，两边不是白折腾吗！\n",
    "\n",
    "def all_b_query2str(query):\n",
    "    ss, d = query\n",
    "    query_str = 'Does %s take all %s courses?' % (ss, d)\n",
    "    return '. ' + query_str\n",
    "\n",
    "\n",
    "def Is_the_intersection_of_two_sets_empty(cxt, query):\n",
    "    SC= cxt\n",
    "    s,d = query\n",
    "    return (seq(SC).filter(_[0] == s).map(_[1])\n",
    "                 .intersection(\n",
    "                     seq(SC).filter(_[0] == d).map(_[1]))\n",
    "                 .non_empty())\n",
    "\n",
    "def intersection_query(cxt,vocab,k):\n",
    "    SC= cxt\n",
    "    k_S, k_C, k_SC = k #k_s = 3, k_C = 5 , k_sc = 6\n",
    "    S = select_distinct(SC, 0)\n",
    "    s,d = sample(S,2)\n",
    "    return s, d\n",
    "\n",
    "def intersection_query2str(query):\n",
    "    s, d = query\n",
    "    query_str = \"%s,%s?\" % (s, d)\n",
    "    return '. ' + query_str\n",
    "\n",
    "def intersection_sample(vocab, k):\n",
    "    S_vocab, C_vocab = vocab  \n",
    "    k_S, k_C, k_SC = k  # k_S = 3, k_C = 5, , k_SC = 6\n",
    "    S, C= sample(S_vocab, k_S), sample(C_vocab, k_C)\n",
    "    all_SC = list(itertools.product(S, C))  \n",
    "    while seq(SC := sample(all_SC, k_SC)).map(_[0]).distinct().len() < k_S: continue \n",
    "    return SC\n",
    "\n",
    "def Is_the_first_set_a_subset_of_the_second_one(cxt, query):\n",
    "    SC= cxt\n",
    "    s,d = query\n",
    "    return (seq(SC).filter(_[0] == d).map(_[1])\n",
    "                 .union(\n",
    "                     seq(SC).filter(_[0] == s).map(_[1]))\n",
    "                 ).distinct().len()== seq(SC).filter(_[0] == d).map(_[1]).distinct().len()\n",
    "\n",
    "def complement_query(cxt,vocab,k):\n",
    "    SC= cxt\n",
    "    k_S, k_C, k_SC = k #k_s = 3, k_C = 5 , k_sc = 6\n",
    "    S = select_distinct(SC, 0)\n",
    "    s,d = sample(S,2)\n",
    "    return s, d\n",
    "\n",
    "def complement_query2str(query):\n",
    "    s, d = query\n",
    "    query_str = \"%s,%s?\" % (s, d)\n",
    "    return '. ' + query_str\n",
    "\n",
    "def complement_sample(vocab, k):\n",
    "    S_vocab, C_vocab = vocab  \n",
    "    k_S, k_C, k_SC = k  # k_S = 3, k_C = 4, k_SC = 5\n",
    "    S, C= sample(S_vocab, k_S), sample(C_vocab, k_C)\n",
    "    all_SC = list(itertools.product(S, C))  \n",
    "    while seq(SC := sample(all_SC, k_SC)).map(_[0]).distinct().len() < k_S: continue \n",
    "    return SC\n",
    "\n",
    "def Are_they_the_union_of_the_last_element(cxt, query):\n",
    "    SC, DC = cxt\n",
    "    ss,d = query\n",
    "    return (seq(ss)\n",
    "            .map(lambda s: seq(SC).filter(_[0] == s).map(_[1]) \n",
    "                 .union(\n",
    "                     seq(DC).filter(_[0] == d).map(_[1])) \n",
    "                 .distinct().len() == seq(DC).filter(_[0] == d).map(_[1]).distinct().len())  \n",
    "            .all()) \n",
    "\n",
    "def union_sample(vocab, k):\n",
    "    S_vocab, C_vocab, D_vocab = vocab  \n",
    "    k_S, k_C, k_D, k_SC = k  # k_S = 3, k_C = 4, k_D = 2, k_SC = 6\n",
    "    S, C, D = sample(S_vocab, k_S), sample(C_vocab, k_C), sample(D_vocab, k_D)\n",
    "    \n",
    "    while len(set(DC := choices(D, k=k_C))) < k_D: continue  \n",
    "    DC = list(zip(DC,C)) \n",
    "    \n",
    "    all_SC = list(itertools.product(S, C))  \n",
    "    while seq(SC := sample(all_SC, k_SC)).map(_[0]).distinct().len() < k_S: continue  \n",
    "    return SC, DC\n",
    "   \n",
    "def union_query(cxt,vocab,k): \n",
    "    SC, DC = cxt\n",
    "    k_S, k_C, k_D, k_SC = k\n",
    "    S, D = select_distinct(SC, 0), select_distinct(DC, 0)\n",
    "    k_ss = randint(2, len(S))\n",
    "    ss = sample(S, k_ss)\n",
    "    d = choice(D)\n",
    "    return ss, d\n",
    "\n",
    "def union_query2str(query):\n",
    "    ss, d = query\n",
    "    query_str = '%s,%s?' % (', '.join(ss[:-1]) + ' and ' + ss[-1], d)\n",
    "    return '. ' + query_str\n",
    "\n",
    "def Are_there_elements_belonging_to_the_same_class(cxt, query): #新建联系，把vocab和属性连起来形成新集合\n",
    "    NA, DA = cxt\n",
    "    s,d = query\n",
    "    D = seq(DA).filter(_[0] == d).map(_[1])\n",
    "    return (seq(NA).filter(_[0] == s).map(_[1]).select(lambda x: sl_vocab[x] == sl_vocab[D[0]]).any())\n",
    "      \n",
    "    \n",
    "def find_sample(vocab, k): \n",
    "    name_vocab, all_vocab = vocab\n",
    "    k_name, k_all, k_D, k_SA = k  # k_name = 3, k_all = 4, k_D = 2, k_SA = 6\n",
    "    S = list(all_vocab.keys())\n",
    "    N, A, D = sample(name_vocab, k_name), sample(S, k_all), sample(string.ascii_lowercase, k_D)\n",
    "#     D = sample(d := name_vocab.pop(name_vocab.index(a) for a in N),k_D)\n",
    "    A1 = sample(S, k_D)\n",
    "    DA = list(zip(D,A1)) \n",
    "    \n",
    "    all_NA = list(itertools.product(N, A))  \n",
    "    while seq(NA := sample(all_NA, k_SA)).map(_[0]).distinct().len() < k_name: continue  \n",
    "    return NA, DA\n",
    "   \n",
    "def find_query(cxt,vocab,k): \n",
    "    NA, DA = cxt\n",
    "    k_name, k_all, k_D, k_SA = k\n",
    "    S,D = select_distinct(NA, 0), select_distinct(DA, 0)\n",
    "    s,d = choice(S), choice(D)\n",
    "    return s, d\n",
    "\n",
    "def find_query2str(query):\n",
    "    s, d = query\n",
    "    query_str = '%s,%s?' % (s, d)\n",
    "    return '. ' + query_str\n",
    "\n",
    "\n",
    "def Are_there_any_elements_different_from_other_elements(cxt, query):\n",
    "    NA = cxt\n",
    "    ss = query\n",
    "    return (seq(ss).map(lambda s: seq(NA).filter(_[0] == s).map(_[1])\n",
    "                        .select(lambda x: sl_vocab[x])[0])\n",
    "            .distinct().len( ) == 2)\n",
    "               \n",
    "def find_dif_sample(vocab, k):\n",
    "    name_vocab, all_vocab = vocab\n",
    "    k_name, k_all, k_SA = k  # k_name = 4, k_all = 4, k_SA= 3\n",
    "    N, A = sample(name_vocab, k_name), sample(list(all_vocab.keys()), k_all) \n",
    "    NA = list(zip(N,A)) \n",
    "    return NA\n",
    "   \n",
    "def find_dif_query(cxt,vocab,k): \n",
    "    NA = cxt\n",
    "    k_name, k_all, k_NA = k\n",
    "    S = select_distinct(NA, 0)\n",
    "    ss = sample(S,k_NA)\n",
    "    return ss\n",
    "\n",
    "\n",
    "def find_dif_query2str(query):\n",
    "    ss = query\n",
    "    query_str = '%s?' % (', '.join(ss[:-1]) + ' and ' + ss[-1])\n",
    "    return '. ' + query_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "464efbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def How_many_elements_are_similar_to_the_case(cxt, query):\n",
    "    s = cxt\n",
    "    q = query\n",
    "    return seq(s).filter(lambda x: sl_vocab[x] == sl_vocab[q[0]]).len()\n",
    "                     \n",
    "def count_sample(vocab, k):\n",
    "    all_vocab = vocab\n",
    "    k_cxt,k_query = k  # k_cxt = 4 ,k_query =1\n",
    "    N = list(all_vocab.keys())\n",
    "    s = sample(N, k_cxt) \n",
    "    return s\n",
    "   \n",
    "def count_query(cxt,vocab,k): \n",
    "    NA = cxt\n",
    "    k_cxt,k_query = k\n",
    "    N = list(vocab.keys())\n",
    "    q = sample(N,k_query)\n",
    "    return q\n",
    "\n",
    "def count_query2str(query):\n",
    "    q = query\n",
    "    query_str = '%s?' % (q[0])\n",
    "    return '. ' + query_str\n",
    "\n",
    "def Is_the_number_of_first_elements_greater_than_the_second_one(cxt, query):\n",
    "    s = cxt\n",
    "    q = query\n",
    "    return (seq(s).filter(lambda x: sl_vocab[x] == sl_vocab[q[0]]).len() >= len(s)/2)\n",
    "                     \n",
    "def compare_sample(vocab, k):\n",
    "    all_vocab,s_vocab,l_vocab = vocab\n",
    "    k_cxt,k_query = k  # k_cxt = 5 ,k_query =2\n",
    "    N = list(all_vocab.keys())\n",
    "    s = sample(N, k_cxt) \n",
    "    return s\n",
    "   \n",
    "def compare_query(cxt,vocab,k): \n",
    "    NA = cxt\n",
    "    all_vocab,s_vocab,l_vocab = vocab\n",
    "    k_cxt,k_query = k\n",
    "    q = sample(s_vocab,1)+sample(l_vocab,1)\n",
    "    random.shuffle(q)\n",
    "    return q\n",
    "\n",
    "def compare_query2str(query):\n",
    "    ss,q = query\n",
    "    query_str = '%s,%s?' % (ss,q)\n",
    "    return '. ' + query_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62aee837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ascii_size_existence(l, query): return seq(l).map(_[0] > query).any()\n",
    "def Ascii_size_all(l, query): return seq(l).map(_[0] > query).all()\n",
    "def Ascii_size_None(l, query): return seq(l).filter(_[0] > query).empty()\n",
    "def ith_element(l, query=None): return seq(l).slice(1, 2)\n",
    "def ith_group(l, query=None): return seq(l).group_by(_).select(_[1]).slice(1, 2).flatten()#.distinct()# davinci F w/ and wo dist\n",
    "# def element_at_index(l, query): return seq(l).slice(query, query + 1) # davinci F\n",
    "def element_at_index(l, query): return seq(l).enumerate().filter(_[0] == query).select(_[1])\n",
    "def replace(l, query): return seq(l).map(lambda x: query.get(x, x))\n",
    "def replace_with_the_other(l, query): # davinci F\n",
    "    query = {k: (set(l) - {k}).pop() for k in l}\n",
    "    return replace(l, query)\n",
    "def replace_all_with(l, query): return seq(l).map(lambda x: query)  # davinci F?!\n",
    "def interleave_with(l, query): return seq(l).flat_map(lambda x: [x, query])  # davinci T!!\n",
    "def unique_elements(l, query=None): return seq(l).distinct() # davinci F\n",
    "def how_many_unique_elements(l, query=None): return seq(l).distinct().len()  # davinci F\n",
    "def how_many(l, query): return seq(l).filter(_ == query).len() # davinci F\n",
    "def select_same_as(l, query): return seq(l).filter(_ == query) # simpler version of how_many. davinci F\n",
    "def select_same_number_as(l, query): return seq(l).group_by(_).select(_[1]).filter(lambda x: len(x) == len(query)).flatten() # F\n",
    "def includes(l, query): return seq(l).union(seq(query)).distinct().len() == seq(l).distinct().len() # davinci F\n",
    "def is_included_by(l, query): return seq(l).difference(seq(query)).empty() # davinci F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "388dd77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compare_the_values_of_two_sets(cxt, query):\n",
    "    s = cxt\n",
    "    q = query\n",
    "    if(seq(s).filter(lambda x: sl_vocab[x] == sl_vocab[q[0]]).len() > len(s)/2):\n",
    "        return \">\"\n",
    "    elif(seq(s).filter(lambda x: sl_vocab[x] == sl_vocab[q[0]]).len() < len(s)/2):\n",
    "        return \"<\"\n",
    "    else:\n",
    "        return \"=\"\n",
    "\n",
    "def Compare_sample(vocab, k):\n",
    "    all_vocab,s_vocab,l_vocab = vocab\n",
    "    k_cxt,k_query = k  # k_cxt = 5 ,k_query =2\n",
    "    N = list(all_vocab.keys())\n",
    "    s = sample(N, k_cxt) \n",
    "    return s\n",
    "   \n",
    "def Compare_query(cxt,vocab,k): \n",
    "    NA = cxt\n",
    "    all_vocab,s_vocab,l_vocab = vocab\n",
    "    k_cxt,k_query = k\n",
    "    q = sample(s_vocab,1)+sample(l_vocab,1)\n",
    "    random.shuffle(q)\n",
    "    return q\n",
    "\n",
    "def Compare_query2str(query):\n",
    "    ss,q = query\n",
    "    query_str = '%s,%s?' % (ss,q)\n",
    "    return '. ' + query_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48028352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Relationship_between_two_sets(cxt, query): #新建联系，把vocab和属性连起来形成新集合\n",
    "    NA = cxt\n",
    "    s,q= query   #s:boys/girls  q:fruits/toys\n",
    "    name = seq(NA).filter(lambda x: bg_vocab[x[0]] == s)\n",
    "    if(seq(name).map(_[1]).filter(lambda x: ft_vocab[x] == q).len() == seq(name).len()):\n",
    "        return \"all\"\n",
    "    elif(seq(name).map(_[1]).filter(lambda x: ft_vocab[x] == q).empty()):\n",
    "        return \"none\"\n",
    "    else:\n",
    "        return \"some\"\n",
    "    \n",
    "def Relationship_sample(vocab, k): \n",
    "    name_vocab, all_vocab = vocab\n",
    "    k_name, k_all, k_SA = k  # k_name = 4, k_all = 4, k_SA = 4\n",
    "    Name = list(name_vocab.keys())\n",
    "    S = list(all_vocab.keys())\n",
    "    N, A = sample(Name, k_name), sample(S, k_all)\n",
    "#     D = sample(d := name_vocab.pop(name_vocab.index(a) for a in N),k_D)\n",
    "    \n",
    "    all_NA = list(itertools.product(N, A))  \n",
    "    while seq(NA := sample(all_NA, k_SA)).map(_[0]).distinct().len() < k_name: continue  \n",
    "    return NA\n",
    "   \n",
    "def Relationship_query(cxt,vocab,k): \n",
    "    NA = cxt\n",
    "    name_vocab, all_vocab = vocab\n",
    "    k_name, k_all, k_SA = k\n",
    "    S,D = select_distinct(NA, 0),select_distinct(NA, 1)\n",
    "    s,d = choice(S),choice(D)\n",
    "    s1,d1 = name_vocab[s],all_vocab[d]\n",
    "    return s1,d1\n",
    "\n",
    "def Relationship_query2str(query):\n",
    "    s,q = query\n",
    "    query_str = '[] %s have %s. [all / some / none]?' % (s,q)\n",
    "    return '. ' + query_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f199b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\n",
    "    (ith_element,            None,                               sample,    None,None),\n",
    "    (ith_group,              None, lambda vocab, k: seq(sample(vocab, k)).map(lambda x:[x]*randint(1, 3)).flatten().list(),None,None),\n",
    "    (element_at_index,       lambda: upper_letters,              sample,    lambda l,vocab,k: randint(0, min(2,len(l)-1))),\n",
    "    (replace,                None,                               sample,    lambda l,vocab,k: {choice(l): choice(vocab)}),\n",
    "    (replace_with_the_other, lambda: sample(full_vocab, 2),   lambda vocab,k: sample(vocab+choices(vocab, k=k-2),k), None),\n",
    "    (replace_all_with,       None,                               sample_rand_len, lambda l,vocab,k: choice(vocab)),\n",
    "    (interleave_with,        None,                               sample_rand_len, lambda l,vocab,k: choice(vocab)),\n",
    "    (unique_elements,        lambda: sample(upper_letters, 3),   choices,   None),\n",
    "    (how_many_unique_elements,lambda: sample(upper_letters, 3),  choices,   None),\n",
    "    (how_many,               lambda: sample(upper_letters, 3),   choices,   lambda l,vocab,k: choice(list(set(l)))),\n",
    "    (select_same_as,         lambda: sample(upper_letters, 3),   choices,   lambda l,vocab,k: choice(list(set(l)))),\n",
    "    (select_same_number_as,  None, lambda vocab, k: seq(sample(vocab, k)).map(lambda x:[x]*randint(1, 3)).flatten().list(),   \n",
    "     lambda l,vocab,k: [choice(vocab)]*randint(1, 3)),\n",
    "    (includes,               lambda: sample(upper_letters, 6),   sample,    lambda l,vocab,k: sample(vocab, 3)),\n",
    "    (is_included_by,         lambda: sample(upper_letters, 6),   sample,    lambda l,vocab,k: sample(vocab, 5)),\n",
    "    \n",
    "    (Ascii_size_None,        lambda: string.ascii_uppercase,              sample,    lambda l,vocab,k: \"Is there no element greater than %s?\" % choice(list(set(l)))),\n",
    "    (Ascii_size_all,         lambda: string.ascii_uppercase,              sample,    lambda l,vocab,k: \"Are all elements greater than %s?\" % choice(list(set(l)))),\n",
    "    (Ascii_size_existence,   lambda: string.ascii_uppercase,              sample,    lambda l,vocab,k: \"Is there an element greater than %s?\" % choice(list(set(l)))),\n",
    "    \n",
    "#     (all_a,                  lambda: [names_vocab,courses_vocab,depts_vocab],     all_a_sample,    all_a_query, all_a_query2str),\n",
    "    (Do_all_students_choose_courses_in_a_department,    lambda: [names_vocab,courses_vocab,depts_vocab],     all_a_sample,    all_a_query, all_a_query2str),\n",
    "    (Compare_the_values_of_two_sets,  lambda: [sl_vocab,solid_vocab,liquid_vocab],  Compare_sample,    Compare_query, Compare_query2str),\n",
    "    (Relationship_between_two_sets,   lambda: [bg_vocab,ft_vocab],               Relationship_sample,    Relationship_query, Relationship_query2str),\n",
    "    (Is_the_intersection_of_two_sets_empty,           lambda: [string.ascii_uppercase,string.ascii_lowercase],     intersection_sample,    intersection_query, intersection_query2str),\n",
    "    (Is_the_first_set_a_subset_of_the_second_one,           lambda: [string.ascii_uppercase,string.ascii_lowercase],     complement_sample,    complement_query, complement_query2str),\n",
    "    (Are_they_the_union_of_the_last_element,                lambda: [string.ascii_uppercase,string.ascii_lowercase,depts_vocab],     union_sample,    union_query, union_query2str),\n",
    "    (Are_there_elements_belonging_to_the_same_class,            lambda: [string.ascii_uppercase,sl_vocab],      find_sample,    find_query, find_query2str ),\n",
    "    (Are_there_any_elements_different_from_other_elements,          lambda: [string.ascii_uppercase,sl_vocab],      find_dif_sample,  find_dif_query, find_dif_query2str ),\n",
    "    (How_many_elements_are_similar_to_the_case,                lambda: sl_vocab,                                      count_sample,            count_query,count_query2str),\n",
    "    (Is_the_number_of_first_elements_greater_than_the_second_one,              lambda: [sl_vocab,solid_vocab,liquid_vocab],          compare_sample,            compare_query,compare_query2str),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1365,
   "id": "105e915f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-8], nrows=30, ncols=(4, 4, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "91683062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-9], nrows=8, ncols=(4,2))) #比较，query中给了两个元素（固体、液体），\n",
    "                                                        #若前一个元素的类型数目大于后一个，就输出YES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "dc45005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-9], nrows=80, ncols=(2, 3, 2, 5))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "e98e87d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Are there any elements different from other elements. For example:\n",
      "M: beer, N: pear, B: milk, G: peach. N, B and G? -> Yes\n",
      "F: juice, P: cola, E: coffee, G: pineapple. F, P and E? -> No\n",
      "U: grape, C: whisky, Z: juice, T: beer. Z, C and T? -> No\n",
      "H: whisky, R: apple, L: strawberry, O: brandy. R, L and O? -> Yes\n",
      "V: juice, W: brandy, P: coffee, O: banana. O, W and P? -> Yes\n",
      "H: banana, J: pineapple, E: coffee, G: grape. H, G and J? -> No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(make_input_str(tasks[-3], nrows=80, ncols=(4,4,3))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "6fb4988c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Are there elements belonging to the same class. For example:\n",
      "P: banana, P: brandy, I: brandy, U: peach; v: grape, b: wine. I,b? -> Yes\n",
      "K: whisky, P: apple, K: cola, L: apple; v: whisky, a: strawberry. K,a? -> No\n",
      "R: pear, R: cola, E: strawberry, M: cola; q: pear, h: vodka. E,h? -> No\n",
      "N: pineapple, Z: pineapple, C: coffee, C: juice; p: lemon, j: milk. N,p? -> Yes\n",
      "E: beer, J: milk, I: peach, I: beer; j: peach, n: banana. E,j? -> No\n",
      "R: grape, P: grape, P: juice, N: grape; k: milk, n: vodka. P,k? -> Yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(make_input_str(tasks[-4], nrows=100, ncols=(3,4,2,4)))  #找相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "f4070da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-1], nrows=8, ncols=(5,2))) #比较，query中给了两个元素（固体、液体），\n",
    "                                                        #若前一个元素的类型数目大于后一个，就输出YES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "4f3668d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-2], nrows=30, ncols=(3,1), ans_vocab=[0,1,2,3]))    #数数，数cxt中与query中元素同类的个数\n",
    "                                                                                  #这里修改了balance函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "db442a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-5], nrows=10, ncols=(3,4,2,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "eadf0bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-6], nrows=18, ncols=(3,11,5))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "c8c59a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-7], nrows=4, ncols=(3,4,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1377,
   "id": "c3df9c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Do all students choose courses in a department. For example:\n",
      "L: Geography, L: English, B: Chemistry, L: Chemistry, Z: Chemistry; English: Eng, Geography: Eng, Chemistry: Mat. B and L,Eng? -> No\n",
      "J: History, O: Art, O: History, J: Math, D: History; History: CS, Art: Mat, Math: Mat. D and O,CS? -> Yes\n",
      "Z: Sql, Z: Music, P: Chemistry, P: Sql, T: Music; Sql: Eng, Music: Eng, Chemistry: Chi. P and Z,Chi? -> No\n",
      "J: Chinese, J: Music, U: Music, J: Sql, H: Chinese; Chinese: CS, Sql: Eng, Music: Eng. J and H,CS? -> Yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(make_input_str(tasks[-10], nrows=100, ncols=(3, 3, 2, 5))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "06d90c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-2], nrows=8, ncols=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "3185653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if n_total == 1:\n",
    "#     inputs = tokenizer.encode_plus(text, return_tensors='pt')\n",
    "#     inputs = prepare_inputs(inputs, model.device)\n",
    "#     outputs = model(**inputs, output_attentions=False)\n",
    "\n",
    "#     # assert inputs.input_ids.size(0) == 1\n",
    "#     input_ids = inputs.input_ids\n",
    "#     logits = outputs.logits\n",
    "\n",
    "#     bsz = input_ids.size(0); assert bsz == 1\n",
    "#     labels = torch.ones_like(input_ids) * (-100)\n",
    "#     for bi in range(bsz):\n",
    "#         bos_indices = (input_ids[bi] == bos_id).nonzero().squeeze(1)\n",
    "#         eos_indices = (input_ids[bi] == eos_id).nonzero()[-nrows:].squeeze(1)\n",
    "#         for i, (example, bos_i, eos_i) in enumerate(zip(examples, bos_indices.tolist(), eos_indices.tolist())):\n",
    "#             print(' ' + make_example_str(example))\n",
    "#             ans_ids = input_ids[bi, bos_i + 1: eos_i]\n",
    "#             if i >= 2: labels[bi, bos_i: eos_i - 1] = ans_ids\n",
    "#             ans_prob_dist = logits[bi, bos_i: eos_i - 1].softmax(-1)\n",
    "#             ans_probs = ans_prob_dist[torch.arange(ans_prob_dist.size(0)), ans_ids]\n",
    "#             ans_tokens = tokenizer.convert_ids_to_tokens(ans_ids)\n",
    "#             for ans_id, ans_token, ans_prob, dist in zip(ans_ids, ans_tokens, numpy(ans_probs, decimals=3), ans_prob_dist):\n",
    "#                 top1_correct = (dist.argmax() == ans_id).item()\n",
    "#                 print(('*' if top1_correct else ' ') + ans_token, ans_prob, \n",
    "#                       show_topk(*dist.topk(5), indices_fn=tokenizer.convert_ids_to_tokens)) \n",
    "#     loss = nn.CrossEntropyLoss()(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "#     loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "6b5d2b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.convert_ids_to_tokens(617)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "f7d6edbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(s.count('Yes') for s in input_strs)\n",
    "# sum(s.count('No') for s in input_strs)\n",
    "# sum(s.count('all') for s in input_strs)\n",
    "# sum(s.count('none') for s in input_strs)\n",
    "# sum(s.count('some') for s in input_strs)\n",
    "# sum(s.count('3') for s in input_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d64330f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [e['input_ids'] for e in train_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ee181c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.convert_ids_to_tokens(([e['input_ids'] for e in train_dataset][0]).numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4ff9a2be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(eval_dataset.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c759bca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f588b59",
   "metadata": {},
   "source": [
    "# 请从这里开始,肖老师"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "17373019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Relationship between two sets. For example:\n",
      "Daniel: lemon, Ashley: grape, Amanda: grape, Harrison: pear. [] boys have fruits. [all / some / none]? -> all\n",
      "\n",
      "Instruction: Relationship between two sets. For example:\n",
      "Sarah: lemon, Alex: peach, Harrison: grape, Eva: plasticine. [] boys have toys. [all / some / none]? -> none\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# n_total, n_valid = 500, 100  #全部数目，测试数目\n",
    "# n_total, n_valid = 800, 200\n",
    "n_total, n_valid = 180, 30\n",
    "# n_total, n_valid =4,2\n",
    "n_train = n_total - n_valid\n",
    "# input_strs = [make_input_str(tasks[-7], nrows=1, ncols=(3,4,5)) for __ in range(n_total)]# Is the intersection of two sets empty.\n",
    "# input_strs = [make_input_str(tasks[-3], nrows=1, ncols=(4,4,3)) for __ in range(n_total)]# Are there any elements different from other elements\n",
    "# input_strs = [make_input_str(tasks[-4], nrows=1, ncols=(3,4,2,4)) for __ in range(n_total)]# Are_there_elements_belonging_to_the_same_class\n",
    "# input_strs = [make_input_str(tasks[-1], nrows=1, ncols=(5,2)) for __ in range(n_total)]#Is_the_number_of_first_elements_greater_than_the_second_one\n",
    "# input_strs = [make_input_str(tasks[-2], nrows=1, ncols=(3,1), ans_vocab=[0,1,2,3]) for __ in range(n_total)] #How_many_elements_are_similar_to_the_example\n",
    "# input_strs = [make_input_str(tasks[-5], nrows=1, ncols=(3,4,2,4)) for __ in range(n_total)] #Are_they_the_union_of_the_last_element\n",
    "# input_strs = [make_input_str(tasks[-6], nrows=1, ncols=(3,11,5)) for __ in range(n_total)]#Is the first set a subset of the second one\n",
    "# input_strs = [make_input_str(tasks[-10], nrows=1, ncols=(3, 3, 2, 5)) for __ in range(n_total)]\n",
    "# input_strs = [make_input_str(tasks[-9], nrows=1, ncols=(4,2)) for __ in range(n_total)] #Compare the values of two sets.\n",
    "input_strs = [make_input_str(tasks[-8], nrows=1, ncols=(4, 4, 4)) for __ in range(n_total)] #Relationship between two sets.\n",
    "\n",
    "for s in sample(input_strs, 2): print(s)\n",
    "# print(input_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "58f1d494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s,end = input_strs[0].index(\":\"),input_strs[0].index(\"For\")\n",
    "# name = input_strs[0][s+2:end]\n",
    "# import json\n",
    "# filename = './nrk/'+name\n",
    "# with open(filename,\"w\") as file_obj:\n",
    "#     json.dump(input_strs,file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e64ee95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Is this sentence correct. For example:\n",
      "A is worse at sinking than B because B is lighter. Is that right? -> No\n",
      "\n",
      "Instruction: Is this sentence correct. For example:\n",
      "A is more thoughtful than B because B is a worse friend. Is that right? -> Yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in sample(text, 2): print(s)\n",
    "n_total, n_valid = 200, 20\n",
    "n_train = n_total - n_valid\n",
    "text = text[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e2f80b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = CHILDDataset(input_strs[:-n_valid], tokenizer)\n",
    "# eval_dataset = CHILDDataset(input_strs[-n_valid:], tokenizer)\n",
    "train_dataset = CHILDDataset(text[:-n_valid], tokenizer)\n",
    "eval_dataset = CHILDDataset(text[-n_valid:], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "82ad27d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wte = model.get_input_embeddings() #提取 embedding 中的 词向量部分\n",
    "if hasattr(wte, 'wte'): wte = wte.wte  # already been wrapped\n",
    "we = WrappedEmbedding(wte, prompt_len=40000)\n",
    "model.set_input_embeddings(we) #为词向量赋值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "416bbc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = []\n",
    "    bos_indices = []\n",
    "    eos_indices = []\n",
    "    preds = []\n",
    "    m = nn.Softmax(dim = -1)\n",
    "    labels_loc = pred.label_ids.argmax(-1)\n",
    "    for i in range(len(labels_loc)):\n",
    "        labels.append(pred.label_ids[i][labels_loc[i]])\n",
    "#     arraypre = pred.predictions[0] # 6B\n",
    "    arraypre = pred.predictions # 1.3B\n",
    "    predss = arraypre.argmax(-1)\n",
    "    num = \"\"\n",
    "   \n",
    "    for bi in range(predss.shape[0]):\n",
    "        num = labels_loc[bi]\n",
    "        preds.append(predss[bi, num-1:num])\n",
    "        t = torch.from_numpy(pred.predictions[bi,num-1:num]) #1.3B\n",
    "#         t = torch.from_numpy(pred.predictions[0][bi,num-1:num])  #6B\n",
    "        n = m(t)\n",
    "        ids = torch.topk(n,3)[1].numpy().tolist()  #ids   /[0] 概率\n",
    "        loc = torch.topk(n,3)[0].numpy().tolist()\n",
    "#         print(ids)\n",
    "        ids = tokenizer.convert_ids_to_tokens(ids[0])\n",
    "        loc = [float('{:.4f}'.format(i)) for i in loc[0]]\n",
    "        precision = [i+\" : \"+str(j) for i,j in zip(ids,loc)]\n",
    "    acc = accuracy_score(labels, list(preds))    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d34fd7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, 1400, -100, -100, -100, -100, -100, -100])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset[0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eb7bf973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_metrics(pred):\n",
    "#     labels = []\n",
    "#     bos_indices = []\n",
    "#     preds = []\n",
    "#     labels_loc = pred.label_ids.argmax(-1)\n",
    "#     for i in range(len(labels_loc)):\n",
    "#         labels.append(pred.label_ids[i][labels_loc[i]])\n",
    "# #     print(labels)\n",
    "#     arraypre = pred.predictions[0] # 6B\n",
    "# # #     arraypre = pred.predictions # 1.3B\n",
    "#     print(arraypre)\n",
    "#     predss = arraypre.argmax(-1)\n",
    "#     sent = tokenizer.convert_ids_to_tokens(predss[0])\n",
    "#     sent1 = \" \".join(sent)\n",
    "#     sent1=sent1.replace(\"Ġ\",\"\")\n",
    "#     sent1=sent1.replace(\"Ċ\",\"\\n\")\n",
    "#     print(sent1)\n",
    "#     for bi in range(predss.shape[0]):\n",
    "#         for j in range(predss.shape[1]):\n",
    "#             if(predss[bi][j] == bos_id):\n",
    "#                 bos_indices.append(j)\n",
    "#         bos_i = bos_indices[-1]\n",
    "#         preds.append(predss[bi, bos_i + 1:bos_i + 2])\n",
    "    \n",
    "#     acc = accuracy_score(labels, list(preds))\n",
    "#     return {\n",
    "# #         'accuracy': acc,\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6ebf074a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(output_dir=\"./models/model_name\",                                                             #模型预测和检查点的输出目录\n",
    "    overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=True, \n",
    "    per_device_train_batch_size=1, per_device_eval_batch_size=1,                                                  #每个GPU / TPU内核/ CPU的批处理大小\n",
    "    gradient_accumulation_steps=3,eval_steps=5, \n",
    "    weight_decay=0.001, adam_beta2=0.98, adam_epsilon=1e-6,                                      #weight_decay要应用的权重衰减,adam_epsilon AdamW优化器的ε超参数\n",
    "    lr_scheduler_type='constant', learning_rate=0.001, num_train_epochs=3,                                  #learning_rate:Adam初始学习率\n",
    "    logging_strategy ='epoch',  save_steps=0,                                             #save_steps保存两个检查点之前的更新步骤数\n",
    "    no_cuda=True, report_to='none',                                                         # to avoid report to wandb\n",
    "    evaluation_strategy ='steps',\n",
    "#     evaluation_strategy ='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ff25273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(filename,\"a\") as f:\n",
    "#         f.write(str(training_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d89c7d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/xd/projects/transformers/src/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, training_args, train_dataset=train_dataset, eval_dataset=eval_dataset,compute_metrics=compute_metrics,\n",
    "                  optimizers=(create_optimizer(model, training_args), None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "567bbf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.886038303375244,\n",
       " 'eval_accuracy': 0.0,\n",
       " 'eval_precision': ['ĠA : 0.1994', 'ĠB : 0.0537', 'ĠIs : 0.0511'],\n",
       " 'eval_runtime': 6.1771,\n",
       " 'eval_samples_per_second': 3.238,\n",
       " 'eval_steps_per_second': 3.238}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c5b8d21d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 30\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 3\n",
      "  Gradient Accumulation steps = 3\n",
      "  Total optimization steps = 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 01:28, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.526731</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>['ĠYes : 0.3467', 'ĠNo : 0.17', 'Ġyes : 0.0455']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.944145</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>['ĠNo : 0.4682', 'ĠYes : 0.295', 'Ġyes : 0.0318']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.945200</td>\n",
       "      <td>0.764015</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>['ĠNo : 0.605', 'ĠYes : 0.2978', 'Ġyes : 0.0139']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.945200</td>\n",
       "      <td>0.772530</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>['ĠYes : 0.4841', 'ĠNo : 0.4689', 'Ġyes : 0.0099']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.796300</td>\n",
       "      <td>0.860189</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>['ĠNo : 0.8637', 'ĠYes : 0.1097', 'ĠNO : 0.0048']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.796300</td>\n",
       "      <td>0.879473</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>['ĠYes : 0.5875', 'ĠNo : 0.3763', 'Ġyes : 0.0078']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=30, training_loss=1.1704187393188477, metrics={'train_runtime': 90.1074, 'train_samples_per_second': 0.999, 'train_steps_per_second': 0.333, 'total_flos': 26909548462080.0, 'train_loss': 1.1704187393188477, 'epoch': 3.0})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "90777ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 10\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.735599160194397, 'test_accuracy': 0.5, 'test_precision': ['ĠYes : 0.6578', 'ĠNo : 0.3009', 'Ġyes : 0.0071'], 'test_runtime': 3.1062, 'test_samples_per_second': 3.219, 'test_steps_per_second': 3.219}\n"
     ]
    }
   ],
   "source": [
    "test_dataset = CHILDDataset(text[:10], tokenizer)\n",
    "a = trainer.predict(test_dataset) #此处新生成了测试集\n",
    "print(a.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8d29120e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 30\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.0003098619054071605, 'test_accuracy': 1.0, 'test_precision': ['ĠNo : 0.9999', 'No : 0.0', 'Ġ : 0.0'], 'test_runtime': 50.5283, 'test_samples_per_second': 0.594, 'test_steps_per_second': 0.594}\n"
     ]
    }
   ],
   "source": [
    "# input_strs = [make_input_str(tasks[-7], nrows=100, ncols=(3,4,5)) for __ in range(30)]# Is the intersection of two sets empty.\n",
    "# input_strs = [make_input_str(tasks[-3], nrows=100, ncols=(4,4,3)) for __ in range(30)]# Are there any elements different from other elements\n",
    "# input_strs = [make_input_str(tasks[-4], nrows=100, ncols=(3,4,2,4)) for __ in range(30)]# Are_there_elements_belonging_to_the_same_class\n",
    "# input_strs = [make_input_str(tasks[-1], nrows=120, ncols=(5,2)) for __ in range(30)]#Is_the_number_of_first_elements_greater_than_the_second_one\n",
    "# input_strs = [make_input_str(tasks[-2], nrows=80, ncols=(3,1), ans_vocab=[0,1,2,3]) for __ in range(30)] #How_many_elements_are_similar_to_the_example\n",
    "# input_strs = [make_input_str(tasks[-5], nrows=100, ncols=(3,4,2,4)) for __ in range(30)] #Are_they_the_union_of_the_last_element\n",
    "# input_strs = [make_input_str(tasks[-6], nrows=100, ncols=(3,11,5)) for __ in range(30)]#Is the first set a subset of the second one\n",
    "# input_strs = [make_input_str(tasks[-10], nrows=100, ncols=(3, 3, 2, 5)) for __ in range(30)]\n",
    "# input_strs = [make_input_str(tasks[-9], nrows=100, ncols=(4,2)) for __ in range(30)] #Compare the values of two sets.\n",
    "# input_strs = [make_input_str(tasks[-8], nrows=100, ncols=(4, 4, 4)) for __ in range(30)] #Relationship between two sets.\n",
    "test_dataset = CHILDDataset(input_strs[:], tokenizer)\n",
    "a = trainer.predict(test_dataset) #此处新生成了测试集\n",
    "print(a.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d1961b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ef98c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedb8237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4622d39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a194cd0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afa17cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e6b876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b37a9874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.place_model_on_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9b4b3eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prev(elem):\n",
    "    i, v = elem\n",
    "    return _l[i - 1] if i > 0 else None\n",
    "\n",
    "false = lambda *_: False\n",
    "true  = lambda *_: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "721cb66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Element = namedtuple('Element', 'index value')\n",
    "_l = 'A B C B'.split()\n",
    "n = len(_l)\n",
    "# l = [Element._make(e) for e in enumerate(l)]\n",
    "l = seq(_l)\n",
    "l = l.enumerate().map(Element._make)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9f22f664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  index</th><th>value  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">      0</td><td>A      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      1</td><td>B      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      2</td><td>C      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      3</td><td>B      </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[Element(index=0, value='A'), Element(index=1, value='B'), Element(index=2, value='C'), Element(index=3, value='B')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['C']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['b']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['C', 'A', 'B', 'B']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['B', 'B', 'C', 'A']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  index</th><th>value  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">      0</td><td>A      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      1</td><td>A      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      2</td><td>C      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      3</td><td>B      </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[Element(index=0, value='A'), Element(index=1, value='A'), Element(index=2, value='C'), Element(index=3, value='B')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'B', 'C', 'C']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 1, 2, 3]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['B']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['B']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.map(lambda x: {'B': 'D'}.get(x, x))\n",
    "\n",
    "l.filter(lambda x: get_prev(x) == 'B').select(_.value)\n",
    "\n",
    "find_fn = _.index == 1\n",
    "l.filter(find_fn).select(_.value).map(lower)\n",
    "\n",
    "find_fn = _.value == 'C'\n",
    "l.filter(find_fn).select(_.index)\n",
    "\n",
    "# move x to first\n",
    "update_filter = _.value == 'C'\n",
    "get_new = lambda x: -1\n",
    "l.map(lambda x: Element(update_fn(x, 'index'), x.value)).order_by(_.index).select(_.value)\n",
    "\n",
    "# swap first and last\n",
    "update_filter = true\n",
    "get_new = lambda x: {0: n - 1, n - 1: 0}.get(x.index, x.index)\n",
    "l.map(lambda x: Element(update_fn(x, 'index'), x.value)).order_by(_.index).select(_.value)\n",
    "\n",
    "# get inbetween == drop_while + take_while?\n",
    "\n",
    "# update by index to its prev\n",
    "update_filter = _.index == 1\n",
    "get_new = lambda x: get_prev(x)\n",
    "def update_fn(x, update_field): return get_new(x) if update_filter(x) else getattr(x, update_field)\n",
    "l.map(lambda x: Element(x.index, update_fn(x, 'value')))\n",
    "\n",
    "# if two adjacent elements by indices are equal\n",
    "l.filter(lambda x: x.index in [0, 1]).select(_.value).distinct().len() == 1\n",
    "\n",
    "seq('A B C B C'.split()).group_by(_).select(_[1]).flatten()\n",
    "\n",
    "# count occurance till current\n",
    "seq('A B A C B A'.split()).inits().reverse().tail().map(lambda x: x.filter(_ == x.last()).len())\n",
    "\n",
    "# find special\n",
    "seq('A B A A'.split()).count_by_value().filter(_[1] == 1).select(_[0])\n",
    "\n",
    "# generalized find special\n",
    "seq('A A B C C D D'.split()).group_by(_).map(lambda x: (x[0], len(x[1]))).filter(_[1] == 1).select(_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b3e124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
