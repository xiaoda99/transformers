{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6ea7a72",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (4.17.0)\n",
      "Requirement already satisfied: sacremoses in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: filelock in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (2021.10.8)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/xd/.local/lib/python3.8/site-packages (from transformers) (4.60.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (0.11.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/xd/.local/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages/PyYAML-6.0-py3.8-linux-x86_64.egg (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (1.21.2)\n",
      "Requirement already satisfied: requests in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/xd/.local/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: six in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "0faf2697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.12 | packaged by conda-forge | (default, Jan 30 2022, 23:53:36) \\n[GCC 9.4.0]'"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e11bc1d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pyfunctional\n",
      "  Using cached PyFunctional-1.4.3-py3-none-any.whl (49 kB)\n",
      "Requirement already satisfied: dill>=0.2.5 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from pyfunctional) (0.3.4)\n",
      "Requirement already satisfied: tabulate<=1.0.0 in /home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages (from pyfunctional) (0.8.9)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pyfunctional\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed pyfunctional-1.4.3\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yfunctional (/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pyfunctional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "367b7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run \"context_learning_nrk.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "9398a888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Is this sentence correct. For example:\n",
      "A should be easier to melt than B because B is hotter. Is that right? -> No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text1 = text\n",
    "print(text1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7292808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54a886cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ['HF_HOME'] = '/raid/xd/.cache/torch'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from types import MethodType\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, OrderedDict, Counter\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "from itertools import chain\n",
    "import math\n",
    "from functools import reduce\n",
    "import numpy as np \n",
    "# np.set_printoptions(threshold=np.inf)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data.sampler import RandomSampler, Sampler, SequentialSampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from transformers.data.data_collator import DataCollator, default_data_collator\n",
    "from transformers import AutoConfig, pipeline\n",
    "from transformers import RobertaForMaskedLM, RobertaTokenizer, GPT2LMHeadModel, GPT2Tokenizer, GPTNeoForCausalLM, AutoModelForCausalLM\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import HfArgumentParser, Trainer, TrainingArguments, set_seed, AdamW\n",
    "# from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "# from transformers.trainer_utils import EvaluationStrategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f54c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPTNeoForCausalLM, GPTJForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd287822",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/nas/xd/projects/PyFunctional')\n",
    "from functional import seq\n",
    "from functional.pipeline import Sequence\n",
    "from fn import _\n",
    "from collections import namedtuple \n",
    "import sys\n",
    "# sys.path.insert(0, '/nas/xd/projects/transformers/src/transformers')\n",
    "import os\n",
    "# device_mappings = {0: 1, 1: 5, 2: 6, 3: 7, 4: 2, 5: 3, 6: 0, 1: 4}\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(device_mappings[2])\n",
    "\n",
    "import random\n",
    "import string\n",
    "from collections import defaultdict, OrderedDict\n",
    "from itertools import product, chain\n",
    "import math\n",
    "import numpy as np\n",
    "from pattern.en import comparative\n",
    "import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "a2a577ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/nas/xd/projects/PyFunctional')\n",
    "from functional import seq\n",
    "from functional.pipeline import Sequence\n",
    "from fn import _\n",
    "from collections import namedtuple \n",
    "import sys\n",
    "# sys.path.insert(0, '/nas/xd/projects/transformers/src/transformers')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "7d5907ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "import openai\n",
    "openai.api_key = open('/nas/xd/projects/openai_api_keys.txt').readlines()[-1].split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "86a17aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Do all students choose courses in a department. For example:\n",
      "D: Chinese, U: Art, A: Art, U: Chinese, D: Art; Art: Chi, Chinese: Eng, Physics: Eng. A and U,Chi? -> Yes\n",
      "\n",
      "Instruction: Do all students choose courses in a department. For example:\n",
      "C: Sql, H: Physics, H: Sql, H: Chemistry, K: Sql; Sql: Chi, Physics: Chi, Chemistry: Eng. H and C,Eng? -> No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_total, n_valid =2,1\n",
    "n_train = n_total - n_valid\n",
    "# input_strs = [make_input_str(tasks[-7], nrows=1, ncols=(3,4,5)) for __ in range(n_total)]# Is the intersection of two sets empty.\n",
    "# input_strs = [make_input_str(tasks[-3], nrows=1, ncols=(4,4,3)) for __ in range(n_total)]# Are there any elements different from other elements\n",
    "# input_strs = [make_input_str(tasks[-4], nrows=1, ncols=(3,4,2,4)) for __ in range(n_total)]# Are_there_elements_belonging_to_the_same_class\n",
    "# input_strs = [make_input_str(tasks[-1], nrows=1, ncols=(5,2)) for __ in range(n_total)]#Is_the_number_of_first_elements_greater_than_the_second_one\n",
    "# input_strs = [make_input_str(tasks[-2], nrows=1, ncols=(3,1), ans_vocab=[0,1,2,3]) for __ in range(n_total)] #How_many_elements_are_similar_to_the_example\n",
    "# input_strs = [make_input_str(tasks[-5], nrows=1, ncols=(3,4,2,4)) for __ in range(n_total)] #Are_they_the_union_of_the_last_element\n",
    "# input_strs = [make_input_str(tasks[-6], nrows=1, ncols=(3,11,5)) for __ in range(n_total)]#Is the first set a subset of the second one\n",
    "input_strs = [make_input_str(tasks[-10], nrows=1, ncols=(3, 3, 2, 5)) for __ in range(n_total)]\n",
    "# input_strs = [make_input_str(tasks[-9], nrows=1, ncols=(4,2)) for __ in range(n_total)] #Compare the values of two sets.\n",
    "# input_strs = [make_input_str(tasks[-8], nrows=1, ncols=(4, 4, 4)) for __ in range(n_total)] #Relationship between two sets.\n",
    "\n",
    "for s in sample(input_strs, 2): print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "21465a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_fn(engine):  # XD\n",
    "    def fn(text):\n",
    "        return openai.Completion.create(engine=engine, prompt=text, max_tokens=1, echo=True, logprobs=5).choices[0]\n",
    "    return fn\n",
    "\n",
    "engines = ['davinci', 'curie']\n",
    "for engine in engines:\n",
    "    model_name = 'openai_api_' + engine\n",
    "#     model = lambda x: openai.Completion.create(engine=engine, prompt=x, max_tokens=0, echo=True, logprobs=5).choices[0]\n",
    "    model = get_model_fn(engine)\n",
    "    models[model_name] = model, tokenizer\n",
    "    \n",
    "# model_name = 'openai_api_davinci'\n",
    "model_name = 'openai_api_curie'\n",
    "model, tokenizer = models[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "bf3af01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['EleutherAI/gpt-j-6B'])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "693f563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_dist(d, topk=5): return {k: round(math.exp(v), 3) for k, v in sorted(d.items(), key=lambda x: x[1], reverse=True)[:topk]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "77d1817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ans_indices0(input_ids):\n",
    "    bos_id = tokenizer._convert_token_to_id('Ġ->')\n",
    "    eos_id = tokenizer._convert_token_to_id('Ċ')\n",
    "    bos_indices = (input_ids == bos_id).nonzero().squeeze(1).tolist()\n",
    "    eos_indices = (input_ids == eos_id).nonzero()[-len(bos_indices):].squeeze(1).tolist()\n",
    "    return bos_indices, eos_indices\n",
    "\n",
    "# def get_ans_indices1(input_ids):\n",
    "#     bos_id = tokenizer._convert_token_to_id('?')\n",
    "# #     print(\"bos_id\",bos_id)\n",
    "#     eos_id = tokenizer._convert_token_to_id('Ċ')\n",
    "#     period_ids = [tokenizer._convert_token_to_id('.'), tokenizer._convert_token_to_id('Ġ.')]\n",
    "# #     print(\"period_ids:\",period_ids)\n",
    "# #     l_bracket_id, r_bracket_id = tokenizer._convert_token_to_id('Ġ['), tokenizer._convert_token_to_id('Ġ]')\n",
    "# #     print(\"l_bracket_id\",l_bracket_id)\n",
    "# #     print(\"r_bracket_id:\",r_bracket_id)\n",
    "#     eos_indices = (input_ids == eos_id).nonzero().squeeze(1).tolist() #.nonezero()取非零元素坐标\n",
    "# #     print(\"eos_indices0:\",eos_indices)\n",
    "#     eos_indices = [i - 1 if input_ids[i - 1] in period_ids else i for i in eos_indices]\n",
    "# #     print(\"eos_indices1:\",eos_indices)\n",
    "# #     eos_indices = [i - 1 if input_ids[i - 1] == r_bracket_id else i for i in eos_indices]\n",
    "# #     print(\"eos_indices2:\",eos_indices)\n",
    "    \n",
    "#     def find_bos_index(start_i):\n",
    "#         for bos_i in range(start_i, start_i - 3, -1):\n",
    "# #             if input_ids[bos_i] == bos_id or input_ids[bos_i] == l_bracket_id and input_ids[bos_i - 1] == bos_id:\n",
    "#             if input_ids[bos_i] == bos_id:\n",
    "#                 if bos_i != start_i: print('subtokens:', tokenizer.convert_ids_to_tokens(input_ids[bos_i + 1: start_i + 2]))\n",
    "#                 return bos_i\n",
    "#         assert False\n",
    "#     bos_indices = [find_bos_index(i - 2) for i in eos_indices]\n",
    "# #     print(\"bos:\",bos_indices)\n",
    "# #     print(\"eos:\",eos_indices)\n",
    "#     return bos_indices, eos_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "bb474e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_num = 0\n",
    "def predict(model, text, ans_indices_fn, topk=5, return_reduced_loss=False, verbose=True):\n",
    "    use_openai_api = type(model) in [types.MethodType, types.FunctionType]  # openai.Completion.create\n",
    "    print(\"[]\",[types.MethodType, types.FunctionType])\n",
    "    print(\"type(model):\",type(model))\n",
    "    inputs = tokenizer.encode_plus(text, return_tensors='pt')\n",
    "    print(inputs)\n",
    "    input_ids = inputs.input_ids\n",
    "#     print(input_ids)\n",
    "    bsz = input_ids.size(0)\n",
    "#     print(\"bsz = \",bsz)\n",
    "    labels = torch.ones_like(input_ids) * (-100)\n",
    "    if use_openai_api:\n",
    "        assert bsz == 1\n",
    "#         outputs = model(engine=engine, prompt=text, max_tokens=0, echo=True, logprobs=5).choices[0].logprobs\n",
    "        outputs = model(text).logprobs  # XD\n",
    "        ans_nlls = []\n",
    "    else:\n",
    "        inputs = prepare_inputs(inputs, model.device)\n",
    "        outputs = model(**inputs, output_attentions=False)\n",
    "        logits = outputs.logits\n",
    "    for bi in range(bsz):\n",
    "\n",
    "        bos_indices, eos_indices = ans_indices_fn(input_ids[bi])\n",
    "#         print(\"input_ids :\",input_ids[bi])\n",
    "#         print(\"ans_indices_fn:\",ans_indices_fn(input_ids[bi]))\n",
    "#         print(\"bos_indices:\",bos_indices)\n",
    "#         print(\"eos_indices:\",eos_indices)\n",
    "        examples = text.strip().split('\\n')\n",
    "#         print(\"bos_indices:\",bos_indices)\n",
    "        print(\"examples:\",examples)\n",
    "        assert len(bos_indices) == len(examples)-1, '%d != %d' % (len(bos_indices), len(examples))\n",
    "        num = 0\n",
    "        for i, (example, bos_i, eos_i) in enumerate(zip(examples, bos_indices, eos_indices)):\n",
    "#             if verbose: print(' ' + example, end='\\t')\n",
    "            ans_ids = input_ids[bi, bos_i + 1: eos_i]\n",
    "            print(\"ans_ids:\",ans_ids)\n",
    "            labels[bi, bos_i: eos_i - 1] = ans_ids\n",
    "            if use_openai_api:\n",
    "                ans_prob_dist = [get_prob_dist(d, topk=topk) for d in outputs.top_logprobs[bos_i + 1: eos_i]]\n",
    "                ans_probs = [math.exp(lp) for lp in outputs.token_logprobs[bos_i + 1: eos_i]]\n",
    "                ans_nlls += [-lp for lp in outputs.token_logprobs[bos_i + 1: eos_i]]\n",
    "            else:\n",
    "                ans_prob_dist = logits[bi, bos_i: eos_i - 1].softmax(-1)\n",
    "                ans_probs = ans_prob_dist[torch.arange(ans_prob_dist.size(0)), ans_ids]\n",
    "            ans_tokens = tokenizer.convert_ids_to_tokens(ans_ids)\n",
    "            num += 1\n",
    "            for ans_id, ans_token, ans_prob, dist in zip(ans_ids, ans_tokens, numpy(ans_probs, decimals=3), ans_prob_dist):\n",
    "                top1_correct = max(dist.items(), key=lambda x: x[1])[0] == ans_token.replace('Ġ', ' ') \\\n",
    "                    if use_openai_api else (dist.argmax() == ans_id).item()  \n",
    "                \n",
    "                if verbose:\n",
    "                    if(num == 1 and top1_correct):\n",
    "                        global correct_num\n",
    "                        correct_num += 1\n",
    "                    if(len(ans_tokens) <= 1):\n",
    "#                         if(top1_correct):\n",
    "#                             dictlocation1[example] = 1\n",
    "                        print(('！！！' if top1_correct else ' ') + ans_token, ans_prob, \n",
    "                              dist if use_openai_api else show_topk(*dist.topk(topk), indices_fn=tokenizer.convert_ids_to_tokens)) \n",
    "                        \n",
    "                    else:\n",
    "                        pass\n",
    "    if use_openai_api:\n",
    "        loss = ans_nlls if return_reduced_loss else sum(ans_nlls) / len(ans_nlls)\n",
    "    else:\n",
    "        loss = nn.CrossEntropyLoss()(logits.view(-1, logits.size(-1)), labels.view(-1)) if return_reduced_loss \\\n",
    "            else nn.CrossEntropyLoss(reduction='none')(logits.view(-1, logits.size(-1)), labels.view(-1))[labels.view(-1)>=0].tolist()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "f49b21a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Instruction: Do all students choose courses in a department. For example:\n",
      "D: Chinese, U: Art, A: Art, U: Chinese, D: Art; Art: Chi, Chinese: Eng, Physics: Eng. A and U,Chi? -> Yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(input_strs))\n",
    "print(input_strs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "490ff768",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [<class 'method'>, <class 'function'>]\n",
      "type(model): <class 'function'>\n",
      "{'input_ids': tensor([[ 6310,  2762,    25,  2141,   477,  2444,  3853, 10902,   287,   257,\n",
      "          5011,    13,  1114,  1672,    25,   198,    35,    25,  3999,    11,\n",
      "           471,    25,  3683,    11,   317,    25,  3683,    11,   471,    25,\n",
      "          3999,    11,   360,    25,  3683,    26,  3683,    25, 21380,    11,\n",
      "          3999,    25,  1985,    11, 23123,    25,  1985,    13,   317,   290,\n",
      "           471,    11,  1925,    72,    30,  4613,  3363,   198]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'D: Chinese, U: Art, A: Art, U: Chinese, D: Art; Art: Chi, Chinese: Eng, Physics: Eng. A and U,Chi? -> Yes']\n",
      "ans_ids: tensor([3363])\n",
      " ĠYes 0.008 {' A': 0.086, ' U': 0.047, ' D': 0.037, ' Art': 0.031, ' Eng': 0.025}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.8359756"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [<class 'method'>, <class 'function'>]\n",
      "type(model): <class 'function'>\n",
      "{'input_ids': tensor([[ 6310,  2762,    25,  2141,   477,  2444,  3853, 10902,   287,   257,\n",
      "          5011,    13,  1114,  1672,    25,   198,    34,    25,   311, 13976,\n",
      "            11,   367,    25, 23123,    11,   367,    25,   311, 13976,    11,\n",
      "           367,    25, 27867,    11,   509,    25,   311, 13976,    26,   311,\n",
      "         13976,    25, 21380,    11, 23123,    25, 21380,    11, 27867,    25,\n",
      "          1985,    13,   367,   290,   327,    11,  7936,    30,  4613,  1400,\n",
      "           198]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "examples: ['Instruction: Do all students choose courses in a department. For example:', 'C: Sql, H: Physics, H: Sql, H: Chemistry, K: Sql; Sql: Chi, Physics: Chi, Chemistry: Eng. H and C,Eng? -> No']\n",
      "ans_ids: tensor([1400])\n",
      " ĠNo 0.018 {' H': 0.067, ' S': 0.056, ' Eng': 0.045, ' C': 0.03, ' K': 0.026}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.990212"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_num = 0\n",
    "for i in input_strs:\n",
    "# for i in text1:\n",
    "    text = i\n",
    "    predict(model, text, get_ans_indices0, verbose=True, topk=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c1fe66",
   "metadata": {},
   "source": [
    "# 从这里开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58cba5e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from child_utils import *\n",
    "from common_utils import *\n",
    "from model_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90f62ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "# cache_dir = '/nas/xd/.cache/torch/transformers/'  # for models besides t5-3b/11b\n",
    "cache_dir = '/mnt/nvme1/xd/.cache/torch/transformers/'  # for gpt-j-6B on elderberry\n",
    "proxies = {'http': '192.168.50.1:1081'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "520d34a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = \"EleutherAI/gpt-j-6B\"\n",
    "# model_name = \"EleutherAI/gpt-neo-1.3B\"\n",
    "# model = GPTJForCausalLM.from_pretrained(model_name, proxies=proxies, cache_dir=cache_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, proxies=proxies, cache_dir=cache_dir)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', cache_dir=cache_dir)\n",
    "models[model_name] = model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "830ce082",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.eval()\n",
    "unify(model)\n",
    "blocks = model.transformer.h\n",
    "attn = blocks[0].attn\n",
    "ln_f = model.transformer.ln_f\n",
    "L, H, embed_dim = len(blocks), attn.num_heads, attn.embed_dim\n",
    "\n",
    "_we = model.transformer.wte.weight.data.t()\n",
    "_wu = model.lm_head.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e50583a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTJAttention(\n",
       "  (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "  (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "  (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c128d0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LayerNorm((4096,), eps=1e-05, elementwise_affine=True)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cd64c2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d82cfd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50400, 4096])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_wu.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "ef8becf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def T(f): return lambda x: f(x.T).T\n",
    "mlp = lambda x: mlp_forward(blocks[0], x)\n",
    "v = we.size(1) #// 2\n",
    "_we, _wu = we[:, :v], wu[:v]\n",
    "with torch.no_grad(): _e = mlp(_we.T) + _we.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "id": "9a94c107",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer, head = 1, 1 # prev ov: 13-9, next num ov: 14-13, next word ov: 13-4, prepend space ov: 18-3/17-10, isa ov: 14-7, antonym ov: 16-14, copy ov 13-2\n",
    "wq, wk, wv, wo = get_head_weights(model, layer, head, transpose=True)\n",
    "with torch.no_grad():\n",
    "    eq = ek = e = blocks[layer].ln_1(_e)\n",
    "    # A, B = _wu, ln_f(e @ wv @ wo)\n",
    "    A, B = _wu @ wo.T, e @ wv\n",
    "    q, k = eq @ wq, ek @ wk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "id": "a7f6529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qk = True\n",
    "with torch.no_grad():  # ve,ed,de,ev->vv\n",
    "    # _m = ln(mlp(_we.T)) @ (wq.T @ wk) @ T(ln)(T(mlp)(_we)) if qk else _wu @ T(ln_f)(wo @ (wv @ T(ln)(T(mlp)(_we))))\n",
    "    _m = q @ k.T if qk else _wu @ ln_f(B @ wo).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "id": "459d21eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9317412376403809"
      ]
     },
     "execution_count": 939,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAABuCAYAAAA0wiR3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXWElEQVR4nO3df2wk53nY8e8zv/YXfx7J053uzrq75JxWNgrHJgyhrYMiTmPZaCsHdQs1QK3GRtU0MdACLVq5+sdo+kfSIi0axLWhtELlIqjsuk0kBA4c2XXSv2TrLpYtybYknixLR90defx13J+zM/P0j3nJ7PG4vOWRXHLJ5wMMOPvMzM777u7Ms/O+7yxFVTHGGGPuxNvvAhhjjBkMljCMMcb0xBKGMcaYnljCMMYY0xNLGMYYY3oS7HcB9srk5KSePXt2v4thjDED5dKlSzdUdWqzZYc2YZw9e5aLFy/udzGMMWagiMhPui07tAnDGLO34iSjnWaEvkcUWOv2UWAJwxizbXGSMbtURwEBTo2XLWkcAfYOG2O2rZ1mKFApBKh7bA4/SxjGmG0LfQ8Baq0EcY/N4WdNUsaYbYsCj1PjZevDOGJ2/C6LyBkR+ZaI/EBEXhGRf+binxORWRF50U0f69jmsyIyIyKvishHOuIPutiMiDzWET8nIt928S+LSLTTchtjdiYKPCqFwJLFEbIb73QC/AtVvR94APh1EbnfLftPqvo+N30NwC17GHgP8CDwX0TEFxEf+DzwUeB+4B90PM9vuef6aWAJ+PQulNsYY8w27DhhqOpVVf1zN78K/BA4tcUmDwFPq2pLVX8MzAAfdNOMqr6hqjHwNPCQiAjw88BX3fZPAR/fabmNMcZsz65eS4rIWeBngW+70GdE5Psi8qSIjLvYKeDtjs2uuFi3+ASwrKrJhvhm+39URC6KyMX5+fndqJIxxhhn1xKGiAwB/xv456p6E/gC8FPA+4CrwG/v1r66UdUnVHVaVaenpja9s90YY8xd2pVRUiISkieL31fV/wOgqtc7lv8e8Efu4SxwpmPz0y5Gl/gCMCYigbvK6FzfGGNMn+zGKCkB/hvwQ1X9jx3xkx2r/RLwspt/FnhYRAoicg64AHwHeAG44EZEReQd489q/j9kvwV8wm3/CPDMTsttjDFme3bjCuOvAf8QeElEXnSxf0M+yul9gAJvAv8EQFVfEZGvAD8gH2H166qaAojIZ4CvAz7wpKq+4p7vXwNPi8i/A75LnqCMMcb0keRf4A+f6elptV+rNcaY7RGRS6o6vdkyu+PGGGNMTyxhGGOM6YklDGOMMT2xhGGMMaYnljCMMcb0xBKGMcaYnljCMMYY0xNLGMYYY3piCcMYY0xPLGEYY4zpiSUMY4wxPbGEYYwxpieWMIwxxvTEEoYxxpie7Mp/3DPGmM3ESUY7zQh9jyiw76eDzhKGMWZPxEnG7FIdBQQ4NV4+FEnjKCdBSxjGmD3RTjMUqBQCaq2EdpoN/An2sCbBXh2dmhpjdlWcZNRaCXGS3TK/JvQ9BKi1EsQ93my9QdKZBNU9PkrsCsOYAbDWDKIKIuxpc0i3JpfOOLD+TTtxJ00F0lR510SFoWJAFHicGi933WZquEilEKzvo99NPXezv82S4FFiCcOYA2KrE/XsUp04zZhbaXJ8tEjkez01h2w8yW+VdNa+/c+vNgl8b/2kHvoe7TRbjwswVo6IXRNTPU7z586Um/UWjTjlZ06OrCeNtX0s1WLqcUop8rm20qCdKuXI59R4mTjJeGuhhu/LpnXb+Nr0crLfap27bVramAR72eYw9XlYwjDmAOh2AouTjOV6TJxmiEC9nX+zXWsO2ezkWW0m1OMEFG5UW/i+IG79dqosVVvce6xM5HtMDRcRAVV4Z7nOzUbCYrXJ6YkK15YbLNfbrNRjxioRjTjlzESZeislChLmVpq0sox2O2WsHFGPE6qtlCRroddu8pdOjBAFXt5/kWTMV5ssVFs0kwwyJQyEOM2T1NXlBvPVJuUoYKQUuj4PD1VuS1ZTw0XmV5vEabZ+RRMF3i2JsTPxbZYQdtK/0pkE7/Z9HVQDkzBE5EHgPwM+8F9V9Tf3uUjG7JqNJ7BaK2G5nn/rVmC52kI98hNuO+X4cBEPeCfLuLHaWj8xjpZCZq6vIr5wZanOcCHg5FiZYuBzY7VJ4Avz1RanJsrU4oTFqzcpRHmSWWnEFEOf1+eqVJspzSRhIssTlucLzTjhpbdjhgo+7bRIIfRp1lPEE0LPpxIJzXbGzXqMolyeEwJfWKjGNNsZvg/nJodYrLaYW21ydblBliqFwCNDKRdC6q02ke/lCSFRrq7UGSvnyer88SHiJGOlEbPSaFOPE5cEM0qRv35VlL+eykK1tb7NxoSgCs04zeO+t2dNS4et438gEoaI+MDngb8JXAFeEJFnVfUHu72vQbx8HMQy78Sg1nerJqc4yUjS/OTcjFOuLNR44ccLPPejt4jjgHtGAz707pMUQ58fXFml2mwjnlKIfFSFqaEC1biNKCSq3DNS5K3FOlPD+d+zx0os1BJKRZ+5lSYvv71EvZ1SCnxamZIkGY0448x4kSj0GB+KWKoq1VZCK0l5Z6mOijJRLqEiLFZjFmoN4kQJw4BjlYyJoYh3Vhq0MiVKlDjNqLcVBIqhUG2mLFZjQt9jcrhAlsFCs8mN1RZL9ZjJ4QJjpYjRUkg1TliqxSzWWvieB5onRgFuoszdjFmqtzgzUUGBepwyWs6bx0LfY6QUslBtslJvU458VPOrjrXEML/axPeFNFWmxorArcu3asrazmdvP/o89vL4GIiEAXwQmFHVNwBE5GngIWBXE8YgXj4OYpl3YlDru1WT01p8rcnoZiPmqy+8xTdfmaMGQMobSy2+9+YMU2M+tXZGmoEonBgvUgkC3ln2SDKh1kxIyBgOAzwPhsOA5VZCq52x2mgzUg5ZXI2pNhOabUU1A5Qo8CkHAc00JU0z3l6qEbdTvMDj8rUqpSgk9JShwOfy9RalQkCaZgSh0EqU164mvPvECIXAoxR4iC+ICkvVBjdqMShMDhXwPaGdKpevV2mncKPawAPE92i2M0aKAa004+pyg1SVYhigmjFaLCBAprBYjzk+XCBJM8qhT+h5zN1ssNKISbM8WbbTjBOjpfU+mPnV5vpr39n/EpOtN3l1duBv1pR1N5+9u+nz2Im9Pj4O/pGWOwW83fH4iovdQkQeFZGLInJxfn5+2zsZxCFzg1jmnRjU+nYrd2ccxJ1UfFbjNq0Nz5EC1WZKu620E6XeVm7cjJlbbXFtpcVyvc1iI0YTCIP8yuOdlTpLtRZpCs0kpdbKSDRjrBgCSr3dZqXRxvc8fA8qkc9PTw3n5VQIRUhSOD9ZIk4yrq22aLQT7hsv0UgS2qkS+sJYJaQS5c0uqYAvwuRIROD7TFSKlEKfqZEi946XAGW4HHJ2skyqcGWlQStRAk8AYawcMVkpUgx8xksR5ULIyfEiw6WQ0VLIwmqL66sNAl8YK4dMjRSYGikxOVTk+HCJqaEiQ4WAe8fKjFeivI+m87VP8sEDby3UmFtp3vIetFOlneqmn6+7/exFgXfLaLC9tNfHx6BcYfREVZ8AngCYnp7W7W4/iEPmBrHMOzGo9e1W7s546AsAngeVMLzt21wKRB4kaf7tMQpgvBRQKUZUij7tRAk9ISEjTlICT5gYKjFXbZJqRpZCFAhx22O52SbwhBMjJdptpRz6KFCLU2bmV6kUQlYbCSnQTBJevV6jHHqcGC7Szhr8ZKnBUCHkWCUCAU+EdpYxVo7ykzT5iXmt/6MWJzTiNO9v8TwiT1iuxUxUIs6MlZDAc30JwnI9ZqnRotnKWKjFHB+NWK4HbrSWMjFcYKJc4B3XKV9rpszfbOD5QpopIkrJJa8oKN/+2gfe+kiz2H3z3/gebPb5utvPXj+bUPf6+BiUhDELnOl4fNrFdlW/Lx93wyCWeScGtb7dyt0ZXxsRVCkE/PJfvY8LJ4Z45rtv0Ew9xoY8fvbee0gVFldbtNKMkYLPsaECzVQZr0Q028ltfRhDpQClwInRIoXQ48R4icXVFj81WaGVpBR8n5VmQuAJrTTj3pEiszebnJ2ocHmuigL3TZYYLxfwfShEIe89VUBUWK43abZT0gzedazMWCnkrYUqr11vEXoep4+VGCr6rMYZIsJKvcVIKSQMhPFKRDVICXw4OV4hyTImhwvrQ3iPVQrc9NrEWUYpyr/5j5UDQs8DlNmlJqutNvV2RDmE8aECo+WQlXobECqFgOV6zHI9Zqwc3XY/SFT31kdZhf7t94ts9vm62yG1/WxC3evjY1ASxgvABRE5R54oHgZ+eS92tJ0hcwfFIJZ5Jwa1vt3KvRbrvKltcqjIh99zkvOTQ1RKEa1Wm7ZmvHatxn1TFSYqASdHy/i+x8JKk4nRIpHn3TJKqhj5DBcCpoaLBJ7Hcq1FMfIp+h7vPTNOvZWSpMrEcMS1lSZLtRaVQkC8UGe1nlCJPEbKEdWWz4nRMs04Ic0yRIVjQwWKoUe1lVAIPVCPK0sNVIXQg3tGC5SjAE8E34uJyhGpQCnyWay1WKzFTA0X0SxjqOBTi5XLc1VAmRgqEHoe7Sy/UmrECWmSj4RaGwrcTpWhok87SZHQp+Q6tsuRD8ByPWZupQnk37ZPjZdds19uari4ft/H/GrztuXdPl/b/eztxyipvTw+BiJhqGoiIp8Bvk4+rPZJVX1ln4tlzK7ZeGIZL0dEgcfZiSHqccJSPUYEfM/j9HiFYuRzfLhIFHjoqVtvxDs5VqYeJ7z/zLFb7sOYGIryPgfPu+XkqgoTlYiRYkAjzrhwfGj9PoyhYshKPWakGBJ63vp9GGPlkFdr+eimNFOGCzFR4JGo0s6glWSUI5/7jlW4utIgU5hbbTC7WKOZZKzU24xX8j6OMPAglvykD4Bw73iJe8dL68Nmq62EsXK0PpJptBRSivyu92Es12OA9W02nqhFoBj5e34iH9Qm1G4GImEAqOrXgK/tdzmM2QsbTyydnaRrN7/FacZIMaLovml360gdKgYMFfNDe6wS3X6n9/Hh9QSzFuu84W2kFBD4HqePlW+703st0ZSjgFPjZU4fK7OwGhP4AiIE9RaVsRLnp4YYc0mvUgxopxnHRwrMr7YoRT5vzq8SeT6TowGjpfyk3ohTQBkrhbf9ZEic1G95bfIO6tub99asJYpuJ+qdnMi30ycxqE2o3YjqtvuGB8L09LRevHhxv4thTM/u9FMWg/ZbUnfapvO3pNZ+lgTYNBHeTcfxnba52+ccxGHd2yEil1R1erNlA3OFYcxht1Xbcz/7bbbqa+mM36mjeLOTa7dv2/lzR9su093UYyfPedju3N4uSxjGmLuy8YS78cS52cm1X/cj7JXD1iexXZYwjDF74jCeXA9bn8R2WcIwxuyJw3pyHdRh3bvBEoYxZs8c5ZPrYWTvpDHGmJ5YwjDGGNMTSxjGGGN6YgnDGGNMTyxhGGOM6YklDGOMMT2xhGGMMaYnljCMMcb0xBKGMcaYnljCMMYY0xNLGMYYY3piCcMYY0xPLGEYY4zpiSUMY4wxPbGEYYwxpic7Shgi8h9E5Eci8n0R+QMRGXPxsyLSEJEX3fTFjm0+ICIviciMiPyOiIiLHxOR50Tkdfd33MXFrTfj9vP+nZTZGGPM3dnpFcZzwHtV9a8ArwGf7Vh2WVXf56Zf7Yh/AfjHwAU3PejijwHfVNULwDfdY4CPdqz7qNveGGNMn+0oYajqn6hq4h4+D5zean0ROQmMqOrzqqrAl4CPu8UPAU+5+ac2xL+kueeBMfc8xhhj+mg3+zA+Bfxxx+NzIvJdEfkzEfmQi50CrnSsc8XFAO5R1atu/hpwT8c2b3fZ5hYi8qiIXBSRi/Pz8zuoijHGmI3u+D+9ReQbwIlNFj2uqs+4dR4HEuD33bKrwLtUdUFEPgD8oYi8p9dCqaqKiPa6fsd2TwBPAExPT297e2OMMd3dMWGo6i9stVxE/hHwt4APu2YmVLUFtNz8JRG5DLwbmOXWZqvTLgZwXUROqupV1+Q05+KzwJku2xhjjOmTnY6SehD4V8DfUdV6R3xKRHw3f568w/oN1+R0U0QecKOjPgk84zZ7FnjEzT+yIf5JN1rqAWClo+nKGGNMn9zxCuMOfhcoAM+50bHPuxFRPwf8WxFpAxnwq6q66Lb5NeC/AyXyPo+1fo/fBL4iIp8GfgL8fRf/GvAxYAaoA7+ywzIbY3ZBnGS004zQ94gCu6XrKBDXinToTE9P68WLF/e7GMYcSnGSMbtURwEBTo2XLWkcEiJySVWnN1tm77AxZtvaaYYClUKAusfm8LOEYYzZttD3EKDWShD32Bx+O+3DMMYcQVHgcWq8bH0YR4wlDGPMXYkCSxRHzaHt9BaReaAG3NjvsvTJJEenrnC06mt1PbwOYn3vU9WpzRYc2oQBICIXu/X2HzZHqa5wtOprdT28Bq2+dj1pjDGmJ5YwjDHG9OSwJ4wn9rsAfXSU6gpHq75W18NroOp7qPswjDHG7J7DfoVhjDFml1jCMMYY05MDnzBE5O+JyCsikonIdEf8rIg0RORFN32xY9kHROQlEZkRkd9xP6WOiBwTkedE5HX3d9zFxa03IyLfF5H3dzzXI27910XkEfZYt/q6ZZ91ZXxVRD7SEX/QxWZE5LGO+DkR+baLf1lEIhcvuMczbvnZO+1jr4nI50RktuP9/NidyrSb9T6outXxoBORN90x+KKIXHSxXTv+uh3jfazfkyIyJyIvd8T2vH7d9tE3qnqgJ+AvAz8D/Ckw3RE/C7zcZZvvAA+Q/5DmHwMfdfF/Dzzm5h8DfsvNf8ytJ267b7v4MeAN93fczY/vU33vB75H/nPy54DLgO+my8B5IHLr3O+2+QrwsJv/IvBP3fyvAV908w8DX95qH316nz8H/MtN4nte74M6bVXHgz4BbwKTG2K7dvx1O8b7WL+fA95PxzmoH/Xrto9+TQf+CkNVf6iqr/a6vuT/rW9EVZ/X/FX9EvBxt/gh4Ck3/9SG+Jc09zww5p7nI8BzqrqoqkvAc8CDO63TVrao70PA06raUtUfk/9/kA+6aUZV31DVGHgaeMh9I/l54Ktu+431XXsdvgp82K3fbR/7qR/1Pqg2reM+l2knduX4u8Mx3heq+v+AxQ3hftSv2z764sAnjDs4JyLfFZE/E5EPudgp4ErHOldcDOAe/Yv/1ncNuKdjm7c32aZbfD9st4wTwLKqJhvitzyXW77i1t/v+n7GXbI/2XGp3Y96H1T7/X7shAJ/IiKXRORRF9ut42+rY3w/9aN+3fbRFwfixwdF5BvAiU0WPa6qz2wSB7gKvEtVF0TkA8Afish7et2nqqqI7MuY4rus78Dbqt7AF4DfID/R/Abw28Cn+lc6s8v+uqrOishx8v/I+aPOhft5/PVDP+q3H6/hgUgYqvoLd7FNC2i5+Usichl4NzALnO5Y9bSLAVwXkZOqetVd9s25+CxwZpNtZoG/sSH+p9st6yZl33Z96V5GusQXyC99A/dtunP9tee6IiIBMOrW32ofO9ZrvUXk94A/2lDWzcq0W/U+qPb0/dhLqjrr/s6JyB+QN6/t1vG31TG+n/pRv2776IuBbZISkSkR8d38eeAC8Ia7XLspIg+49ulPAmvf2p8F1kYiPLIh/kk3muEBYMU9z9eBXxSRcddE8osuth+eBR6WfKTPOfL6fgd4Abgg+cigiLwz91nX9vkt4BNu+431XXsdPgH8X7d+t33sOffhX/NLwNrok37U+6DatI77XKY7EpGKiAyvzZMfNy+zS8ffHY7x/dSP+nXbR3/0s4f9bibyk8cV8quJ6+4FBfi7wCvAi8CfA3+7Y5tp8g/oZeB3+Ys72ieAbwKvA98Ajrm4AJ9367/EraOTPkXe0ToD/Mp+1dcte9yV8VU6RoWQj8J4zS17vCN+nvzkOgP8L6Dg4kX3eMYtP3+nffSh3v/DvfbfJz8oTvaz3gd16lbHgzy51/97bnplrdy7efx1O8b7WMf/Sd4s3nbH66f7Ub9u++jXZD8NYowxpicD2yRljDGmvyxhGGOM6YklDGOMMT2xhGGMMaYnljCMMcb0xBKGMcaYnljCMMYY05P/D0NNnk7MS44zAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_eigv((k.T @ q).eig()[0] if qk else (B.T @ A).eig()[0], start_i=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "id": "801cf7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = _m  # q->k, output->input\n",
    "m = _m.T  # k->q, input->output\n",
    "values, indices = m.topk(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "id": "d258e52b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_topk.indices_fn = tokenizer.convert_ids_to_tokens\n",
    "ans1 = []\n",
    "for i in values.mean(1).topk(1000).indices.tolist():\n",
    "    ans = tokenizer.convert_ids_to_tokens(i), show_topk(values[i][:6].long(), indices[i][:6])\n",
    "    ans1.append(ans)\n",
    "#     print(tokenizer.convert_ids_to_tokens(i), show_topk(values[i][:6].long(), indices[i][:6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "id": "e5ff11ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<|endoftext|>',\n",
       "  {'add': 366,\n",
       "   'list': 363,\n",
       "   'note': 362,\n",
       "   'lists': 362,\n",
       "   'limit': 362,\n",
       "   'the': 360}),\n",
       " ('ãĢĤ',\n",
       "  {'add': 342, 'a': 335, 'list': 335, 'no': 334, 'the': 333, 'limit': 332}),\n",
       " (']).',\n",
       "  {'add': 341,\n",
       "   'list': 338,\n",
       "   'note': 336,\n",
       "   'limit': 334,\n",
       "   'lists': 332,\n",
       "   'a': 331}),\n",
       " (').',\n",
       "  {'add': 341,\n",
       "   'list': 337,\n",
       "   'note': 333,\n",
       "   'limit': 332,\n",
       "   'lists': 331,\n",
       "   'a': 331}),\n",
       " ('$.',\n",
       "  {'add': 340, 'list': 333, 'limit': 332, 'note': 332, 'a': 330, 'the': 330}),\n",
       " ('].',\n",
       "  {'add': 337,\n",
       "   'list': 335,\n",
       "   'limit': 331,\n",
       "   'note': 331,\n",
       "   'lists': 328,\n",
       "   'a': 328}),\n",
       " (')).',\n",
       "  {'add': 336, 'list': 333, 'note': 329, 'the': 326, 'lists': 326, 'a': 326}),\n",
       " ('Ċ',\n",
       "  {'add': 335,\n",
       "   'the': 332,\n",
       "   'list': 327,\n",
       "   'note': 326,\n",
       "   'limit': 325,\n",
       "   'hit': 325}),\n",
       " ('.',\n",
       "  {'add': 334,\n",
       "   'list': 330,\n",
       "   'the': 327,\n",
       "   'note': 325,\n",
       "   'lists': 324,\n",
       "   'limit': 324}),\n",
       " ('})',\n",
       "  {'add': 334, 'limit': 328, 'list': 326, 'note': 325, 'at': 325, 'AT': 325}),\n",
       " (')}',\n",
       "  {'add': 331, 'limit': 327, 'note': 326, 'list': 325, 'no': 325, 'go': 324}),\n",
       " (']),',\n",
       "  {'add': 332, 'limit': 328, 'list': 328, 'note': 325, 'no': 321, '1': 321}),\n",
       " (')),',\n",
       "  {'add': 331, 'no': 325, 'list': 325, 'note': 324, 'the': 324, 'limit': 322}),\n",
       " ('),',\n",
       "  {'add': 334, 'list': 327, 'note': 324, 'limit': 324, 'no': 321, 'a': 319}),\n",
       " ('}}}',\n",
       "  {'add': 327, 'limit': 326, 'go': 324, 'note': 324, 'put': 322, 'no': 322}),\n",
       " ('}.',\n",
       "  {'note': 328, 'add': 327, 'list': 325, 'limit': 323, 'no': 322, 'go': 320}),\n",
       " ('}}',\n",
       "  {'add': 328, 'limit': 324, 'note': 323, 'list': 321, 'go': 321, 'no': 321}),\n",
       " (')\\\\',\n",
       "  {'add': 336,\n",
       "   'list': 324,\n",
       "   'ADD': 324,\n",
       "   'note': 323,\n",
       "   'limit': 320,\n",
       "   '177': 319}),\n",
       " (')]',\n",
       "  {'add': 330,\n",
       "   'note': 324,\n",
       "   'list': 323,\n",
       "   'notes': 319,\n",
       "   'the': 319,\n",
       "   'draw': 318}),\n",
       " (')].',\n",
       "  {'list': 327,\n",
       "   'limit': 323,\n",
       "   'note': 323,\n",
       "   'lists': 322,\n",
       "   'add': 320,\n",
       "   'notes': 318}),\n",
       " ('channelAvailability',\n",
       "  {'add': 329,\n",
       "   'list': 326,\n",
       "   'limit': 322,\n",
       "   'note': 321,\n",
       "   'lists': 319,\n",
       "   'at': 318}),\n",
       " ('},',\n",
       "  {'add': 327, 'note': 326, 'list': 322, 'limit': 321, 'no': 320, 'at': 318}),\n",
       " ('Ġè£ıè',\n",
       "  {'add': 327, 'list': 324, 'at': 322, 'AT': 320, 'limit': 318, 'zz': 318}),\n",
       " ('\"}',\n",
       "  {'add': 329, 'list': 324, 'note': 323, 'limit': 322, 'the': 318, 'no': 318}),\n",
       " ('Ġthe',\n",
       "  {'the': 332,\n",
       "   'add': 328,\n",
       "   'list': 323,\n",
       "   'limit': 320,\n",
       "   'lists': 318,\n",
       "   'note': 317}),\n",
       " ('.).',\n",
       "  {'add': 325, 'note': 325, 'list': 325, 'a': 321, 'notes': 318, 'Name': 318}),\n",
       " ('quickShip',\n",
       "  {'add': 328,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 321,\n",
       "   'lists': 318,\n",
       "   'hit': 318}),\n",
       " ('Ġè£ıè¦ļéĨĴ',\n",
       "  {'add': 328,\n",
       "   'list': 325,\n",
       "   'limit': 322,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " ('ĠguiActiveUnfocused',\n",
       "  {'add': 328,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 321,\n",
       "   'hit': 318,\n",
       "   'lists': 318}),\n",
       " ('ĠguiIcon',\n",
       "  {'add': 328,\n",
       "   'list': 325,\n",
       "   'limit': 320,\n",
       "   'lists': 319,\n",
       "   'note': 319,\n",
       "   'at': 318}),\n",
       " ('ÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤ',\n",
       "  {'add': 328,\n",
       "   'list': 324,\n",
       "   'limit': 320,\n",
       "   'note': 319,\n",
       "   'at': 319,\n",
       "   'lists': 318}),\n",
       " ('\").',\n",
       "  {'add': 329, 'note': 322, 'list': 322, 'limit': 320, 'a': 318, 'Name': 318}),\n",
       " ('ÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤ',\n",
       "  {'add': 328,\n",
       "   'list': 324,\n",
       "   'at': 319,\n",
       "   'limit': 319,\n",
       "   'note': 319,\n",
       "   'lists': 318}),\n",
       " ('ĠRandomRedditor',\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " ('ĠUCHIJ',\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 318,\n",
       "   'at': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " ('isSpecialOrderable',\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'hit': 318,\n",
       "   'lists': 317}),\n",
       " ('Downloadha',\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'at': 317}),\n",
       " ('ĠSmartstocks',\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 321,\n",
       "   'hit': 317,\n",
       "   'lists': 317}),\n",
       " ('ú',\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " ('ü',\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " ('ÿ',\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " ('EStreamFrame',\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 318,\n",
       "   'ulu': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 318,\n",
       "   'at': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " ('÷',\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " ('\"),',\n",
       "  {'add': 330, 'limit': 324, 'list': 320, 'no': 320, 'note': 319, 'put': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " ('û',\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " ('PsyNetMessage',\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " ('þ',\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " ('ĠexternalToEVA',\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " ('ĠSolidGoldMagikarp',\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " ('ĠRandomRedditorWithNo',\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " ('InstoreAndOnline',\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " ('À',\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " ('ĠAdinida',\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'at': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " ('ĠãĤµãĥ¼ãĥĨãĤ£ãĥ¯ãĥ³',\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 319,\n",
       "   'at': 318,\n",
       "   'lists': 318,\n",
       "   'note': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " ('ĠTheNitrome',\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'at': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'at': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " ('ĠTheNitromeFan',\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 318,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " ('ý',\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " ('ĠattRot',\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " ('Á',\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " ('ĠunfocusedRange',\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " ('ù',\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " ('ø',\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " ('oreAndOnline',\n",
       "  {'add': 327,\n",
       "   'list': 325,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " ('StreamerBot',\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " ('assetsadobe',\n",
       "  {'add': 327, 'list': 324, 'limit': 319, 'at': 319, 'note': 318, 'AT': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'ulu': 316}),\n",
       " ('embedreportprint',\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " ('ö',\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " ('GoldMagikarp',\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " ('õ',\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " ('ĠexternalToEVAOnly',\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'hit': 317,\n",
       "   'lists': 316}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " ('rawdownload',\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " ('ĠguiActiveUn',\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'lists': 317,\n",
       "   'hit': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " ('ĠsrfN',\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'ulu': 317}),\n",
       " (None,\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 320,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'hit': 316}),\n",
       " ('}\\\\',\n",
       "  {'add': 328, 'list': 320, 'go': 319, 'limit': 319, 'note': 318, 'ADD': 317}),\n",
       " ('ĠstrutConnector',\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 320,\n",
       "   'note': 318,\n",
       "   'at': 317,\n",
       "   'lists': 317}),\n",
       " ('cloneembedreportprint',\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 320,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'at': 316}),\n",
       " ('natureconservancy',\n",
       "  {'add': 326, 'list': 321, 'at': 319, 'note': 318, 'limit': 317, 'IT': 317}),\n",
       " ('ĠguiActive',\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 319,\n",
       "   'lists': 318,\n",
       "   'note': 317,\n",
       "   'at': 317}),\n",
       " ('reportprint',\n",
       "  {'add': 326,\n",
       "   'list': 324,\n",
       "   'limit': 320,\n",
       "   'note': 319,\n",
       "   'at': 317,\n",
       "   'lists': 317}),\n",
       " ('ĠDevOnline',\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 320,\n",
       "   'note': 319,\n",
       "   'lists': 317,\n",
       "   'at': 316}),\n",
       " ('é¾įå¥ĳå£«',\n",
       "  {'add': 326,\n",
       "   'list': 324,\n",
       "   'limit': 319,\n",
       "   'note': 318,\n",
       "   'at': 317,\n",
       "   'lists': 317}),\n",
       " ('Ġdavidjl',\n",
       "  {'add': 327,\n",
       "   'list': 324,\n",
       "   'limit': 320,\n",
       "   'note': 318,\n",
       "   'lists': 317,\n",
       "   'ulu': 316}),\n",
       " ('iHUD',\n",
       "  {'add': 327, 'list': 323, 'limit': 319, 'IT': 317, 'at': 317, 'it': 316}),\n",
       " (');',\n",
       "  {'add': 329,\n",
       "   'list': 324,\n",
       "   'limit': 321,\n",
       "   'note': 321,\n",
       "   'Name': 316,\n",
       "   'AT': 314}),\n",
       " ('rawdownloadcloneembedreportprint',\n",
       "  {'add': 326,\n",
       "   'list': 323,\n",
       "   'limit': 320,\n",
       "   'note': 319,\n",
       "   'lists': 316,\n",
       "   'hit': 316}),\n",
       " ('DragonMagazine',\n",
       "  {'add': 326,\n",
       "   'list': 324,\n",
       "   'limit': 319,\n",
       "   'note': 318,\n",
       "   'lists': 317,\n",
       "   'at': 316}),\n",
       " (']}',\n",
       "  {'limit': 324, 'add': 321, 'no': 320, 'go': 318, 'note': 317, 'list': 316}),\n",
       " ('TPPStreamerBot',\n",
       "  {'add': 326,\n",
       "   'list': 324,\n",
       "   'limit': 319,\n",
       "   'note': 318,\n",
       "   'lists': 317,\n",
       "   'at': 316}),\n",
       " ('ÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤ',\n",
       "  {'add': 326, 'list': 322, 'limit': 318, 'note': 318, 'at': 317, 'IT': 315}),\n",
       " ('))',\n",
       "  {'add': 327, 'no': 320, 'note': 318, 'limit': 318, 'list': 317, 'the': 317}),\n",
       " ('soDeliveryDate',\n",
       "  {'add': 326,\n",
       "   'list': 323,\n",
       "   'limit': 319,\n",
       "   'note': 318,\n",
       "   'lists': 316,\n",
       "   'hit': 315}),\n",
       " ('?????-?????-',\n",
       "  {'add': 325,\n",
       "   'list': 323,\n",
       "   'limit': 319,\n",
       "   'note': 318,\n",
       "   'lists': 316,\n",
       "   'at': 315}),\n",
       " ('ĠãĤµãĥ¼ãĥĨãĤ£',\n",
       "  {'add': 325,\n",
       "   'list': 323,\n",
       "   'limit': 319,\n",
       "   'note': 318,\n",
       "   'lists': 315,\n",
       "   'hit': 315}),\n",
       " ('Ġdstg',\n",
       "  {'add': 328, 'list': 322, 'at': 319, 'lists': 317, 'zz': 315, 'AT': 314}),\n",
       " ('BuyableInstoreAndOnline',\n",
       "  {'add': 325,\n",
       "   'list': 322,\n",
       "   'limit': 318,\n",
       "   'note': 317,\n",
       "   'lists': 315,\n",
       "   'hit': 315}),\n",
       " ('])',\n",
       "  {'add': 325, 'list': 320, 'note': 319, 'limit': 319, 'no': 315, 'ADD': 314}),\n",
       " ('quickShipAvailable',\n",
       "  {'add': 324, 'list': 321, 'limit': 319, 'note': 318, 'hit': 315, 'at': 314}),\n",
       " ('Ġsqor',\n",
       "  {'add': 324,\n",
       "   'list': 322,\n",
       "   'limit': 318,\n",
       "   'note': 317,\n",
       "   'lists': 315,\n",
       "   'ulu': 314}),\n",
       " ('âĢ',\n",
       "  {'add': 325, 'list': 319, 'limit': 318, 'a': 316, 'note': 315, 'no': 315}),\n",
       " (']);',\n",
       "  {'add': 327,\n",
       "   'limit': 321,\n",
       "   'note': 320,\n",
       "   'list': 317,\n",
       "   'Name': 313,\n",
       "   'ADD': 313}),\n",
       " ('}', {'add': 323, 'list': 318, 'no': 316, 'go': 316, 'a': 314, 'note': 314}),\n",
       " (')))',\n",
       "  {'add': 325, 'limit': 319, 'list': 317, 'put': 315, '1': 314, 'note': 314}),\n",
       " ('],',\n",
       "  {'add': 324, 'list': 321, 'limit': 320, 'note': 316, '1': 315, 'no': 314}),\n",
       " ('ĠTHE',\n",
       "  {'the': 322, 'AT': 321, 'ADD': 316, 'IT': 316, 'AND': 314, 'END': 314}),\n",
       " ('));',\n",
       "  {'add': 323,\n",
       "   'list': 321,\n",
       "   'limit': 320,\n",
       "   'note': 318,\n",
       "   'no': 314,\n",
       "   'Name': 313}),\n",
       " ('.),',\n",
       "  {'add': 322, 'list': 319, 'note': 318, 'no': 316, 'put': 314, 'the': 313}),\n",
       " ('Ġè£ıç',\n",
       "  {'add': 322, 'list': 317, 'zz': 317, 'at': 315, 'AT': 314, 'hit': 314}),\n",
       " ('ItemThumbnailImage',\n",
       "  {'add': 323, 'list': 320, 'at': 316, 'limit': 314, 'AT': 314, 'IT': 313}),\n",
       " (')',\n",
       "  {'add': 324, 'list': 318, 'note': 315, 'AT': 314, 'limit': 314, 'at': 314}),\n",
       " ('.)',\n",
       "  {'add': 321, 'list': 320, 'note': 319, 'a': 314, 'no': 314, 'the': 313}),\n",
       " ('\"},',\n",
       "  {'list': 323, 'add': 322, 'note': 321, 'limit': 318, 'no': 309, 'AT': 309}),\n",
       " ('\\\\',\n",
       "  {'add': 326, 'the': 316, 'list': 315, 'ADD': 314, 'note': 312, 'put': 312}),\n",
       " ('ĠexternalTo',\n",
       "  {'add': 322, 'list': 318, 'note': 315, 'limit': 315, 'at': 313, 'hit': 312}),\n",
       " ('ĠSkydragon',\n",
       "  {'add': 322, 'list': 319, 'lists': 313, 'at': 313, 'zz': 312, 'limit': 312}),\n",
       " ('inventoryQuantity',\n",
       "  {'add': 322, 'list': 318, 'note': 314, 'at': 314, 'limit': 313, 'AT': 312}),\n",
       " (',',\n",
       "  {'add': 326, 'list': 320, 'limit': 316, 'note': 313, 'at': 310, 'no': 310}),\n",
       " (']',\n",
       "  {'add': 323,\n",
       "   'list': 318,\n",
       "   'limit': 316,\n",
       "   'note': 314,\n",
       "   'no': 311,\n",
       "   'lists': 310}),\n",
       " ('ĠlargeDownload',\n",
       "  {'add': 323, 'list': 318, 'at': 316, 'lists': 312, 'zz': 312, 'AT': 311}),\n",
       " ('ĠØ', {'a': 322, 'add': 317, 'ulu': 315, 'pa': 312, 'hit': 311, 'zz': 311}),\n",
       " ('Ġistg',\n",
       "  {'add': 321,\n",
       "   'list': 318,\n",
       "   'limit': 314,\n",
       "   'note': 313,\n",
       "   'lists': 312,\n",
       "   'hit': 311}),\n",
       " ('\");',\n",
       "  {'add': 324,\n",
       "   'limit': 319,\n",
       "   'list': 314,\n",
       "   'Name': 313,\n",
       "   'note': 312,\n",
       "   'ulu': 309}),\n",
       " (\"').\",\n",
       "  {'add': 324, 'list': 318, 'limit': 313, 'lists': 312, 'a': 311, 'go': 309}),\n",
       " ('\"))',\n",
       "  {'add': 322, 'put': 314, 'no': 313, 'note': 311, 'the': 311, 'a': 311}),\n",
       " ('ĠMechdragon',\n",
       "  {'add': 320, 'list': 317, 'note': 315, 'limit': 314, 'at': 311, 'hit': 310}),\n",
       " ('ĠguiName',\n",
       "  {'zz': 324, 'add': 316, 'list': 315, 'Name': 311, 'note': 310, 'it': 310}),\n",
       " ('Ġ).',\n",
       "  {'list': 320, 'add': 319, 'note': 312, 'lists': 311, 'Name': 310, '1': 310}),\n",
       " ('ãĢģ',\n",
       "  {'add': 322, 'list': 315, 'a': 313, 'go': 313, 'limit': 310, 'hit': 310}),\n",
       " ('é¾įåĸļå£«',\n",
       "  {'add': 319, 'list': 315, 'AT': 314, 'at': 313, 'a': 313, 'zz': 310}),\n",
       " ('Ġpetertodd',\n",
       "  {'add': 318, 'at': 315, 'zz': 314, 'AT': 311, 'limit': 311, 'IT': 310}),\n",
       " ('ForgeModLoader',\n",
       "  {'add': 321, 'at': 316, 'zz': 314, 'AT': 313, 'list': 312, 'note': 311}),\n",
       " ('$,',\n",
       "  {'add': 322, 'limit': 313, 'list': 311, 'no': 311, 'note': 311, 'a': 311}),\n",
       " ('Ġ})',\n",
       "  {'add': 323, 'at': 313, 'AT': 313, 'list': 312, 'limit': 311, 'ATS': 311}),\n",
       " ('};',\n",
       "  {'Name': 314,\n",
       "   'add': 313,\n",
       "   'note': 313,\n",
       "   'END': 312,\n",
       "   'limit': 312,\n",
       "   'Names': 311}),\n",
       " ('ÃĥÃĤÃĥÃĤ',\n",
       "  {'add': 316, 'IT': 315, 'AT': 314, 'zz': 314, 'it': 310, 'END': 309}),\n",
       " ('.]',\n",
       "  {'add': 321,\n",
       "   'list': 313,\n",
       "   'note': 312,\n",
       "   'no': 311,\n",
       "   'Name': 310,\n",
       "   'limit': 308}),\n",
       " (']]',\n",
       "  {'add': 321, 'list': 315, 'put': 312, 'ADD': 310, 'lists': 309, 'hit': 309}),\n",
       " (\"'),\",\n",
       "  {'add': 323, 'limit': 314, 'list': 313, 'no': 308, 'go': 307, 'a': 307}),\n",
       " ('ĸļå£«',\n",
       "  {'add': 317, 'list': 315, 'at': 311, 'zz': 310, 'AT': 309, 'a': 308}),\n",
       " ('Ġ}',\n",
       "  {'add': 321, 'END': 312, 'list': 311, 'put': 310, 'no': 308, 'ADD': 306}),\n",
       " (\"');\",\n",
       "  {'add': 321, 'limit': 315, 'list': 314, 'Name': 308, 'zz': 307, 'go': 307}),\n",
       " ('});',\n",
       "  {'add': 316, 'note': 312, 'limit': 312, 'go': 308, 'list': 308, 'END': 307}),\n",
       " ('\")',\n",
       "  {'add': 322,\n",
       "   'note': 311,\n",
       "   'put': 310,\n",
       "   'limit': 308,\n",
       "   'Name': 307,\n",
       "   'list': 307}),\n",
       " ('\"],',\n",
       "  {'add': 319, 'limit': 313, '1': 311, 'no': 310, 'note': 308, 'list': 308}),\n",
       " ('))))',\n",
       "  {'add': 317, 'note': 315, 'no': 308, 'list': 307, 'zz': 307, 'limit': 307}),\n",
       " ('é¾įå¥',\n",
       "  {'zz': 321, 'AT': 310, 'list': 309, 'at': 308, 'ATS': 307, 'add': 305}),\n",
       " ('ItemTracker',\n",
       "  {'add': 313, 'list': 311, 'AT': 311, 'IT': 311, 'at': 308, 'ATS': 306}),\n",
       " ('];',\n",
       "  {'add': 314,\n",
       "   'limit': 312,\n",
       "   'list': 310,\n",
       "   'Name': 309,\n",
       "   'note': 309,\n",
       "   'name': 305}),\n",
       " ('Ġ].',\n",
       "  {'add': 316, 'list': 314, 'AT': 307, '1': 306, 'no': 306, 'Name': 305}),\n",
       " ('</',\n",
       "  {'add': 315, 'ulu': 311, 'at': 308, 'note': 308, 'list': 307, 'AT': 306}),\n",
       " ('!).',\n",
       "  {'list': 313, 'note': 311, 'put': 307, 'add': 307, 'no': 307, 'all': 305}),\n",
       " ('Ġ},',\n",
       "  {'add': 316, 'AT': 308, 'limit': 307, 'END': 306, 'no': 305, 'note': 305}),\n",
       " ('Ġ}}',\n",
       "  {'add': 312, 'AT': 310, 'at': 310, 'list': 306, 'limit': 305, 'ATS': 305}),\n",
       " ('Ġ);',\n",
       "  {'add': 318,\n",
       "   'list': 313,\n",
       "   'limit': 306,\n",
       "   'END': 306,\n",
       "   'Name': 305,\n",
       "   'ADD': 304}),\n",
       " ('Ġ),',\n",
       "  {'add': 317, 'list': 314, '1': 305, 'limit': 304, 'no': 304, 'ulu': 303}),\n",
       " ('Ġ});',\n",
       "  {'add': 316, 'END': 310, 'limit': 308, 'list': 307, 'note': 304, 'at': 304}),\n",
       " ('.\"',\n",
       "  {'add': 313,\n",
       "   'note': 309,\n",
       "   'limit': 305,\n",
       "   'hit': 305,\n",
       "   'Name': 304,\n",
       "   'put': 303}),\n",
       " ('ĠItemLevel',\n",
       "  {'add': 314, 'IT': 312, 'list': 307, 'AT': 306, 'lists': 304, 'DD': 303}),\n",
       " ('ĠÐ',\n",
       "  {'add': 315, 'zz': 306, 'a': 305, 'list': 305, 'leases': 303, 'at': 303}),\n",
       " ('ĠDragonbound',\n",
       "  {'add': 313, 'AT': 307, 'zz': 306, 'at': 306, 'IT': 304, 'ATS': 302}),\n",
       " (')\",',\n",
       "  {'add': 314, 'DD': 309, 'note': 307, 'zz': 306, 'help': 302, 'no': 302}),\n",
       " ('Ġand',\n",
       "  {'add': 316, 'limit': 308, 'and': 307, 'list': 307, 'ADD': 301, 'ulu': 301}),\n",
       " ('Ġ',\n",
       "  {'add': 316, 'list': 308, 'limit': 304, 'note': 304, '1': 302, 'at': 302}),\n",
       " ('\"]',\n",
       "  {'add': 315,\n",
       "   'Name': 306,\n",
       "   'limit': 305,\n",
       "   'list': 305,\n",
       "   'name': 302,\n",
       "   'put': 301}),\n",
       " ('ĉ',\n",
       "  {'add': 310, 'list': 306, '177': 304, 'note': 302, 'hit': 302, 'at': 301}),\n",
       " ('Ġ)',\n",
       "  {'add': 313, 'list': 308, 'AT': 303, 'lists': 302, 'put': 301, 'no': 301}),\n",
       " ('Nitrome',\n",
       "  {'zz': 309, 'Nat': 307, 'at': 306, 'add': 304, 'IT': 302, 'AT': 301}),\n",
       " (\"']\",\n",
       "  {'add': 312, 'limit': 308, 'list': 305, 'go': 305, 'zz': 304, 'Name': 302}),\n",
       " ('?).',\n",
       "  {'no': 308, 'list': 308, 'add': 307, 'note': 306, '1': 302, 'yes': 302}),\n",
       " ('.\")',\n",
       "  {'add': 308,\n",
       "   'note': 305,\n",
       "   'Name': 305,\n",
       "   'list': 304,\n",
       "   'no': 302,\n",
       "   'Names': 301}),\n",
       " ('%).',\n",
       "  {'list': 309, 'add': 308, 'no': 303, 'note': 303, 'lists': 302, 'zz': 300}),\n",
       " ('\".',\n",
       "  {'add': 311, 'hit': 308, 'note': 304, '177': 304, 'list': 302, 'put': 299}),\n",
       " ('SpaceEngineers',\n",
       "  {'zz': 312, 'ER': 308, 'add': 306, 'END': 303, 'AT': 301, 'er': 300}),\n",
       " ('].\"',\n",
       "  {'add': 309,\n",
       "   'note': 308,\n",
       "   'Name': 307,\n",
       "   'limit': 305,\n",
       "   'name': 302,\n",
       "   'Names': 298}),\n",
       " (')=',\n",
       "  {'note': 314,\n",
       "   'add': 306,\n",
       "   'notes': 303,\n",
       "   'limit': 303,\n",
       "   'put': 302,\n",
       "   'Name': 299}),\n",
       " ('Ġ};',\n",
       "  {'END': 313,\n",
       "   'add': 306,\n",
       "   'Names': 302,\n",
       "   'list': 301,\n",
       "   'Name': 301,\n",
       "   'limit': 300}),\n",
       " ('Ġ\\\\',\n",
       "  {'add': 315, 'list': 303, '255': 302, 'ulu': 301, 'ADD': 301, 'at': 300}),\n",
       " ('());',\n",
       "  {'limit': 305,\n",
       "   'add': 305,\n",
       "   'Name': 304,\n",
       "   'list': 302,\n",
       "   'no': 302,\n",
       "   'note': 300}),\n",
       " ('Ġ(',\n",
       "  {'add': 314,\n",
       "   'list': 305,\n",
       "   'leases': 302,\n",
       "   'hit': 301,\n",
       "   'note': 301,\n",
       "   'AT': 299}),\n",
       " ('MpServer',\n",
       "  {'list': 309, 'at': 305, 'zz': 303, 'add': 301, 'lists': 299, 'AT': 298}),\n",
       " ('ãĤ¼ãĤ¦ãĤ¹',\n",
       "  {'zz': 313, 'add': 301, 'Nat': 301, 'AT': 300, 'a': 300, 'gen': 300}),\n",
       " ('Ġ×',\n",
       "  {'a': 305, 'zz': 304, 'add': 304, 'limit': 300, 'hit': 300, 'ya': 299}),\n",
       " ('\",',\n",
       "  {'add': 313, 'hit': 301, 'note': 301, 'zz': 300, 'list': 299, 'limit': 299}),\n",
       " (\"')\",\n",
       "  {'add': 315,\n",
       "   'zz': 301,\n",
       "   'limit': 301,\n",
       "   'list': 301,\n",
       "   'lists': 298,\n",
       "   'put': 298}),\n",
       " ('ĠAND',\n",
       "  {'AND': 327, 'END': 303, 'ADD': 301, 'ANT': 299, 'IND': 298, 'AT': 298}),\n",
       " ('ÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤÃĥÃĤ',\n",
       "  {'IT': 306, 'add': 302, 'go': 302, 'zz': 302, 'it': 301, 'AT': 298}),\n",
       " ('?),',\n",
       "  {'no': 310, 'add': 303, 'note': 302, '1': 302, 'yes': 302, 'list': 301}),\n",
       " (';}',\n",
       "  {'DD': 306, 'add': 302, 'END': 302, 'list': 300, 'go': 298, 'limit': 298}),\n",
       " ('ĠÃ', {'zz': 308, 'at': 304, 'a': 302, 'add': 301, 'list': 298, 'AT': 298}),\n",
       " ('Č',\n",
       "  {'add': 309, 'at': 303, 'hit': 301, 'no': 300, 'pop': 298, 'ever': 296}),\n",
       " ('wcsstore',\n",
       "  {'AND': 304, 'at': 302, 'zz': 302, 'add': 300, 'IT': 298, 'END': 297}),\n",
       " ('ĠThe',\n",
       "  {'the': 309,\n",
       "   'add': 303,\n",
       "   'list': 299,\n",
       "   'lists': 299,\n",
       "   'limit': 298,\n",
       "   'orig': 298}),\n",
       " ('Ã¤', {'a': 304, 'pa': 303, 'zz': 302, 'inn': 301, 'all': 300, 'alt': 296}),\n",
       " ('}:',\n",
       "  {'note': 309, 'list': 300, 'add': 298, 'go': 298, 'zz': 297, 'no': 297}),\n",
       " (')</',\n",
       "  {'add': 303, 'at': 302, 'go': 300, 'list': 298, 'ulu': 298, 'note': 298}),\n",
       " ('Ġ],',\n",
       "  {'add': 307, 'list': 305, 'AT': 300, 'END': 296, 'at': 296, 'limit': 296}),\n",
       " (')?',\n",
       "  {'add': 303,\n",
       "   'no': 303,\n",
       "   'Questions': 302,\n",
       "   'question': 300,\n",
       "   'yes': 299,\n",
       "   'list': 297}),\n",
       " ('ò', {'zz': 311, 'at': 302, 'ats': 301, 'AT': 298, 'ATS': 297, 'icks': 296}),\n",
       " (').\"',\n",
       "  {'add': 304,\n",
       "   'note': 303,\n",
       "   'limit': 301,\n",
       "   'Name': 299,\n",
       "   'name': 295,\n",
       "   'notes': 295}),\n",
       " ('ãĤĴ',\n",
       "  {'leases': 304, 'zz': 302, 'go': 301, 'add': 297, 'limit': 297, 'ENN': 295}),\n",
       " ('Ġà¤', {'a': 303, 'zz': 301, 'list': 299, 'i': 297, 'go': 297, 'add': 297}),\n",
       " ('.}',\n",
       "  {'no': 300, 'list': 299, 'kill': 298, 'all': 297, 'Name': 297, 'note': 297}),\n",
       " ('_.',\n",
       "  {'list': 302, 'Name': 298, 'rew': 297, 'put': 297, 'note': 297, 'hit': 296}),\n",
       " ('Ġ])',\n",
       "  {'add': 308, 'ATS': 298, 'put': 297, 'AT': 297, 'list': 296, 'limit': 295}),\n",
       " ('The',\n",
       "  {'the': 311,\n",
       "   'add': 297,\n",
       "   'limit': 297,\n",
       "   'Nat': 296,\n",
       "   'list': 295,\n",
       "   'orig': 294}),\n",
       " ('>)',\n",
       "  {'Name': 302,\n",
       "   'leases': 299,\n",
       "   'add': 297,\n",
       "   'note': 296,\n",
       "   'AT': 296,\n",
       "   'list': 296}),\n",
       " ('),\"',\n",
       "  {'add': 304,\n",
       "   'note': 301,\n",
       "   'limit': 298,\n",
       "   'say': 295,\n",
       "   'list': 295,\n",
       "   'Name': 294}),\n",
       " (';',\n",
       "  {'add': 310,\n",
       "   'list': 301,\n",
       "   'zz': 300,\n",
       "   'note': 296,\n",
       "   'limit': 294,\n",
       "   'Name': 293}),\n",
       " ('.</',\n",
       "  {'at': 302, 'add': 301, 'ulu': 297, 'AT': 296, 'note': 295, 'a': 294}),\n",
       " ('Ä',\n",
       "  {'at': 305, 'pa': 303, 'Nat': 301, 'add': 296, 'gate': 293, 'hey': 293}),\n",
       " ('Ġ];',\n",
       "  {'add': 303,\n",
       "   'END': 302,\n",
       "   'limit': 302,\n",
       "   'list': 299,\n",
       "   'Name': 294,\n",
       "   'Names': 292}),\n",
       " (\"',\",\n",
       "  {'add': 310, 'zz': 300, 'list': 299, 'limit': 297, 'hit': 293, 'kill': 291}),\n",
       " ('Ġ]',\n",
       "  {'add': 310, 'list': 300, 'ADD': 294, 'AT': 294, 'no': 293, 'Name': 293}),\n",
       " (\"'.\",\n",
       "  {'add': 303, 'zz': 299, 'list': 297, 'hit': 296, '177': 294, 'note': 293}),\n",
       " ('.\",',\n",
       "  {'name': 297, 'no': 296, 'note': 295, 'anna': 295, 'all': 295, 'Name': 295}),\n",
       " ('Ġ)))',\n",
       "  {'add': 304, 'put': 300, 'zz': 295, 'list': 294, 'all': 294, 'limit': 293}),\n",
       " ('())',\n",
       "  {'add': 299,\n",
       "   'limit': 298,\n",
       "   'Name': 296,\n",
       "   'put': 296,\n",
       "   '111': 294,\n",
       "   'list': 293}),\n",
       " ('ãĢį',\n",
       "  {'add': 301, 'pop': 297, 'put': 296, 'hit': 295, 'limit': 295, 'no': 293}),\n",
       " ('Ġ))',\n",
       "  {'add': 307, 'put': 294, 'list': 293, 'at': 293, 'AT': 292, 'sent': 292}),\n",
       " ('(),',\n",
       "  {'add': 300, 'limit': 295, 'all': 295, 'list': 294, 'no': 294, 'put': 293}),\n",
       " ('();',\n",
       "  {'ulu': 297, 'add': 296, 'limit': 295, 'DD': 295, 'END': 293, 'zz': 292}),\n",
       " ('&&',\n",
       "  {'AND': 299, 'END': 298, 'list': 293, 'no': 293, 'add': 293, 'hey': 292}),\n",
       " ('Ġ)]',\n",
       "  {'list': 301, 'add': 296, 'note': 294, 'no': 294, 'put': 292, '1': 292}),\n",
       " ('Table',\n",
       "  {'ADD': 300, 'Name': 297, 'DD': 295, 'add': 294, 'AT': 292, 'Stat': 292}),\n",
       " ('Ġ\"$:/',\n",
       "  {'put': 298, 'add': 295, 'enda': 294, 'END': 293, 'zz': 293, 'note': 292}),\n",
       " ('cffffcc',\n",
       "  {'zz': 319, 'add': 297, 'IT': 292, 'AT': 291, 'bb': 289, 'ATS': 289}),\n",
       " ('):',\n",
       "  {'note': 301,\n",
       "   'add': 297,\n",
       "   'notes': 295,\n",
       "   'zz': 294,\n",
       "   'limit': 293,\n",
       "   'list': 293}),\n",
       " ('\";',\n",
       "  {'add': 305,\n",
       "   'note': 294,\n",
       "   'zz': 294,\n",
       "   'limit': 293,\n",
       "   'Name': 292,\n",
       "   'list': 291}),\n",
       " ('>,',\n",
       "  {'add': 299,\n",
       "   'list': 296,\n",
       "   'note': 294,\n",
       "   'Name': 292,\n",
       "   'all': 292,\n",
       "   'anna': 291}),\n",
       " ('\"},\"',\n",
       "  {'add': 299, 'AT': 296, 'note': 294, 'at': 293, 'put': 293, 'ATS': 291}),\n",
       " ('],\"',\n",
       "  {'add': 302, 'note': 298, 'limit': 294, 'Name': 291, '1': 290, 'say': 289}),\n",
       " ('<',\n",
       "  {'note': 297,\n",
       "   'list': 295,\n",
       "   'leases': 294,\n",
       "   'add': 293,\n",
       "   'no': 293,\n",
       "   '177': 290}),\n",
       " ('.,',\n",
       "  {'note': 295,\n",
       "   'add': 294,\n",
       "   'name': 293,\n",
       "   'list': 291,\n",
       "   'Name': 291,\n",
       "   'berger': 291}),\n",
       " (')\"',\n",
       "  {'add': 299, 'note': 297, 'Name': 293, 'help': 293, 'no': 290, 'yes': 289}),\n",
       " ('\"}],\"',\n",
       "  {'add': 304, 'DD': 296, 'AND': 294, 'END': 292, 'AT': 289, 'ADD': 289}),\n",
       " ('_',\n",
       "  {'add': 297, 'Name': 292, 'note': 292, 'name': 291, 'AT': 291, 'put': 290}),\n",
       " ('?',\n",
       "  {'Questions': 297,\n",
       "   'question': 295,\n",
       "   'yes': 295,\n",
       "   'no': 295,\n",
       "   'add': 293,\n",
       "   'list': 290}),\n",
       " ('Å',\n",
       "  {'add': 298, 'note': 295, 'Nat': 294, 'no': 292, 'zz': 291, 'put': 291}),\n",
       " ('Ġì',\n",
       "  {'anka': 297, 'rick': 292, 'ulu': 291, 'add': 290, 'icks': 290, 'zz': 290}),\n",
       " ('ĠOkawaru',\n",
       "  {'put': 297, 'go': 296, 'add': 296, 'zz': 293, 'Op': 291, 'Bow': 290}),\n",
       " (']\"',\n",
       "  {'add': 298,\n",
       "   'Name': 293,\n",
       "   'note': 292,\n",
       "   'AT': 291,\n",
       "   'limit': 290,\n",
       "   'name': 288}),\n",
       " ('ĠâĢ',\n",
       "  {'add': 300,\n",
       "   'draw': 294,\n",
       "   'put': 292,\n",
       "   'leases': 292,\n",
       "   'hit': 288,\n",
       "   'note': 288}),\n",
       " (')+',\n",
       "  {'add': 308, 'plus': 299, 'ADD': 295, '1': 288, 'note': 287, 'DD': 287}),\n",
       " ('>.',\n",
       "  {'add': 295,\n",
       "   'note': 294,\n",
       "   'Name': 294,\n",
       "   'leases': 293,\n",
       "   'list': 290,\n",
       "   'anka': 287}),\n",
       " ('Ġa', {'a': 313, 'add': 299, 'at': 287, 'zz': 287, 'ulu': 286, 'anka': 285}),\n",
       " ('%),',\n",
       "  {'list': 297, 'add': 294, 'no': 293, 'zz': 292, 'limit': 289, 'note': 287}),\n",
       " ('(',\n",
       "  {'add': 298, 'limit': 295, 'list': 293, 'note': 290, 'go': 288, 'no': 287}),\n",
       " ('$$',\n",
       "  {'add': 301, 'note': 293, 'put': 292, 'AND': 288, 'ADD': 288, '1': 287}),\n",
       " (')-',\n",
       "  {'add': 296, 'note': 296, 'zz': 293, 'at': 289, 'ATS': 289, 'limit': 288}),\n",
       " ('.):',\n",
       "  {'note': 298, 'AT': 294, 'zz': 294, 'at': 291, 'list': 287, 'add': 286}),\n",
       " ('(\\\\',\n",
       "  {'add': 295, 'ulu': 293, '177': 290, 'list': 289, 'no': 289, 'note': 288}),\n",
       " ('ñ', {'AT': 299, 'at': 295, 'ATS': 293, 'ats': 291, 'acks': 288, 'zz': 287}),\n",
       " ('_{',\n",
       "  {'limit': 296, 'at': 294, 'AT': 291, 'hit': 288, 'ulu': 287, 'put': 287}),\n",
       " (':',\n",
       "  {'add': 296,\n",
       "   'note': 295,\n",
       "   'list': 293,\n",
       "   'zz': 291,\n",
       "   'limit': 287,\n",
       "   'Name': 286}),\n",
       " ('Ã¥',\n",
       "  {'add': 300, 'zz': 298, 'mark': 294, 'anna': 289, 'kill': 285, 'gen': 284}),\n",
       " ('}\"',\n",
       "  {'Name': 295, 'add': 293, 'put': 289, 'name': 289, 'AT': 287, 'note': 286}),\n",
       " (\"';\",\n",
       "  {'add': 299, 'zz': 298, 'list': 288, 'limit': 288, 'Name': 286, 'go': 284}),\n",
       " (')*', {'add': 293, 'note': 293, 'w': 289, 'a': 289, 'no': 288, 'list': 287}),\n",
       " ('*,',\n",
       "  {'note': 293, 'list': 293, 'no': 289, 'a': 288, 'add': 286, 'at': 286}),\n",
       " (\".'\",\n",
       "  {'add': 299,\n",
       "   'limit': 288,\n",
       "   'ya': 288,\n",
       "   'note': 287,\n",
       "   'list': 287,\n",
       "   'Name': 287}),\n",
       " (',\"',\n",
       "  {'add': 297, 'note': 294, 'hit': 287, 'Name': 287, 'list': 286, 'say': 285}),\n",
       " ('ĠTable',\n",
       "  {'ADD': 298, 'DD': 292, 'add': 291, 'AT': 287, 'leases': 285, 'note': 284}),\n",
       " ('*.',\n",
       "  {'list': 291, 'a': 289, 'note': 288, 'leases': 288, 'no': 288, 'as': 287}),\n",
       " ('-', {'add': 292, 'zz': 292, 'note': 289, 'at': 289, 'AT': 288, 'Nat': 285}),\n",
       " ('?\"',\n",
       "  {'add': 296, 'note': 289, 'no': 288, 'hit': 288, 'Name': 288, '1': 286}),\n",
       " ('ĠÙ',\n",
       "  {'zz': 298, 'no': 289, 'at': 287, 'leases': 287, 'add': 286, 'ever': 285}),\n",
       " ('çļĦ',\n",
       "  {'add': 291, 'zz': 291, 'a': 289, 'at': 288, 'pop': 288, 'ever': 286}),\n",
       " ('Ġ*/',\n",
       "  {'limit': 292,\n",
       "   'add': 291,\n",
       "   'list': 291,\n",
       "   'Name': 287,\n",
       "   'entry': 286,\n",
       "   'name': 285}),\n",
       " ('ãģ®',\n",
       "  {'limit': 293, 'add': 291, 'no': 289, 'Nat': 289, 'zz': 286, 'ENN': 285}),\n",
       " ('!),',\n",
       "  {'list': 293, 'note': 291, 'anna': 288, 'no': 288, 'add': 288, 'all': 286}),\n",
       " ('?)',\n",
       "  {'no': 296, 'yes': 292, 'add': 291, 'list': 288, '1': 285, 'note': 284}),\n",
       " ('the',\n",
       "  {'the': 323, 'add': 289, 'note': 286, 'no': 284, 'hit': 283, 'a': 281}),\n",
       " ('Ġ$\\\\',\n",
       "  {'add': 296, 'ulu': 290, 'put': 289, 'ADD': 287, '111': 287, 'anna': 285}),\n",
       " ('().',\n",
       "  {'put': 291, 'rew': 290, 'add': 290, 'no': 287, 'limit': 287, 'go': 285}),\n",
       " ('.\\'\"',\n",
       "  {'note': 294, 'add': 289, 'put': 288, 'Name': 286, 'name': 286, 'it': 286}),\n",
       " ('ĠPsyNet',\n",
       "  {'zz': 302, 'Nat': 291, 'Net': 286, 'rick': 285, 'add': 284, 'list': 284}),\n",
       " ('*)',\n",
       "  {'note': 289, 'a': 288, 'list': 288, 'no': 287, 'add': 286, 'Name': 286}),\n",
       " ('?\",',\n",
       "  {'no': 297, 'add': 289, 'yes': 288, 'list': 286, 'name': 286, 'note': 284}),\n",
       " ('Ġ=',\n",
       "  {'add': 297, 'note': 289, 'AT': 287, 'list': 286, 'hit': 286, 'at': 286}),\n",
       " ('Ġ));',\n",
       "  {'add': 298, 'DD': 290, 'zz': 289, 'list': 287, 'ADD': 286, 'AT': 283}),\n",
       " ('Ġattm',\n",
       "  {'att': 300, 'at': 299, 'AT': 296, 'ats': 287, 'ATS': 284, 'add': 283}),\n",
       " ('Ġ</',\n",
       "  {'add': 292, 'ulu': 291, 'END': 290, 'AT': 284, 'at': 284, 'aster': 283}),\n",
       " ('\":',\n",
       "  {'add': 293, 'note': 289, 'zz': 288, 'Name': 287, 'hit': 286, 'limit': 285}),\n",
       " ('?]',\n",
       "  {'no': 297, 'yes': 291, '1': 287, 'note': 285, 'YES': 284, 'list': 283}),\n",
       " (']:',\n",
       "  {'note': 294, 'AT': 288, 'add': 286, 'limit': 286, 'Name': 284, 'zz': 284}),\n",
       " ('ï',\n",
       "  {'list': 293,\n",
       "   'add': 292,\n",
       "   'zz': 287,\n",
       "   'lists': 284,\n",
       "   'aler': 282,\n",
       "   'leases': 282}),\n",
       " ('\">',\n",
       "  {'add': 297, 'note': 287, 'list': 286, 'Name': 283, 'all': 283, 'at': 282}),\n",
       " ('Ġan',\n",
       "  {'an': 294, 'a': 293, 'add': 288, 'han': 288, 'lan': 284, 'anka': 284}),\n",
       " (')/',\n",
       "  {'add': 298, 'limit': 287, 'ADD': 286, 'note': 286, 'no': 283, 'Name': 282}),\n",
       " ('></',\n",
       "  {'add': 290, 'note': 290, 'ulu': 287, 'zz': 285, 'AT': 282, 'enda': 282}),\n",
       " ('?\".', {'no': 293, 'yes': 285, 'zz': 285, '1': 283, 'note': 283, 'as': 283}),\n",
       " ('{\\\\',\n",
       "  {'add': 288, '177': 287, 'note': 286, 'DD': 286, 'END': 285, 'list': 284}),\n",
       " ('!)',\n",
       "  {'list': 290, 'note': 289, 'rew': 286, 'add': 284, 'put': 284, 'anna': 284}),\n",
       " ('Ġla',\n",
       "  {'ulu': 292, 'a': 292, 'add': 285, 'ya': 282, 'na': 281, 'ague': 281}),\n",
       " ('THE',\n",
       "  {'the': 295, 'AT': 288, 'ITH': 287, 'AND': 284, 'THE': 281, 'DEN': 281}),\n",
       " ('=\"',\n",
       "  {'note': 292, 'add': 291, 'put': 287, 'at': 284, 'Name': 281, 'notes': 281}),\n",
       " ('`,',\n",
       "  {'add': 291, 'leases': 285, 'no': 284, 'Name': 283, 'as': 283, 'zz': 282}),\n",
       " ('=',\n",
       "  {'note': 294, 'add': 290, 'put': 283, 'Name': 282, 'notes': 281, 'AT': 281}),\n",
       " ('æ', {'add': 297, 'zz': 292, 'ADD': 284, 'a': 283, 'DD': 281, 'sa': 280}),\n",
       " ('Ġ{\\\\',\n",
       "  {'add': 289, 'DD': 287, 'ulu': 286, 'END': 283, 'list': 281, 'ADD': 281}),\n",
       " ('#$#$',\n",
       "  {'zz': 292, 'DD': 289, 'END': 285, 'AT': 284, 'AND': 281, 'add': 281}),\n",
       " ('ãģ',\n",
       "  {'zz': 294, 'add': 291, 'leases': 286, 'list': 282, 'at': 279, 'a': 279}),\n",
       " ('ĠWITH',\n",
       "  {'ITH': 319, 'ATS': 286, 'AT': 283, 'ISTER': 280, 'OUT': 279, 'END': 278}),\n",
       " ('%)',\n",
       "  {'list': 289, 'zz': 288, 'add': 286, 'no': 284, 'AT': 281, 'lists': 281}),\n",
       " ('){',\n",
       "  {'DD': 297, 'add': 291, 'ADD': 282, 'zz': 281, 'limit': 281, 'list': 280}),\n",
       " ('Ġis',\n",
       "  {'list': 292,\n",
       "   'is': 292,\n",
       "   'nis': 286,\n",
       "   'lists': 285,\n",
       "   'add': 284,\n",
       "   'limit': 281}),\n",
       " ('%);',\n",
       "  {'zz': 289, 'list': 287, 'add': 287, 'note': 284, 'AT': 281, 'no': 280}),\n",
       " ('ãĢĳ',\n",
       "  {'add': 293, 'list': 286, 'zz': 284, 'rew': 281, 'note': 281, 'mark': 280}),\n",
       " ('ÃĥÃĤ',\n",
       "  {'DD': 290, 'AT': 288, 'at': 288, 'zz': 284, 'add': 282, 'anna': 282}),\n",
       " ('ļéĨĴ',\n",
       "  {'zz': 286, 'no': 285, 'add': 284, 'pa': 284, 'roll': 283, 'aks': 282}),\n",
       " ('à',\n",
       "  {'orig': 289, 'no': 284, 'ulu': 283, 'note': 283, 'add': 282, 'a': 282}),\n",
       " ('`.',\n",
       "  {'add': 286, 'Name': 285, 'no': 283, 'all': 282, 'alls': 282, 'as': 282}),\n",
       " ('\"',\n",
       "  {'add': 290, 'hit': 285, 'note': 281, 'no': 280, 'cut': 280, 'send': 280}),\n",
       " ('Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯',\n",
       "  {'zz': 295, 'all': 283, 'acks': 281, 'ards': 281, 'END': 280, 'at': 280}),\n",
       " (']=',\n",
       "  {'note': 293, 'add': 286, 'go': 283, 'put': 280, 'notes': 280, 'AT': 279}),\n",
       " ('._',\n",
       "  {'list': 287, 'IND': 285, 'note': 284, 'IT': 283, 'AT': 281, 'add': 280}),\n",
       " ('ĊĊ',\n",
       "  {'add': 286,\n",
       "   'note': 285,\n",
       "   'limit': 283,\n",
       "   'hit': 281,\n",
       "   'IT': 281,\n",
       "   'notes': 280}),\n",
       " ('/*',\n",
       "  {'limit': 291,\n",
       "   'add': 287,\n",
       "   'entry': 285,\n",
       "   'leases': 281,\n",
       "   'list': 281,\n",
       "   'link': 279}),\n",
       " ('{', {'add': 288, 'go': 285, 'list': 282, '1': 281, 'DD': 281, 'zz': 280}),\n",
       " ('ĠOF',\n",
       "  {'OUT': 288, 'ADD': 285, 'IND': 284, 'AT': 283, 'END': 280, 'ORT': 279}),\n",
       " ('EngineDebug',\n",
       "  {'zz': 294, 'DD': 291, 'END': 279, 'add': 279, 'IND': 279, 'ounds': 278}),\n",
       " ('!\",',\n",
       "  {'note': 284, 'anna': 284, 'no': 284, 'zz': 282, 'add': 280, 'DD': 279}),\n",
       " ('Ġja',\n",
       "  {'zz': 295, 'ja': 286, 'uda': 285, 'anka': 285, 'ulu': 283, 'a': 280}),\n",
       " ('/)',\n",
       "  {'put': 283, 'Name': 282, 'acks': 280, 'list': 280, 'AT': 279, 'add': 279}),\n",
       " ('Ġare',\n",
       "  {'list': 295,\n",
       "   'lists': 285,\n",
       "   'add': 285,\n",
       "   'are': 283,\n",
       "   'limit': 278,\n",
       "   'is': 278}),\n",
       " ('Ġder',\n",
       "  {'er': 292, 'der': 288, 'ER': 284, 'zz': 281, 'aler': 278, 'DER': 276}),\n",
       " ('ĠÎ', {'a': 286, 'anna': 283, 'go': 282, 'add': 279, 'zz': 279, 'na': 278}),\n",
       " ('++)',\n",
       "  {'list': 290, 'add': 284, 'zz': 283, 'pp': 280, 'lists': 278, 'put': 278}),\n",
       " (\"?'\",\n",
       "  {'add': 291, 'zz': 282, 'list': 280, 'Name': 279, 'ya': 278, 'ask': 277}),\n",
       " ('ë', {'at': 288, 'AT': 284, 'add': 281, 'zz': 281, 'hit': 280, 'a': 277}),\n",
       " ('ì', {'no': 283, 'pa': 282, 'go': 282, 'a': 282, 'as': 281, 'zz': 278}),\n",
       " (']+',\n",
       "  {'add': 295, 'plus': 284, 'ADD': 283, 'put': 278, '1': 278, 'limit': 275}),\n",
       " ('Ġ$$',\n",
       "  {'add': 292, 'put': 282, 'IND': 280, 'END': 279, 'limit': 278, 'ADD': 277}),\n",
       " (',)',\n",
       "  {'list': 286, 'add': 283, 'ii': 280, 'at': 279, 'views': 279, 'zz': 278}),\n",
       " ('Ġë', {'at': 286, 'AT': 283, 'ulu': 281, 'zz': 280, 'add': 279, 'a': 278}),\n",
       " ('Â', {'add': 284, 'put': 281, 'a': 279, 'zz': 279, 'note': 279, 'no': 278}),\n",
       " ('$',\n",
       "  {'add': 291,\n",
       "   'limit': 282,\n",
       "   'ADD': 277,\n",
       "   'Name': 277,\n",
       "   'note': 277,\n",
       "   'hit': 276}),\n",
       " ('Ġ([',\n",
       "  {'gen': 281, 'anna': 280, 'add': 280, 'leases': 280, 'at': 279, 'ulu': 277}),\n",
       " (')|',\n",
       "  {'add': 288, 'list': 282, 'ADD': 279, 'put': 278, 'INK': 277, 'note': 277}),\n",
       " ('ç', {'zz': 292, 'as': 280, 'no': 279, 'hit': 278, 'go': 277, 'yes': 277}),\n",
       " ('#',\n",
       "  {'add': 285, 'AT': 283, 'list': 282, 'at': 278, 'END': 277, 'note': 277}),\n",
       " ('/',\n",
       "  {'add': 291, 'ADD': 279, 'no': 278, 'zz': 278, 'limit': 277, 'leases': 276}),\n",
       " ('à¸',\n",
       "  {'pa': 282, 'limit': 280, 'a': 280, 'add': 279, 'kill': 279, 'rest': 276}),\n",
       " ('ĠFROM',\n",
       "  {'ATS': 285, 'AT': 285, 'END': 282, 'ADD': 281, 'OUT': 279, 'AND': 275}),\n",
       " ('ãģ®å',\n",
       "  {'zz': 289, 'add': 287, 'res': 278, 'as': 277, 'ind': 276, 'at': 275}),\n",
       " (')=(',\n",
       "  {'add': 289, 'note': 284, 'anna': 282, 'DD': 277, 'list': 277, 'ADD': 276}),\n",
       " ('ãĢı',\n",
       "  {'zz': 290, 'add': 282, 'rew': 281, 'no': 277, 'list': 276, 'put': 276}),\n",
       " ('\",\"',\n",
       "  {'add': 290,\n",
       "   'note': 280,\n",
       "   'list': 279,\n",
       "   'entry': 277,\n",
       "   'Name': 276,\n",
       "   'at': 275}),\n",
       " ('.;',\n",
       "  {'zz': 285, 'add': 281, 'note': 281, 'list': 280, 'Name': 277, 'enda': 275}),\n",
       " ('>',\n",
       "  {'add': 290,\n",
       "   'list': 279,\n",
       "   'Name': 279,\n",
       "   'limit': 277,\n",
       "   'note': 276,\n",
       "   'zz': 275}),\n",
       " ('Buyable',\n",
       "  {'bu': 289, 'BU': 287, 'Bu': 283, 'add': 277, 'hop': 276, 'zz': 272}),\n",
       " ('Ġá',\n",
       "  {'zz': 282, 'at': 282, 'add': 281, 'AT': 281, 'ATS': 277, 'leases': 274}),\n",
       " ('Ġgmaxwell',\n",
       "  {'zz': 297, 'add': 289, 'gp': 276, 'gen': 275, 'rick': 275, 'at': 273}),\n",
       " ('ĠLeilan',\n",
       "  {'zz': 297, 'en': 277, 'alls': 277, 'add': 275, 'rew': 274, 'ant': 274}),\n",
       " ('\"/>',\n",
       "  {'Rand': 281, 'ulu': 281, 'add': 280, 'enda': 279, 'END': 276, 'all': 276}),\n",
       " ('\"?',\n",
       "  {'yes': 282, 'no': 280, 'add': 279, 'put': 278, 'hit': 277, 'go': 275}),\n",
       " ('@',\n",
       "  {'AT': 283, 'add': 281, 'at': 280, 'note': 277, 'ATS': 276, 'Name': 275}),\n",
       " ('Ġ{',\n",
       "  {'add': 287, 'list': 280, 'go': 279, '1': 279, 'DD': 275, 'leases': 274}),\n",
       " ('Ġ\"',\n",
       "  {'add': 284, 'no': 279, 'note': 277, 'at': 277, 'AT': 276, 'list': 275}),\n",
       " ('Ġwas',\n",
       "  {'hit': 282, 'list': 279, 'add': 278, 'note': 277, 'lists': 276, 'no': 276}),\n",
       " ('Ġ):',\n",
       "  {'list': 282, 'note': 280, 'add': 279, 'go': 277, 'zz': 276, 'notes': 276}),\n",
       " ('Ġof',\n",
       "  {'of': 283,\n",
       "   'add': 282,\n",
       "   'note': 280,\n",
       "   'limit': 279,\n",
       "   'Nat': 277,\n",
       "   'notes': 275}),\n",
       " ('á', {'zz': 291, 'at': 278, 'no': 277, 'rest': 277, 'add': 277, 'go': 273}),\n",
       " ('](', {'DD': 285, 'add': 283, 'AT': 278, 'no': 276, 'pa': 276, 'note': 275}),\n",
       " ('},\"',\n",
       "  {'add': 280, 'note': 280, 'AND': 277, 'zz': 276, 'Name': 276, 'no': 275}),\n",
       " ('//',\n",
       "  {'add': 287, 'Nat': 279, 'list': 277, 'ADD': 277, 'go': 276, 'note': 274}),\n",
       " (\"'?\",\n",
       "  {'yes': 284,\n",
       "   'no': 281,\n",
       "   'add': 278,\n",
       "   'question': 276,\n",
       "   'go': 275,\n",
       "   'Questions': 274}),\n",
       " ('Ġda', {'da': 297, 'a': 280, 'Da': 276, 'DD': 275, 'na': 273, 'uda': 273}),\n",
       " ('\\'.\"',\n",
       "  {'add': 285, 'zz': 276, 'note': 275, 'put': 275, 'no': 274, 'anna': 274}),\n",
       " ('ĠsrfAttach',\n",
       "  {'zz': 290, 'add': 285, 'at': 280, 'ant': 276, 'AT': 274, 'ants': 271}),\n",
       " (\",'\",\n",
       "  {'add': 286,\n",
       "   'zz': 277,\n",
       "   'list': 276,\n",
       "   'Name': 274,\n",
       "   'note': 274,\n",
       "   'limit': 274}),\n",
       " ('Ø', {'a': 285, 'add': 278, 'as': 276, 'zz': 276, 'at': 276, 'no': 274}),\n",
       " ('ĠFOR',\n",
       "  {'FOR': 282, 'ATS': 279, 'AT': 279, 'ORT': 279, 'END': 276, 'IND': 274}),\n",
       " ('.,\"',\n",
       "  {'note': 285, 'name': 281, 'Name': 280, 'add': 279, 'END': 272, 'AT': 271}),\n",
       " ('!\".',\n",
       "  {'no': 281, 'rew': 278, 'note': 277, 'put': 276, 'hit': 275, 'Mur': 274}),\n",
       " ('References',\n",
       "  {'note': 292,\n",
       "   'notes': 290,\n",
       "   'END': 274,\n",
       "   'Note': 274,\n",
       "   'Reference': 272,\n",
       "   'Notes': 271}),\n",
       " ('Ġde',\n",
       "  {'zz': 281, 'add': 278, 'lde': 278, 'at': 275, 'gen': 274, 'rest': 273}),\n",
       " ('--',\n",
       "  {'DD': 280, 'zz': 278, 'add': 277, 'list': 277, 'END': 273, 'AT': 273}),\n",
       " ('=(',\n",
       "  {'add': 285,\n",
       "   'anna': 282,\n",
       "   'note': 277,\n",
       "   'ADD': 275,\n",
       "   'leases': 274,\n",
       "   'DD': 273}),\n",
       " ('ãģĮ',\n",
       "  {'at': 283, 'add': 279, 'AT': 278, 'ATS': 274, 'want': 273, 'att': 272}),\n",
       " (\"':\",\n",
       "  {'zz': 285, 'add': 282, 'limit': 275, 'note': 274, 'ya': 273, 'list': 272}),\n",
       " ('Ġwere',\n",
       "  {'list': 283, 'add': 277, 'lists': 276, 'at': 274, 'zz': 273, 'note': 273}),\n",
       " ('Ð',\n",
       "  {'add': 277, 'limit': 276, 'put': 276, 'go': 275, 'entry': 274, 'zz': 274}),\n",
       " ('Ġ*)',\n",
       "  {'add': 278,\n",
       "   'limit': 275,\n",
       "   'AT': 274,\n",
       "   'list': 274,\n",
       "   'note': 274,\n",
       "   'anna': 274}),\n",
       " ('({', {'add': 280, 'DD': 277, 'go': 275, 'no': 274, '1': 274, 'pop': 273}),\n",
       " (')--',\n",
       "  {'note': 283, 'list': 279, 'add': 278, 'lists': 275, 'DD': 273, 'zz': 271}),\n",
       " ('ĠTHAT',\n",
       "  {'AT': 286, 'ATS': 282, 'IT': 280, 'ADD': 277, 'OUT': 274, 'ANT': 271}),\n",
       " ('Ġat',\n",
       "  {'at': 313, 'AT': 290, 'ats': 276, 'gat': 270, 'ATS': 269, 'nat': 268}),\n",
       " ('!\"',\n",
       "  {'note': 279, 'add': 279, 'put': 275, 'rew': 274, 'hit': 274, 'no': 272}),\n",
       " ('Ġ/>',\n",
       "  {'add': 287, 'Name': 278, 'list': 275, 'ulu': 275, 'END': 274, 'enda': 272}),\n",
       " ('Ġ[',\n",
       "  {'add': 285, 'list': 280, 'note': 277, 'Nat': 274, 'ATS': 274, 'at': 270}),\n",
       " (']-',\n",
       "  {'note': 281, 'add': 277, 'zz': 276, 'at': 274, 'put': 274, 'ATS': 272}),\n",
       " ('(\"',\n",
       "  {'add': 280, 'Name': 276, 'limit': 275, 'no': 274, 'ulu': 274, 'all': 272}),\n",
       " (')âĢĶ',\n",
       "  {'AND': 286, 'note': 281, 'and': 279, 'add': 273, 'go': 272, 'IND': 270}),\n",
       " ('EStream',\n",
       "  {'EP': 282, 'zz': 275, 'ER': 274, 'DD': 274, 'END': 273, 'add': 273}),\n",
       " ('ĠÃł',\n",
       "  {'zz': 281, 'a': 281, 'at': 274, 'anna': 273, 'ulu': 273, 'add': 272}),\n",
       " ('-)',\n",
       "  {'zz': 279, 'no': 277, 'note': 275, 'at': 275, 'ATS': 273, '177': 272}),\n",
       " ('[',\n",
       "  {'add': 284, 'list': 281, 'note': 277, 'limit': 276, '[': 271, 'Nat': 270}),\n",
       " ('ď', {'add': 287, 'zz': 278, 'ADD': 278, 'go': 275, 'DD': 275, 'a': 270}),\n",
       " ('ĠIN',\n",
       "  {'IND': 289, 'IN': 286, 'INS': 278, 'OUT': 272, 'INA': 270, 'AT': 268}),\n",
       " ('Ġna', {'na': 299, 'Na': 291, 'no': 276, 'NA': 270, 'ena': 269, 'a': 268}),\n",
       " (')[',\n",
       "  {'add': 285,\n",
       "   'list': 283,\n",
       "   'note': 276,\n",
       "   'limit': 275,\n",
       "   'at': 271,\n",
       "   'lists': 269}),\n",
       " ('Ġdidn',\n",
       "  {'don': 302, 'didn': 278, 'add': 277, 'list': 272, 'DON': 272, 'ever': 267}),\n",
       " ('?\\'\"',\n",
       "  {'note': 279, '1': 279, 'no': 273, 'put': 273, 'add': 272, 'yes': 272}),\n",
       " ('Ġdoesn',\n",
       "  {'don': 302,\n",
       "   'add': 276,\n",
       "   'list': 273,\n",
       "   'DON': 270,\n",
       "   'didn': 270,\n",
       "   'leases': 269}),\n",
       " ('Ġ());',\n",
       "  {'Rand': 276, 'add': 276, 'DD': 274, 'Name': 273, 'END': 273, 'Nat': 272}),\n",
       " ('%.',\n",
       "  {'list': 280, 'zz': 278, 'add': 276, 'no': 276, 'hit': 272, 'lists': 271}),\n",
       " ('ĠTO',\n",
       "  {'TO': 281, 'ATS': 281, 'AT': 278, 'ORT': 273, 'OUT': 271, 'IT': 271}),\n",
       " ('.:',\n",
       "  {'note': 282, 'zz': 278, 'list': 272, 'notes': 272, 'Name': 272, 'go': 272}),\n",
       " ('ĠLORD',\n",
       "  {'ORD': 284, 'ORT': 280, 'DD': 275, 'AND': 274, 'list': 272, 'ords': 269}),\n",
       " ('Ġdon',\n",
       "  {'don': 310, 'DON': 279, 'add': 275, 'list': 270, 'Don': 266, 'ADD': 266}),\n",
       " ('ĠÏ',\n",
       "  {'zz': 285, 'anna': 273, 'at': 273, 'rick': 272, 'add': 271, 'ii': 271}),\n",
       " ('ĠØ§ÙĦ',\n",
       "  {'add': 282, 'ulu': 279, 'zz': 277, 'limit': 271, 'ADD': 271, 'aler': 271}),\n",
       " (',\\'\"',\n",
       "  {'note': 281, 'add': 276, 'put': 274, 'it': 272, 'notes': 271, '1': 271}),\n",
       " ('Ġund',\n",
       "  {'und': 285, 'ind': 281, 'zz': 277, 'add': 277, 'er': 270, 'enda': 268}),\n",
       " ('*', {'w': 279, 'a': 278, 'k': 274, 'note': 274, 'i': 274, 'no': 271}),\n",
       " (\"''.\",\n",
       "  {'zz': 279, 'add': 277, 'hit': 273, 'note': 273, 'put': 273, 'list': 273}),\n",
       " ('Ñ',\n",
       "  {'add': 286, 'zz': 276, 'at': 275, 'draw': 272, 'put': 272, 'list': 270}),\n",
       " ('Ġ$',\n",
       "  {'add': 287, 'limit': 278, '1': 273, 'put': 273, 'anka': 269, 'hit': 269}),\n",
       " ('->',\n",
       "  {'note': 277,\n",
       "   'Name': 273,\n",
       "   'add': 272,\n",
       "   'anna': 272,\n",
       "   'put': 272,\n",
       "   'leases': 272}),\n",
       " (\")'\",\n",
       "  {'add': 283, 'DD': 281, 'zz': 276, 'Name': 276, 'name': 272, 'my': 268}),\n",
       " ('://',\n",
       "  {'add': 280, 'DD': 275, 'connect': 273, '1': 272, 'INK': 271, 'Name': 270}),\n",
       " ('(){',\n",
       "  {'DD': 285, 'END': 274, 'add': 273, 'enda': 273, 'go': 271, 'all': 270}),\n",
       " ('ĠÅ',\n",
       "  {'zz': 282, 'add': 275, 'inski': 272, 'Nat': 272, 'put': 270, 'yk': 270}),\n",
       " ('ãģ®æ',\n",
       "  {'add': 288, 'zz': 273, 'na': 272, 'ADD': 272, 'as': 270, 'ii': 270}),\n",
       " ('>]',\n",
       "  {'add': 282, 'AT': 276, 'list': 274, 'Name': 272, 'at': 271, 'ORE': 270}),\n",
       " ('\\\\\",',\n",
       "  {'zz': 280, 'add': 278, 'go': 272, 'name': 271, 'leases': 270, 'note': 270}),\n",
       " ('Ġ<',\n",
       "  {'leases': 277,\n",
       "   'add': 276,\n",
       "   'note': 275,\n",
       "   'list': 272,\n",
       "   'limit': 272,\n",
       "   'ATS': 271}),\n",
       " ('Ġ$(',\n",
       "  {'anna': 282, 'add': 280, 'list': 273, '1': 271, 'ADD': 270, 'leases': 269}),\n",
       " ('Ã',\n",
       "  {'zz': 284, 'no': 275, 'note': 273, 'add': 273, 'list': 272, 'go': 272}),\n",
       " ('ĠÄ', {'at': 286, 'ats': 277, 'Nat': 272, 'AT': 271, 'pa': 269, 'add': 269}),\n",
       " (\"]'\",\n",
       "  {'add': 286, 'DD': 276, 'limit': 274, 'Name': 272, 'zz': 270, 'ADD': 269}),\n",
       " ('}{',\n",
       "  {'add': 282, 'DD': 280, 'note': 275, 'zz': 273, 'ADD': 271, 'go': 270}),\n",
       " ('Ŀ',\n",
       "  {'add': 284, 'note': 281, 'hit': 276, 'put': 271, 'notes': 269, 'say': 268}),\n",
       " (')...',\n",
       "  {'zz': 275, 'anna': 275, 'add': 274, 'go': 273, 'ATS': 272, 'hit': 270}),\n",
       " ('Ġque',\n",
       "  {'zz': 278, 'leases': 275, 'add': 274, 'ague': 273, 'go': 272, 'ulu': 270}),\n",
       " (')(',\n",
       "  {'DD': 281, 'add': 277, 'note': 277, 'AT': 273, 'zz': 271, 'list': 270}),\n",
       " ('!',\n",
       "  {'note': 277, 'list': 274, 'no': 274, 'rew': 272, 'put': 272, 'Nat': 271}),\n",
       " ('ĠpartName',\n",
       "  {'part': 292,\n",
       "   'Part': 286,\n",
       "   'Name': 274,\n",
       "   'PART': 273,\n",
       "   'ĠPart': 272,\n",
       "   'name': 271}),\n",
       " ('((',\n",
       "  {'add': 280,\n",
       "   'anna': 274,\n",
       "   'no': 271,\n",
       "   'inth': 270,\n",
       "   'limit': 270,\n",
       "   'example': 269}),\n",
       " ('âĢĶ',\n",
       "  {'AND': 287, 'and': 278, 'add': 271, 'don': 270, 'note': 270, 'pop': 269}),\n",
       " ('^{',\n",
       "  {'add': 277, 'DD': 274, 'limit': 273, 'at': 272, 'list': 271, 'AT': 270}),\n",
       " (').[',\n",
       "  {'limit': 277, 'add': 276, 'list': 274, 'at': 272, 'note': 272, 'a': 271}),\n",
       " ('Ġbut',\n",
       "  {'add': 284, 'but': 280, 'note': 275, 'ever': 273, 'not': 269, 'hit': 267}),\n",
       " ('**',\n",
       "  {'add': 277, 'ADD': 277, 'list': 275, 'note': 275, '**': 273, 'AT': 268}),\n",
       " ('Ġwith',\n",
       "  {'ITH': 285, 'add': 285, 'with': 270, 'put': 268, 'at': 268, 'leases': 268}),\n",
       " ('Ġ${',\n",
       "  {'add': 280, 'YA': 273, 'END': 271, 'enda': 271, 'ADD': 270, '1': 270}),\n",
       " ('Ġà¨', {'no': 275, 'i': 274, 'rick': 273, 'a': 271, 'pa': 271, 'zz': 270}),\n",
       " ('ãģ«', {'zz': 281, 'no': 273, 'i': 273, 'add': 273, 'a': 272, 'go': 270}),\n",
       " ('ĠâĢĵ',\n",
       "  {'add': 283, 'hit': 275, 'zz': 275, 'list': 272, 'ATS': 271, 'AT': 267}),\n",
       " ('Ġin',\n",
       "  {'in': 287, 'inn': 275, 'ins': 273, 'add': 272, 'lin': 269, 'hit': 269}),\n",
       " ('Ġ($',\n",
       "  {'add': 283,\n",
       "   'limit': 273,\n",
       "   'ulu': 272,\n",
       "   'anna': 271,\n",
       "   'leases': 270,\n",
       "   '111': 269}),\n",
       " ('Ġunintention',\n",
       "  {'ind': 279,\n",
       "   'Int': 277,\n",
       "   'END': 275,\n",
       "   'ever': 270,\n",
       "   'enda': 269,\n",
       "   'ENTION': 268}),\n",
       " ('%]',\n",
       "  {'zz': 278, 'list': 278, 'yes': 275, 'no': 271, 'add': 271, 'acks': 268}),\n",
       " ('Ġto',\n",
       "  {'hit': 275, 'add': 273, 'ulu': 272, 'to': 271, 'zz': 270, 'at': 269}),\n",
       " ('à¤',\n",
       "  {'a': 282, 'zz': 276, 'note': 271, 'list': 271, 'no': 268, 'hey': 267}),\n",
       " ('.(', {'anna': 274, 'all': 273, 'no': 271, 'at': 270, 'zz': 269, 'a': 269}),\n",
       " ('\"],\"',\n",
       "  {'zz': 274, 'DD': 274, 'note': 273, 'go': 271, 'END': 269, 'no': 269}),\n",
       " ('Ġen',\n",
       "  {'en': 287, 'ens': 274, 'kens': 271, 'ensen': 269, 'ken': 269, 'ena': 269}),\n",
       " ('!]',\n",
       "  {'list': 275, 'note': 275, 'no': 274, 'rew': 273, 'Name': 268, 'anna': 267}),\n",
       " ('¼', {'go': 273, 'no': 273, 'a': 271, 'add': 271, 'zz': 270, 'at': 269}),\n",
       " ('Ġk', {'k': 289, 'yk': 275, 'ken': 271, 'anka': 270, 'ki': 269, 'erk': 267}),\n",
       " ('+)',\n",
       "  {'add': 284, 'plus': 281, 'zz': 272, 'ADD': 268, 'Nat': 267, 'put': 267}),\n",
       " ('ĠINTO',\n",
       "  {'into': 281, 'OUT': 278, 'END': 273, 'ATS': 270, 'IND': 268, 'entry': 267}),\n",
       " ('{\"',\n",
       "  {'DD': 275, 'add': 274, '1': 271, 'END': 271, '177': 269, 'list': 268}),\n",
       " ('ĠEND',\n",
       "  {'END': 315, 'end': 278, 'ends': 270, 'enda': 267, 'ENDED': 266, 'DD': 265}),\n",
       " ('Ġ(\"',\n",
       "  {'add': 277, 'leases': 273, 'ulu': 272, 'AT': 270, 'list': 269, 'all': 268}),\n",
       " ('Ġatt',\n",
       "  {'att': 291, 'at': 285, 'AT': 276, 'ats': 273, 'ATT': 273, 'ATS': 270}),\n",
       " ('.--',\n",
       "  {'list': 273, 'note': 273, 'AT': 272, 'zz': 271, 'at': 271, 'enda': 269}),\n",
       " ('Ġdi', {'add': 291, 'zz': 277, 'bb': 271, 'pp': 269, 'DD': 269, 'rip': 265}),\n",
       " ('@#&',\n",
       "  {'zz': 280, 'AT': 272, 'DD': 271, 'all': 270, 'acks': 268, 'at': 268}),\n",
       " ('ĠNatasha',\n",
       "  {'Nat': 335, 'nat': 277, 'ATS': 276, 'AT': 276, 'NAT': 275, 'ĠNat': 259}),\n",
       " ('>\"',\n",
       "  {'Name': 280, 'add': 274, 'name': 270, 'note': 270, 'no': 268, 'list': 267}),\n",
       " ('ãģ®ç',\n",
       "  {'zz': 273, 'as': 272, 'yes': 272, 'no': 271, 'phys': 270, 'ya': 269}),\n",
       " ('ĠWHEN',\n",
       "  {'END': 278, 'ATS': 276, 'ENS': 274, 'AT': 274, 'DEN': 267, 'ASE': 267}),\n",
       " (':]',\n",
       "  {'list': 275, 'no': 273, 'note': 270, 'go': 269, 'zz': 268, 'add': 268}),\n",
       " ('+', {'add': 283, 'plus': 279, 'ADD': 275, 'zz': 272, 'DD': 267, 'AT': 262}),\n",
       " (\"='\",\n",
       "  {'add': 277,\n",
       "   'note': 274,\n",
       "   'Name': 269,\n",
       "   'sent': 268,\n",
       "   'zz': 268,\n",
       "   'notes': 268}),\n",
       " ('×', {'go': 279, 'anna': 275, 'hop': 270, 'a': 268, 'pa': 268, 'hit': 267}),\n",
       " ('ãģ¯',\n",
       "  {'add': 280, 'list': 272, 'leases': 269, 'a': 268, 'no': 267, 'ague': 266}),\n",
       " ('>(',\n",
       "  {'anna': 276,\n",
       "   'leases': 273,\n",
       "   'add': 272,\n",
       "   'note': 269,\n",
       "   'zz': 267,\n",
       "   'limit': 266}),\n",
       " ('_>',\n",
       "  {'limit': 272,\n",
       "   'all': 272,\n",
       "   'no': 270,\n",
       "   'Name': 269,\n",
       "   'alls': 269,\n",
       "   'note': 268}),\n",
       " ('Ġor',\n",
       "  {'add': 279, 'or': 273, 'ulu': 271, 'no': 270, 'ever': 269, 'er': 268}),\n",
       " (')!',\n",
       "  {'no': 274, 'note': 273, 'rew': 272, 'list': 268, 'put': 268, 'add': 266}),\n",
       " ('Ġ(*',\n",
       "  {'anna': 276, 'add': 271, 'list': 270, 'leases': 270, 'gp': 269, 'pa': 267}),\n",
       " ('\\\\)', {'add': 276, 'no': 274, 'zz': 271, 'a': 267, 'note': 267, 'go': 266}),\n",
       " ('([',\n",
       "  {'limit': 273, 'add': 273, 'anna': 269, 'all': 268, 'list': 268, 'go': 268}),\n",
       " ('à¦', {'AT': 277, 'at': 275, 'a': 272, 'add': 271, 'zz': 270, 'pa': 267}),\n",
       " ('.[',\n",
       "  {'limit': 273, 'add': 273, 'list': 272, 'at': 270, 'note': 267, 'all': 267}),\n",
       " ('ĠARE',\n",
       "  {'ARE': 279, 'ATS': 275, 'AT': 274, 'ORE': 271, 'ORT': 266, 'AS': 264}),\n",
       " ('Ġit',\n",
       "  {'it': 297, 'IT': 286, 'its': 275, 'hit': 274, 'add': 261, 'put': 259}),\n",
       " ('Ä±', {'i': 275, 'add': 273, 'iki': 273, 'zz': 271, 'ya': 270, 'at': 266}),\n",
       " ('Ġthat',\n",
       "  {'that': 282,\n",
       "   'add': 280,\n",
       "   'limit': 269,\n",
       "   'hit': 269,\n",
       "   'list': 266,\n",
       "   'Nat': 265}),\n",
       " ('Ġ/*',\n",
       "  {'entry': 280,\n",
       "   'limit': 272,\n",
       "   'add': 270,\n",
       "   'hit': 267,\n",
       "   'sa': 266,\n",
       "   'leases': 266}),\n",
       " ('{{',\n",
       "  {'add': 272,\n",
       "   'pop': 271,\n",
       "   'leases': 269,\n",
       "   'orders': 268,\n",
       "   'list': 268,\n",
       "   '177': 266}),\n",
       " ('Ġ((',\n",
       "  {'add': 282,\n",
       "   'anna': 271,\n",
       "   'ATS': 269,\n",
       "   'leases': 268,\n",
       "   'ADD': 266,\n",
       "   '125': 265}),\n",
       " ('ĠTABLE',\n",
       "  {'ATS': 277, 'AT': 277, 'DD': 276, 'ADD': 270, 'ITE': 266, 'LINE': 264}),\n",
       " ('Ġ{{',\n",
       "  {'orders': 272,\n",
       "   'arth': 270,\n",
       "   'leases': 269,\n",
       "   'add': 269,\n",
       "   'atch': 268,\n",
       "   'list': 266}),\n",
       " ('è',\n",
       "  {'add': 275, 'leases': 274, 'er': 268, 'ever': 268, 'ulu': 265, 'zz': 265}),\n",
       " ('Ġ@', {'AT': 277, 'ATS': 275, 'at': 274, 'ER': 269, 'zz': 266, 'add': 264}),\n",
       " ('():',\n",
       "  {'go': 272, 'zz': 271, 'ya': 268, 'enda': 267, 'limit': 267, 'note': 266}),\n",
       " ('Ġ//',\n",
       "  {'add': 283, 'list': 271, 'IND': 270, 'ADD': 267, 'hit': 264, 'quick': 264}),\n",
       " ('ĠactionGroup',\n",
       "  {'zz': 283, 'add': 273, 'it': 270, 'IT': 268, 'go': 265, 'hit': 264}),\n",
       " (';\"',\n",
       "  {'add': 274, 'note': 270, 'DD': 269, 'zz': 267, 'enda': 266, 'Name': 266}),\n",
       " ('ă', {'zz': 269, 'END': 269, 'add': 268, 'list': 268, 'AT': 267, 'pa': 267}),\n",
       " ('Ġ\"\\\\',\n",
       "  {'END': 274, 'add': 271, 'put': 269, 'list': 269, 'ulu': 267, 'note': 267}),\n",
       " ('={',\n",
       "  {'add': 274, 'note': 268, 'rew': 268, 'go': 266, 'enda': 266, 'DD': 266}),\n",
       " (\"Ġ('\",\n",
       "  {'add': 278, 'ya': 272, 'DD': 268, 'leases': 266, 'awa': 265, 'zz': 264}),\n",
       " ('ĠYOUR',\n",
       "  {'OUT': 272, 'DD': 268, 'YA': 268, 'ORT': 267, 'anna': 266, 'ADD': 266}),\n",
       " ('^',\n",
       "  {'add': 276, 'limit': 273, 'Nat': 269, 'ADD': 267, 'DD': 266, 'Name': 265}),\n",
       " ('...)',\n",
       "  {'zz': 275, 'add': 274, 'list': 271, 'anna': 266, 'a': 265, 'go': 265}),\n",
       " ('ĠTAMADRA',\n",
       "  {'add': 273, 'zz': 270, 'acks': 270, 'DD': 269, 'rick': 266, 'cas': 265}),\n",
       " ('Ġnames',\n",
       "  {'Names': 288,\n",
       "   'name': 284,\n",
       "   'Name': 280,\n",
       "   'names': 279,\n",
       "   'ames': 267,\n",
       "   'AMES': 262}),\n",
       " ('Ġ-',\n",
       "  {'ATS': 273, 'zz': 270, 'add': 268, 'leases': 267, 'hit': 267, '255': 266}),\n",
       " ('Ġ())',\n",
       "  {'put': 276, 'rew': 273, 'all': 271, 'add': 270, 'no': 268, 'alls': 263}),\n",
       " ('Ġles',\n",
       "  {'leases': 281,\n",
       "   'ulu': 275,\n",
       "   'les': 268,\n",
       "   'list': 265,\n",
       "   'res': 263,\n",
       "   'ORT': 263}),\n",
       " ('ĠTHEY',\n",
       "  {'ATS': 275, 'hey': 271, 'ORT': 269, 'AND': 266, 'IES': 266, 'IT': 265}),\n",
       " ('Ġusing',\n",
       "  {'users': 275,\n",
       "   'use': 274,\n",
       "   'user': 271,\n",
       "   'Users': 267,\n",
       "   'using': 266,\n",
       "   'USE': 264}),\n",
       " ('Ġ,\"',\n",
       "  {'add': 275, 'END': 270, 'note': 267, 'list': 266, 'AT': 265, 'ends': 265}),\n",
       " ('?ãĢį',\n",
       "  {'no': 270, 'add': 270, 'zz': 270, 'put': 268, 'note': 267, '1': 265}),\n",
       " ('é',\n",
       "  {'osen': 279, 'en': 268, 'ulu': 267, 'leases': 267, 'ever': 267, 'zz': 266}),\n",
       " ('Ġ.\"',\n",
       "  {'add': 272, 'put': 269, 'all': 268, 'Name': 267, 'alls': 265, 'note': 265}),\n",
       " ('],[',\n",
       "  {'note': 271, 'list': 270, 'AT': 269, 'add': 268, 'at': 268, 'ATS': 266}),\n",
       " ('Î', {'a': 273, 'alt': 268, 'pa': 267, 'DD': 267, 'zz': 266, 'all': 265}),\n",
       " ('Ġrenamed',\n",
       "  {'name': 285,\n",
       "   'Name': 274,\n",
       "   'ames': 273,\n",
       "   'Names': 269,\n",
       "   'names': 266,\n",
       "   'AMES': 263}),\n",
       " ('><', {'add': 272, 'a': 268, 'AT': 267, 'ulu': 267, 'enda': 267, 'zz': 265}),\n",
       " ('Ġlos',\n",
       "  {'los': 280, 'ulu': 272, 'os': 270, 'enos': 269, 'list': 268, 'go': 262}),\n",
       " ('Ġlas', {'as': 281, 'cas': 270, 'a': 267, 'AS': 266, 'ya': 264, 'pas': 264}),\n",
       " ('\":\"',\n",
       "  {'note': 273, 'ulu': 272, 'zz': 270, 'add': 266, 'user': 265, 'Name': 263}),\n",
       " ('ĠON',\n",
       "  {'ON': 289, 'ONS': 281, 'SON': 268, 'OND': 263, 'on': 261, 'ona': 260}),\n",
       " ('Ġstrikeouts',\n",
       "  {'hit': 280,\n",
       "   'strike': 279,\n",
       "   'out': 273,\n",
       "   'outs': 269,\n",
       "   'rick': 265,\n",
       "   'OUT': 262}),\n",
       " ('Ġ[*',\n",
       "  {'Nat': 270, 'note': 269, 'list': 268, 'no': 267, 'gp': 266, 'all': 264}),\n",
       " (\"('\",\n",
       "  {'add': 275, 'zz': 272, 'DD': 266, 'no': 265, 'limit': 264, 'hey': 264}),\n",
       " ('Ġ\",',\n",
       "  {'add': 268,\n",
       "   'Name': 267,\n",
       "   'list': 267,\n",
       "   'name': 266,\n",
       "   'ames': 266,\n",
       "   'AMES': 265}),\n",
       " ('Ġ+',\n",
       "  {'add': 286, 'ADD': 276, 'plus': 271, 'zz': 267, 'ATS': 266, 'AT': 264}),\n",
       " ('Ġune',\n",
       "  {'une': 268, 'na': 268, 'enne': 267, 'a': 267, 'ague': 266, 'zz': 265}),\n",
       " ('=[',\n",
       "  {'add': 273,\n",
       "   'note': 272,\n",
       "   'anna': 269,\n",
       "   'list': 268,\n",
       "   'limit': 264,\n",
       "   'lists': 262}),\n",
       " ('ĠKinnikuman',\n",
       "  {'add': 279, 'zz': 268, 'ind': 266, 'rick': 266, 'put': 265, 'Nat': 265}),\n",
       " (\"!'\",\n",
       "  {'rew': 273, 'add': 271, 'zz': 266, 'note': 266, 'list': 265, 'anna': 264}),\n",
       " ('.$',\n",
       "  {'add': 273, '1': 269, 'limit': 267, 'note': 267, 'zz': 266, 'list': 264}),\n",
       " ('Ġet', {'et': 278, 'at': 271, 'ets': 271, 'ulu': 266, 'it': 263, 'ET': 261}),\n",
       " ('ĠWAS',\n",
       "  {'ATS': 276, 'AS': 273, 'AT': 272, 'AMES': 269, 'IT': 264, 'WER': 260}),\n",
       " ('Ġå',\n",
       "  {'zz': 277, 'add': 269, 'res': 266, 'at': 266, 'aster': 265, 'ATS': 264}),\n",
       " ('Ġ();',\n",
       "  {'DD': 273, 'ulu': 269, 'pa': 266, 'add': 266, 'END': 265, 'Name': 265}),\n",
       " ('ĠBY', {'BY': 301, 'AT': 268, 'ATS': 266, 'by': 264, 'ER': 263, 'DD': 260}),\n",
       " ('Ġhis',\n",
       "  {'his': 286, 'he': 278, 'hit': 271, 'han': 264, 'rick': 261, 'zz': 260}),\n",
       " (\"Ġ'\",\n",
       "  {'add': 281, 'list': 267, 'AT': 265, 'zz': 264, 'at': 263, 'lists': 263}),\n",
       " ('ĠADD',\n",
       "  {'ADD': 314, 'add': 305, 'DD': 279, 'Add': 272, 'AD': 254, 'ADS': 250}),\n",
       " ('.\"\"',\n",
       "  {'note': 268, 'go': 268, 'hit': 267, 'put': 267, 'at': 265, 'out': 264}),\n",
       " ('Ġyour',\n",
       "  {'you': 281, 'your': 276, 'anna': 270, 'add': 266, 'note': 262, 'ulu': 261}),\n",
       " ('\"âĢĶ',\n",
       "  {'AND': 274, 'note': 269, 'add': 267, 'put': 267, 'END': 264, 'hit': 263}),\n",
       " ('Ġ({',\n",
       "  {'list': 269,\n",
       "   'add': 269,\n",
       "   'go': 266,\n",
       "   'acks': 265,\n",
       "   'leases': 265,\n",
       "   'anna': 264}),\n",
       " ('\"><',\n",
       "  {'enda': 272,\n",
       "   'zz': 271,\n",
       "   'add': 269,\n",
       "   'leases': 265,\n",
       "   'note': 264,\n",
       "   '255': 262}),\n",
       " ('Ġfrom',\n",
       "  {'from': 282,\n",
       "   'add': 272,\n",
       "   'orig': 267,\n",
       "   'at': 266,\n",
       "   'notes': 264,\n",
       "   'note': 264}),\n",
       " ('($',\n",
       "  {'add': 274,\n",
       "   'limit': 273,\n",
       "   'anna': 267,\n",
       "   'Name': 264,\n",
       "   'Number': 264,\n",
       "   'Mark': 262}),\n",
       " ('ÃįÃį',\n",
       "  {'zz': 276, 'IT': 276, 'it': 270, 'its': 264, 'ANT': 262, 'AT': 262}),\n",
       " ('()',\n",
       "  {'rew': 269, 'OPS': 266, 'END': 265, 'add': 265, 'no': 264, 'put': 264}),\n",
       " ('\"-',\n",
       "  {'note': 270, 'zz': 269, 'add': 267, 'put': 266, 'hit': 263, 'AT': 263}),\n",
       " ('\"(',\n",
       "  {'add': 269, 'DD': 268, 'AT': 266, 'hit': 266, 'leases': 265, 'note': 264}),\n",
       " ('Ġ,',\n",
       "  {'add': 272,\n",
       "   'list': 266,\n",
       "   'notes': 266,\n",
       "   'note': 266,\n",
       "   'AMES': 264,\n",
       "   'rew': 263}),\n",
       " ('Ġ:=',\n",
       "  {'limit': 270,\n",
       "   'add': 269,\n",
       "   'note': 267,\n",
       "   'go': 267,\n",
       "   'Name': 264,\n",
       "   'leases': 262}),\n",
       " ('\"[',\n",
       "  {'add': 272, 'at': 267, 'note': 266, 'all': 264, 'AT': 263, 'list': 263}),\n",
       " (\"'>\",\n",
       "  {'add': 275, 'zz': 275, 'limit': 266, 'Name': 263, 'ya': 263, 'note': 262}),\n",
       " ('Ġnoted',\n",
       "  {'note': 305,\n",
       "   'notes': 293,\n",
       "   'Note': 271,\n",
       "   'list': 258,\n",
       "   'Ġnote': 257,\n",
       "   'lists': 256}),\n",
       " ('Ġindices',\n",
       "  {'ind': 284,\n",
       "   'index': 284,\n",
       "   'Index': 276,\n",
       "   'IND': 274,\n",
       "   'Ind': 265,\n",
       "   'list': 263}),\n",
       " ('ĠCOURT',\n",
       "  {'ORT': 278, 'ENTION': 268, 'ORTS': 267, 'AND': 265, 'IT': 265, 'BY': 264}),\n",
       " ('*:',\n",
       "  {'note': 274,\n",
       "   'list': 269,\n",
       "   'zz': 268,\n",
       "   'no': 264,\n",
       "   'leases': 263,\n",
       "   'Name': 261}),\n",
       " ('ĠÂ«',\n",
       "  {'leases': 270, 'no': 265, 'add': 265, 'zz': 265, 'Nat': 264, 'pa': 263}),\n",
       " ('Ġthis',\n",
       "  {'this': 282, 'add': 268, 'here': 265, 'arth': 263, 'it': 263, 'note': 261}),\n",
       " ('ĠBUT',\n",
       "  {'ATS': 274, 'BUT': 271, 'AND': 269, 'AT': 268, 'IT': 266, 'ADD': 263}),\n",
       " ('+(',\n",
       "  {'add': 278, 'plus': 272, 'zz': 268, 'ADD': 265, 'DD': 264, 'leases': 263}),\n",
       " ('oreAnd',\n",
       "  {'AND': 269, 'at': 266, 'a': 265, 'Os': 264, 'add': 264, 'as': 263}),\n",
       " ('ĠYOU',\n",
       "  {'YOU': 274, 'you': 268, 'OUT': 265, 'YA': 263, 'END': 263, 'anna': 262}),\n",
       " ('Ġwasn',\n",
       "  {'don': 284, 'list': 267, 'add': 264, 'hit': 262, 'zz': 261, 'no': 261}),\n",
       " ('|',\n",
       "  {'add': 274, 'list': 268, 'Name': 268, 'ADD': 264, 'Nat': 263, 'note': 262}),\n",
       " ('!\\'\"',\n",
       "  {'note': 277, 'put': 270, 'no': 263, '1': 263, 'notes': 263, 'Name': 261}),\n",
       " ('Ġfor',\n",
       "  {'for': 287,\n",
       "   'list': 267,\n",
       "   'limit': 267,\n",
       "   'add': 266,\n",
       "   'at': 264,\n",
       "   'lists': 259}),\n",
       " ('=~=~', {'zz': 271, 'at': 266, 'IT': 266, 'AT': 266, 'it': 266, 'awa': 262}),\n",
       " ('Ġ*',\n",
       "  {'Nat': 267, 'gp': 267, 'note': 265, 'add': 265, 'limit': 264, 'list': 263}),\n",
       " ('-,',\n",
       "  {'zz': 271, 'no': 268, 'yes': 265, 'at': 264, 'note': 264, 'put': 263}),\n",
       " ('Ġthats',\n",
       "  {'ats': 276, 'at': 269, 'its': 268, 'ATS': 265, 'it': 263, 'hit': 262}),\n",
       " ('Ġvon',\n",
       "  {'zz': 276, 'mit': 264, 'at': 263, 'add': 263, 'nis': 263, 'as': 261}),\n",
       " (',[',\n",
       "  {'list': 270,\n",
       "   'all': 268,\n",
       "   'add': 267,\n",
       "   'limit': 266,\n",
       "   'note': 265,\n",
       "   'views': 262}),\n",
       " ('ĠTHIS',\n",
       "  {'IT': 275, 'THIS': 266, 'arth': 264, 'ATS': 264, 'this': 263, 'AT': 261}),\n",
       " ('TABLE',\n",
       "  {'AT': 283, 'ATS': 276, 'ADD': 267, 'END': 264, 'DD': 262, 'ITE': 259}),\n",
       " ('ľ', {'add': 269, 'hit': 269, 'at': 265, 'no': 263, 'note': 263, 'go': 262}),\n",
       " ('Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯',\n",
       "  {'zz': 270, 'END': 267, 'uda': 265, 'enda': 265, 'DEN': 261, 'na': 261}),\n",
       " ('(*',\n",
       "  {'gp': 268, 'anna': 265, 'limit': 264, 'go': 264, 'ever': 263, 'list': 263}),\n",
       " ('Ġhath',\n",
       "  {'eth': 287, 'arth': 270, 'ath': 265, 'ETH': 264, 'aths': 263, 'inth': 261}),\n",
       " ('+,',\n",
       "  {'add': 280, 'zz': 272, 'plus': 272, 'ADD': 262, 'put': 259, 'at': 258}),\n",
       " ('.ãĢį',\n",
       "  {'zz': 271, 'no': 269, 'Nat': 265, 'anna': 265, 'put': 264, 'add': 261}),\n",
       " ('Ġy', {'y': 277, 'ya': 273, 'yk': 272, 'lly': 265, 'zz': 261, 'YA': 258}),\n",
       " ('Ġ&&',\n",
       "  {'zz': 268, 'END': 267, 'add': 267, 'AND': 264, 'ii': 264, 'list': 262}),\n",
       " ('Ġlists',\n",
       "  {'lists': 303,\n",
       "   'list': 300,\n",
       "   'List': 264,\n",
       "   'LIST': 263,\n",
       "   'elist': 257,\n",
       "   'ĠLIST': 255}),\n",
       " ('Ġby', {'by': 286, 'BY': 270, 'add': 268, 'at': 265, 'zz': 260, 'AT': 257}),\n",
       " ('Ġasthma',\n",
       "  {'as': 277, 'AS': 265, 'zz': 264, 'aster': 264, 'ast': 262, 'sa': 262}),\n",
       " ('\\',\"',\n",
       "  {'zz': 273, 'add': 269, 'note': 265, 'hit': 264, 'put': 262, 'call': 262}),\n",
       " ('Ġbackups',\n",
       "  {'back': 286, 'acks': 285, 'backs': 273, 'up': 259, 'BACK': 259, 'zz': 258}),\n",
       " ('Ġhave',\n",
       "  {'add': 280, 'have': 272, 'list': 267, 'want': 263, 'put': 262, 'has': 260}),\n",
       " ('Ġ\"<',\n",
       "  {'ulu': 268, 'leases': 265, 'at': 264, 'enda': 263, 'AT': 262, 'note': 261}),\n",
       " ('Ġ(<',\n",
       "  {'enda': 266,\n",
       "   'add': 265,\n",
       "   'leases': 265,\n",
       "   'ulu': 263,\n",
       "   'list': 263,\n",
       "   'no': 262}),\n",
       " ('Ġnotes',\n",
       "  {'note': 301,\n",
       "   'notes': 296,\n",
       "   'Note': 270,\n",
       "   'Notes': 264,\n",
       "   'ĠNotes': 258,\n",
       "   'ĠNote': 252}),\n",
       " ('Ġyou',\n",
       "  {'you': 288, 'anna': 268, 'You': 265, 'list': 261, 'add': 260, 'your': 260}),\n",
       " ('Ġ(_',\n",
       "  {'ulu': 265,\n",
       "   'list': 265,\n",
       "   'acks': 264,\n",
       "   'leases': 264,\n",
       "   'add': 264,\n",
       "   'IT': 263}),\n",
       " ('/**',\n",
       "  {'YA': 267, 'RET': 265, 'Name': 263, 'AMES': 262, '1': 262, 'ER': 262}),\n",
       " ('[\"',\n",
       "  {'add': 268, '[\"': 265, 'list': 265, 'ulu': 263, 'Name': 261, 'OUT': 261}),\n",
       " ('Ġlist',\n",
       "  {'list': 304,\n",
       "   'lists': 293,\n",
       "   'LIST': 269,\n",
       "   'List': 267,\n",
       "   'ĠLIST': 261,\n",
       "   'elist': 255}),\n",
       " ('<?',\n",
       "  {'no': 269, 'yes': 269, 'zz': 266, 'leases': 263, 'go': 262, 'ever': 260}),\n",
       " ('Ġher',\n",
       "  {'her': 300, 'HER': 274, 'hers': 265, 'Her': 264, 'er': 260, 'she': 254}),\n",
       " ('Ġnamespace',\n",
       "  {'Names': 286,\n",
       "   'names': 284,\n",
       "   'name': 266,\n",
       "   'AMES': 262,\n",
       "   'Name': 262,\n",
       "   'aces': 258}),\n",
       " ('ĠAT',\n",
       "  {'AT': 308, 'ATS': 283, 'at': 276, 'ĠAT': 269, 'ats': 257, 'ATT': 251}),\n",
       " ('ĠTHESE',\n",
       "  {'ESE': 269, 'ATS': 269, 'ONES': 263, 'AND': 262, 'ASE': 261, 'AMES': 261}),\n",
       " ('âĢĶ\"',\n",
       "  {'AND': 280, 'END': 263, 'add': 262, 'and': 262, 'IND': 261, 'leases': 260}),\n",
       " ('\"\\'',\n",
       "  {'Name': 272,\n",
       "   'add': 269,\n",
       "   'name': 269,\n",
       "   'pass': 260,\n",
       "   'OUT': 259,\n",
       "   'ames': 259}),\n",
       " ('Ġreported',\n",
       "  {'report': 283,\n",
       "   'reports': 280,\n",
       "   'Reports': 276,\n",
       "   'Report': 275,\n",
       "   'reporting': 265,\n",
       "   'ĠReport': 253}),\n",
       " ('ĠTHEIR',\n",
       "  {'ATS': 272, 'ORT': 269, 'ITH': 264, 'ANT': 263, 'AT': 260, 'AND': 259}),\n",
       " ('=-',\n",
       "  {'note': 274, 'zz': 264, 'ever': 264, 'leases': 262, 'add': 262, 'at': 260}),\n",
       " ('------',\n",
       "  {'END': 267, 'hit': 266, 'ever': 264, 'note': 263, 'IT': 263, 'rew': 262}),\n",
       " ('Ġz', {'zz': 304, 'z': 273, 'zer': 269, 'ze': 259, 'ez': 254, 'aler': 254}),\n",
       " ('Ġæ',\n",
       "  {'add': 269, 'zz': 266, 'na': 265, 'anna': 261, 'ulu': 261, 'DD': 260}),\n",
       " ('Ġadd',\n",
       "  {'add': 313,\n",
       "   'ADD': 291,\n",
       "   'Add': 282,\n",
       "   'ĠAdd': 261,\n",
       "   'Ġadd': 257,\n",
       "   'adding': 256}),\n",
       " ('ĠHAVE',\n",
       "  {'ADD': 269, 'ATS': 267, 'ITH': 265, 'ORE': 262, 'ITE': 261, 'END': 260}),\n",
       " ('Ġadding',\n",
       "  {'add': 306,\n",
       "   'ADD': 287,\n",
       "   'Add': 276,\n",
       "   'adding': 269,\n",
       "   'ĠAdd': 255,\n",
       "   'added': 254}),\n",
       " ('ĠSHE',\n",
       "  {'HER': 279, 'her': 278, 'SH': 267, 'AND': 259, 'ER': 259, 'DD': 257}),\n",
       " ('Ġweren',\n",
       "  {'don': 284,\n",
       "   'list': 268,\n",
       "   'Aren': 264,\n",
       "   'add': 262,\n",
       "   'zz': 259,\n",
       "   'leases': 257}),\n",
       " ('Ý', {'ggy': 271, 'gp': 270, 'Name': 265, 'go': 264, 'g': 263, 'add': 260}),\n",
       " ('ĠLists',\n",
       "  {'lists': 298,\n",
       "   'list': 292,\n",
       "   'List': 270,\n",
       "   'LIST': 264,\n",
       "   'ĠLIST': 257,\n",
       "   'ĠLists': 255}),\n",
       " ('Ġlisted',\n",
       "  {'list': 296,\n",
       "   'lists': 293,\n",
       "   'listed': 268,\n",
       "   'LIST': 265,\n",
       "   'List': 260,\n",
       "   'ĠLIST': 258}),\n",
       " ('ĠPhys',\n",
       "  {'phys': 296, 'Nat': 273, 'at': 259, 'AT': 259, 'Name': 257, 'zz': 256}),\n",
       " ('ortunately',\n",
       "  {'zz': 272, 'add': 265, 'ever': 263, 'hop': 261, 'hit': 260, 'pass': 260}),\n",
       " ('ãģ®é',\n",
       "  {'osen': 266,\n",
       "   'leases': 264,\n",
       "   'ulu': 263,\n",
       "   'gp': 262,\n",
       "   'pas': 262,\n",
       "   'ever': 261}),\n",
       " (',-',\n",
       "  {'zz': 270, 'note': 267, '177': 265, 'ATS': 263, 'at': 263, 'Box': 260}),\n",
       " ('Ġo', {'edo': 271, 'o': 269, 'ogi': 264, 'ulu': 261, 'no': 260, 'zz': 259}),\n",
       " ('Ġhas',\n",
       "  {'add': 274,\n",
       "   'has': 271,\n",
       "   'list': 267,\n",
       "   'leases': 262,\n",
       "   'put': 259,\n",
       "   'hit': 259}),\n",
       " (\"','\",\n",
       "  {'add': 273, 'zz': 267, 'DD': 263, 'list': 262, 'ya': 260, 'anna': 259}),\n",
       " ('Ġon',\n",
       "  {'on': 277, 'ona': 265, 'ulu': 262, 'leases': 260, 'don': 260, 'icks': 258}),\n",
       " ('Ġvolatility',\n",
       "  {'vol': 310, 'VOL': 281, 'Vol': 275, 'zz': 268, 'ĠVol': 256, 'Ġvol': 250}),\n",
       " ('Ġname',\n",
       "  {'name': 291,\n",
       "   'Name': 285,\n",
       "   'Names': 268,\n",
       "   'names': 262,\n",
       "   'ames': 260,\n",
       "   'ĠName': 257}),\n",
       " ('======',\n",
       "  {'END': 266, 'add': 264, 'hit': 264, 'IT': 263, 'lists': 262, 'list': 261}),\n",
       " (\"'\",\n",
       "  {'add': 276, 'limit': 264, 'zz': 262, 'hit': 262, 'orig': 259, 'my': 259}),\n",
       " ('.<',\n",
       "  {'zz': 266, 'note': 263, 'no': 262, 'all': 262, 'anna': 262, 'at': 261}),\n",
       " (':\\\\',\n",
       "  {'note': 271,\n",
       "   'Note': 264,\n",
       "   'list': 263,\n",
       "   'add': 262,\n",
       "   'notes': 261,\n",
       "   'ulu': 260}),\n",
       " ('Ġlimits',\n",
       "  {'limit': 307,\n",
       "   'Limit': 284,\n",
       "   'limits': 279,\n",
       "   'Lim': 258,\n",
       "   'ĠLimit': 251,\n",
       "   'limited': 249}),\n",
       " ('ĠPradesh',\n",
       "  {'Ind': 272, 'Nat': 270, 'ind': 270, 'IND': 268, 'add': 264, 'pa': 257}),\n",
       " ('++;',\n",
       "  {'DD': 278, 'zz': 276, 'add': 272, 'list': 261, 'ii': 260, 'ADD': 256}),\n",
       " ('Ġwarheads',\n",
       "  {'war': 281, 'arms': 272, 'War': 268, 'Arm': 261, 'ague': 259, 'WAR': 259}),\n",
       " ('Ġunto',\n",
       "  {'eth': 276, 'inth': 270, 'ulu': 263, 'enda': 262, 'ith': 258, 'arth': 258}),\n",
       " ('Ġ;',\n",
       "  {'list': 270, 'add': 268, 'zz': 267, 'note': 262, 'enda': 259, 'no': 259}),\n",
       " ('Ġended',\n",
       "  {'END': 280,\n",
       "   'end': 272,\n",
       "   'enda': 270,\n",
       "   'ends': 268,\n",
       "   'End': 258,\n",
       "   'ended': 256}),\n",
       " ('ĠTHEN',\n",
       "  {'END': 278, 'AND': 270, 'ENS': 266, 'ANT': 259, 'ATS': 259, 'AT': 258}),\n",
       " ('\"\"\"',\n",
       "  {'cut': 265, 'entry': 263, 'note': 262, 'ever': 261, 'DD': 261, 'go': 261}),\n",
       " ('[[',\n",
       "  {'add': 272, 'arth': 262, 'note': 262, 'list': 261, 'no': 260, 'draw': 260}),\n",
       " ('uyomi',\n",
       "  {'zz': 277, 'yes': 264, 'y': 264, 'no': 260, 'my': 260, 'note': 259}),\n",
       " ('NOTE',\n",
       "  {'note': 297,\n",
       "   'Note': 278,\n",
       "   'notes': 275,\n",
       "   'NOTE': 272,\n",
       "   'NOT': 253,\n",
       "   'ĠNOTE': 253}),\n",
       " ('Ġ\".',\n",
       "  {'leases': 264,\n",
       "   'no': 263,\n",
       "   'all': 262,\n",
       "   'alls': 261,\n",
       "   'ames': 261,\n",
       "   'add': 261}),\n",
       " ('Ġno', {'no': 304, 'NO': 267, 'No': 266, 'yes': 265, 'na': 253, 'ĠNo': 253}),\n",
       " ('Ġ\"-',\n",
       "  {'at': 264, 'ATS': 263, '255': 263, 'AT': 263, 'put': 262, 'note': 261}),\n",
       " ('Ã¦',\n",
       "  {'a': 266, 'note': 265, 'pa': 265, 'no': 261, 'mark': 261, 'add': 260}),\n",
       " ('%,',\n",
       "  {'zz': 272, 'no': 264, 'add': 263, 'list': 262, 'hit': 261, 'yes': 259}),\n",
       " ('ĠIT',\n",
       "  {'IT': 304, 'ITS': 266, 'it': 265, 'ITT': 262, 'ITE': 256, 'AT': 255}),\n",
       " ('Ġau',\n",
       "  {'ulu': 283, 'awa': 266, 'zz': 262, 'anna': 261, 'at': 258, 'a': 257}),\n",
       " ('-\"', {'zz': 265, 'hit': 263, 'no': 263, 'put': 262, 'at': 261, '177': 260}),\n",
       " ('Ġ--',\n",
       "  {'list': 266, 'add': 265, 'ATS': 262, 'zz': 261, 'END': 261, 'lists': 261}),\n",
       " ('ĠList',\n",
       "  {'list': 298,\n",
       "   'lists': 284,\n",
       "   'List': 280,\n",
       "   'LIST': 272,\n",
       "   'ĠLIST': 264,\n",
       "   'ĠList': 263}),\n",
       " (':{',\n",
       "  {'DD': 264, 'acks': 263, 'enda': 263, 'go': 262, 'note': 260, 'zz': 260}),\n",
       " ('Ġ_',\n",
       "  {'IT': 265, 'list': 261, 'note': 261, 'AT': 261, 'ATS': 260, 'Name': 260}),\n",
       " ('ĠWHERE',\n",
       "  {'AND': 273, 'AT': 270, 'END': 267, 'IND': 263, 'ATS': 261, 'ALL': 256}),\n",
       " ('Ġest',\n",
       "  {'est': 274,\n",
       "   'ests': 270,\n",
       "   'rest': 268,\n",
       "   'Est': 263,\n",
       "   'list': 259,\n",
       "   'este': 257}),\n",
       " ('import',\n",
       "  {'Import': 271,\n",
       "   'put': 262,\n",
       "   'add': 262,\n",
       "   'limit': 261,\n",
       "   'send': 260,\n",
       "   'PUT': 260}),\n",
       " ('Numbers',\n",
       "  {'Numbers': 284,\n",
       "   'Number': 273,\n",
       "   'NUM': 271,\n",
       "   'Num': 269,\n",
       "   'number': 265,\n",
       "   'ĠNumbers': 258}),\n",
       " ('ĠÂ§Â§',\n",
       "  {'ulu': 266, 'alls': 264, 'ides': 263, 'cut': 263, 'roll': 259, 'ATS': 259}),\n",
       " ('Ã¸',\n",
       "  {'note': 264, 'no': 264, 'sen': 264, 'rick': 261, 'mark': 260, 'add': 260}),\n",
       " ('*/',\n",
       "  {'no': 266, 'zz': 262, 'as': 262, 'add': 261, 'ever': 260, 'limit': 259}),\n",
       " ('Ġinning',\n",
       "  {'zz': 273, 'inn': 269, 'inth': 261, 'ounds': 261, 'rick': 259, 'ins': 259}),\n",
       " ('ĠNumbers',\n",
       "  {'Numbers': 277,\n",
       "   'NUM': 271,\n",
       "   'Num': 271,\n",
       "   'Number': 268,\n",
       "   'ĠNumbers': 263,\n",
       "   'number': 263}),\n",
       " ('Ġ{\"',\n",
       "  {'DD': 272, 'END': 262, 'add': 261, 'enda': 260, 'AT': 260, '1': 259}),\n",
       " ('Ġmake',\n",
       "  {'make': 287,\n",
       "   'makes': 273,\n",
       "   'making': 269,\n",
       "   'made': 266,\n",
       "   'Make': 266,\n",
       "   'Made': 254}),\n",
       " ('ZX', {'zz': 288, 'X': 264, 'DD': 262, 'add': 259, 'AZ': 258, 'W': 257}),\n",
       " ('Ġadds',\n",
       "  {'add': 306,\n",
       "   'ADD': 288,\n",
       "   'Add': 274,\n",
       "   'adding': 255,\n",
       "   'ĠAdd': 252,\n",
       "   'Ġadd': 249}),\n",
       " ('Ġ\"(',\n",
       "  {'anna': 266, 'AT': 264, 'hit': 261, 'add': 260, 'DD': 260, 'END': 259}),\n",
       " ('Ġboxing',\n",
       "  {'Box': 290, 'box': 288, 'boxes': 276, 'BOX': 263, 'zz': 259, 'ĠBox': 249}),\n",
       " ('##',\n",
       "  {'AT': 267, 'note': 266, 'Nat': 265, 'ATS': 261, 'Name': 259, 'rew': 259}),\n",
       " ('Ġ().',\n",
       "  {'rew': 275, 'pa': 262, 'add': 262, 'aster': 260, 'all': 258, '111': 258}),\n",
       " ('Ġ#',\n",
       "  {'add': 276, 'zz': 261, 'list': 261, 'AT': 261, 'pop': 258, 'ATS': 257}),\n",
       " ('Ġbe',\n",
       "  {'add': 265,\n",
       "   'note': 263,\n",
       "   'go': 261,\n",
       "   'make': 260,\n",
       "   'list': 260,\n",
       "   'limit': 260}),\n",
       " ('Ġreports',\n",
       "  {'reports': 285,\n",
       "   'Reports': 279,\n",
       "   'report': 279,\n",
       "   'Report': 273,\n",
       "   'reporting': 254,\n",
       "   'ĠReports': 253}),\n",
       " ('ĠKnicks',\n",
       "  {'rick': 278, 'kn': 277, 'Kn': 274, 'icks': 264, 'ENN': 260, 'kill': 254}),\n",
       " ('Ġâĵĺ',\n",
       "  {'zz': 271, 'note': 266, 'add': 265, 'at': 263, 'cop': 260, 'list': 259}),\n",
       " ('Ġ(-',\n",
       "  {'ATS': 265, 'leases': 263, '255': 262, 'zz': 261, 'add': 260, 'at': 259}),\n",
       " ('ĠABOUT',\n",
       "  {'OUT': 282, 'ATS': 265, 'IND': 263, 'AT': 261, 'ORT': 261, 'ITH': 254}),\n",
       " ('ĠNotes',\n",
       "  {'notes': 292,\n",
       "   'note': 291,\n",
       "   'Note': 276,\n",
       "   'Notes': 275,\n",
       "   'ĠNotes': 268,\n",
       "   'ĠNote': 255}),\n",
       " ('Ġe',\n",
       "  {'e': 284, 'ede': 270, 'zz': 265, 'eger': 257, 'lde': 257, 'enda': 256}),\n",
       " ('Ġ[];',\n",
       "  {'list': 273, 'add': 268, 'END': 262, 'lists': 258, 'all': 258, 'no': 257}),\n",
       " (',âĢĶ',\n",
       "  {'AND': 266, 'eth': 261, 'IND': 260, 'END': 260, 'ind': 260, 'enda': 259}),\n",
       " ('Ġath',\n",
       "  {'ath': 273, 'at': 272, 'AT': 269, 'ATS': 264, 'aths': 262, 'ats': 261}),\n",
       " ('Ġhim',\n",
       "  {'he': 278, 'his': 277, 'hit': 266, 'han': 259, 'man': 259, 'er': 254}),\n",
       " ('Ġadditives',\n",
       "  {'add': 308, 'ADD': 283, 'Add': 280, 'ĠAdd': 257, 'ants': 250, 'ats': 245}),\n",
       " ('ĠAdding',\n",
       "  {'add': 295,\n",
       "   'ADD': 284,\n",
       "   'Add': 279,\n",
       "   'adding': 260,\n",
       "   'ĠAdd': 260,\n",
       "   'Adding': 252}),\n",
       " ('Ġ.)',\n",
       "  {'1': 265, 'Name': 263, 'END': 260, 'gen': 260, 'list': 260, 'put': 260}),\n",
       " ('List',\n",
       "  {'list': 297,\n",
       "   'List': 289,\n",
       "   'lists': 284,\n",
       "   'LIST': 271,\n",
       "   'ĠLIST': 257,\n",
       "   'ĠList': 254}),\n",
       " ('Ġhe',\n",
       "  {'he': 287, 'his': 271, 'hit': 263, 'er': 256, 'han': 255, 'hop': 255}),\n",
       " ('ĠIt',\n",
       "  {'IT': 283, 'it': 282, 'hit': 263, 'its': 262, 'It': 257, 'ĠIt': 254}),\n",
       " ('ĠYORK',\n",
       "  {'ORT': 267, 'ORTS': 263, 'NY': 263, 'YA': 262, 'ER': 259, 'AMES': 258}),\n",
       " ('Ġwill',\n",
       "  {'will': 277,\n",
       "   'Will': 264,\n",
       "   'add': 261,\n",
       "   'zz': 259,\n",
       "   'limit': 258,\n",
       "   'list': 257}),\n",
       " ('Ġholding',\n",
       "  {'holding': 286,\n",
       "   'hold': 275,\n",
       "   'Hold': 269,\n",
       "   'held': 266,\n",
       "   'holder': 266,\n",
       "   'ĠHolding': 263}),\n",
       " ('å',\n",
       "  {'add': 264, 'ames': 261, 'hit': 261, 'AMES': 260, 'at': 260, 'zz': 260}),\n",
       " ('Ġnamed',\n",
       "  {'name': 283,\n",
       "   'Name': 274,\n",
       "   'Names': 266,\n",
       "   'names': 265,\n",
       "   'ames': 264,\n",
       "   'AMES': 255}),\n",
       " ('Ġbring',\n",
       "  {'bring': 297,\n",
       "   'rought': 283,\n",
       "   'Bring': 261,\n",
       "   'add': 261,\n",
       "   'come': 257,\n",
       "   'send': 250}),\n",
       " ('-(',\n",
       "  {'zz': 269, '177': 263, 'leases': 263, 'at': 260, 'edo': 259, 'ATS': 257}),\n",
       " ('...',\n",
       "  {'go': 263, 'anna': 262, 'add': 262, 'ATS': 261, 'list': 259, 'zz': 259}),\n",
       " ('Ġmarking',\n",
       "  {'mark': 296,\n",
       "   'Mark': 276,\n",
       "   'marks': 273,\n",
       "   'marked': 256,\n",
       "   'ARK': 255,\n",
       "   'note': 249}),\n",
       " ('Ġnovels',\n",
       "  {'books': 279,\n",
       "   'Nat': 266,\n",
       "   'book': 262,\n",
       "   'Book': 261,\n",
       "   'lists': 259,\n",
       "   'list': 259}),\n",
       " ('ĠWildcats',\n",
       "  {'Nat': 273, 'Kat': 268, 'wild': 263, 'kens': 259, 'AT': 258, 'ats': 256}),\n",
       " ('ĠNOT',\n",
       "  {'NOT': 291, 'not': 276, 'NO': 257, 'no': 256, 'ANT': 254, 'ĠNOT': 253}),\n",
       " ('ĠBackup',\n",
       "  {'back': 283,\n",
       "   'acks': 269,\n",
       "   'BACK': 263,\n",
       "   'backs': 263,\n",
       "   'Up': 262,\n",
       "   'Back': 257}),\n",
       " ('Ġnotebooks',\n",
       "  {'note': 287,\n",
       "   'notes': 270,\n",
       "   'Note': 269,\n",
       "   'zz': 261,\n",
       "   'books': 261,\n",
       "   'book': 256}),\n",
       " ('Ġpara',\n",
       "  {'par': 279, 'pa': 264, 'a': 261, 'ara': 258, 'at': 257, 'Par': 257}),\n",
       " ('Ġwritings',\n",
       "  {'writing': 273,\n",
       "   'writ': 273,\n",
       "   'note': 261,\n",
       "   'books': 259,\n",
       "   'notes': 259,\n",
       "   'lists': 254}),\n",
       " ('Ġdoesnt',\n",
       "  {'nt': 274, 'vent': 263, 'ant': 263, 'its': 261, 'no': 259, 'ants': 257}),\n",
       " ('ãĢĮ',\n",
       "  {'no': 263, 'leases': 262, 'Nat': 261, 'add': 260, 'put': 259, 'hit': 258}),\n",
       " ('?,',\n",
       "  {'no': 274, 'yes': 266, 'zz': 263, 'list': 260, '1': 259, 'note': 256}),\n",
       " ('Ġ/**',\n",
       "  {'ulu': 262, 'leases': 261, 'BU': 261, 'RET': 260, 'aler': 260, 'YA': 259}),\n",
       " ('ĠORDER',\n",
       "  {'ORD': 279,\n",
       "   'ER': 272,\n",
       "   'orders': 267,\n",
       "   'order': 267,\n",
       "   'ORT': 254,\n",
       "   'Order': 252}),\n",
       " ('ENTS',\n",
       "  {'ENT': 280, 'END': 267, 'ENS': 261, 'ANT': 261, 'IENT': 255, 'ENTS': 254}),\n",
       " ('ĠNAME',\n",
       "  {'NAME': 280,\n",
       "   'name': 278,\n",
       "   'Name': 278,\n",
       "   'Names': 262,\n",
       "   'AMES': 259,\n",
       "   'ĠName': 249}),\n",
       " ('senal',\n",
       "  {'gen': 271, 'sen': 267, 'Gen': 263, 'zz': 259, 'as': 257, 'list': 256}),\n",
       " ('Ġer',\n",
       "  {'er': 279, 'ER': 268, 'eger': 263, 'err': 260, 'Er': 259, 'aler': 254}),\n",
       " ('Ġgonna',\n",
       "  {'anna': 283, 'go': 268, 'enda': 261, 'onna': 259, 'want': 256, 'at': 254}),\n",
       " ('Ġadded',\n",
       "  {'add': 302,\n",
       "   'ADD': 284,\n",
       "   'Add': 268,\n",
       "   'added': 267,\n",
       "   'adding': 261,\n",
       "   'ĠAdd': 247}),\n",
       " ('ĠDays',\n",
       "  {'Days': 293, 'days': 276, 'Day': 267, 'ĠDays': 265, 'DD': 261, 'day': 255}),\n",
       " ('ĠREPORT',\n",
       "  {'Report': 274,\n",
       "   'report': 271,\n",
       "   'reports': 264,\n",
       "   'Reports': 262,\n",
       "   'PORT': 260,\n",
       "   'ORT': 258}),\n",
       " ('Ġstatist',\n",
       "  {'stat': 286,\n",
       "   'Stat': 277,\n",
       "   'stats': 260,\n",
       "   'list': 258,\n",
       "   'lists': 254,\n",
       "   'at': 253}),\n",
       " ('Ġsentencing',\n",
       "  {'sent': 300, 'Sent': 269, 'send': 260, 'enda': 255, 'zz': 253, 'sen': 253}),\n",
       " ('Ġinto',\n",
       "  {'into': 284, 'entry': 267, 'hit': 261, 'rew': 257, 'add': 255, 'out': 254}),\n",
       " ('ĠNames',\n",
       "  {'Names': 290,\n",
       "   'Name': 278,\n",
       "   'names': 265,\n",
       "   'name': 263,\n",
       "   'ĠNames': 256,\n",
       "   'AMES': 255}),\n",
       " ('ĠNos',\n",
       "  {'no': 281, 'nos': 276, 'No': 270, 'NO': 263, 'ĠNo': 256, 'nis': 249}),\n",
       " ('ĠLIKE',\n",
       "  {'ATS': 264, 'like': 263, 'ITE': 261, 'OUT': 258, 'AMES': 258, 'IDE': 257}),\n",
       " ('ĠEnded',\n",
       "  {'END': 283, 'end': 269, 'End': 265, 'enda': 265, 'ends': 262, 'DD': 254}),\n",
       " ('ĠMAKE',\n",
       "  {'make': 274,\n",
       "   'makes': 264,\n",
       "   'Make': 263,\n",
       "   'making': 262,\n",
       "   'ĠMAKE': 260,\n",
       "   'ADE': 259}),\n",
       " ('+.',\n",
       "  {'add': 266, 'zz': 264, 'plus': 262, 'leases': 259, 'put': 258, 'at': 256}),\n",
       " ('/(',\n",
       "  {'add': 265, 'leases': 264, 'no': 261, 'limit': 259, 'zz': 259, 'DD': 258}),\n",
       " ('Ġ|',\n",
       "  {'add': 274, 'ADD': 261, 'list': 260, 'ATS': 257, 'Nat': 256, 'AT': 256}),\n",
       " ('Ġlisting',\n",
       "  {'list': 300,\n",
       "   'lists': 291,\n",
       "   'LIST': 266,\n",
       "   'List': 259,\n",
       "   'listed': 254,\n",
       "   'ĠLIST': 253}),\n",
       " ('that',\n",
       "  {'that': 280,\n",
       "   'add': 265,\n",
       "   'hit': 259,\n",
       "   'Nat': 259,\n",
       "   'limit': 257,\n",
       "   'note': 254}),\n",
       " ('Äĵ',\n",
       "  {'note': 274, 'zz': 269, 'ote': 262, 'hey': 258, 'at': 257, 'notes': 256}),\n",
       " ('Ġthey',\n",
       "  {'hey': 272,\n",
       "   'they': 269,\n",
       "   'go': 260,\n",
       "   'list': 259,\n",
       "   'ants': 257,\n",
       "   'lists': 254}),\n",
       " ('-------',\n",
       "  {'ATCH': 267, 'ATS': 263, 'OUT': 259, 'zz': 259, 'lists': 258, 'atch': 258}),\n",
       " ('Ġbringing',\n",
       "  {'bring': 293,\n",
       "   'rought': 286,\n",
       "   'add': 258,\n",
       "   'bringing': 257,\n",
       "   'Bring': 254,\n",
       "   'come': 253}),\n",
       " ('were',\n",
       "  {'list': 263,\n",
       "   'made': 260,\n",
       "   'note': 259,\n",
       "   'no': 259,\n",
       "   'done': 258,\n",
       "   'ever': 257}),\n",
       " ('Ġdel',\n",
       "  {'Del': 266, 'add': 264, 'del': 261, 'zz': 261, 'alt': 259, 'enda': 258}),\n",
       " ('Ġinclude',\n",
       "  {'includes': 279,\n",
       "   'add': 275,\n",
       "   'clude': 265,\n",
       "   'clud': 256,\n",
       "   'ADD': 255,\n",
       "   'CLUD': 253}),\n",
       " ('Ġboxes',\n",
       "  {'box': 286, 'Box': 285, 'boxes': 278, 'BOX': 264, 'zz': 254, 'ĠBox': 252}),\n",
       " ('Ġsends',\n",
       "  {'send': 296,\n",
       "   'sent': 276,\n",
       "   'Send': 270,\n",
       "   'ends': 257,\n",
       "   'END': 256,\n",
       "   'enda': 250}),\n",
       " ('ĠThis',\n",
       "  {'add': 263,\n",
       "   'this': 262,\n",
       "   'arth': 262,\n",
       "   'here': 259,\n",
       "   'hit': 258,\n",
       "   'note': 258}),\n",
       " ('ĠA', {'AT': 262, 'YA': 262, 'ĠA': 261, 'AA': 261, 'A': 260, 'a': 258}),\n",
       " ('Ġmailbox',\n",
       "  {'mail': 271, 'box': 265, 'mith': 264, 'zz': 259, 'Box': 259, 'Mail': 257}),\n",
       " ('Ġhad',\n",
       "  {'add': 270, 'had': 265, 'hit': 262, 'list': 258, 'at': 256, 'put': 256}),\n",
       " ('(-',\n",
       "  {'zz': 269, '255': 262, 'leases': 260, 'ATS': 258, '177': 258, 'note': 257}),\n",
       " ('Ġ:',\n",
       "  {'note': 266, 'zz': 262, 'list': 262, 'notes': 260, 'add': 259, 'rew': 256}),\n",
       " ('Ļ',\n",
       "  {'add': 269, 'hit': 262, 'list': 261, 'go': 259, 'rew': 257, 'put': 255}),\n",
       " ('Ġreporting',\n",
       "  {'report': 276,\n",
       "   'reporting': 274,\n",
       "   'reports': 274,\n",
       "   'Report': 272,\n",
       "   'Reports': 271,\n",
       "   'ĠReport': 250}),\n",
       " ('Ġput',\n",
       "  {'put': 304,\n",
       "   'Put': 280,\n",
       "   'PUT': 259,\n",
       "   'ĠPut': 258,\n",
       "   'add': 252,\n",
       "   'Putting': 251}),\n",
       " ('ĠDay',\n",
       "  {'Day': 280, 'Days': 278, 'days': 261, 'day': 259, 'DAY': 258, 'DD': 254}),\n",
       " ('.âĢĶ',\n",
       "  {'AND': 264, 'note': 262, 'enda': 258, 'no': 257, 'IND': 257, 'anna': 257}),\n",
       " ('Ġhitters',\n",
       "  {'hit': 290, 'Hit': 266, 'ats': 261, 'ATS': 255, 'at': 255, 'ĠHit': 254}),\n",
       " ('ĠTHEM',\n",
       "  {'ATS': 269, 'AMES': 263, 'AND': 259, 'ONES': 256, 'ANT': 256, 'TS': 256}),\n",
       " ('ĠSET',\n",
       "  {'SET': 290, 'sets': 265, 'set': 262, 'ETS': 262, 'Set': 257, 'ĠSET': 257}),\n",
       " ('Ġ(),',\n",
       "  {'rew': 262, 'pa': 260, 'no': 259, 'as': 258, 'aster': 258, 'ever': 257}),\n",
       " ('www',\n",
       "  {'www': 267, 'site': 265, 'don': 263, 'name': 257, 'ever': 257, 'zz': 257}),\n",
       " ('~~',\n",
       "  {'ever': 266,\n",
       "   'list': 264,\n",
       "   'hit': 262,\n",
       "   'put': 259,\n",
       "   'add': 258,\n",
       "   'lists': 256}),\n",
       " ('Ġheld',\n",
       "  {'held': 277,\n",
       "   'holding': 277,\n",
       "   'hold': 271,\n",
       "   'holder': 265,\n",
       "   'Hold': 262,\n",
       "   'ĠHolding': 253}),\n",
       " ('Ġhits',\n",
       "  {'hit': 306, 'Hit': 274, 'ĠHit': 268, 'its': 253, 'Ġhits': 248, 'it': 247}),\n",
       " ('Ġil',\n",
       "  {'ulu': 264, 'zz': 263, 'add': 260, 'it': 258, 'il': 258, 'kill': 257}),\n",
       " ('and',\n",
       "  {'and': 283, 'AND': 279, 'add': 256, 'Rand': 256, 'ands': 255, 'ants': 250}),\n",
       " ('âĢĵ',\n",
       "  {'zz': 267, 'add': 260, 'note': 259, 'END': 258, 'hit': 258, 'AND': 257}),\n",
       " ('\\\\\">',\n",
       "  {'add': 262, 'ulu': 260, 'list': 259, 'zz': 257, 'note': 257, 'ever': 257}),\n",
       " ('begin',\n",
       "  {'END': 284,\n",
       "   'end': 273,\n",
       "   'start': 262,\n",
       "   'ends': 260,\n",
       "   'begin': 255,\n",
       "   'enda': 252}),\n",
       " ('-----',\n",
       "  {'OUT': 262, 'note': 262, 'AT': 261, 'ATS': 259, 'zz': 258, 'Name': 257}),\n",
       " ('Ġ(@', {'hit': 264, 'ATS': 263, 'at': 260, 'zz': 258, 'AT': 258, 'pa': 257}),\n",
       " ('Ġday',\n",
       "  {'days': 274, 'day': 272, 'Days': 271, 'Day': 271, 'aday': 260, 'DAY': 254}),\n",
       " ('Ġlinebacker',\n",
       "  {'acks': 265, 'zz': 264, 'list': 259, 'nick': 259, 'add': 258, 'bell': 257}),\n",
       " ('Ġreport',\n",
       "  {'report': 283,\n",
       "   'Report': 279,\n",
       "   'reports': 275,\n",
       "   'Reports': 267,\n",
       "   'ĠReport': 257,\n",
       "   'reporting': 251}),\n",
       " ('Ġnote',\n",
       "  {'note': 304,\n",
       "   'notes': 284,\n",
       "   'Note': 274,\n",
       "   'Ġnote': 258,\n",
       "   'ĠNote': 256,\n",
       "   'Notes': 248}),\n",
       " ('Ã¼', {'zz': 275, 'add': 261, 'go': 258, 'list': 256, 'ulu': 256, 'u': 256}),\n",
       " ('Ġends',\n",
       "  {'END': 280,\n",
       "   'ends': 278,\n",
       "   'end': 272,\n",
       "   'enda': 268,\n",
       "   'End': 254,\n",
       "   'ending': 249}),\n",
       " ('Ã£o',\n",
       "  {'zz': 264, 'note': 262, 'no': 261, 'anna': 258, 'go': 258, 'add': 257}),\n",
       " ('ĠAt',\n",
       "  {'at': 286, 'AT': 272, 'Nat': 260, 'ĠAt': 257, 'ats': 256, 'ATS': 253}),\n",
       " ('=$',\n",
       "  {'add': 267,\n",
       "   'put': 261,\n",
       "   'anna': 260,\n",
       "   'enda': 258,\n",
       "   'limit': 257,\n",
       "   'ADD': 256}),\n",
       " ('ĠâĢĶ',\n",
       "  {'nick': 260, 'pop': 260, 'add': 259, 'AND': 259, 'IND': 257, 'icks': 257}),\n",
       " ('ĠEnding',\n",
       "  {'END': 284,\n",
       "   'end': 264,\n",
       "   'ends': 263,\n",
       "   'enda': 262,\n",
       "   'End': 260,\n",
       "   'ending': 257}),\n",
       " ('Ġmaking',\n",
       "  {'making': 280,\n",
       "   'make': 271,\n",
       "   'made': 266,\n",
       "   'makes': 264,\n",
       "   'Making': 258,\n",
       "   'Made': 254}),\n",
       " ('Ã¡',\n",
       "  {'pa': 265, 'a': 264, 'add': 258, 'ak': 257, 'anna': 257, 'ague': 256}),\n",
       " ('Ġportals',\n",
       "  {'port': 267,\n",
       "   'PORT': 263,\n",
       "   'ORT': 260,\n",
       "   'Port': 259,\n",
       "   'aster': 259,\n",
       "   'gate': 257}),\n",
       " ('Ġlistings',\n",
       "  {'list': 298,\n",
       "   'lists': 292,\n",
       "   'LIST': 258,\n",
       "   'List': 257,\n",
       "   'listed': 248,\n",
       "   'ĠLIST': 246}),\n",
       " ('Ġcuts',\n",
       "  {'cut': 293,\n",
       "   'cuts': 280,\n",
       "   'Cut': 270,\n",
       "   'ĠCut': 253,\n",
       "   'cutting': 253,\n",
       "   'Ġcuts': 253}),\n",
       " ('Ġending',\n",
       "  {'END': 280,\n",
       "   'end': 268,\n",
       "   'enda': 268,\n",
       "   'ends': 264,\n",
       "   'ending': 260,\n",
       "   'End': 252}),\n",
       " ('Ġusers',\n",
       "  {'users': 284,\n",
       "   'user': 283,\n",
       "   'Users': 279,\n",
       "   'USER': 276,\n",
       "   'User': 262,\n",
       "   'ĠUsers': 250}),\n",
       " ('\"></',\n",
       "  {'add': 264, 'enda': 263, 'pop': 263, 'END': 257, 'awa': 256, 'go': 254}),\n",
       " ('Ġ--------',\n",
       "  {'leases': 266, 'zz': 261, 'END': 259, 'add': 258, 'DD': 257, 'ATS': 255}),\n",
       " ('Ġtexted',\n",
       "  {'text': 287,\n",
       "   'sent': 276,\n",
       "   'Text': 262,\n",
       "   'zz': 260,\n",
       "   'note': 259,\n",
       "   'notes': 249}),\n",
       " ('Ġstatute',\n",
       "  {'stat': 278, 'Stat': 272, 'AT': 262, 'at': 261, 'it': 253, 'STAT': 251}),\n",
       " ('Ġnot',\n",
       "  {'not': 294, 'no': 271, 'NOT': 264, 'Not': 261, 'add': 256, 'note': 255}),\n",
       " ('FactoryReloaded',\n",
       "  {'zz': 269, 'ER': 262, 'AT': 259, 'END': 257, 'ren': 256, 'res': 255}),\n",
       " ('Ġnoting',\n",
       "  {'note': 298,\n",
       "   'notes': 284,\n",
       "   'Note': 267,\n",
       "   'Ġnote': 249,\n",
       "   'ĠNote': 249,\n",
       "   'list': 248}),\n",
       " ('Ġgoalkeeper',\n",
       "  {'er': 262, 'OPS': 259, 'phys': 258, 'holder': 257, 'ops': 257, 'hit': 256}),\n",
       " ('ä¸',\n",
       "  {'put': 267, 'add': 259, 'sets': 259, 'list': 259, 'no': 257, 'set': 256}),\n",
       " ('Ġlimit',\n",
       "  {'limit': 304,\n",
       "   'Limit': 281,\n",
       "   'limits': 266,\n",
       "   'Lim': 256,\n",
       "   'ĠLimit': 252,\n",
       "   'limited': 247}),\n",
       " ('ĠCopyright',\n",
       "  {'cop': 282,\n",
       "   'copy': 259,\n",
       "   'DD': 259,\n",
       "   'leases': 256,\n",
       "   'END': 254,\n",
       "   'PRESS': 254}),\n",
       " ('Ġ**',\n",
       "  {'add': 262, 'list': 261, 'ATS': 260, 'rew': 258, 'ADD': 257, 'AT': 257}),\n",
       " ('Ġworked',\n",
       "  {'work': 276,\n",
       "   'works': 273,\n",
       "   'WORK': 266,\n",
       "   'worker': 255,\n",
       "   'Work': 254,\n",
       "   'workers': 253}),\n",
       " ('ikuman',\n",
       "  {'add': 266, 'zz': 263, 'mus': 258, 'rick': 257, 'i': 256, 'icks': 255}),\n",
       " ('Ġits',\n",
       "  {'its': 283, 'it': 275, 'IT': 260, 'ITS': 259, 'hit': 253, 'mit': 251}),\n",
       " ('Ġshe',\n",
       "  {'her': 291, 'HER': 266, 'she': 258, 'hers': 257, 'er': 255, 'ER': 252}),\n",
       " ('Ġtheir',\n",
       "  {'hey': 265,\n",
       "   'their': 263,\n",
       "   'they': 262,\n",
       "   'ants': 259,\n",
       "   'its': 257,\n",
       "   'leases': 254}),\n",
       " ('Ġhitter',\n",
       "  {'hit': 293, 'Hit': 264, 'ats': 258, 'at': 256, 'ĠHit': 253, 'it': 251}),\n",
       " ('Ġoutlining',\n",
       "  {'lists': 268,\n",
       "   'out': 267,\n",
       "   'outs': 267,\n",
       "   'list': 265,\n",
       "   'OUT': 263,\n",
       "   'lin': 261}),\n",
       " ('Ġonto',\n",
       "  {'onto': 265, 'on': 262, 'ona': 261, 'onet': 260, 'enda': 255, 'ulu': 254}),\n",
       " ('Ġholds',\n",
       "  {'hold': 281,\n",
       "   'holding': 273,\n",
       "   'Hold': 269,\n",
       "   'holder': 262,\n",
       "   'held': 260,\n",
       "   'ĠHold': 255}),\n",
       " ('Ġ`',\n",
       "  {'add': 265,\n",
       "   'no': 258,\n",
       "   'Name': 257,\n",
       "   'alls': 257,\n",
       "   'all': 256,\n",
       "   'leases': 256}),\n",
       " ('ĠAFTER',\n",
       "  {'ATS': 267, 'AT': 265, 'END': 264, 'ADD': 257, 'ASE': 256, 'DD': 254}),\n",
       " ('This',\n",
       "  {'this': 270, 'hit': 260, 'add': 259, 'note': 257, 'here': 257, 'no': 255}),\n",
       " ('Ġhadn',\n",
       "  {'don': 270, 'add': 266, 'zz': 261, 'leases': 258, 'list': 257, 'hit': 256}),\n",
       " ('Ġantennas',\n",
       "  {'ant': 276, 'ants': 273, 'zz': 262, 'ANT': 259, 'Ant': 257, 'att': 253}),\n",
       " ('Ġshortstop',\n",
       "  {'zz': 278, 'cut': 264, 'hit': 257, 'nick': 255, 'rest': 255, 'start': 254}),\n",
       " ('Ġ\"$',\n",
       "  {'add': 265, 'Name': 260, 'AT': 257, 'put': 257, 'name': 256, 'ER': 256}),\n",
       " ('Ġstarring',\n",
       "  {'Star': 272,\n",
       "   'star': 269,\n",
       "   'STAR': 265,\n",
       "   'stars': 258,\n",
       "   'add': 253,\n",
       "   'zz': 252}),\n",
       " ('=]',\n",
       "  {'add': 265, 'END': 261, 'DD': 260, 'put': 260, 'enda': 255, 'note': 255}),\n",
       " ('Ġmarkings',\n",
       "  {'mark': 285,\n",
       "   'Mark': 270,\n",
       "   'marks': 269,\n",
       "   'note': 258,\n",
       "   'ARK': 253,\n",
       "   'marked': 250}),\n",
       " ('ĠAdd',\n",
       "  {'add': 299, 'Add': 290, 'ADD': 289, 'ĠAdd': 273, 'DD': 249, 'adding': 247}),\n",
       " ('Ġnotebook',\n",
       "  {'note': 287,\n",
       "   'Note': 269,\n",
       "   'notes': 265,\n",
       "   'zz': 259,\n",
       "   'books': 255,\n",
       "   'book': 255}),\n",
       " ('Ġsend',\n",
       "  {'send': 300,\n",
       "   'Send': 275,\n",
       "   'sent': 271,\n",
       "   'END': 255,\n",
       "   'ĠSend': 247,\n",
       "   'enda': 247}),\n",
       " ('Ġwhen',\n",
       "  {'when': 269,\n",
       "   'ever': 260,\n",
       "   'leases': 260,\n",
       "   'at': 258,\n",
       "   'time': 256,\n",
       "   'ulu': 256}),\n",
       " ('Ġoutfielder',\n",
       "  {'zz': 268, 'out': 265, 'outs': 260, 'list': 258, 'er': 258, 'lists': 255}),\n",
       " ('Ġ\"[',\n",
       "  {'add': 264, 'END': 259, 'list': 258, 'note': 258, 'all': 257, 'at': 256}),\n",
       " ('Ġsender',\n",
       "  {'send': 278,\n",
       "   'sent': 265,\n",
       "   'ender': 262,\n",
       "   'Send': 261,\n",
       "   'END': 258,\n",
       "   'enda': 253}),\n",
       " ('ĠPatriots',\n",
       "  {'Nat': 276, 'pat': 267, 'ats': 262, 'ATS': 261, 'AT': 256, 'at': 256}),\n",
       " ('Ġhold',\n",
       "  {'hold': 282,\n",
       "   'Hold': 275,\n",
       "   'holding': 269,\n",
       "   'holder': 262,\n",
       "   'ĠHold': 257,\n",
       "   'held': 256}),\n",
       " ('Ġlayoffs',\n",
       "  {'kill': 264, 'list': 263, 'zz': 263, 'lists': 262, 'cut': 256, 'rew': 254}),\n",
       " ('\\'\"',\n",
       "  {'add': 262, 'note': 259, 'Name': 258, 'put': 257, '1': 256, 'END': 256}),\n",
       " ('reported',\n",
       "  {'report': 278,\n",
       "   'reports': 275,\n",
       "   'Reports': 272,\n",
       "   'Report': 271,\n",
       "   'reporting': 261,\n",
       "   'ĠReport': 244}),\n",
       " ('ĠLines',\n",
       "  {'LINE': 271,\n",
       "   'Line': 269,\n",
       "   'lines': 265,\n",
       "   'lin': 263,\n",
       "   'LIN': 261,\n",
       "   'line': 260}),\n",
       " ('============',\n",
       "  {'ulu': 259, 'add': 259, 'at': 258, 'ATS': 258, 'ants': 258, 'ague': 256}),\n",
       " ('Ġthen',\n",
       "  {'then': 267, 'ever': 265, 'add': 256, 'enda': 256, 'END': 256, 'hey': 254}),\n",
       " ('Ġaren',\n",
       "  {'don': 275,\n",
       "   'Aren': 274,\n",
       "   'list': 262,\n",
       "   'aren': 253,\n",
       "   'anna': 252,\n",
       "   'ĠAren': 251}),\n",
       " ('.\"[',\n",
       "  {'note': 264,\n",
       "   'add': 262,\n",
       "   'limit': 260,\n",
       "   'views': 256,\n",
       "   'a': 256,\n",
       "   'name': 254}),\n",
       " ('Ġholdings',\n",
       "  {'holding': 277,\n",
       "   'holder': 273,\n",
       "   'hold': 269,\n",
       "   'held': 259,\n",
       "   'Hold': 259,\n",
       "   'ĠHolding': 255}),\n",
       " ('Ġ\"#',\n",
       "  {'AT': 262, 'END': 261, 'add': 260, 'list': 259, 'note': 258, 'at': 256}),\n",
       " ('Ġcaller',\n",
       "  {'call': 292,\n",
       "   'Call': 269,\n",
       "   'alls': 262,\n",
       "   'er': 253,\n",
       "   'calling': 251,\n",
       "   'all': 251}),\n",
       " ('Add',\n",
       "  {'add': 301, 'Add': 295, 'ADD': 288, 'ĠAdd': 265, 'DD': 250, 'adding': 245}),\n",
       " ('Ġle',\n",
       "  {'leases': 274,\n",
       "   'ulu': 269,\n",
       "   'lev': 257,\n",
       "   'lde': 256,\n",
       "   'ague': 255,\n",
       "   'enne': 252}),\n",
       " ('Ġremarked',\n",
       "  {'note': 278,\n",
       "   'rem': 274,\n",
       "   'notes': 267,\n",
       "   'add': 254,\n",
       "   'comment': 251,\n",
       "   'comments': 251}),\n",
       " ('Ġpitchers',\n",
       "  {'hit': 265,\n",
       "   'pit': 263,\n",
       "   'er': 260,\n",
       "   'lists': 257,\n",
       "   'put': 257,\n",
       "   'holder': 253}),\n",
       " ('Ġgotta',\n",
       "  {'anna': 270, 'got': 261, 'go': 260, 'ATS': 259, 'at': 258, 'ats': 253}),\n",
       " ('Ġdrops',\n",
       "  {'Dro': 279,\n",
       "   'dro': 271,\n",
       "   'drop': 269,\n",
       "   'Drop': 260,\n",
       "   'drops': 259,\n",
       "   'ĠDro': 252}),\n",
       " ('Ġreductions',\n",
       "  {'red': 271, 'Red': 263, 'add': 261, 'RED': 261, 'cut': 258, 'cuts': 251}),\n",
       " ('with',\n",
       "  {'ITH': 281, 'with': 265, 'add': 264, 'ith': 255, 'at': 253, 'put': 251}),\n",
       " ('ÃĽÃĽ',\n",
       "  {'zz': 292, 'bb': 263, 'ever': 263, 'er': 251, 'ii': 251, 'DD': 250}),\n",
       " ('AMES',\n",
       "  {'AMES': 308,\n",
       "   'ames': 272,\n",
       "   'Name': 255,\n",
       "   'Names': 253,\n",
       "   'name': 252,\n",
       "   'NAME': 250})]"
      ]
     },
     "execution_count": 945,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "id": "d7da0142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ġ2019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Background': 13.564,\n",
       " 'Enter': 12.778,\n",
       " 'Synopsis': 12.387,\n",
       " 'SE': 12.276,\n",
       " 'Names': 11.9,\n",
       " 'SELECT': 11.613,\n",
       " 'TABLE': 11.599,\n",
       " 'Exit': 11.501,\n",
       " 'Input': 11.327,\n",
       " 'Broad': 11.219,\n",
       " 'FIG': 11.141,\n",
       " 'Overview': 11.127,\n",
       " 'Copy': 10.958,\n",
       " 'ADD': 10.956,\n",
       " 'Category': 10.955,\n",
       " 'FILE': 10.845,\n",
       " 'Description': 10.794,\n",
       " 'Numbers': 10.666,\n",
       " 'Program': 10.665,\n",
       " 'Joined': 10.473}"
      ]
     },
     "execution_count": 908,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = tokenizer.encode(' 2019')[0]; print(tokenizer.convert_ids_to_tokens(i))\n",
    "show_topk(*m[i].topk(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c168801f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "052c1e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_token = 'Ġ!'; prompt_id = tokenizer._convert_token_to_id(prompt_token)\n",
    "bop_str = 'Instruction: '; bop_id = tokenizer.encode(bop_str)[0]  # 'Inst'\n",
    "eop_str = '. For example:'; eop_id = tokenizer.encode(eop_str)[2] # 'Ġexample'\n",
    "bos_id = tokenizer._convert_token_to_id('Ġ->')\n",
    "eos_id = tokenizer._convert_token_to_id('Ċ')\n",
    "\n",
    "\n",
    "class CHILDDataset(Dataset):\n",
    "    def __init__(self, input_strs, tokenizer):\n",
    "        if tokenizer.pad_token is None: tokenizer.pad_token = '!'\n",
    "        self.inputs = tokenizer.batch_encode_plus(input_strs, add_special_tokens=False, padding=True, return_tensors='pt')#长的截，短的补\n",
    "        input_ids = self.inputs.input_ids\n",
    "        self.labels = torch.ones_like(input_ids) * (-100)\n",
    "\n",
    "        for bi in range(input_ids.size(0)): \n",
    "            bop_idx = (input_ids[bi] == bop_id).nonzero().squeeze(1) #prompt\n",
    "            eop_idx = (input_ids[bi] == eop_id).nonzero().squeeze(1) #context\n",
    "\n",
    "            if len(bop_idx) > 0:\n",
    "                assert len(bop_idx) == 1 and len(eop_idx) == 1\n",
    "                bop_idx, eop_idx = bop_idx.item(), eop_idx.item() #取出单元素张量的元素值并返回该值，保持原元素类型不变\n",
    "                #bop: 0   eop:6\n",
    "                input_ids[bi, bop_idx: eop_idx + 2] *= -1  # use prompt embedding for prompt tokens\n",
    "  \n",
    "            bos_indices = (input_ids[bi] == bos_id).nonzero().squeeze(1)\n",
    "#             print(\"bos_indices:\",bos_indices)\n",
    "            eos_indices = (input_ids[bi] == eos_id).nonzero()[-len(bos_indices):].squeeze(1) #每一位 eos都比bos大2\n",
    "#             print(\"eos_indices:\",eos_indices)\n",
    "            for i, (bos_i, eos_i) in enumerate(zip(bos_indices.tolist(), eos_indices.tolist())):\n",
    "                assert eos_i > bos_i + 1\n",
    "                if i >= 0:  #zero-shot\n",
    "                    self.labels[bi, bos_i + 1: eos_i] = input_ids[bi, bos_i + 1: eos_i] \n",
    "        \n",
    "        \n",
    "    def re_input(self):\n",
    "        return self.inputs['input_ids']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputs['input_ids'])\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {'input_ids': self.inputs['input_ids'][i],  #输入\n",
    "                'attention_mask': self.inputs['attention_mask'][i],\n",
    "                'labels': self.labels[i]}   #结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b322160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4613, 198)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_id,eos_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "696ea332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from child_utils import *\n",
    "torch.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56fcd441",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedEmbedding(nn.Module):\n",
    "    def __init__(self,  \n",
    "                wte: nn.Embedding,  #正常向量\n",
    "                prompt_id: int = None,\n",
    "                prompt_len: int = 10, \n",
    "                random_range: float = 0.5,\n",
    "                initialize_from_vocab: bool = True):\n",
    "        super(WrappedEmbedding, self).__init__()\n",
    "#         self.wte = wte\n",
    "#         self.prompt_id = prompt_id\n",
    "#         self.prompt_len = prompt_len\n",
    "        self.__dict__.update(locals()); del self.self #locals()以字典类型返回当前位置的全部局部变量\n",
    "        if self.prompt_id is not None: #prompt_embedding prompt词向量\n",
    "            self.prompt_embedding = nn.parameter.Parameter( #将一个不可训练的类型Tensor转换成可以训练的类型parameter\n",
    "                self.initialize_embedding(random_range, initialize_from_vocab)).to(self.wte.weight.device) #在-0.5-0.5中随机取值初始化\n",
    "        else:\n",
    "            self.prompt_embedding = nn.Embedding(self.prompt_len, self.wte.weight.size(1)).to(self.wte.weight.device)\n",
    "                                        #词典大小（总共输入多少词） 嵌入向量维度（多少维表示一个符号）\n",
    "            \n",
    "            assert initialize_from_vocab\n",
    "            self.init_prompt_embedding_()  #将wte的weight值作为初始化\n",
    "#             self.prompt_embedding.weight.data = self.initialize_embedding(random_range, initialize_from_vocab)     \n",
    " \n",
    "    def initialize_embedding(self, random_range: float = 0.5, initialize_from_vocab: bool = True):\n",
    "        if initialize_from_vocab: return self.wte.weight[:self.prompt_len].clone().detach() #返回一个新的tensor，新的tensor和原来的tensor共享数据内存，但不涉及梯度计算\n",
    "        return torch.FloatTensor(self.prompt_len, self.wte.weight.size(1)).uniform_(-random_range, random_range) #产生随机数\n",
    "    \n",
    "    def init_prompt_embedding_(self):\n",
    "#         print(self.wte.weight)\n",
    "        self.prompt_embedding.weight.data[:] = self.wte.weight[:self.prompt_len]\n",
    "\n",
    "        \n",
    "    def forward(self, input_ids):\n",
    "        if self.prompt_id is not None:\n",
    "            input_embeds = self.wte(input_ids)\n",
    "            input_embeds[input_ids == self.prompt_id] = self.prompt_embedding.expand(input_embeds.size(0), -1, -1)\n",
    "        else: # adapted from cpm-2\n",
    "            prompt_mask = input_ids < 0  #返回bool类型\n",
    "#             print(\"prompt_mask:\",prompt_mask.shape)\n",
    "            prompt_ids = -input_ids * prompt_mask #将prompt的值变为正数，其他置零\n",
    "#             print(\"prompt_ids:\",prompt_ids)\n",
    "#             print(prompt_ids < self.prompt_len)\n",
    "#             print(prompt_ids)\n",
    "            assert torch.all(prompt_ids < self.prompt_len)\n",
    "#             print(self.prompt_embedding(prompt_ids).shape)\n",
    "            p_embeds = self.prompt_embedding(prompt_ids) * prompt_mask.float().unsqueeze(-1)\n",
    "#             print(\"p_embeds:\",p_embeds.shape)\n",
    "            input_ids = input_ids * ~prompt_mask\n",
    "            w_embeds = self.wte(input_ids) * (~prompt_mask).float().unsqueeze(-1)\n",
    "#             print(\"w_embeds:\",w_embeds.shape)\n",
    "            input_embeds = w_embeds + p_embeds \n",
    "#         print(input_embeds)\n",
    "        return input_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44b17b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from cpm-2: https://github.com/TsinghuaAI/CPM-2-Finetune/blob/master/utils.py#L133-L164    #不训练模型参数，只训练prompt_embading，这个函数是取这些参数\n",
    "def get_params_for_prompt_optimization(module: nn.Module): \n",
    "    params = []\n",
    "    for t in module.named_modules():\n",
    "        if \"prompt_embedding\" in t[0]:\n",
    "            params.append({'params': [p for p in list(t[1]._parameters.values()) if p is not None]})\n",
    "    for t in module.named_parameters():\n",
    "        if \"prompt\" not in t[0]:\n",
    "            t[1].requires_grad_(False)    \n",
    "    return params\n",
    "\n",
    "def create_optimizer(model, training_args):\n",
    "    from torch.nn.parallel.distributed import DistributedDataParallel as DDP\n",
    "    while isinstance(model, (DDP, )): model = model.module\n",
    "        \n",
    "    we.init_prompt_embedding_()\n",
    "    param_groups = get_params_for_prompt_optimization(model)\n",
    "    optimizer = AdamW(param_groups, lr=training_args.learning_rate, \n",
    "                      betas=(training_args.adam_beta1, training_args.adam_beta2),eps=training_args.adam_epsilon)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39b4f350",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# wte = model.get_input_embeddings() #提取 embedding 中的 词向量部分\n",
    "# if hasattr(wte, 'wte'): wte = wte.wte  # already been wrapped\n",
    "# we = WrappedEmbedding(wte, prompt_len=20000)\n",
    "# model.set_input_embeddings(we) #为词向量赋值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae3bb45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbalize(obj):\n",
    "    if type(obj) == bool: return 'Yes' if obj else 'No'\n",
    "    return str(obj)\n",
    "\n",
    "def list2str(l): return ' '.join(str(i) for i in l)\n",
    "def pairs2str(pairs): return ', '.join(str(k) + ': ' + str(v) for k, v in pairs)\n",
    "\n",
    "def make_context_str(cxt):\n",
    "    if type(cxt) == list:\n",
    "        return pairs2str(cxt) if type(cxt[0]) == tuple and len(cxt[0]) == 2 else list2str(cxt)\n",
    "    if type(cxt) == tuple:\n",
    "        return '; '.join(make_context_str(c) for c in cxt)  # 用分号分隔context的不同部分\n",
    "    \n",
    "def make_query_str(instruction, query):\n",
    "    if instruction is None and query is None: return ''\n",
    "    s = '.'\n",
    "    if instruction is not None: s = s + ' ' + instruction\n",
    "    if query is not None:\n",
    "        if type(query) in [int, bool, str]: query = [query]\n",
    "        if type(query) == dict:# and list(query.keys())[0] != \"CS\"):  # by nrk\n",
    "            s = s + ' ' + '{' + ','.join([' replace %s with %s' % (str(k), str(v)) for k, v in query.items()]) + ' }'\n",
    "        if type(query) in [list, tuple]:\n",
    "            s = s + ' ' + ' '.join([list2str(i) if type(i) == list else str(i) for i in query])\n",
    "    return s\n",
    "\n",
    "def make_example_str(example, query2str):\n",
    "    instruction, cxt, query, ans = example\n",
    "    if type(ans) not in [Sequence, list]: ans = [ans]\n",
    "    ans = [verbalize(a) for a in ans]\n",
    "#     return '%s -> %s' % (''.join(l[0]) + make_query_str(instruction if with_instruction else None, query), ' '.join(ans))  # by nrk\n",
    "#     return '%s -> %s' % (' '.join(l) + make_query_str(instruction if with_instruction else None, query), ' '.join(ans))  # by XD\n",
    "#     return '%s -> %s' % (make_context_str(cxt) + make_query_str(instruction if with_instruction else None, query[0]), ' '.join(ans))\n",
    "    return '%s -> %s' % (make_context_str(cxt) + query2str(query), ' '.join(ans))\n",
    "\n",
    "\n",
    "def sample_rand_len(vocab, k): return sample(vocab, k=randint(1, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df63ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def promptize(s):\n",
    "#     return prompt_token * len(s.split())\n",
    "    return bop_str + s + eop_str\n",
    "\n",
    "courses_vocab=[\"Sql\",\"Math\",\"English\",\"Chinese\",\"Art\",\"Music\",\"History\",\"Biology\",\"Chemistry\",\"Physics\",\"Geography\"]\n",
    "all_vocab = [\"apple\",\"pear\",\"peach\",\"grape\",\"banana\",\"pineapple\",\"lemon\",\"strawberry\",\"cola\",\"juice\",\"coffee\",\"milk\",\"wine\",\"beer\",\"whisky\",\"vodka\",\"brandy\"]\n",
    "solid_vocab=[\"apple\",\"pear\",\"peach\",\"grape\",\"banana\",\"pineapple\",\"lemon\",\"strawberry\"]\n",
    "liquid_vocab=[\"cola\",\"juice\",\"coffee\",\"milk\",\"wine\",\"beer\",\"whisky\",\"vodka\",\"brandy\"]\n",
    "names_vocab =  [i for i in string.ascii_uppercase]\n",
    "depts_vocab = [\"CS\",\"Chi\",\"Eng\",\"Mat\"]\n",
    "sl = [\"solid\"]*len(solid_vocab)+[\"liquid\"]*len(liquid_vocab)\n",
    "sl_vocab = dict(zip(all_vocab,sl))\n",
    "toys = [\"ball\",\"doll\",\"puppet\",\"weiqi\",\"chess\",\"slide\",\"diabolo\",\"plasticine\",\"tumbler\"]\n",
    "                                              #滑梯     空竹      橡皮泥      不倒翁\n",
    "boys = [\"Alex\",\"Dylan\",\"Daniel\",\"Patrick\",\"Austin\",\"Harrison\",\"Tom\",\"Neil\"]\n",
    "girls = [\"Ashley\",\"jessica\",\"Sarah\",\"Amanda\",\"Nicole\",\"Katherine\",\"Anne\",\"Eva\"]\n",
    "all = boys+girls\n",
    "bg = [\"boys\"]*len(boys)+[\"girls\"]*len(girls)\n",
    "bg_vocab = dict(zip(all,bg))\n",
    "\n",
    "all = solid_vocab+toys\n",
    "ft = [\"fruits\"]*len(solid_vocab)+[\"toys\"]*len(toys)\n",
    "ft_vocab = dict(zip(all,ft))\n",
    "\n",
    "def make_input_str(task, nrows=4, ncols=4, full_vocab=None, ans_vocab=[True, False]):\n",
    "    if full_vocab is None: full_vocab = string.ascii_uppercase + string.digits\n",
    "    transform_fn, vocab_fn, sample_fn, query_fn, query2str = task\n",
    "    instruction = transform_fn.__name__.replace('_', ' ')\n",
    "    if vocab_fn is None: vocab_fn = lambda: full_vocab\n",
    "    if query_fn is None: query_fn = lambda *_: None\n",
    "        \n",
    "    examples = []\n",
    "    query = None\n",
    "    for i in range(nrows):\n",
    "        vocab = vocab_fn()\n",
    "        l = sample_fn(vocab, k=ncols)\n",
    "        query = query_fn(l, vocab, ncols)\n",
    "        examples.append([instruction, l, query, transform_fn(l, query=query)])\n",
    "#     examples = balance(examples,ans_vocab)\n",
    "\n",
    "    desc = promptize(instruction) if True else ''\n",
    "    text = '\\n'.join([make_example_str(e, query2str) for e in examples])\n",
    "    text = desc + '\\n' + text + '\\n'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd0c286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def balance(examples, ans_vocab=[True, False]):\n",
    "# def balance1(examples, ans_vocab):\n",
    "#     groups = seq(examples).group_by(_[-1]).map(_[1])  # 按ans分组\n",
    "# #     assert groups.len() == len(ans_vocab), '%d < %d' % (groups.len(), len(ans_vocab))  # 保证每种ans都出现\n",
    "#     min_cnt = groups.map(lambda x: len(x)).min()\n",
    "#     examples = groups.map(lambda x: sample(x, min_cnt)).flatten().list() # 每组都采样最小个数后去分组\n",
    "#     return sample(examples, len(examples))  # 重新打乱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d664342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(examples, ans_vocab):\n",
    "    groups = seq(examples).group_by(_[-1]).map(_[1])  # 按ans分组\n",
    "#     min_cnt = groups.map(lambda x: len(x)).min()\n",
    "    min_cnt =3\n",
    "    if(groups.len()>3):\n",
    "        min_cnt = 3\n",
    "    elif(groups.len()==3):\n",
    "        min_cnt = 3\n",
    "    if(min_cnt > 2):\n",
    "        examples = groups.map(lambda x: sample(x, 3)).flatten().list() # 每组都采样最小个数后去分组\n",
    "        return sample(examples, len(examples))  # 重新打乱\n",
    "    else:\n",
    "        examples = groups.map(lambda x: sample(x, min_cnt)).flatten().list() # 每组都采样最小个数后去分组\n",
    "        return sample(examples, len(examples))  # 重新打乱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab80cfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools  \n",
    "def Do_all_students_choose_courses_in_a_department(cxt, query):\n",
    "    SC, CD = cxt  # SC paris: studeng-course relation, CD pairs: course-department function\n",
    "    ss, d = query  # ss: 学生子集（可以*不止两个学生*），d: 课程\n",
    "#     return seq(ss).map(lambda s: seq(SC).filter(_[0] == s).map(_[1]).intersection(CD.filter(_.[1] == d).map(_.[0])).non_empty()).all()\n",
    "    return (seq(ss)\n",
    "            .map(lambda s: seq(SC).filter(_[0] == s).map(_[1])  # 学生s选的所有课程\n",
    "                 .intersection(\n",
    "                     seq(CD).filter(_[1] == d).map(_[0])) # d系的课程\n",
    "                 .non_empty())  # s选了d系的课程\n",
    "            .all())  # 学生子集ss都选了d系的课程\n",
    "\n",
    "def all_a_sample(vocab, k):\n",
    "    S_vocab, C_vocab, D_vocab = vocab  # vocabs of students, courses, departments\n",
    "    k_S, k_C, k_D, k_SC = k  # default values: k_S = 3, k_C = 3, k_D = 2, k_SC = 5\n",
    "    S, C, D = sample(S_vocab, k_S), sample(C_vocab, k_C), sample(D_vocab, k_D)\n",
    "    \n",
    "    while len(set(CD := choices(D, k=k_C))) < k_D: continue  # ds里每个系的课都要出现\n",
    "    CD = list(zip(C, CD))  # 得到每门课所属的系\n",
    "    \n",
    "    all_SC = list(itertools.product(S, C))  # or seq(S).cartesian(C).list()\n",
    "    while seq(SC := sample(all_SC, k_SC)).map(_[0]).distinct().len() < k_S: continue  # ss里每个学生都要选课\n",
    "    return SC, CD\n",
    "\n",
    "def select_distinct(tuples, col): return seq(tuples).map(_[col]).distinct().list()\n",
    "    \n",
    "def all_a_query(cxt,vocab,k):\n",
    "    SC, CD = cxt\n",
    "    k_S, k_C, k_D, k_SC = k\n",
    "    S, D = select_distinct(SC, 0), select_distinct(CD, 1)\n",
    "#     k_ss = randint(2, len(S))\n",
    "    ss = sample(S, 2)\n",
    "    d = choice(D)\n",
    "    return ss, d\n",
    "\n",
    "def all_a_query2str(query):\n",
    "    ss, d = query\n",
    "    query_str = '%s,%s?' % (', '.join(ss[:-1]) + ' and ' + ss[-1], d)\n",
    "    return '. ' + query_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8103db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_b(cxt, query):\n",
    "    SC, CD = cxt\n",
    "    ss,d = query\n",
    "    return (seq(CD).filter(_[1] == d).map(_[0])\n",
    "                 .difference(\n",
    "                     seq(SC).filter(_[0] == ss).map(_[1]))\n",
    "                 .empty())\n",
    "\n",
    "def all_b_sample(vocab, k):\n",
    "    S_vocab, C_vocab, D_vocab = vocab  \n",
    "    k_S, k_C, k_D, k_SC = k  # default values: k_S = 2, k_C = 3, k_D = 2, k_SC = 5\n",
    "    S, C, D = sample(S_vocab, k_S), sample(C_vocab, k_C), sample(D_vocab, k_D)\n",
    "    \n",
    "    while len(set(CD := choices(D, k=k_C))) < k_D: continue  \n",
    "    CD = list(zip(C, CD)) \n",
    "    \n",
    "    all_SC = list(itertools.product(S, C))  \n",
    "    while seq(SC := sample(all_SC, k_SC)).map(_[0]).distinct().len() < k_S: continue  # ss里每个学生都要选课\n",
    "    return SC, CD\n",
    "   \n",
    "def all_b_query(cxt,vocab,k):  # XD: 不要给qeury_fn加st参数\n",
    "    SC, CD = cxt\n",
    "    k_S, k_C, k_D, k_SC = k\n",
    "    S, D = select_distinct(SC, 0), select_distinct(CD, 1)\n",
    "#     k_ss = randint(2, len(S))  # XD: k_ss unused\n",
    "    ss = choice(S)\n",
    "    d = choice(D)\n",
    "    return ss, d\n",
    "    # XD: 不要在query_fn里转str！！这里转str，transform_fn里再解析回来，两边不是白折腾吗！\n",
    "\n",
    "def all_b_query2str(query):\n",
    "    ss, d = query\n",
    "    query_str = 'Does %s take all %s courses?' % (ss, d)\n",
    "    return '. ' + query_str\n",
    "\n",
    "\n",
    "def Is_the_intersection_of_two_sets_empty(cxt, query):\n",
    "    SC= cxt\n",
    "    s,d = query\n",
    "    return (seq(SC).filter(_[0] == s).map(_[1])\n",
    "                 .intersection(\n",
    "                     seq(SC).filter(_[0] == d).map(_[1]))\n",
    "                 .non_empty())\n",
    "\n",
    "def intersection_query(cxt,vocab,k):\n",
    "    SC= cxt\n",
    "    k_S, k_C, k_SC = k #k_s = 3, k_C = 5 , k_sc = 6\n",
    "    S = select_distinct(SC, 0)\n",
    "    s,d = sample(S,2)\n",
    "    return s, d\n",
    "\n",
    "def intersection_query2str(query):\n",
    "    s, d = query\n",
    "    query_str = \"%s,%s?\" % (s, d)\n",
    "    return '. ' + query_str\n",
    "\n",
    "def intersection_sample(vocab, k):\n",
    "    S_vocab, C_vocab = vocab  \n",
    "    k_S, k_C, k_SC = k  # k_S = 3, k_C = 5, , k_SC = 6\n",
    "    S, C= sample(S_vocab, k_S), sample(C_vocab, k_C)\n",
    "    all_SC = list(itertools.product(S, C))  \n",
    "    while seq(SC := sample(all_SC, k_SC)).map(_[0]).distinct().len() < k_S: continue \n",
    "    return SC\n",
    "\n",
    "def Is_the_first_set_a_subset_of_the_second_one(cxt, query):\n",
    "    SC= cxt\n",
    "    s,d = query\n",
    "    return (seq(SC).filter(_[0] == d).map(_[1])\n",
    "                 .union(\n",
    "                     seq(SC).filter(_[0] == s).map(_[1]))\n",
    "                 ).distinct().len()== seq(SC).filter(_[0] == d).map(_[1]).distinct().len()\n",
    "\n",
    "def complement_query(cxt,vocab,k):\n",
    "    SC= cxt\n",
    "    k_S, k_C, k_SC = k #k_s = 3, k_C = 5 , k_sc = 6\n",
    "    S = select_distinct(SC, 0)\n",
    "    s,d = sample(S,2)\n",
    "    return s, d\n",
    "\n",
    "def complement_query2str(query):\n",
    "    s, d = query\n",
    "    query_str = \"%s,%s?\" % (s, d)\n",
    "    return '. ' + query_str\n",
    "\n",
    "def complement_sample(vocab, k):\n",
    "    S_vocab, C_vocab = vocab  \n",
    "    k_S, k_C, k_SC = k  # k_S = 3, k_C = 4, k_SC = 5\n",
    "    S, C= sample(S_vocab, k_S), sample(C_vocab, k_C)\n",
    "    all_SC = list(itertools.product(S, C))  \n",
    "    while seq(SC := sample(all_SC, k_SC)).map(_[0]).distinct().len() < k_S: continue \n",
    "    return SC\n",
    "\n",
    "def Are_they_the_union_of_the_last_element(cxt, query):\n",
    "    SC, DC = cxt\n",
    "    ss,d = query\n",
    "    return (seq(ss)\n",
    "            .map(lambda s: seq(SC).filter(_[0] == s).map(_[1]) \n",
    "                 .union(\n",
    "                     seq(DC).filter(_[0] == d).map(_[1])) \n",
    "                 .distinct().len() == seq(DC).filter(_[0] == d).map(_[1]).distinct().len())  \n",
    "            .all()) \n",
    "\n",
    "def union_sample(vocab, k):\n",
    "    S_vocab, C_vocab, D_vocab = vocab  \n",
    "    k_S, k_C, k_D, k_SC = k  # k_S = 3, k_C = 4, k_D = 2, k_SC = 6\n",
    "    S, C, D = sample(S_vocab, k_S), sample(C_vocab, k_C), sample(D_vocab, k_D)\n",
    "    \n",
    "    while len(set(DC := choices(D, k=k_C))) < k_D: continue  \n",
    "    DC = list(zip(DC,C)) \n",
    "    \n",
    "    all_SC = list(itertools.product(S, C))  \n",
    "    while seq(SC := sample(all_SC, k_SC)).map(_[0]).distinct().len() < k_S: continue  \n",
    "    return SC, DC\n",
    "   \n",
    "def union_query(cxt,vocab,k): \n",
    "    SC, DC = cxt\n",
    "    k_S, k_C, k_D, k_SC = k\n",
    "    S, D = select_distinct(SC, 0), select_distinct(DC, 0)\n",
    "    k_ss = randint(2, len(S))\n",
    "    ss = sample(S, k_ss)\n",
    "    d = choice(D)\n",
    "    return ss, d\n",
    "\n",
    "def union_query2str(query):\n",
    "    ss, d = query\n",
    "    query_str = '%s,%s?' % (', '.join(ss[:-1]) + ' and ' + ss[-1], d)\n",
    "    return '. ' + query_str\n",
    "\n",
    "def Are_there_elements_belonging_to_the_same_class(cxt, query): #新建联系，把vocab和属性连起来形成新集合\n",
    "    NA, DA = cxt\n",
    "    s,d = query\n",
    "    D = seq(DA).filter(_[0] == d).map(_[1])\n",
    "    return (seq(NA).filter(_[0] == s).map(_[1]).select(lambda x: sl_vocab[x] == sl_vocab[D[0]]).any())\n",
    "      \n",
    "    \n",
    "def find_sample(vocab, k): \n",
    "    name_vocab, all_vocab = vocab\n",
    "    k_name, k_all, k_D, k_SA = k  # k_name = 3, k_all = 4, k_D = 2, k_SA = 6\n",
    "    S = list(all_vocab.keys())\n",
    "    N, A, D = sample(name_vocab, k_name), sample(S, k_all), sample(string.ascii_lowercase, k_D)\n",
    "#     D = sample(d := name_vocab.pop(name_vocab.index(a) for a in N),k_D)\n",
    "    A1 = sample(S, k_D)\n",
    "    DA = list(zip(D,A1)) \n",
    "    \n",
    "    all_NA = list(itertools.product(N, A))  \n",
    "    while seq(NA := sample(all_NA, k_SA)).map(_[0]).distinct().len() < k_name: continue  \n",
    "    return NA, DA\n",
    "   \n",
    "def find_query(cxt,vocab,k): \n",
    "    NA, DA = cxt\n",
    "    k_name, k_all, k_D, k_SA = k\n",
    "    S,D = select_distinct(NA, 0), select_distinct(DA, 0)\n",
    "    s,d = choice(S), choice(D)\n",
    "    return s, d\n",
    "\n",
    "def find_query2str(query):\n",
    "    s, d = query\n",
    "    query_str = '%s,%s?' % (s, d)\n",
    "    return '. ' + query_str\n",
    "\n",
    "\n",
    "def Are_there_any_elements_different_from_other_elements(cxt, query):\n",
    "    NA = cxt\n",
    "    ss = query\n",
    "    return (seq(ss).map(lambda s: seq(NA).filter(_[0] == s).map(_[1])\n",
    "                        .select(lambda x: sl_vocab[x])[0])\n",
    "            .distinct().len( ) == 2)\n",
    "               \n",
    "def find_dif_sample(vocab, k):\n",
    "    name_vocab, all_vocab = vocab\n",
    "    k_name, k_all, k_SA = k  # k_name = 4, k_all = 4, k_SA= 3\n",
    "    N, A = sample(name_vocab, k_name), sample(list(all_vocab.keys()), k_all) \n",
    "    NA = list(zip(N,A)) \n",
    "    return NA\n",
    "   \n",
    "def find_dif_query(cxt,vocab,k): \n",
    "    NA = cxt\n",
    "    k_name, k_all, k_NA = k\n",
    "    S = select_distinct(NA, 0)\n",
    "    ss = sample(S,k_NA)\n",
    "    return ss\n",
    "\n",
    "\n",
    "def find_dif_query2str(query):\n",
    "    ss = query\n",
    "    query_str = '%s?' % (', '.join(ss[:-1]) + ' and ' + ss[-1])\n",
    "    return '. ' + query_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "464efbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def How_many_elements_are_similar_to_the_case(cxt, query):\n",
    "    s = cxt\n",
    "    q = query\n",
    "    return seq(s).filter(lambda x: sl_vocab[x] == sl_vocab[q[0]]).len()\n",
    "                     \n",
    "def count_sample(vocab, k):\n",
    "    all_vocab = vocab\n",
    "    k_cxt,k_query = k  # k_cxt = 4 ,k_query =1\n",
    "    N = list(all_vocab.keys())\n",
    "    s = sample(N, k_cxt) \n",
    "    return s\n",
    "   \n",
    "def count_query(cxt,vocab,k): \n",
    "    NA = cxt\n",
    "    k_cxt,k_query = k\n",
    "    N = list(vocab.keys())\n",
    "    q = sample(N,k_query)\n",
    "    return q\n",
    "\n",
    "def count_query2str(query):\n",
    "    q = query\n",
    "    query_str = '%s?' % (q[0])\n",
    "    return '. ' + query_str\n",
    "\n",
    "def Is_the_number_of_first_elements_greater_than_the_second_one(cxt, query):\n",
    "    s = cxt\n",
    "    q = query\n",
    "    return (seq(s).filter(lambda x: sl_vocab[x] == sl_vocab[q[0]]).len() >= len(s)/2)\n",
    "                     \n",
    "def compare_sample(vocab, k):\n",
    "    all_vocab,s_vocab,l_vocab = vocab\n",
    "    k_cxt,k_query = k  # k_cxt = 5 ,k_query =2\n",
    "    N = list(all_vocab.keys())\n",
    "    s = sample(N, k_cxt) \n",
    "    return s\n",
    "   \n",
    "def compare_query(cxt,vocab,k): \n",
    "    NA = cxt\n",
    "    all_vocab,s_vocab,l_vocab = vocab\n",
    "    k_cxt,k_query = k\n",
    "    q = sample(s_vocab,1)+sample(l_vocab,1)\n",
    "    random.shuffle(q)\n",
    "    return q\n",
    "\n",
    "def compare_query2str(query):\n",
    "    ss,q = query\n",
    "    query_str = '%s,%s?' % (ss,q)\n",
    "    return '. ' + query_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62aee837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ascii_size_existence(l, query): return seq(l).map(_[0] > query).any()\n",
    "def Ascii_size_all(l, query): return seq(l).map(_[0] > query).all()\n",
    "def Ascii_size_None(l, query): return seq(l).filter(_[0] > query).empty()\n",
    "def ith_element(l, query=None): return seq(l).slice(1, 2)\n",
    "def ith_group(l, query=None): return seq(l).group_by(_).select(_[1]).slice(1, 2).flatten()#.distinct()# davinci F w/ and wo dist\n",
    "# def element_at_index(l, query): return seq(l).slice(query, query + 1) # davinci F\n",
    "def element_at_index(l, query): return seq(l).enumerate().filter(_[0] == query).select(_[1])\n",
    "def replace(l, query): return seq(l).map(lambda x: query.get(x, x))\n",
    "def replace_with_the_other(l, query): # davinci F\n",
    "    query = {k: (set(l) - {k}).pop() for k in l}\n",
    "    return replace(l, query)\n",
    "def replace_all_with(l, query): return seq(l).map(lambda x: query)  # davinci F?!\n",
    "def interleave_with(l, query): return seq(l).flat_map(lambda x: [x, query])  # davinci T!!\n",
    "def unique_elements(l, query=None): return seq(l).distinct() # davinci F\n",
    "def how_many_unique_elements(l, query=None): return seq(l).distinct().len()  # davinci F\n",
    "def how_many(l, query): return seq(l).filter(_ == query).len() # davinci F\n",
    "def select_same_as(l, query): return seq(l).filter(_ == query) # simpler version of how_many. davinci F\n",
    "def select_same_number_as(l, query): return seq(l).group_by(_).select(_[1]).filter(lambda x: len(x) == len(query)).flatten() # F\n",
    "def includes(l, query): return seq(l).union(seq(query)).distinct().len() == seq(l).distinct().len() # davinci F\n",
    "def is_included_by(l, query): return seq(l).difference(seq(query)).empty() # davinci F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "388dd77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compare_the_values_of_two_sets(cxt, query):\n",
    "    s = cxt\n",
    "    q = query\n",
    "    if(seq(s).filter(lambda x: sl_vocab[x] == sl_vocab[q[0]]).len() > len(s)/2):\n",
    "        return \">\"\n",
    "    elif(seq(s).filter(lambda x: sl_vocab[x] == sl_vocab[q[0]]).len() < len(s)/2):\n",
    "        return \"<\"\n",
    "    else:\n",
    "        return \"=\"\n",
    "\n",
    "def Compare_sample(vocab, k):\n",
    "    all_vocab,s_vocab,l_vocab = vocab\n",
    "    k_cxt,k_query = k  # k_cxt = 5 ,k_query =2\n",
    "    N = list(all_vocab.keys())\n",
    "    s = sample(N, k_cxt) \n",
    "    return s\n",
    "   \n",
    "def Compare_query(cxt,vocab,k): \n",
    "    NA = cxt\n",
    "    all_vocab,s_vocab,l_vocab = vocab\n",
    "    k_cxt,k_query = k\n",
    "    q = sample(s_vocab,1)+sample(l_vocab,1)\n",
    "    random.shuffle(q)\n",
    "    return q\n",
    "\n",
    "def Compare_query2str(query):\n",
    "    ss,q = query\n",
    "    query_str = '%s,%s?' % (ss,q)\n",
    "    return '. ' + query_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48028352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Relationship_between_two_sets(cxt, query): #新建联系，把vocab和属性连起来形成新集合\n",
    "    NA = cxt\n",
    "    s,q= query   #s:boys/girls  q:fruits/toys\n",
    "    name = seq(NA).filter(lambda x: bg_vocab[x[0]] == s)\n",
    "    if(seq(name).map(_[1]).filter(lambda x: ft_vocab[x] == q).len() == seq(name).len()):\n",
    "        return \"all\"\n",
    "    elif(seq(name).map(_[1]).filter(lambda x: ft_vocab[x] == q).empty()):\n",
    "        return \"none\"\n",
    "    else:\n",
    "        return \"some\"\n",
    "    \n",
    "def Relationship_sample(vocab, k): \n",
    "    name_vocab, all_vocab = vocab\n",
    "    k_name, k_all, k_SA = k  # k_name = 4, k_all = 4, k_SA = 4\n",
    "    Name = list(name_vocab.keys())\n",
    "    S = list(all_vocab.keys())\n",
    "    N, A = sample(Name, k_name), sample(S, k_all)\n",
    "#     D = sample(d := name_vocab.pop(name_vocab.index(a) for a in N),k_D)\n",
    "    \n",
    "    all_NA = list(itertools.product(N, A))  \n",
    "    while seq(NA := sample(all_NA, k_SA)).map(_[0]).distinct().len() < k_name: continue  \n",
    "    return NA\n",
    "   \n",
    "def Relationship_query(cxt,vocab,k): \n",
    "    NA = cxt\n",
    "    name_vocab, all_vocab = vocab\n",
    "    k_name, k_all, k_SA = k\n",
    "    S,D = select_distinct(NA, 0),select_distinct(NA, 1)\n",
    "    s,d = choice(S),choice(D)\n",
    "    s1,d1 = name_vocab[s],all_vocab[d]\n",
    "    return s1,d1\n",
    "\n",
    "def Relationship_query2str(query):\n",
    "    s,q = query\n",
    "    query_str = '[] %s have %s. [all / some / none]?' % (s,q)\n",
    "    return '. ' + query_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f199b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\n",
    "    (ith_element,            None,                               sample,    None,None),\n",
    "    (ith_group,              None, lambda vocab, k: seq(sample(vocab, k)).map(lambda x:[x]*randint(1, 3)).flatten().list(),None,None),\n",
    "    (element_at_index,       lambda: upper_letters,              sample,    lambda l,vocab,k: randint(0, min(2,len(l)-1))),\n",
    "    (replace,                None,                               sample,    lambda l,vocab,k: {choice(l): choice(vocab)}),\n",
    "    (replace_with_the_other, lambda: sample(full_vocab, 2),   lambda vocab,k: sample(vocab+choices(vocab, k=k-2),k), None),\n",
    "    (replace_all_with,       None,                               sample_rand_len, lambda l,vocab,k: choice(vocab)),\n",
    "    (interleave_with,        None,                               sample_rand_len, lambda l,vocab,k: choice(vocab)),\n",
    "    (unique_elements,        lambda: sample(upper_letters, 3),   choices,   None),\n",
    "    (how_many_unique_elements,lambda: sample(upper_letters, 3),  choices,   None),\n",
    "    (how_many,               lambda: sample(upper_letters, 3),   choices,   lambda l,vocab,k: choice(list(set(l)))),\n",
    "    (select_same_as,         lambda: sample(upper_letters, 3),   choices,   lambda l,vocab,k: choice(list(set(l)))),\n",
    "    (select_same_number_as,  None, lambda vocab, k: seq(sample(vocab, k)).map(lambda x:[x]*randint(1, 3)).flatten().list(),   \n",
    "     lambda l,vocab,k: [choice(vocab)]*randint(1, 3)),\n",
    "    (includes,               lambda: sample(upper_letters, 6),   sample,    lambda l,vocab,k: sample(vocab, 3)),\n",
    "    (is_included_by,         lambda: sample(upper_letters, 6),   sample,    lambda l,vocab,k: sample(vocab, 5)),\n",
    "    \n",
    "    (Ascii_size_None,        lambda: string.ascii_uppercase,              sample,    lambda l,vocab,k: \"Is there no element greater than %s?\" % choice(list(set(l)))),\n",
    "    (Ascii_size_all,         lambda: string.ascii_uppercase,              sample,    lambda l,vocab,k: \"Are all elements greater than %s?\" % choice(list(set(l)))),\n",
    "    (Ascii_size_existence,   lambda: string.ascii_uppercase,              sample,    lambda l,vocab,k: \"Is there an element greater than %s?\" % choice(list(set(l)))),\n",
    "    \n",
    "#     (all_a,                  lambda: [names_vocab,courses_vocab,depts_vocab],     all_a_sample,    all_a_query, all_a_query2str),\n",
    "    (Do_all_students_choose_courses_in_a_department,    lambda: [names_vocab,courses_vocab,depts_vocab],     all_a_sample,    all_a_query, all_a_query2str),\n",
    "    (Compare_the_values_of_two_sets,  lambda: [sl_vocab,solid_vocab,liquid_vocab],  Compare_sample,    Compare_query, Compare_query2str),\n",
    "    (Relationship_between_two_sets,   lambda: [bg_vocab,ft_vocab],               Relationship_sample,    Relationship_query, Relationship_query2str),\n",
    "    (Is_the_intersection_of_two_sets_empty,           lambda: [string.ascii_uppercase,string.ascii_lowercase],     intersection_sample,    intersection_query, intersection_query2str),\n",
    "    (Is_the_first_set_a_subset_of_the_second_one,           lambda: [string.ascii_uppercase,string.ascii_lowercase],     complement_sample,    complement_query, complement_query2str),\n",
    "    (Are_they_the_union_of_the_last_element,                lambda: [string.ascii_uppercase,string.ascii_lowercase,depts_vocab],     union_sample,    union_query, union_query2str),\n",
    "    (Are_there_elements_belonging_to_the_same_class,            lambda: [string.ascii_uppercase,sl_vocab],      find_sample,    find_query, find_query2str ),\n",
    "    (Are_there_any_elements_different_from_other_elements,          lambda: [string.ascii_uppercase,sl_vocab],      find_dif_sample,  find_dif_query, find_dif_query2str ),\n",
    "    (How_many_elements_are_similar_to_the_case,                lambda: sl_vocab,                                      count_sample,            count_query,count_query2str),\n",
    "    (Is_the_number_of_first_elements_greater_than_the_second_one,              lambda: [sl_vocab,solid_vocab,liquid_vocab],          compare_sample,            compare_query,compare_query2str),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1365,
   "id": "105e915f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-8], nrows=30, ncols=(4, 4, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "91683062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-9], nrows=8, ncols=(4,2))) #比较，query中给了两个元素（固体、液体），\n",
    "                                                        #若前一个元素的类型数目大于后一个，就输出YES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "dc45005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-9], nrows=80, ncols=(2, 3, 2, 5))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "e98e87d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Are there any elements different from other elements. For example:\n",
      "M: beer, N: pear, B: milk, G: peach. N, B and G? -> Yes\n",
      "F: juice, P: cola, E: coffee, G: pineapple. F, P and E? -> No\n",
      "U: grape, C: whisky, Z: juice, T: beer. Z, C and T? -> No\n",
      "H: whisky, R: apple, L: strawberry, O: brandy. R, L and O? -> Yes\n",
      "V: juice, W: brandy, P: coffee, O: banana. O, W and P? -> Yes\n",
      "H: banana, J: pineapple, E: coffee, G: grape. H, G and J? -> No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(make_input_str(tasks[-3], nrows=80, ncols=(4,4,3))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "6fb4988c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Are there elements belonging to the same class. For example:\n",
      "P: banana, P: brandy, I: brandy, U: peach; v: grape, b: wine. I,b? -> Yes\n",
      "K: whisky, P: apple, K: cola, L: apple; v: whisky, a: strawberry. K,a? -> No\n",
      "R: pear, R: cola, E: strawberry, M: cola; q: pear, h: vodka. E,h? -> No\n",
      "N: pineapple, Z: pineapple, C: coffee, C: juice; p: lemon, j: milk. N,p? -> Yes\n",
      "E: beer, J: milk, I: peach, I: beer; j: peach, n: banana. E,j? -> No\n",
      "R: grape, P: grape, P: juice, N: grape; k: milk, n: vodka. P,k? -> Yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(make_input_str(tasks[-4], nrows=100, ncols=(3,4,2,4)))  #找相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "f4070da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-1], nrows=8, ncols=(5,2))) #比较，query中给了两个元素（固体、液体），\n",
    "                                                        #若前一个元素的类型数目大于后一个，就输出YES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "4f3668d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-2], nrows=30, ncols=(3,1), ans_vocab=[0,1,2,3]))    #数数，数cxt中与query中元素同类的个数\n",
    "                                                                                  #这里修改了balance函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "db442a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-5], nrows=10, ncols=(3,4,2,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "eadf0bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-6], nrows=18, ncols=(3,11,5))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "c8c59a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-7], nrows=4, ncols=(3,4,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1377,
   "id": "c3df9c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Do all students choose courses in a department. For example:\n",
      "L: Geography, L: English, B: Chemistry, L: Chemistry, Z: Chemistry; English: Eng, Geography: Eng, Chemistry: Mat. B and L,Eng? -> No\n",
      "J: History, O: Art, O: History, J: Math, D: History; History: CS, Art: Mat, Math: Mat. D and O,CS? -> Yes\n",
      "Z: Sql, Z: Music, P: Chemistry, P: Sql, T: Music; Sql: Eng, Music: Eng, Chemistry: Chi. P and Z,Chi? -> No\n",
      "J: Chinese, J: Music, U: Music, J: Sql, H: Chinese; Chinese: CS, Sql: Eng, Music: Eng. J and H,CS? -> Yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(make_input_str(tasks[-10], nrows=100, ncols=(3, 3, 2, 5))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "06d90c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_input_str(tasks[-2], nrows=8, ncols=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "3185653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if n_total == 1:\n",
    "#     inputs = tokenizer.encode_plus(text, return_tensors='pt')\n",
    "#     inputs = prepare_inputs(inputs, model.device)\n",
    "#     outputs = model(**inputs, output_attentions=False)\n",
    "\n",
    "#     # assert inputs.input_ids.size(0) == 1\n",
    "#     input_ids = inputs.input_ids\n",
    "#     logits = outputs.logits\n",
    "\n",
    "#     bsz = input_ids.size(0); assert bsz == 1\n",
    "#     labels = torch.ones_like(input_ids) * (-100)\n",
    "#     for bi in range(bsz):\n",
    "#         bos_indices = (input_ids[bi] == bos_id).nonzero().squeeze(1)\n",
    "#         eos_indices = (input_ids[bi] == eos_id).nonzero()[-nrows:].squeeze(1)\n",
    "#         for i, (example, bos_i, eos_i) in enumerate(zip(examples, bos_indices.tolist(), eos_indices.tolist())):\n",
    "#             print(' ' + make_example_str(example))\n",
    "#             ans_ids = input_ids[bi, bos_i + 1: eos_i]\n",
    "#             if i >= 2: labels[bi, bos_i: eos_i - 1] = ans_ids\n",
    "#             ans_prob_dist = logits[bi, bos_i: eos_i - 1].softmax(-1)\n",
    "#             ans_probs = ans_prob_dist[torch.arange(ans_prob_dist.size(0)), ans_ids]\n",
    "#             ans_tokens = tokenizer.convert_ids_to_tokens(ans_ids)\n",
    "#             for ans_id, ans_token, ans_prob, dist in zip(ans_ids, ans_tokens, numpy(ans_probs, decimals=3), ans_prob_dist):\n",
    "#                 top1_correct = (dist.argmax() == ans_id).item()\n",
    "#                 print(('*' if top1_correct else ' ') + ans_token, ans_prob, \n",
    "#                       show_topk(*dist.topk(5), indices_fn=tokenizer.convert_ids_to_tokens)) \n",
    "#     loss = nn.CrossEntropyLoss()(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "#     loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "6b5d2b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.convert_ids_to_tokens(617)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "f7d6edbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(s.count('Yes') for s in input_strs)\n",
    "# sum(s.count('No') for s in input_strs)\n",
    "# sum(s.count('all') for s in input_strs)\n",
    "# sum(s.count('none') for s in input_strs)\n",
    "# sum(s.count('some') for s in input_strs)\n",
    "# sum(s.count('3') for s in input_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d64330f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [e['input_ids'] for e in train_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ee181c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.convert_ids_to_tokens(([e['input_ids'] for e in train_dataset][0]).numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4ff9a2be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(eval_dataset.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c759bca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f588b59",
   "metadata": {},
   "source": [
    "# 请从这里开始,肖老师"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "17373019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Relationship between two sets. For example:\n",
      "Daniel: lemon, Ashley: grape, Amanda: grape, Harrison: pear. [] boys have fruits. [all / some / none]? -> all\n",
      "\n",
      "Instruction: Relationship between two sets. For example:\n",
      "Sarah: lemon, Alex: peach, Harrison: grape, Eva: plasticine. [] boys have toys. [all / some / none]? -> none\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# n_total, n_valid = 500, 100  #全部数目，测试数目\n",
    "# n_total, n_valid = 800, 200\n",
    "n_total, n_valid = 180, 30\n",
    "# n_total, n_valid =4,2\n",
    "n_train = n_total - n_valid\n",
    "# input_strs = [make_input_str(tasks[-7], nrows=1, ncols=(3,4,5)) for __ in range(n_total)]# Is the intersection of two sets empty.\n",
    "# input_strs = [make_input_str(tasks[-3], nrows=1, ncols=(4,4,3)) for __ in range(n_total)]# Are there any elements different from other elements\n",
    "# input_strs = [make_input_str(tasks[-4], nrows=1, ncols=(3,4,2,4)) for __ in range(n_total)]# Are_there_elements_belonging_to_the_same_class\n",
    "# input_strs = [make_input_str(tasks[-1], nrows=1, ncols=(5,2)) for __ in range(n_total)]#Is_the_number_of_first_elements_greater_than_the_second_one\n",
    "# input_strs = [make_input_str(tasks[-2], nrows=1, ncols=(3,1), ans_vocab=[0,1,2,3]) for __ in range(n_total)] #How_many_elements_are_similar_to_the_example\n",
    "# input_strs = [make_input_str(tasks[-5], nrows=1, ncols=(3,4,2,4)) for __ in range(n_total)] #Are_they_the_union_of_the_last_element\n",
    "# input_strs = [make_input_str(tasks[-6], nrows=1, ncols=(3,11,5)) for __ in range(n_total)]#Is the first set a subset of the second one\n",
    "# input_strs = [make_input_str(tasks[-10], nrows=1, ncols=(3, 3, 2, 5)) for __ in range(n_total)]\n",
    "# input_strs = [make_input_str(tasks[-9], nrows=1, ncols=(4,2)) for __ in range(n_total)] #Compare the values of two sets.\n",
    "input_strs = [make_input_str(tasks[-8], nrows=1, ncols=(4, 4, 4)) for __ in range(n_total)] #Relationship between two sets.\n",
    "\n",
    "for s in sample(input_strs, 2): print(s)\n",
    "# print(input_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "58f1d494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s,end = input_strs[0].index(\":\"),input_strs[0].index(\"For\")\n",
    "# name = input_strs[0][s+2:end]\n",
    "# import json\n",
    "# filename = './nrk/'+name\n",
    "# with open(filename,\"w\") as file_obj:\n",
    "#     json.dump(input_strs,file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "2e64ee95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Is this sentence correct. For example:\n",
      "A is less difficult to carry than B because A is smaller. Is that right? -> Yes\n",
      "\n",
      "Instruction: Is this sentence correct. For example:\n",
      "A is more dangerous to look at than B because A is less luminous. Is that right? -> No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in sample(text, 2): print(s)\n",
    "n_total, n_valid = 180, 30\n",
    "n_train = n_total - n_valid\n",
    "text = text[:180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "e2f80b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "# train_dataset = CHILDDataset(input_strs[:-n_valid], tokenizer)\n",
    "# eval_dataset = CHILDDataset(input_strs[-n_valid:], tokenizer)\n",
    "train_dataset = CHILDDataset(text[:-n_valid], tokenizer)\n",
    "eval_dataset = CHILDDataset(text[-n_valid:], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "82ad27d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wte = model.get_input_embeddings() #提取 embedding 中的 词向量部分\n",
    "if hasattr(wte, 'wte'): wte = wte.wte  # already been wrapped\n",
    "we = WrappedEmbedding(wte, prompt_len=40000)\n",
    "model.set_input_embeddings(we) #为词向量赋值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "416bbc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = []\n",
    "    bos_indices = []\n",
    "    eos_indices = []\n",
    "    preds = []\n",
    "    m = nn.Softmax(dim = -1)\n",
    "    labels_loc = pred.label_ids.argmax(-1)\n",
    "    for i in range(len(labels_loc)):\n",
    "        labels.append(pred.label_ids[i][labels_loc[i]])\n",
    "                                                                                 #     arraypre = pred.predictions[0] # 6B\n",
    "    arraypre = pred.predictions                                                                              # 1.3B\n",
    "    predss = arraypre.argmax(-1)\n",
    "    num = \"\"\n",
    "   \n",
    "    for bi in range(predss.shape[0]):\n",
    "        num = labels_loc[bi]\n",
    "        preds.append(predss[bi, num-1:num]) \n",
    "        t = torch.from_numpy(pred.predictions[bi,num-1:num])                        #1.3B\n",
    "                                                                                    #         t = torch.from_numpy(pred.predictions[0][bi,num-1:num])  #6B\n",
    "        n = m(t)\n",
    "        ids = torch.topk(n,3)[1].numpy().tolist()                                              #ids   /[0] 概率\n",
    "        loc = torch.topk(n,3)[0].numpy().tolist()\n",
    "                                                                                                 #         print(ids)\n",
    "        ids = tokenizer.convert_ids_to_tokens(ids[0])\n",
    "        loc = [float('{:.4f}'.format(i)) for i in loc[0]]\n",
    "        precision = [i+\" : \"+str(j) for i,j in zip(ids,loc)]\n",
    "    acc = accuracy_score(labels, list(preds))    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "d34fd7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, 3363, -100, -100, -100, -100,\n",
       "        -100, -100])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset[0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "eb7bf973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_metrics(pred):\n",
    "#     labels = []\n",
    "#     bos_indices = []\n",
    "#     preds = []\n",
    "#     labels_loc = pred.label_ids.argmax(-1)\n",
    "#     for i in range(len(labels_loc)):\n",
    "#         labels.append(pred.label_ids[i][labels_loc[i]])\n",
    "# #     print(labels)\n",
    "#     arraypre = pred.predictions[0] # 6B\n",
    "# # #     arraypre = pred.predictions # 1.3B\n",
    "#     print(arraypre)\n",
    "#     predss = arraypre.argmax(-1)\n",
    "#     sent = tokenizer.convert_ids_to_tokens(predss[0])\n",
    "#     sent1 = \" \".join(sent)\n",
    "#     sent1=sent1.replace(\"Ġ\",\"\")\n",
    "#     sent1=sent1.replace(\"Ċ\",\"\\n\")\n",
    "#     print(sent1)\n",
    "#     for bi in range(predss.shape[0]):\n",
    "#         for j in range(predss.shape[1]):\n",
    "#             if(predss[bi][j] == bos_id):\n",
    "#                 bos_indices.append(j)\n",
    "#         bos_i = bos_indices[-1]\n",
    "#         preds.append(predss[bi, bos_i + 1:bos_i + 2])\n",
    "    \n",
    "#     acc = accuracy_score(labels, list(preds))\n",
    "#     return {\n",
    "# #         'accuracy': acc,\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "6ebf074a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(output_dir=\"./models/model_name\",                                                             #模型预测和检查点的输出目录\n",
    "    overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=True, \n",
    "    per_device_train_batch_size=1, per_device_eval_batch_size=1,                                                  #每个GPU / TPU内核/ CPU的批处理大小\n",
    "    gradient_accumulation_steps=6,eval_steps=5, \n",
    "    weight_decay=0.001, adam_beta2=0.98, adam_epsilon=1e-6,                                      #weight_decay要应用的权重衰减,adam_epsilon AdamW优化器的ε超参数\n",
    "    lr_scheduler_type='constant', learning_rate=0.001, num_train_epochs=5,                                  #learning_rate:Adam初始学习率\n",
    "    logging_strategy ='epoch',  save_steps=0,                                             #save_steps保存两个检查点之前的更新步骤数\n",
    "    no_cuda=True, report_to='none',                                                         # to avoid report to wandb\n",
    "    evaluation_strategy ='steps',\n",
    "#     evaluation_strategy ='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "ff25273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(filename,\"a\") as f:\n",
    "#         f.write(str(training_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "d89c7d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/xd/projects/transformers/src/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, training_args, train_dataset=train_dataset, eval_dataset=eval_dataset,compute_metrics=compute_metrics,\n",
    "                  optimizers=(create_optimizer(model, training_args), None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "0aa95c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 01:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.5578513145446777,\n",
       " 'eval_accuracy': 0.0,\n",
       " 'eval_precision': ['ĠA : 0.1883', 'ĠIs : 0.059', 'ĠB : 0.0472'],\n",
       " 'eval_runtime': 9.2024,\n",
       " 'eval_samples_per_second': 3.26,\n",
       " 'eval_steps_per_second': 3.26}"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "c5b8d21d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 150\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 750\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 09:14, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.616900</td>\n",
       "      <td>1.304838</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>['ĠYes : 0.6459', 'ĠNo : 0.1877', 'Ġ[ : 0.0194']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.889400</td>\n",
       "      <td>13.196543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>['ĊĊ : 0.1545', 'Ċ : 0.1327', '\\\\ : 0.0873']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10.558700</td>\n",
       "      <td>12.672831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>['Ġthe : 0.1758', 'Ġof : 0.0498', '- : 0.0434']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9.712600</td>\n",
       "      <td>9.770533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>['Ġ : 0.273', 'Ġthe : 0.0731', 'Ġlike : 0.035']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.668000</td>\n",
       "      <td>2.120934</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>['ĠNo : 0.1628', 'ĠYes : 0.1345', 'Ġthe : 0.0488']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=750, training_loss=5.889138916015625, metrics={'train_runtime': 554.7103, 'train_samples_per_second': 1.352, 'train_steps_per_second': 1.352, 'total_flos': 224246237184000.0, 'train_loss': 5.889138916015625, 'epoch': 5.0})"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "90777ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 10\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.735599160194397, 'test_accuracy': 0.5, 'test_precision': ['ĠYes : 0.6578', 'ĠNo : 0.3009', 'Ġyes : 0.0071'], 'test_runtime': 3.1062, 'test_samples_per_second': 3.219, 'test_steps_per_second': 3.219}\n"
     ]
    }
   ],
   "source": [
    "test_dataset = CHILDDataset(text[:10], tokenizer)\n",
    "a = trainer.predict(test_dataset) #此处新生成了测试集\n",
    "print(a.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8d29120e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 30\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.0003098619054071605, 'test_accuracy': 1.0, 'test_precision': ['ĠNo : 0.9999', 'No : 0.0', 'Ġ : 0.0'], 'test_runtime': 50.5283, 'test_samples_per_second': 0.594, 'test_steps_per_second': 0.594}\n"
     ]
    }
   ],
   "source": [
    "# input_strs = [make_input_str(tasks[-7], nrows=100, ncols=(3,4,5)) for __ in range(30)]# Is the intersection of two sets empty.\n",
    "# input_strs = [make_input_str(tasks[-3], nrows=100, ncols=(4,4,3)) for __ in range(30)]# Are there any elements different from other elements\n",
    "# input_strs = [make_input_str(tasks[-4], nrows=100, ncols=(3,4,2,4)) for __ in range(30)]# Are_there_elements_belonging_to_the_same_class\n",
    "# input_strs = [make_input_str(tasks[-1], nrows=120, ncols=(5,2)) for __ in range(30)]#Is_the_number_of_first_elements_greater_than_the_second_one\n",
    "# input_strs = [make_input_str(tasks[-2], nrows=80, ncols=(3,1), ans_vocab=[0,1,2,3]) for __ in range(30)] #How_many_elements_are_similar_to_the_example\n",
    "# input_strs = [make_input_str(tasks[-5], nrows=100, ncols=(3,4,2,4)) for __ in range(30)] #Are_they_the_union_of_the_last_element\n",
    "# input_strs = [make_input_str(tasks[-6], nrows=100, ncols=(3,11,5)) for __ in range(30)]#Is the first set a subset of the second one\n",
    "# input_strs = [make_input_str(tasks[-10], nrows=100, ncols=(3, 3, 2, 5)) for __ in range(30)]\n",
    "# input_strs = [make_input_str(tasks[-9], nrows=100, ncols=(4,2)) for __ in range(30)] #Compare the values of two sets.\n",
    "# input_strs = [make_input_str(tasks[-8], nrows=100, ncols=(4, 4, 4)) for __ in range(30)] #Relationship between two sets.\n",
    "test_dataset = CHILDDataset(input_strs[:], tokenizer)\n",
    "a = trainer.predict(test_dataset) #此处新生成了测试集\n",
    "print(a.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d1961b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ef98c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedb8237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4622d39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a194cd0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afa17cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e6b876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b37a9874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.place_model_on_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9b4b3eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prev(elem):\n",
    "    i, v = elem\n",
    "    return _l[i - 1] if i > 0 else None\n",
    "\n",
    "false = lambda *_: False\n",
    "true  = lambda *_: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "721cb66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Element = namedtuple('Element', 'index value')\n",
    "_l = 'A B C B'.split()\n",
    "n = len(_l)\n",
    "# l = [Element._make(e) for e in enumerate(l)]\n",
    "l = seq(_l)\n",
    "l = l.enumerate().map(Element._make)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9f22f664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  index</th><th>value  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">      0</td><td>A      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      1</td><td>B      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      2</td><td>C      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      3</td><td>B      </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[Element(index=0, value='A'), Element(index=1, value='B'), Element(index=2, value='C'), Element(index=3, value='B')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['C']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['b']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['C', 'A', 'B', 'B']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['B', 'B', 'C', 'A']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  index</th><th>value  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">      0</td><td>A      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      1</td><td>A      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      2</td><td>C      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      3</td><td>B      </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[Element(index=0, value='A'), Element(index=1, value='A'), Element(index=2, value='C'), Element(index=3, value='B')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'B', 'C', 'C']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 1, 2, 3]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['B']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['B']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.map(lambda x: {'B': 'D'}.get(x, x))\n",
    "\n",
    "l.filter(lambda x: get_prev(x) == 'B').select(_.value)\n",
    "\n",
    "find_fn = _.index == 1\n",
    "l.filter(find_fn).select(_.value).map(lower)\n",
    "\n",
    "find_fn = _.value == 'C'\n",
    "l.filter(find_fn).select(_.index)\n",
    "\n",
    "# move x to first\n",
    "update_filter = _.value == 'C'\n",
    "get_new = lambda x: -1\n",
    "l.map(lambda x: Element(update_fn(x, 'index'), x.value)).order_by(_.index).select(_.value)\n",
    "\n",
    "# swap first and last\n",
    "update_filter = true\n",
    "get_new = lambda x: {0: n - 1, n - 1: 0}.get(x.index, x.index)\n",
    "l.map(lambda x: Element(update_fn(x, 'index'), x.value)).order_by(_.index).select(_.value)\n",
    "\n",
    "# get inbetween == drop_while + take_while?\n",
    "\n",
    "# update by index to its prev\n",
    "update_filter = _.index == 1\n",
    "get_new = lambda x: get_prev(x)\n",
    "def update_fn(x, update_field): return get_new(x) if update_filter(x) else getattr(x, update_field)\n",
    "l.map(lambda x: Element(x.index, update_fn(x, 'value')))\n",
    "\n",
    "# if two adjacent elements by indices are equal\n",
    "l.filter(lambda x: x.index in [0, 1]).select(_.value).distinct().len() == 1\n",
    "\n",
    "seq('A B C B C'.split()).group_by(_).select(_[1]).flatten()\n",
    "\n",
    "# count occurance till current\n",
    "seq('A B A C B A'.split()).inits().reverse().tail().map(lambda x: x.filter(_ == x.last()).len())\n",
    "\n",
    "# find special\n",
    "seq('A B A A'.split()).count_by_value().filter(_[1] == 1).select(_[0])\n",
    "\n",
    "# generalized find special\n",
    "seq('A A B C C D D'.split()).group_by(_).map(lambda x: (x[0], len(x[1]))).filter(_[1] == 1).select(_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b3e124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
