{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "source": [
    "from IPython import get_ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "source": [
    "import sys\n",
    "# sys.path.insert(0, '/nas/xd/projects/transformers/src/transformers')\n",
    "import os\n",
    "device_mappings = {0: 1, 1: 5, 2: 6, 3: 7, 4: 2, 5: 3, 6: 0, 1: 4}\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(device_mappings[2])\n",
    "\n",
    "import random\n",
    "import string\n",
    "from collections import defaultdict, OrderedDict\n",
    "from itertools import product, chain\n",
    "import math\n",
    "import numpy as np\n",
    "import logging\n",
    "import types\n",
    "\n",
    "from pattern.en import comparative\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# from captum.attr import IntegratedGradients, LayerConductance, LayerIntegratedGradients\n",
    "# from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "import transformers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "source": [
    "transformers.__version__"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'4.18.0.dev0'"
      ]
     },
     "metadata": {},
     "execution_count": 167
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "from torch.utils.data.dataset import Dataset, IterableDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler, Sampler, SequentialSampler\n",
    "from enum import Enum\n",
    "from typing import List, Optional, Union\n",
    "# from transformers import RobertaForMaskedLM\n",
    "\n",
    "\n",
    "from transformers import HfArgumentParser, Trainer, TrainingArguments, set_seed\n",
    "from transformers import AutoConfig, PreTrainedModel, RobertaForMaskedLM, RobertaTokenizer\n",
    "# from transformers.modeling_roberta import RobertaForProbing, RobertaDoubleHeadsModel, \\\n",
    "#     RobertaDoubleHeadsModel2, RobertaDoubleHeadsModel3, RobertaForSequenceClassification  # XD\n",
    "# from transformers.trainer import get_mean_pred_prob  # XD\n",
    "from transformers.data.data_collator import DataCollator, default_data_collator\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPTNeoForCausalLM, GPTJForCausalLM, XGLMForCausalLM\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# from child_frames import frames\n",
    "# from child_utils import *"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "from common_utils import *\n",
    "from utils import *"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 存放所有模型和对应tokenizer的全局字典"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "models = {}\n",
    "cache_dir = '/nas/xd/.cache/torch/transformers/'  # for models besides t5-3b/11b\n",
    "proxies = {'http': '192.168.50.1:1081'} "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 本地模型（模型越大，加载越慢，可长达10几分钟）\n",
    "EleutherAI gpt-neo模型包括gpt-neo-1.3B、gpt-neo-2.7B和gpt-j-6B共3个。\n",
    "gpt-neo模型对应的**同等大小**gpt3模型见注释"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model_name = 't5-11b'\n",
    "# model = model11b = T5ForConditionalGeneration.from_pretrained(model_name, proxies=proxies, cache_dir=cache_dir)\n",
    "# tokenizer = T5Tokenizer.from_pretrained('t5-3b', proxies=proxies, cache_dir=cache_dir)\n",
    "# models[model_name] = model, tokenizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model_name = 'google/t5-v1_1-xxl'\n",
    "# model = T5ForConditionalGeneration.from_pretrained(model_name, proxies=proxies, cache_dir=cache_dir)\n",
    "# models[model_name] = model, tokenizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model_name = \"EleutherAI/gpt-neo-1.3B\"  # = gpt3 babbage\n",
    "# model = GPTNeoForCausalLM.from_pretrained(model_name, proxies=proxies, cache_dir=cache_dir)\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2', cache_dir=cache_dir)\n",
    "# models[model_name] = model, tokenizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model_name = \"EleutherAI/gpt-neo-2.7B\"\n",
    "# model = GPTNeoForCausalLM.from_pretrained(model_name, proxies=proxies, cache_dir=cache_dir)\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2', cache_dir=cache_dir)\n",
    "# models[model_name] = model, tokenizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "model_name = \"EleutherAI/gpt-j-6B\"  # = gpt3 curie\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', cache_dir=cache_dir)\n",
    "model = GPTJForCausalLM.from_pretrained(model_name, proxies=proxies, cache_dir=cache_dir)\n",
    "models[model_name] = model, tokenizer"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "In cached_path: url_or_filename = https://huggingface.co/gpt2/resolve/main/vocab.json\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "In cached_path: url_or_filename = https://huggingface.co/gpt2/resolve/main/merges.txt\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "In cached_path: url_or_filename = https://huggingface.co/gpt2/resolve/main/added_tokens.json\n",
      "In cached_path: url_or_filename = https://huggingface.co/gpt2/resolve/main/special_tokens_map.json\n",
      "In cached_path: url_or_filename = https://huggingface.co/gpt2/resolve/main/tokenizer_config.json\n",
      "In cached_path: url_or_filename = https://huggingface.co/gpt2/resolve/main/config.json\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-j-6B/resolve/main/config.json\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/gpt-j-6B-config.json\n",
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-j-6B/resolve/main/pytorch_model.bin\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/026f12960ffab80e6f4f983cd8672c6f4579e3a12d469f0cad87973e86376f78.c38ac789b8cf0cadade691fc5f5045ad1b1b47f34d438e40a578f6154f250b25\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "model_name = \"gpt2-xl\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', cache_dir=cache_dir)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name, proxies=proxies, cache_dir=cache_dir)\n",
    "models[model_name] = model, tokenizer"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "In cached_path: url_or_filename = https://huggingface.co/gpt2/resolve/main/vocab.json\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "In cached_path: url_or_filename = https://huggingface.co/gpt2/resolve/main/merges.txt\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "In cached_path: url_or_filename = https://huggingface.co/gpt2/resolve/main/added_tokens.json\n",
      "In cached_path: url_or_filename = https://huggingface.co/gpt2/resolve/main/special_tokens_map.json\n",
      "In cached_path: url_or_filename = https://huggingface.co/gpt2/resolve/main/tokenizer_config.json\n",
      "In cached_path: url_or_filename = https://huggingface.co/gpt2/resolve/main/config.json\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "In cached_path: url_or_filename = https://huggingface.co/gpt2-xl/resolve/main/config.json\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/gpt2-xl-config.json\n",
      "In cached_path: url_or_filename = https://huggingface.co/gpt2-xl/resolve/main/pytorch_model.bin\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/96569b907e56747ce3e593c6a13d8475b8c733a64aab8af8f602b90d94c4af71.8fbbcdf404c82c5967934d411f1462fa0574d639f2aa398aa3754fced1bb26c0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model_name = \"KoboldAI/fairseq-dense-13B\"\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2', cache_dir=cache_dir)\n",
    "# model = XGLMForCausalLM.from_pretrained(model_name, proxies=proxies, cache_dir=cache_dir)\n",
    "# models[model_name] = model, tokenizer"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "model_name = \"KoboldAI/fairseq-dense-6.7B\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', cache_dir=cache_dir)\n",
    "model = XGLMForCausalLM.from_pretrained(model_name, proxies=proxies, cache_dir=cache_dir)\n",
    "models[model_name] = model, tokenizer"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "In cached_path: url_or_filename = https://huggingface.co/gpt2/resolve/main/vocab.json\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "In cached_path: url_or_filename = https://huggingface.co/gpt2/resolve/main/merges.txt\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "In cached_path: url_or_filename = https://huggingface.co/gpt2/resolve/main/added_tokens.json\n",
      "In cached_path: url_or_filename = https://huggingface.co/gpt2/resolve/main/special_tokens_map.json\n",
      "In cached_path: url_or_filename = https://huggingface.co/gpt2/resolve/main/tokenizer_config.json\n",
      "In cached_path: url_or_filename = https://huggingface.co/gpt2/resolve/main/config.json\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "In cached_path: url_or_filename = https://huggingface.co/KoboldAI/fairseq-dense-6.7B/resolve/main/config.json\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/f3ca1164068c9d2a342a883597feeed7038ecda6354785381398289bed69cd28.524ccfd6e596466033350df77f0a5d29a4450b2ab2f660b004057a68b784ea22\n",
      "In cached_path: url_or_filename = https://huggingface.co/KoboldAI/fairseq-dense-6.7B/resolve/main/pytorch_model.bin\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/dab7edac52a182b5159e6f5e964c51ce0d71499f5a8d2caf668c6f8416771600.c86f13193fbbc452c8178e6702db53f828994b010629e703e6dfbc9a63ac5d36\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### gpt3 api不同engines作为不同模型"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_model_fn(engine):  # XD\n",
    "    def fn(text):\n",
    "        return openai.Completion.create(engine=engine, prompt=text, max_tokens=0, echo=True, logprobs=5).choices[0]\n",
    "    return fn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "engines = ['davinci', 'curie', 'babbage', 'ada']\n",
    "for engine in engines:\n",
    "    model_name = 'openai_api_' + engine\n",
    "    model = get_model_fn(engine)\n",
    "    models[model_name] = model, tokenizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 从模型字典中用model_name选取模型和tokenizer，供后续使用"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# model_name = 'EleutherAI/gpt-neo-1.3B'\n",
    "# model_name = 'EleutherAI/gpt-neo-2.7B'\n",
    "model_name = 'EleutherAI/gpt-j-6B'\n",
    "# model_name = 'gpt2-xl'\n",
    "# model_name = 'KoboldAI/fairseq-dense-6.7B'\n",
    "# model_name = 'openai_api_davinci'\n",
    "# model_name = 'openai_api_curie'\n",
    "model, tokenizer = models[model_name]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# len(models)\n",
    "model.eval()\n",
    "# model\n",
    "#"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GPTJForCausalLM(\n",
       "  (transformer): GPTJModel(\n",
       "    (wte): Embedding(50400, 4096)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (24): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (25): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (26): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (27): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=50400, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Outputs:\n",
    "    inputs_embeds: torch.FloatTensor = None\n",
    "    position_embeds: torch.FloatTensor = None\n",
    "    attn_outputs: tuple = ()\n",
    "    intermediates: tuple = ()\n",
    "    mlp_outputs: tuple = ()\n",
    "    hidden_states: tuple = ()\n",
    "    attentions: tuple = ()\n",
    "    logits: torch.FloatTensor = None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "# forward function for gpt-neo\n",
    "def forward(model, inputs):\n",
    "    input_ids = inputs.input_ids\n",
    "#     print(input_ids.shape)\n",
    "    input_shape = input_ids.size()\n",
    "#     print(input_shape)\n",
    "    device = input_ids.device\n",
    "    position_ids = torch.arange(0, input_shape[-1], dtype=torch.long, device=device)\n",
    "    \n",
    "    position_ids = position_ids.unsqueeze(0).view(-1, input_shape[-1])\n",
    "#     print(position_ids.shape)\n",
    "    self = model.transformer\n",
    "    inputs_embeds = self.wte(input_ids)\n",
    "#     print(inputs_embeds.shape)\n",
    "    position_embeds = self.wpe(position_ids)\n",
    "    hidden_states = inputs_embeds + position_embeds\n",
    "    hidden_states = self.drop(hidden_states)\n",
    "    attn_outputs, intermediates, mlp_outputs = (), (), ()\n",
    "    all_hidden_states, all_attentions = (), ()\n",
    "    for i, b in enumerate(self.h):\n",
    "        all_hidden_states += (hidden_states,)\n",
    "#         print(b.attn(b.ln_1(hidden_states),output_attentions=True)[0].shape,b.attn(b.ln_1(hidden_states),output_attentions=True)[2].shape)\n",
    "        attn_output, _,attention = b.attn(b.ln_1(hidden_states),output_attentions=True)\n",
    "#         print(attention.shape) \n",
    "        attn_outputs += (attn_output,)\n",
    "        all_attentions += (attention,)\n",
    "        hidden_states = hidden_states + attn_output\n",
    "        mlp_output, intermediate = b.mlp(b.ln_2(hidden_states), return_intermediate=True)\n",
    "        intermediates += (intermediate,)\n",
    "        mlp_outputs += (mlp_output,)\n",
    "        hidden_states = hidden_states + mlp_output\n",
    "    all_hidden_states += (hidden_states,) # both before and after ln_f\n",
    "    hidden_states = self.ln_f(hidden_states)\n",
    "    all_hidden_states += (hidden_states,)\n",
    "    logits = model.lm_head(hidden_states)\n",
    "    return Outputs(\n",
    "        inputs_embeds=inputs_embeds, position_embeds=position_embeds,\n",
    "        attn_outputs=attn_outputs, intermediates=intermediates, mlp_outputs=mlp_outputs,\n",
    "        hidden_states=all_hidden_states, attentions=all_attentions, logits=logits,\n",
    "    )\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# forward function for gpt-j,没有l2 laynormal 而且不是残差相加\n",
    "def forwardGPTJ(model, inputs):\n",
    "    input_ids = inputs.input_ids\n",
    "    input_shape = input_ids.size()\n",
    "    device = input_ids.device\n",
    "    # position_ids = torch.arange(0, input_shape[-1], dtype=torch.long, device=device)\n",
    "    # position_ids = position_ids.unsqueeze(0).view(-1, input_shape[-1])\n",
    "    self = model.transformer\n",
    "    inputs_embeds = self.wte(input_ids)\n",
    "#     print(inputs_embeds.shape)\n",
    "    # position_embeds = self.wpe(position_ids)\n",
    "    # hidden_states = inputs_embeds + position_embeds\n",
    "    hidden_states=inputs_embeds\n",
    "    hidden_states = self.drop(hidden_states)\n",
    "    attn_outputs, intermediates, mlp_outputs = (), (), ()\n",
    "    all_hidden_states, all_attentions = (), ()\n",
    "    for i, b in enumerate(self.h):\n",
    "        all_hidden_states += (hidden_states,)\n",
    "#         print(b.attn(b.ln_1(hidden_states),output_attentions=True)[0].shape,b.attn(b.ln_1(hidden_states),output_attentions=True)[2].shape)\n",
    "        residual=hidden_states\n",
    "        attn_output, _,attention = b.attn(b.ln_1(hidden_states),output_attentions=True)\n",
    "#         print(attention.shape) \n",
    "        attn_outputs += (attn_output,)\n",
    "        all_attentions += (attention,)\n",
    "        # hidden_states = hidden_states + attn_output\n",
    "        mlp_output = b.mlp(b.ln_1(hidden_states))#\n",
    "        # intermediates += (intermediate,)\n",
    "        mlp_outputs += (mlp_output,)\n",
    "        hidden_states = residual + attn_output + mlp_output\n",
    "    all_hidden_states += (hidden_states,) # both before and after ln_f\n",
    "    hidden_states = self.ln_f(hidden_states)\n",
    "    all_hidden_states += (hidden_states,)\n",
    "    logits = model.lm_head(hidden_states)\n",
    "    return Outputs(\n",
    "        inputs_embeds=inputs_embeds, position_embeds=None,\n",
    "        attn_outputs=attn_outputs, intermediates=intermediates, mlp_outputs=mlp_outputs,\n",
    "        hidden_states=all_hidden_states, attentions=all_attentions, logits=logits,\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "source": [
    "# forward function for gpt-xl\n",
    "def forwardxl(model, inputs):\n",
    "    input_ids = inputs.input_ids\n",
    "#     print(input_ids.shape)\n",
    "    input_shape = input_ids.size()\n",
    "#     print(input_shape)\n",
    "    device = input_ids.device\n",
    "    position_ids = torch.arange(0, input_shape[-1], dtype=torch.long, device=device)\n",
    "    position_ids = position_ids.unsqueeze(0).view(-1, input_shape[-1])\n",
    "#     print(position_ids.shape)\n",
    "    self = model.transformer\n",
    "    inputs_embeds = self.wte(input_ids)\n",
    "#     print(inputs_embeds.shape)\n",
    "    position_embeds = self.wpe(position_ids)\n",
    "    hidden_states = inputs_embeds + position_embeds\n",
    "    hidden_states = self.drop(hidden_states)\n",
    "    attn_outputs, intermediates, mlp_outputs = (), (), ()\n",
    "    all_hidden_states, all_attentions = (), ()\n",
    "    for i, b in enumerate(self.h):\n",
    "        all_hidden_states += (hidden_states,)\n",
    "#         print(b.attn(b.ln_1(hidden_states),output_attentions=True)[0].shape,b.attn(b.ln_1(hidden_states),output_attentions=True)[2].shape)\n",
    "        attn_output, _,attention = b.attn(b.ln_1(hidden_states),output_attentions=True)\n",
    "#         print(attention.shape) \n",
    "        attn_outputs += (attn_output,)\n",
    "        all_attentions += (attention,)\n",
    "        hidden_states = hidden_states + attn_output\n",
    "        mlp_output = b.mlp(b.ln_2(hidden_states))\n",
    "        # intermediates += (intermediate,)\n",
    "        mlp_outputs += (mlp_output,)\n",
    "        hidden_states = hidden_states + mlp_output\n",
    "    all_hidden_states += (hidden_states,) # both before and after ln_f\n",
    "    hidden_states = self.ln_f(hidden_states)\n",
    "    all_hidden_states += (hidden_states,)\n",
    "    logits = model.lm_head(hidden_states)\n",
    "    return Outputs(\n",
    "        inputs_embeds=inputs_embeds, position_embeds=position_embeds,\n",
    "        attn_outputs=attn_outputs, intermediates=intermediates, mlp_outputs=mlp_outputs,\n",
    "        hidden_states=all_hidden_states, attentions=all_attentions, logits=logits,\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "source": [
    "# forward function for XGLM\n",
    "def forwardXGLM(model, inputs):\n",
    "    input_ids = inputs.input_ids\n",
    "#     print(input_ids.shape)\n",
    "    input_shape = input_ids.size()\n",
    "#     print(input_shape)\n",
    "    device = input_ids.device\n",
    "#     print(position_ids.shape)\n",
    "    self = model.model\n",
    "    inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale\n",
    "#     print(inputs_embeds.shape)\n",
    "    attention_mask = self._prepare_decoder_attention_mask(\n",
    "        None, input_shape, inputs_embeds, 0)\n",
    "    position_embeds = self.embed_positions(input_ids, inputs_embeds, 0)\n",
    "    hidden_states = inputs_embeds + position_embeds\n",
    "    hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n",
    "    attn_outputs, intermediates, mlp_outputs = (), (), ()\n",
    "    all_hidden_states, all_attentions = (), ()\n",
    "    for i, b in enumerate(self.layers):\n",
    "        all_hidden_states += (hidden_states,)\n",
    "        dropout_probability = random.uniform(0, 1)\n",
    "        if self.training and (dropout_probability < self.layerdrop):\n",
    "            continue\n",
    "        residual = hidden_states\n",
    "        hidden_states = b.self_attn_layer_norm(hidden_states)\n",
    "        attn_output, attention,_ = b.self_attn(hidden_states,attention_mask=attention_mask,output_attentions=True)\n",
    "#         print(attention.shape) \n",
    "        attn_outputs += (attn_output,)\n",
    "        all_attentions += (attention,)\n",
    "        hidden_states = nn.functional.dropout(attn_output, p=b.dropout, training=b.training)\n",
    "        hidden_states = hidden_states + residual\n",
    "\n",
    "        residual = hidden_states\n",
    "        hidden_states = b.final_layer_norm(hidden_states)\n",
    "        hidden_states = b.activation_fn(b.fc1(hidden_states))\n",
    "        hidden_states = nn.functional.dropout(hidden_states, p=b.activation_dropout, training=b.training)\n",
    "        hidden_states = b.fc2(hidden_states)\n",
    "        hidden_states = nn.functional.dropout(hidden_states, p=b.dropout, training=b.training)\n",
    "        mlp_outputs += (hidden_states,)\n",
    "        hidden_states = residual + hidden_states\n",
    "\n",
    "    all_hidden_states += (hidden_states,) # both before and after ln_f\n",
    "    hidden_states = self.layer_norm(hidden_states)\n",
    "    all_hidden_states += (hidden_states,)\n",
    "    logits = model.lm_head(hidden_states)\n",
    "    return Outputs(\n",
    "        inputs_embeds=inputs_embeds, position_embeds=position_embeds,\n",
    "        attn_outputs=attn_outputs, intermediates=intermediates, mlp_outputs=mlp_outputs,\n",
    "        hidden_states=all_hidden_states, attentions=all_attentions, logits=logits,\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "text = '''Instruction: ith element. For example:\n",
    "5 T 7 -> T\n",
    "S 0 E -> 0\n",
    "'''\n",
    "print(text)\n",
    "inputs = tokenizer.encode_plus(text, return_tensors='pt')\n",
    "# inputs = prepare_inputs(inputs, model.device)\n",
    "input_ids = inputs.input_ids\n",
    "input_ids"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Instruction: ith element. For example:\n",
      "5 T 7 -> T\n",
      "S 0 E -> 0\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[6310, 2762,   25,  340,   71, 5002,   13, 1114, 1672,   25,  198,   20,\n",
       "          309,  767, 4613,  309,  198,   50,  657,  412, 4613,  657,  198]])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "with torch.no_grad(): o = forwardGPTJ(model, inputs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "ans=model.transformer(input_ids)[0]\n",
    "ans.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 23, 4096])"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "norm(ans)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'norm' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-25d7e6e59bc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'norm' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "source": [
    "norm(o.hidden_states[-1])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "64.0"
      ]
     },
     "metadata": {},
     "execution_count": 153
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "source": [
    "(ans-o.hidden_states[-1]).abs().mean()\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.6370, grad_fn=<MeanBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 154
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "source": [
    "ans.abs().mean()\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.5097, grad_fn=<MeanBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 155
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "观察每层的隐状态、attention输出、mlp输出的模长"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "def norm(tensor, p=2): return tensor.norm(p=p, dim=-1).mean().round().item()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#gpt-new\n",
    "[(norm(state), norm(attn_o), norm(state + attn_o), norm(mlp_o), (intm > 0).float().mean())\n",
    " for state, attn_o, intm, mlp_o in zip(o.hidden_states, o.attn_outputs, o.intermediates, o.mlp_outputs)]\n",
    "norm(o.hidden_states[-2])\n",
    "norm(o.hidden_states[-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "##gpt 6j\n",
    "[(norm(state), norm(attn_o), norm(state + attn_o), norm(mlp_o))\n",
    " for state, attn_o, mlp_o in zip(o.hidden_states, o.attn_outputs, o.mlp_outputs)]\n",
    "# norm(o.hidden_states[-2])\n",
    "# norm(o.hidden_states[-1])\n",
    "o.attentions[0].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(2.0, 11.0, 11.0, 37.0),\n",
       " (40.0, 9.0, 39.0, 12.0),\n",
       " (42.0, 12.0, 43.0, 181.0),\n",
       " (209.0, 9.0, 210.0, 27.0),\n",
       " (227.0, 9.0, 228.0, 16.0),\n",
       " (233.0, 12.0, 236.0, 18.0),\n",
       " (239.0, 11.0, 239.0, 19.0),\n",
       " (245.0, 13.0, 247.0, 19.0),\n",
       " (249.0, 13.0, 250.0, 21.0),\n",
       " (255.0, 14.0, 257.0, 24.0),\n",
       " (264.0, 14.0, 267.0, 23.0),\n",
       " (271.0, 15.0, 272.0, 25.0),\n",
       " (276.0, 14.0, 278.0, 24.0),\n",
       " (281.0, 16.0, 282.0, 25.0),\n",
       " (289.0, 12.0, 289.0, 24.0),\n",
       " (295.0, 15.0, 297.0, 24.0),\n",
       " (304.0, 13.0, 306.0, 26.0),\n",
       " (315.0, 16.0, 318.0, 27.0),\n",
       " (325.0, 15.0, 327.0, 30.0),\n",
       " (338.0, 12.0, 339.0, 33.0),\n",
       " (353.0, 17.0, 355.0, 34.0),\n",
       " (371.0, 10.0, 369.0, 31.0),\n",
       " (382.0, 13.0, 382.0, 28.0),\n",
       " (391.0, 10.0, 391.0, 29.0),\n",
       " (397.0, 16.0, 399.0, 45.0),\n",
       " (400.0, 13.0, 400.0, 77.0),\n",
       " (381.0, 14.0, 385.0, 125.0),\n",
       " (359.0, 17.0, 370.0, 163.0)]"
      ]
     },
     "metadata": {},
     "execution_count": 40
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 23, 23])"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [
    "#gpt-xl\n",
    "[(norm(state), norm(attn_o), norm(state + attn_o), norm(mlp_o))\n",
    " for state, attn_o, mlp_o in zip(o.hidden_states, o.attn_outputs, o.mlp_outputs)]\n",
    "norm(o.hidden_states[-2])\n",
    "norm(o.hidden_states[-1])\n",
    "# print(len(o.hidden_states))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(2.0, 1.0, 2.0, 24.0),\n",
       " (24.0, 8.0, 28.0, 18.0),\n",
       " (43.0, 11.0, 51.0, 11.0),\n",
       " (57.0, 8.0, 62.0, 10.0),\n",
       " (66.0, 6.0, 68.0, 10.0),\n",
       " (71.0, 7.0, 73.0, 11.0),\n",
       " (76.0, 7.0, 77.0, 12.0),\n",
       " (80.0, 7.0, 80.0, 29.0),\n",
       " (98.0, 6.0, 99.0, 38.0),\n",
       " (127.0, 6.0, 128.0, 35.0),\n",
       " (154.0, 7.0, 156.0, 32.0),\n",
       " (177.0, 7.0, 179.0, 31.0),\n",
       " (200.0, 7.0, 201.0, 27.0),\n",
       " (218.0, 10.0, 220.0, 25.0),\n",
       " (234.0, 8.0, 236.0, 25.0),\n",
       " (249.0, 8.0, 252.0, 22.0),\n",
       " (264.0, 8.0, 266.0, 20.0),\n",
       " (274.0, 10.0, 277.0, 20.0),\n",
       " (284.0, 9.0, 287.0, 20.0),\n",
       " (294.0, 10.0, 296.0, 20.0),\n",
       " (302.0, 9.0, 305.0, 19.0),\n",
       " (310.0, 9.0, 312.0, 18.0),\n",
       " (316.0, 9.0, 319.0, 18.0),\n",
       " (324.0, 10.0, 327.0, 19.0),\n",
       " (332.0, 10.0, 335.0, 19.0),\n",
       " (339.0, 12.0, 343.0, 21.0),\n",
       " (348.0, 12.0, 352.0, 21.0),\n",
       " (358.0, 10.0, 362.0, 22.0),\n",
       " (368.0, 13.0, 373.0, 23.0),\n",
       " (380.0, 12.0, 384.0, 24.0),\n",
       " (392.0, 12.0, 395.0, 24.0),\n",
       " (401.0, 13.0, 406.0, 25.0),\n",
       " (414.0, 13.0, 419.0, 24.0),\n",
       " (426.0, 15.0, 432.0, 25.0),\n",
       " (439.0, 13.0, 445.0, 27.0),\n",
       " (454.0, 15.0, 459.0, 27.0),\n",
       " (466.0, 16.0, 472.0, 28.0),\n",
       " (480.0, 15.0, 486.0, 30.0),\n",
       " (495.0, 16.0, 499.0, 33.0),\n",
       " (508.0, 15.0, 515.0, 35.0),\n",
       " (524.0, 16.0, 531.0, 39.0),\n",
       " (537.0, 16.0, 545.0, 46.0),\n",
       " (545.0, 20.0, 556.0, 55.0),\n",
       " (555.0, 25.0, 570.0, 64.0),\n",
       " (563.0, 37.0, 587.0, 85.0),\n",
       " (582.0, 54.0, 618.0, 97.0),\n",
       " (614.0, 70.0, 624.0, 74.0),\n",
       " (620.0, 40.0, 629.0, 62.0)]"
      ]
     },
     "metadata": {},
     "execution_count": 145
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "631.0"
      ]
     },
     "metadata": {},
     "execution_count": 145
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "metadata": {},
     "execution_count": 145
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "50\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "#gpt-xgm\n",
    "[(norm(state), norm(attn_o), norm(state + attn_o), norm(mlp_o))\n",
    " for state, attn_o, mlp_o in zip(o.hidden_states, o.attn_outputs, o.mlp_outputs)]\n",
    "norm(o.hidden_states[-2])\n",
    "norm(o.hidden_states[-1])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(109.0, 230.0, 255.0, 49.0),\n",
       " (263.0, 31.0, 270.0, 39.0),\n",
       " (265.0, 32.0, 265.0, 41.0),\n",
       " (263.0, 30.0, 259.0, 42.0),\n",
       " (260.0, 37.0, 265.0, 41.0),\n",
       " (266.0, 34.0, 269.0, 38.0),\n",
       " (269.0, 31.0, 275.0, 31.0),\n",
       " (274.0, 32.0, 279.0, 29.0),\n",
       " (279.0, 38.0, 283.0, 31.0),\n",
       " (281.0, 36.0, 282.0, 33.0),\n",
       " (279.0, 43.0, 284.0, 32.0),\n",
       " (286.0, 42.0, 293.0, 32.0),\n",
       " (296.0, 47.0, 302.0, 29.0),\n",
       " (302.0, 47.0, 312.0, 32.0),\n",
       " (313.0, 46.0, 324.0, 32.0),\n",
       " (322.0, 45.0, 327.0, 33.0),\n",
       " (327.0, 54.0, 340.0, 37.0),\n",
       " (340.0, 48.0, 350.0, 37.0),\n",
       " (351.0, 48.0, 361.0, 36.0),\n",
       " (361.0, 55.0, 378.0, 40.0),\n",
       " (376.0, 57.0, 390.0, 41.0),\n",
       " (387.0, 63.0, 399.0, 44.0),\n",
       " (395.0, 79.0, 420.0, 49.0),\n",
       " (422.0, 83.0, 452.0, 44.0),\n",
       " (451.0, 96.0, 487.0, 49.0),\n",
       " (493.0, 90.0, 526.0, 54.0),\n",
       " (531.0, 85.0, 561.0, 57.0),\n",
       " (567.0, 95.0, 593.0, 63.0),\n",
       " (598.0, 95.0, 622.0, 67.0),\n",
       " (625.0, 98.0, 629.0, 68.0),\n",
       " (634.0, 107.0, 663.0, 70.0),\n",
       " (670.0, 109.0, 676.0, 72.0)]"
      ]
     },
     "metadata": {},
     "execution_count": 78
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "679.0"
      ]
     },
     "metadata": {},
     "execution_count": 78
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "64.0"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "all_relation_groups = [('big', 'small'), ('tall', 'short'), ('wide', 'narrow'), ('fast', 'slow'), ('near', 'far'),\n",
    "                   ('bright', 'dark'), ('early', 'late'), ('heavy', 'light'), ('hot', 'cold'), ('strong', 'weak'), \n",
    "                   ('rich', 'poor'), ('old', 'young'), ('easy', 'hard'), ('old', 'new'), ('high', 'low'), ('good', 'bad'),]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tokenizer.tokenize('Yes, _Z is < smaller }.')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "A_template = \"{rel_prefix} {dt} {ent0} {rel} {dt} {ent1}\"\n",
    "B_template = \"{pred_prefix} {dt} {ent} {pred}\"\n",
    "entailment_templates = [\"{A} , so {B} ? {conj} .\", '\"{A}\" {conj} \"{B}\" .', \"{A} .||| {B} .|||{conj}\",\n",
    "                        \"{option_prefix}{A}? {conj}, {B}.\", \"{option_prefix}{A}, so {B}.\"]\n",
    "\n",
    "_tag2id = {'same': 0, 'opposite': 1, 'unrelated': 2, 'former': 0, 'latter': 1, 'another': 5, 'single': 6, 'paired': 7}\n",
    "tag2id = {'Ġ' + k: v for k, v in _tag2id.items()}\n",
    "id2tag = {v: k for k, v in tag2id.items()}\n",
    "\n",
    "markers = {'lexical': '*', 'entity': '#'}\n",
    "ans2verb = {'Right': 'means', 'Wrong': 'contradicts', 'Maybe': ','}\n",
    "ans2adj = {'Right': 'clear', 'Wrong': 'unlikely', 'Maybe': 'possible'}\n",
    "ans2label = {'Right': 'e', 'Wrong': 'c', 'Maybe': 'n'}\n",
    "ans2yesno = {'Right': 'Yes', 'Wrong': 'No', 'Maybe': 'Maybe'}\n",
    "\n",
    "def convert_conj(conj): return ans2verb[conj]\n",
    "def extract_rel_id(s): return int(s[s.index(':') + 1])\n",
    "def extract_rel(s): return [t.split(':')[0] for t in s.split() if ':' in t][0]\n",
    "def strip_rel_id(s, lexical_rel=''):\n",
    "    rel_id_span = s[s.index(':'): s.index(':') + 2]\n",
    "    if lexical_rel != '': lexical_rel = ' ( ' + lexical_rel + ' )'\n",
    "    return s.replace(rel_id_span, lexical_rel)\n",
    "def tag_entity(token, recurred_entity, entity_rel=None):\n",
    "    if token != recurred_entity: return token\n",
    "    return markers['entity'] + ' ' + token\n",
    "def get_option_prefix(relation_group, rels, bracket_rels=False):\n",
    "    comp_rel_group = [[get_comparative(r, False) for r in relations] for relations in relation_group]\n",
    "    assert set(rels).issubset(set(chain.from_iterable(comp_rel_group))), str(rels) + ' ' + str(comp_rel_group)\n",
    "    labeled_rels = [(r, 0 if r in comp_rel_group[0] else 1) for r in rels]\n",
    "    missing_idx = {0, 1} - set(i[1] for i in labeled_rels)\n",
    "    assert len(missing_idx) in [0, 1], str(len(missing_idx))\n",
    "    if len(missing_idx) == 1:\n",
    "        missing_idx = missing_idx.pop()\n",
    "        labeled_rels = [labeled_rels[1], (comp_rel_group[missing_idx][0], missing_idx)]  # B's rel + missing rel\n",
    "    options = [rel for rel, _ in sorted(labeled_rels, key=lambda x: x[1])]\n",
    "    return 'Options: [ %s ] or [ %s ]? ' % (options[0], options[1]) if bracket_rels \\\n",
    "        else '%s or %s? ' % (options[0].capitalize(), options[1])  # \n",
    "        \n",
    "def substitute(templates, entities, entity_set, n_entity_trials):\n",
    "    substituted_groups = []\n",
    "    for template in templates:\n",
    "        group = []\n",
    "        for _ in range(n_entity_trials):\n",
    "            e0, e1 = random.sample(entity_set, 2)\n",
    "            group.append(template.replace(entities[0], e0).replace(entities[1], e1))\n",
    "        substituted_groups.append(group)\n",
    "    return substituted_groups\n",
    " \n",
    "def to_question(A): return 'Is ' + A.replace(' is', '')\n",
    "relation_labels = {'entity': ['former', 'latter'], 'lexical': ['same', 'opposite', 'unrelated']}\n",
    "\n",
    "def make_sentences(entities=['_X', '_Z'], entity_set=string.ascii_uppercase, determiner=\"\",\n",
    "                   relation_group=[['large'], ['small']], rand_relation_group=[[\"short\"], [\"tall\", \"high\"]],\n",
    "                   relation_prefix=\"\", relation_suffix=\"\", predicate_prefix=\"\", n_entity_trials=3, \n",
    "                   has_negA=False, has_negB=False, has_neutral=False, mask_types={'none'}, has_options=False, bracket_rels=False,\n",
    "                   lexical_relations=None, entity_relations=None, tag_lexical_rel=False, tag_entity_rel=False):\n",
    "    entities = ['@' + e for e in entities] # to avoid wrong swap_entities if entities are single letters\n",
    "    relation_group = [r if isinstance(r, list) else [r] for r in relation_group]\n",
    "    def form_As(relations):\n",
    "        return [A_template.format(dt=determiner, ent0=ent0, ent1=ent1, rel=rel, rel_prefix=relation_prefix)\n",
    "              for ent0, ent1, rel in [entities + relations[:1], reverse(entities) + reverse(relations)[:1]]]\n",
    "    As = []\n",
    "    for rel0 in relation_group[0]:\n",
    "        for rel1 in relation_group[1]:\n",
    "            relations = [\"is %s:%d than\" % (get_comparative(rel, tag_lexical_rel), i) for i, rel in enumerate([rel0, rel1])]\n",
    "            As += form_As(relations)\n",
    "#     As = list(set(As))\n",
    "    negAs = join_lists([negate_sent(A)[:1] for A in As]) if has_negA else []\n",
    "    \n",
    "    def form_Bs(predicates): \n",
    "        f = mask if 'entity' in mask_types else (lambda x: x)\n",
    "        return [B_template.format(dt=determiner, ent=f(ent), pred=pred, pred_prefix=predicate_prefix)\n",
    "              for ent, pred in zip(entities, predicates)]\n",
    "\n",
    "    Bs, negBs = {'orig': [], 'rand': []}, {}\n",
    "    for k, group in zip(['orig', 'rand'], [relation_group, rand_relation_group]):\n",
    "        for rel0 in group[0]:\n",
    "            for rel1 in group[1]:\n",
    "                predicates = [\"is %s:%d\" % (get_comparative(rel, tag_lexical_rel), i) for i, rel in enumerate([rel0, rel1])]\n",
    "                Bs[k] += form_Bs(predicates)\n",
    "                \n",
    "    for k in Bs:\n",
    "#         Bs[k] = list(set(Bs[k]))\n",
    "        if has_negB:\n",
    "            negBs[k] = join_lists([negate_sent(B)[:1] for B in Bs[k]])\n",
    "            Bs[k], negBs[k] = Bs[k] + [swap_entities(negB, *entities) for negB in negBs[k]], \\\n",
    "                negBs[k] + [swap_entities(B, *entities) for B in Bs[k]]\n",
    "        else:\n",
    "            negBs[k] = [swap_entities(B, *entities) for B in Bs[k]]\n",
    "      \n",
    "    comparatives = [comparative(r).replace('more ', '') for r in join_lists(relation_group) + join_lists(rand_relation_group)]\n",
    "    def form_sentences(sentence_template, As, Bs, conj):\n",
    "        def compare_and_tag_comparative(A, B):\n",
    "            lexical_rel = 'unrelated' if 'Maybe' in conj else ('same' if extract_rel_id(A) == extract_rel_id(B) else 'opposite')\n",
    "            if lexical_relations and lexical_rel not in lexical_relations: return None, None\n",
    "            if 'lexical_rel' in mask_types: lexical_rel = mask(lexical_rel)\n",
    "            return strip_rel_id(A), strip_rel_id(B, lexical_rel) if tag_lexical_rel else strip_rel_id(B)\n",
    "        def compare_and_tag_entity(A, B):\n",
    "            recurred_entity = [e for e in entities if e in B.split()][0]\n",
    "            if tag_entity_rel:\n",
    "                A = ' '.join([tag_entity(token, recurred_entity) for token in A.split()])\n",
    "                B = ' '.join([tag_entity(token, recurred_entity) for token in B.split()])\n",
    "            entity_rel = 'former' if A.split().index(recurred_entity) in [0, 1] else 'latter'\n",
    "            if entity_relations and entity_rel not in entity_relations: return None, None\n",
    "            if 'entity_rel' in mask_types: entity_rel = mask(entity_rel)\n",
    "            if tag_entity_rel: B = B.replace(recurred_entity, recurred_entity + ' ( ' + entity_rel + ' )')\n",
    "            return A, B\n",
    "        \n",
    "        _has_options = has_options and conj != 'Maybe'\n",
    "        if '?' not in sentence_template:\n",
    "            conj = ans2label[conj] if sentence_template.count('|||') == 2 else ans2verb[conj]\n",
    "        else: conj = ans2yesno[conj]\n",
    "        if 'sent_rel' in mask_types and conj not in ans2label.values(): conj = mask(conj)\n",
    "        sentences = []\n",
    "        for A, B in product(As, Bs):\n",
    "            A_rel, B_rel = extract_rel(A), extract_rel(B)\n",
    "            option_prefix = get_option_prefix(relation_group, [A_rel, B_rel], bracket_rels) if _has_options else ''\n",
    "            A, B = compare_and_tag_comparative(A, B) \\\n",
    "                if tag_lexical_rel or lexical_relations else (strip_rel_id(A), strip_rel_id(B))\n",
    "            if A is None: continue\n",
    "            if tag_entity_rel or entity_relations: A, B = compare_and_tag_entity(A, B)\n",
    "            if A is None: continue\n",
    "#             A = to_question(A)\n",
    "            if bracket_rels: B = B.replace(B_rel, '[ %s ] ' % B_rel)\n",
    "            sent = sentence_template.format(A=A, B=B, conj=conj, option_prefix=option_prefix)\n",
    "            sent = \" \".join(sent.split())\n",
    "            sentences.append(sent.replace('@', ''))\n",
    "        return sentences\n",
    "    \n",
    "    sentences = defaultdict(list)\n",
    "    for entailment_template in entailment_templates[-1:]:\n",
    "        for A, B, conj in [(As, Bs['orig'], 'Right'), (negAs, negBs['orig'], 'Right'), \n",
    "                           (As, negBs['orig'], 'Wrong'), (negAs, Bs['orig'], 'Wrong'),\n",
    "                           (As, Bs['rand'], 'Maybe'), (negAs, negBs['rand'], 'Maybe'), \n",
    "                           (As, negBs['rand'], 'Maybe'), (negAs, Bs['rand'], 'Maybe')]:\n",
    "            ss = form_sentences(entailment_template, A, B, conj)\n",
    "            sentences[conj] += ss\n",
    "    if len(sentences['Right']) != len(sentences['Wrong']):\n",
    "        assert entity_relations is not None and len(relation_group[0]) != len(relation_group[1])\n",
    "        min_len = min(len(sentences['Right']), len(sentences['Wrong']))\n",
    "        for key in ['Right', 'Wrong']:\n",
    "            if len(sentences[key]) > min_len: sentences[key] = random.sample(sentences[key], min_len)\n",
    "    if has_neutral: sentences['Maybe'] = random.sample(sentences['Maybe'], len(sentences['Right']))\n",
    "    sentences = {k: v for k, v in sentences.items() if has_neutral or k in ['Right', 'Wrong']}\n",
    "#     sentences = join_lists(sentences[k] for k in keys)\n",
    "#     if sample_ratio is not None:\n",
    "#         if sample_ratio < 1: sample_ratio = int(round(len(sentences) / sample_ratio))\n",
    "#         sentences = random.sample(sentences, sample_ratio) \n",
    "    return sentences\n",
    "\n",
    "make_sentences(has_negA=False, has_negB=False, has_neutral=False, tag_lexical_rel=False, tag_entity_rel=False,\n",
    "               has_options=True, bracket_rels=False, mask_types={'none'}, entity_relations={'former', 'latter'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def sample_sentence_ids(similar=False):\n",
    "    id_groups = [[0, 3], [1, 2]]\n",
    "    ids = choice(id_groups) if similar else [choice(id_group) for id_group in id_groups]\n",
    "    return sample(ids, 2)  # shuffle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "conj = 'Right'\n",
    "all_nlls = []\n",
    "random.seed(42)\n",
    "for i in range(len(all_relation_groups)//1):\n",
    "    n_sents = 4\n",
    "    entities_list = sample(string.ascii_uppercase, 2 * n_sents)\n",
    "    entities_list = [entities_list[j: j + 2] for j in range(0, len(entities_list), 2)]\n",
    "#     relation_groups = sample(all_relation_groups, 2)\n",
    "    relation_groups = [all_relation_groups[i]] * n_sents\n",
    "    sentence_ids = [0, 1, 2, 3] #+ sample_sentence_ids()#; print(sentence_ids)\n",
    "\n",
    "    sentences = [make_sentences(entities=entities, relation_group=rg, has_options=True, bracket_rels=False)[conj][sid] \\\n",
    "        for entities, rg, sid in zip(entities_list, relation_groups, sentence_ids)]\n",
    "#         text = '\\n'.join(sentences) + '\\n'\n",
    "    all_nlls.append([predict(model, sent+'\\n', get_ans_indices1, verbose=True, topk=3) for sent in sentences])\n",
    "    print()"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sentences = [\n",
    "    'Bigger or smaller? X is easier to put into a box than Y because X is smaller.',\n",
    "    'Bigger or smaller? X is easier to put into a box than Y because Y is bigger.', # change entity\n",
    "    'Bigger or smaller? X is harder to put into a box than Y because X is bigger.', # change keyword\n",
    "    'Bigger or smaller? X is harder to put into a box than Y because Y is smaller.', # change keyword + entity\n",
    "    'Bigger or smaller? X is easier to put into a box than Y although X is bigger.', # change conj\n",
    "    'Bigger or smaller? X is easier to put into a box than Y although Y is smaller.', # change conj + entity\n",
    "    'Bigger or smaller? X is harder to put into a box than Y although X is smaller.', # change conj + keyword\n",
    "    'Bigger or smaller? X is harder to put into a box than Y although Y is bigger.', # change conj + keyword + entity\n",
    "]\n",
    "text = '\\n'.join(sentences) + '\\n'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# davinci = 175B\n",
    "all_nlls = np.array(all_nlls)\n",
    "[math.exp(-all_nlls[:, indices].mean()) for indices in [[0], [1], [2], [3]]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# curie = 6B\n",
    "all_nlls = np.array(all_nlls)\n",
    "[math.exp(-all_nlls[:, indices].mean()) for indices in [[0], [1], [2], [3]]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 6B\n",
    "all_nlls = np.array(all_nlls)\n",
    "[math.exp(-all_nlls[:, indices].mean()) for indices in [[0], [1], [2], [3]]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 6B\n",
    "all_nlls = np.array(all_nlls)\n",
    "[math.exp(-all_nlls[:, indices].mean()) for indices in [[0], [1], ]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 6B\n",
    "all_nlls = np.array(all_nlls)\n",
    "[math.exp(-all_nlls[:, indices].mean()) for indices in [[0], [1], ]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model_name = 'EleutherAI/gpt-neo-1.3B'\n",
    "# model_name = 'EleutherAI/gpt-neo-2.7B'\n",
    "model_name = 'EleutherAI/gpt-j-6B'\n",
    "# model_name = 'openai_api'; engines = ['davinci', 'curie', 'babbage', 'ada']; engine = engines[1]\n",
    "model, tokenizer = models[model_name]\n",
    "\n",
    "if len(tokenizer.additional_special_tokens) > 0: # t5\n",
    "    mask_token = tokenizer.additional_special_tokens[0]\n",
    "elif tokenizer.mask_token is not None: # roberta\n",
    "    mask_token = tokenizer.mask_token\n",
    "else:\n",
    "    mask_token = None  # gpt\n",
    "# predict(model, text, get_ans_indices1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tokenizer_class, shortcut = RobertaTokenizer, 'roberta-large'\n",
    "tokenizer = tokenizer_roberta = tokenizer_class.from_pretrained(shortcut)\n",
    "model = None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## rand_relation_group=_frames[(i + 1) % len(_frames)], \n",
    "random.seed(42)\n",
    "random.shuffle(frames)\n",
    "entity_set = list(string.ascii_uppercase)\n",
    "random.shuffle(entity_set)\n",
    "split_pct = [0.6, 0.4]"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# random.seed(4242)\n",
    "n_entity_trials = 2\n",
    "sample_ratios = [8, 8]\n",
    "kwargs = {'n_entity_trials': n_entity_trials, 'has_neutral': False, 'has_negA': False, 'has_negB': False, \n",
    "          'tag_lexical_rel': True, 'tag_entity_rel': True, 'mask_types': {'sent_rel',}}#, 'entity_relations': {'former'}}\n",
    "train_lines, eval_lines = [[make_sentences(relation_group=rg, rand_relation_group=_frames[(i+1) % len(_frames)], \n",
    "                                           entity_set=_ent_set, sample_ratio=_sample_ratio, **kwargs)[1] for i, rg in enumerate(_frames)]\n",
    "                           for _frames, _ent_set, _sample_ratio in zip(split(frames, split_pct), split(entity_set, split_pct), sample_ratios)]\n",
    "random.sample(flatten(train_lines), 10)\n",
    "print(len(flatten(train_lines)), len(flatten(eval_lines)))\n",
    "\n",
    "train_pathname, eval_pathname = dump_datasets([flatten(train_lines), flatten(eval_lines)], split(frames, split_pct), \n",
    "    sample_ratios, [None, None], has_neg=False, tagged=kwargs['tag_lexical_rel'] or kwargs['tag_entity_rel'])"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_pathname = '../data/train_neg0_64rgx8x2_tagged.txt'\n",
    "eval_pathname = '../data/eval_neg0_43rgx8x2_tagged.txt'\n",
    "tokenizer.tag2id, tokenizer.id2tag = tag2id, id2tag\n",
    "kwargs = {'has_tags': True, 'max_noise_len': 0, 'n_replicas': 1}\n",
    "train_dataset = CHILDDataset(train_pathname, tokenizer, mode='train', **kwargs)\n",
    "eval_dataset = CHILDDataset(eval_pathname, tokenizer, mode='dev', **kwargs)\n",
    "# for i in random.sample(range(len(eval_dataset)), 10): top_tokens, top_probs = predict_mask(eval_dataset[i].__dict__, model, tokenizer)\n",
    "print('nTrain = %d, nValid = %d' % (len(train_dataset), len(eval_dataset)))\n",
    "eval_datasets = None\n",
    "if 'neg0' not in eval_pathname:\n",
    "    eval_datasets = {}\n",
    "    for suffix in ['neg0', 'neg1', 'neg2']:\n",
    "        eval_datasets[suffix] = CHILDDataset(eval_pathname + '.' + suffix, tokenizer, mode='dev', **kwargs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "models[model_name] = models[model_name][0], models['openai_api'][1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import openai\n",
    "model_name = 'openai_api'\n",
    "openai.api_key = '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'\n",
    "model = openai.Completion.create\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', cache_dir=cache_dir)\n",
    "models[model_name] = model, tokenizer"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from child_frames_old import frames"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "text = \"X dosen't fit in Y because X is <extra_id_0>. Options: larger, smaller.\"\n",
    "text = \"Larger or smaller? X dosen't fit in Y because Y is <extra_id_0>.\"\n",
    "text = \"X can fit in Y because Y is <extra_id_0> than X.\"\n",
    "text = \"X dosen't fit in Y. Which one is smaller, X or Y? <extra_id_0> is smaller.\"\n",
    "# text = \"Weaker or stronger? X beat Y because X is <extra_id_0>.\"\n",
    "texts = [\n",
    "    \"Larger or smaller? X dosen't fit in Y because X is _.\",\n",
    "    \"Weaker or stronger? X beat Y because Y is _.\",\n",
    "    \"Recieved or given? Mary thanked David for the help David had _.\",\n",
    "    \"Rich or poor? John gave a lot of money to Susan because Susan was very _.\",\n",
    "    \"Fast or slow? The delivery truck overtook the school bus because school bus was going so _.\",\n",
    "    \"Short or tall? John couldn't see the stage with Donna in front of him because Donna is so _.\", # wrong\n",
    "    \"Hard of soft? The ball crashed right through the table because the table was very _.\", # wrong\n",
    "    \"Far away or near? The firemen arrived after the police because the police were coming from so _.\", # wrong\n",
    "    \"Diligent or lazy? Anna did a lot better than Lucy on the test because Lucy was so _ in study.\",\n",
    "    \"First or later? The sack of potatoes had been placed above the bag of flour, so the sack of potatoes had to be moved _.\",#down\n",
    "    'Forgot or remembered? Ann asked Mary what time the library closes, because Mary _ it.',  # wrong\n",
    "    'So many or not enough? We had hoped to place copies of our newsletter on all the chairs in the auditorium, but there were simply _ of the copies of newsletter.', # wrong\n",
    "    'We can put an apple on every plate because the apple are (more/fewer) _ than the plates.'\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_ans_indices1(input_ids):\n",
    "    bos_id = tokenizer._convert_token_to_id('Ġis')\n",
    "    eos_id = tokenizer._convert_token_to_id('Ċ')\n",
    "    period_ids = [tokenizer._convert_token_to_id('.'), tokenizer._convert_token_to_id('Ġ.')]\n",
    "    l_bracket_id, r_bracket_id = tokenizer._convert_token_to_id('Ġ['), tokenizer._convert_token_to_id('Ġ]')\n",
    "    eos_indices = (input_ids == eos_id).nonzero().squeeze(1).tolist()\n",
    "    eos_indices = [i - 1 if input_ids[i - 1] in period_ids else i for i in eos_indices]\n",
    "    eos_indices = [i - 1 if input_ids[i - 1] == r_bracket_id else i for i in eos_indices]\n",
    "    def find_bos_index(start_i):\n",
    "        for bos_i in range(start_i, start_i - 3, -1):\n",
    "            if input_ids[bos_i] == bos_id or input_ids[bos_i] == l_bracket_id and input_ids[bos_i - 1] == bos_id:\n",
    "                if bos_i != start_i: print('subtokens:', tokenizer.convert_ids_to_tokens(input_ids[bos_i + 1: start_i + 2]))\n",
    "                return bos_i\n",
    "        assert False\n",
    "    bos_indices = [find_bos_index(i - 2) for i in eos_indices]\n",
    "    return bos_indices, eos_indices"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def predict(model, text, ans_indices_fn, topk=5, return_reduced_loss=False, verbose=True):\n",
    "    use_openai_api = isinstance(model, types.MethodType)  # openai.Completion.create\n",
    "    inputs = tokenizer.encode_plus(text, return_tensors='pt')\n",
    "    input_ids = inputs.input_ids\n",
    "    bsz = input_ids.size(0)\n",
    "    labels = torch.ones_like(input_ids) * (-100)\n",
    "    if use_openai_api:\n",
    "        assert bsz == 1\n",
    "        outputs = model(engine=engine, prompt=text, max_tokens=0, echo=True, logprobs=5).choices[0].logprobs\n",
    "        ans_nlls = []\n",
    "    else:\n",
    "        inputs = prepare_inputs(inputs, model.device)\n",
    "        outputs = model(**inputs, output_attentions=False)\n",
    "        logits = outputs.logits\n",
    "    for bi in range(bsz):\n",
    "        bos_indices, eos_indices = ans_indices_fn(input_ids[bi])\n",
    "        examples = text.strip().split('\\n')\n",
    "        assert len(bos_indices) == len(examples), '%d != %d' % (len(bos_indices), len(examples))\n",
    "        for i, (example, bos_i, eos_i) in enumerate(zip(examples, bos_indices, eos_indices)):\n",
    "            if verbose: print(' ' + example, end='\\t')\n",
    "            ans_ids = input_ids[bi, bos_i + 1: eos_i]\n",
    "            labels[bi, bos_i: eos_i - 1] = ans_ids\n",
    "            if use_openai_api:\n",
    "                ans_prob_dist = [get_prob_dist(d, topk=topk) for d in outputs.top_logprobs[bos_i + 1: eos_i]]\n",
    "                ans_probs = [math.exp(lp) for lp in outputs.token_logprobs[bos_i + 1: eos_i]]\n",
    "                ans_nlls += [-lp for lp in outputs.token_logprobs[bos_i + 1: eos_i]]\n",
    "            else:\n",
    "                ans_prob_dist = logits[bi, bos_i: eos_i - 1].softmax(-1)\n",
    "                ans_probs = ans_prob_dist[torch.arange(ans_prob_dist.size(0)), ans_ids]\n",
    "            ans_tokens = tokenizer.convert_ids_to_tokens(ans_ids)\n",
    "            for ans_id, ans_token, ans_prob, dist in zip(ans_ids, ans_tokens, numpy(ans_probs, decimals=3), ans_prob_dist):\n",
    "                top1_correct = max(dist.items(), key=lambda x: x[1])[0] == ans_token.replace('Ġ', ' ') \\\n",
    "                    if use_openai_api else (dist.argmax() == ans_id).item()\n",
    "                if verbose:\n",
    "                    print(('*' if top1_correct else ' ') + ans_token, ans_prob, \n",
    "                          dist if use_openai_api else show_topk(*dist.topk(topk), indices_fn=tokenizer.convert_ids_to_tokens)) \n",
    "    if use_openai_api:\n",
    "        loss = ans_nlls if return_reduced_loss else sum(ans_nlls) / len(ans_nlls)\n",
    "    else:\n",
    "        loss = nn.CrossEntropyLoss()(logits.view(-1, logits.size(-1)), labels.view(-1)) if return_reduced_loss \\\n",
    "            else nn.CrossEntropyLoss(reduction='none')(logits.view(-1, logits.size(-1)), labels.view(-1))[labels.view(-1)>=0].tolist()\n",
    "    return loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "models.keys()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model_name = 'EleutherAI/gpt-neo-2.7B'\n",
    "# model_name = 'EleutherAI/gpt-j-6B'\n",
    "model_name = 'openai_api'\n",
    "model, tokenizer = models[model_name]\n",
    "engines = ['davinci', 'curie', 'babbage', 'ada']; engine = engines[0]\n",
    "\n",
    "if len(tokenizer.additional_special_tokens) > 0: # t5\n",
    "    mask_token = tokenizer.additional_special_tokens[0]\n",
    "elif tokenizer.mask_token is not None: # roberta\n",
    "    mask_token = tokenizer.mask_token\n",
    "else:\n",
    "    mask_token = None  # gpt\n",
    "# print(mask_token)\n",
    "\n",
    "predict(model, text, get_ans_indices1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "text = '''John is taller than Tom? Yes, Tom is shorter.\n",
    "Mary is younger than Anna? Yes, Mary is younger.\n",
    "Jim is stronger than Bill? No, Jim is weaker.\n",
    "Emma is fatter than Kate? No, Kate is'''\n",
    "text = '''Is John taller than Tom? Yes, Tom is shorter.\n",
    "Is Mary younger than Anna? Yes, Mary is younger.\n",
    "Is Jim stronger than Bill? No, Jim is weaker.\n",
    "Is Emma fatter than Kate? Yes, Kate is'''\n",
    "text = '''John is taller than Tom? T, Tom is shorter.\n",
    "Mary is younger than Anna? F, Mary is younger.\n",
    "Jim is stronger than Bill? F, Jim is weaker.\n",
    "Emma is fatter than Kate? F, Kate is fatter.\n",
    "'''\n",
    "text = '''Younger or older? Is Mary younger than Anna? No, Anna is younger.\n",
    "Stronger or weaker? Is Jim stronger than Bill? No, Bill is stronger.\n",
    "'''\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "text = '\\n'.join(sentences) + '\\n'\n",
    "print(text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if '_' in text: text = text.replace('_', mask_token)  # t5, mask_token == '<extra_id_0>'\n",
    "elif mask_token is not None: text += ' %s.' % mask_token  # t5 or roberta\n",
    "print(text)\n",
    "    \n",
    "input_ids = tokenizer.encode_plus(text, return_tensors='pt').input_ids\n",
    "outputs = model.generate(input_ids, temperature=0.2, max_length=5)\n",
    "print(tokenizer.convert_ids_to_tokens(outputs[0]))\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=False))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = RobertaForProbing.from_pretrained('roberta-large', state_dict=state_dict)\n",
    "# model = RobertaForMaskedLM.from_pretrained('roberta-large', model=model)#, state_dict=state_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bsz = 16\n",
    "steps = len(train_dataset) / bsz # max(int(round(100 * n_entity_trials / 3)), int(len(train_dataset) / 32 / 4))\n",
    "training_args = TrainingArguments(output_dir=\"./models/model_name\", \n",
    "    overwrite_output_dir=True, do_train=True, do_eval=True,\n",
    "    per_device_train_batch_size=bsz, per_device_eval_batch_size=64,\n",
    "    weight_decay=0.01,\n",
    "#     adam_beta2=0.98, adam_epsilon=1e-6,\n",
    "    learning_rate=1e-2, num_train_epochs=28,\n",
    "    logging_steps=steps, eval_steps=steps, save_steps=0,\n",
    "    no_cuda=False, evaluate_during_training=True,\n",
    ")\n",
    "training_args.verbose_eval_steps = steps * 4\n",
    "trainer = Trainer(model, training_args, train_dataset=train_dataset, eval_dataset=eval_dataset)\n",
    "trainer.tokenizer = tokenizer\n",
    "# trainer.eval_datasets = eval_datasets\n",
    "model.tokenizer = tokenizer\n",
    "\n",
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer.train()"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "output_dir = '/nas/xd/data/models/CHILD/roberta-large_sRICA-neg0-48-tagged_acc94e4/'\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "# model.save_pretrained(output_dir)\n",
    "\n",
    "state_dict = torch.load(output_dir + 'pytorch_model.bin')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model = RobertaForMaskedLM.from_pretrained('roberta-base')\n",
    "model = RobertaForMaskedLM.from_pretrained(output_dir)\n",
    "_ = model.to(trainer.args.device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataloader = DataLoader(\n",
    "    eval_dataset,\n",
    "    sampler=RandomSampler(eval_dataset),\n",
    "    batch_size=16, # or trainer.args.eval_batch_size,\n",
    "    collate_fn=default_data_collator, #trainer.data_collator,\n",
    "    drop_last=False, #trainer.args.dataloader_drop_last,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for inputs in dataloader: break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i, inputs in enumerate(dataloader):\n",
    "    if i == 1: break\n",
    "    labels = inputs['labels']\n",
    "    del inputs['labels']\n",
    "    # inputs = trainer._prepare_inputs(inputs, model)\n",
    "#     outputs = model.generate(**inputs, max_length=8)\n",
    "#     outputs2 = model2.generate(**inputs, max_length=8)\n",
    "\n",
    "    for i in range(len(inputs['input_ids'])):\n",
    "        print(i, tokenizer.decode_old(inputs['input_ids'][i]), tokenizer.decode_strip_special_tokens(labels[i]))#, \n",
    "#               tokenizer.decode_strip_special_tokens(outputs[i]), tokenizer.decode_strip_special_tokens(outputs2[i]))\n",
    "    #           [tokenizer.convert_ids_to_tokens(inputs['input_ids'][i])[j] for j in inputs['marked_pos_labels'][i][0]])"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "H = model.config.num_attention_heads\n",
    "base_layer, layer, head = model.probe_layers[0], 12, 7\n",
    "probe_idx = model.probe_position_keys.index('be1')\n",
    "\n",
    "_ = model.eval()\n",
    "inputs = trainer._prepare_inputs(inputs, model)\n",
    "_, logits, probe_logits, all_attentions = model(**inputs, output_attentions=True, detach=False)[:4]\n",
    "\n",
    "outputs = probe_logits[:, (layer - base_layer) * H + head] if model.probe_type.startswith('per_head') \\\n",
    "    else probe_logits[:, (layer - base_layer) * model.n_probe_positions + probe_idx]\n",
    "outputs = outputs.max(dim=1).values\n",
    "attns = all_attentions[layer]\n",
    "attns.retain_grad()\n",
    "model.zero_grad()\n",
    "grads = torch.autograd.grad(torch.unbind(outputs), attns)[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "probe_pos = model.roberta.encoder.probe_positions[:, probe_idx]\n",
    "grad = grads[torch.arange(grads.size(0)), :, probe_pos]\n",
    "attn = attns[torch.arange(attns.size(0)), :, probe_pos]\n",
    "attr = attn * grad"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "values, indices = attr.view(attr.size(0), -1).topk(H, dim=1)\n",
    "\n",
    "indices // attr.size(-1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "values"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "head = 8\n",
    "\n",
    "for i in range(len(attns)):\n",
    "#     seq_len = inputs['attention_mask'][i].sum().item()\n",
    "    seq_len = inputs['input_ids'].size(1)\n",
    "    attn =  attns[i, head, : seq_len, : seq_len]\n",
    "    grad = grads[i, head, : seq_len, : seq_len]\n",
    "    tokens = normalize_tokens(tokenizer.convert_ids_to_tokens(inputs['input_ids'][i])[: seq_len])\n",
    "    size = round(attn.size(0) / 3)\n",
    "    fig, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(size * 3., size))#, gridspec_kw={'width_ratios': [3, 1]})\n",
    "    _ = sns.heatmap(attn.detach().cpu(), square=True, cbar=True, annot=False, fmt='d', xticklabels=tokens, yticklabels=tokens, ax=ax0)\n",
    "    _ = sns.heatmap((attn * grad).detach().cpu(), square=True, cbar=True, annot=False, xticklabels=tokens, yticklabels=tokens, ax=ax1)\n",
    "    _ = sns.heatmap(grad.detach().cpu(), square=True, cbar=True, annot=False, xticklabels=tokens, yticklabels=tokens, ax=ax2)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "_ = model.eval()\n",
    "model.zero_grad()\n",
    "# with torch.no_grad():\n",
    "_, logits, probe_logits, all_attentions = model(**inputs, output_attentions=True, detach=False)[:4]\n",
    "attn_probs = all_attentions  # torch.stack(all_attentions, dim=0).cpu()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "base_layer, layer = 6, 6\n",
    "H, bsz = 12, probe_logits.size(0)\n",
    "tc_labels = inputs['tc_labels'][inputs['tc_labels'] != -100]\n",
    "so_token_id, mask_token_id = tokenizer._convert_token_to_id('Ġso'), tokenizer.mask_token_id\n",
    "pos = (inputs['input_ids'] == so_token_id).nonzero()[:, 1].item()\n",
    "tokens = normalize_tokens(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0]))\n",
    "attn_probs[layer].retain_grad()\n",
    "probe_logits[torch.arange(bsz), (layer - base_layer) * H: (layer - base_layer + 1) * H, tc_labels].mean().backward()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "head = 6\n",
    "ga = attn_probs[layer].grad[:, head][0, pos]\n",
    "a = attn_probs[layer][:, head][0, pos]\n",
    "nn.Softmax(dim=-1)(probe_logits)[torch.arange(bsz), (layer - base_layer) * H + head, tc_labels].item()\n",
    "\n",
    "_ = plt.plot(normalize(ga.cpu()))\n",
    "_ = plt.plot(a.detach().cpu())\n",
    "_ = plt.bar(range(len(tokens)), normalize((ga * a.detach()).cpu()), alpha=0.3)\n",
    "_ = plt.axhline(y=0, linewidth=0.5, color='k')\n",
    "_ = plt.xticks(range(len(tokens)), tokens, rotation=45)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "head = 10\n",
    "ga = attn_probs[layer].grad[:, head][0, pos]\n",
    "a = attn_probs[layer][:, head][0, pos]\n",
    "nn.Softmax(dim=-1)(probe_logits)[torch.arange(bsz), (layer - base_layer) * H + head, tc_labels].item()\n",
    "\n",
    "_ = plt.plot(normalize(ga.cpu()))\n",
    "_ = plt.plot(a.detach().cpu())\n",
    "_ = plt.bar(range(len(tokens)), normalize((ga * a.detach()).cpu()), alpha=0.3)\n",
    "_ = plt.axhline(y=0, linewidth=0.5, color='k')\n",
    "_ = plt.xticks(range(len(tokens)), tokens, rotation=45)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sample_indices = [[0, 1, 2, 3], \n",
    "                  [4, 5, 6, 7]]\n",
    "# sample_indices = [[0, 0], \n",
    "#                   [0, 0]]\n",
    "n_rows, n_cols = len(sample_indices), len(sample_indices[0])\n",
    "fig, axs = plt.subplots(n_rows, n_cols, sharey=False, figsize=(4 * n_cols, 4.5 * n_rows))\n",
    "sep_id = tokenizer._convert_token_to_id('Ġ,')\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        i, ax = sample_indices[row][col], axs[row][col]\n",
    "        tokens = normalize_tokens(tokenizer.convert_ids_to_tokens(inputs['input_ids'][i]))\n",
    "        \n",
    "        p, h = inputs['marked_pos_labels'][i][0]\n",
    "        p, h = p.item(), h.item()\n",
    "        so_pos = (inputs['input_ids'][i] == tokenizer._convert_token_to_id('Ġso')).nonzero()[0, 0].item()\n",
    "        be2_pos = so_pos + 2\n",
    "        mask_pos = (inputs['input_ids'][i] == tokenizer.mask_token_id).nonzero()[0, 0].item()\n",
    "#         j = 17\n",
    "        pos_attn = attn_probs[:, i, :, mask_pos, h]\n",
    "        pos_attn[-1, -1] = 1.\n",
    "        ax = sns.heatmap((pos_attn * 100).long(), square=True, cbar=False, annot=False, fmt='d', ax=ax)\n",
    "        ax.tick_params(top=True, labeltop=True)\n",
    "        _ = ax.set_xlabel('%s - %s' % (tokens[p], tokens[h]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "i = 0\n",
    "layer, head = 7, 10\n",
    "seq_len = inputs['attention_mask'][i].sum().item()\n",
    "attn =  attn_probs[layer][i, head, : seq_len, : seq_len]\n",
    "tokens = normalize_tokens(tokenizer.convert_ids_to_tokens(inputs['input_ids'][i])[: seq_len])\n",
    "size = round(attn.size(0) / 3)\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(size  * 2., size), gridspec_kw={'width_ratios': [3, 1]})\n",
    "_ = sns.heatmap((attn * 100).long().cpu(), square=True, cbar=True, annot=True, fmt='d', xticklabels=tokens, yticklabels=tokens, ax=ax0)\n",
    "plot_head_attn(attn, tokens, ax1=ax1, marked_positions=inputs['marked_pos_labels'][i])"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "H5-8, H6-4, H7-6(+1), H7-10: ,/so/is/more -> h_ent  \n",
    "H8-6: ?/mask -> so\n",
    "\n",
    "H6-6: ,/so/is/more -> h  \n",
    "H6-10: ,/so/is/more -> p  \n",
    "H7-9: ?/mask -> so"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#         pos_attn = attn_probs[:, i]\n",
    "#         pos_attn = pos_attn * (pos_attn > 0.3)\n",
    "# #         pos_attn[0] = 0  # layer 0\n",
    "# #         pos_attn[1, 1] = 0  # ->pos-2\n",
    "#         pos_attn = pos_attn.mean(dim=(0, 1))\n",
    "#         input_ids = inputs['input_ids'][i]\n",
    "#         sep_pos = (input_ids == sep_id).nonzero()[0].item()\n",
    "#         segment_ids = torch.zeros_like(input_ids)\n",
    "#         segment_ids[sep_pos + 1:] = 1\n",
    "#         segment_mask = segment_ids.unsqueeze(0) != segment_ids.unsqueeze(1)\n",
    "#         pos_attn = pos_attn * segment_mask.cpu()\n",
    "#         seq_len = inputs['attention_mask'][i].sum().item()\n",
    "#         pos_attn[:, [0, 2, seq_len - 1]] = 0\n",
    "#         k = torch.arange(1, pos_attn.size(0) - 1)\n",
    "#         pos_attn[k, k] = 0\n",
    "#         pos_attn[k, k - 1] = 0\n",
    "#         pos_attn[k, k + 1] = 0\n",
    "#         ax = sns.heatmap((pos_attn * 100).long(), square=True, cbar=False, annot=False, fmt='d', \n",
    "#                          xticklabels=tokens, yticklabels=tokens, ax=ax)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "length = 4\n",
    "range_vec = torch.arange(length)\n",
    "range_mat = range_vec.unsqueeze(-1).expand(-1, length).transpose(0, 1)\n",
    "distance_mat = range_mat - range_mat.transpose(0, 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "range_vec"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "range_mat"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "distance_mat"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "max_relative_positions = 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "distance_mat_clipped = torch.clamp(distance_mat,\n",
    "                                   min=-max_relative_positions,\n",
    "                                   max=max_relative_positions)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "distance_mat_clipped"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "final_mat = distance_mat_clipped + max_relative_positions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "final_mat"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.arange(-length + 1, 1, 1).unsqueeze(0)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "09ddf9bd75b357bac9db25bb02e545e10b89ac9f13622c0038ea1d9ad2e84ca3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}