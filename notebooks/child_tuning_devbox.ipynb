{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7292808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'  #'last', 'last_expr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d03e56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In utils/hub.py: default_cache_path: /raid3/xd/.cache/torch/hub->/nas/xd/.cache/torch/transformers/\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.insert(0, '/nas/xd/projects/transformers/src')\n",
    "import os\n",
    "os.environ['HF_HOME'] = '/raid3/xd/.cache/torch'  # deliberately set this wrong path to avoid migrating cache\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"8,7\"\n",
    "\n",
    "from types import MethodType\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, OrderedDict, Counter\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "from dataclasses import dataclass, fields, asdict\n",
    "import itertools\n",
    "from itertools import chain, product\n",
    "import math\n",
    "from functools import reduce, partial\n",
    "from collections.abc import Iterable\n",
    "from collections import namedtuple \n",
    "import traceback\n",
    "import pickle, gzip\n",
    "\n",
    "# from multiprocessing import Pool\n",
    "# from torch.multiprocessing import Pool\n",
    "# torch.multiprocessing.set_start_method('spawn', force=True)\n",
    "from multiprocessing.dummy import Pool\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data.sampler import RandomSampler, Sampler, SequentialSampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, GPT2Tokenizer, LlamaTokenizer\n",
    "# from transformers import T5Tokenizer, T5TokenizerFast, T5ForConditionalGeneration\n",
    "torch.set_grad_enabled(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58cba5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common_utils ... done 0:00:00.000021\n",
      "utils ... done 0:00:00.000654\n",
      "child_utils ... In const.py: Loading tokenizer ... done 0:00:00.106995\n",
      "done 0:00:00.167705\n",
      "tasks ... done 0:00:00.000213\n",
      "model_utils ... done 0:00:00.090774\n",
      "weight_analysis ... done 0:00:00.000016\n"
     ]
    }
   ],
   "source": [
    "from common_utils import Timer\n",
    "with Timer('common_utils'): from common_utils import *\n",
    "with Timer('utils'): from utils import *\n",
    "with Timer('child_utils'): from child_utils import *\n",
    "from child_utils import _str, _cxt2str, _item2str, _s, _be\n",
    "from child_frames import *\n",
    "with Timer('tasks'): from tasks import *\n",
    "with Timer('model_utils'): from model_utils import *\n",
    "with Timer('weight_analysis'): from weight_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90f62ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "cache_dir = '/nas/xd/.cache/torch/transformers/'  # for models besides t5-3b/11b\n",
    "# cache_dir = '/mnt/nvme1/xd/.cache/torch/transformers/'  # for gpt-neox-20b on elderberry\n",
    "proxies = {'http': '192.168.50.1:1081'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4ab655d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EleutherAI/gpt-j-6B ... In huggingface_hub.file_download.cached_download: url = https://huggingface.co/EleutherAI/gpt-j-6B/resolve/float16/config.json\n",
      "In huggingface_hub.file_download.cached_download: url = https://huggingface.co/EleutherAI/gpt-j-6B/resolve/float16/pytorch_model.bin\n",
      "In huggingface_hub.file_download.cached_download: url = https://huggingface.co/EleutherAI/gpt-j-6B/resolve/main/vocab.json\n",
      "In huggingface_hub.file_download.cached_download: url = https://huggingface.co/EleutherAI/gpt-j-6B/resolve/main/merges.txt\n",
      "In huggingface_hub.file_download.cached_download: url = https://huggingface.co/EleutherAI/gpt-j-6B/resolve/main/added_tokens.json\n",
      "In huggingface_hub.file_download.cached_download: url = https://huggingface.co/EleutherAI/gpt-j-6B/resolve/main/special_tokens_map.json\n",
      "In huggingface_hub.file_download.cached_download: url = https://huggingface.co/EleutherAI/gpt-j-6B/resolve/main/tokenizer_config.json\n",
      "done 0:00:15.149014\n"
     ]
    }
   ],
   "source": [
    "# curl -x http://192.168.50.1:1081 -L -O [-C -] https://huggingface.co/google/ul2/resolve/main/pytorch_model.bin  # -C for 断点续传\n",
    "s2s_model_names = ['google/t5-xl-lm-adapt', 'google/t5-xxl-lm-adapt', 'bigscience/T0p', 'bigscience/T0_3B', \n",
    "    'allenai/tk-instruct-3b-pos', 'allenai/tk-instruct-3b-def-pos', 'google/ul2']\n",
    "gpt_model_names = ['EleutherAI/gpt-j-6B/cpu', 'EleutherAI/gpt-j-6B/int8', 'EleutherAI/gpt-j-6B',\n",
    "                  ]#, 'EleutherAI/gpt-neox-20b/cpu', #'EleutherAI/gpt-neox-20b', 'gpt2-xl', 'gpt2']\n",
    "llama_model_names = ['models/vicuna/vicuna-7b@int8', 'models/vicuna/vicuna-13b@int8',\n",
    "                     'lmsys/vicuna-13b-v1.3@cpu', 'lmsys/vicuna-13b-v1.3@int8', \n",
    "                     'lmsys/vicuna-33b-v1.3@cpu', 'lmsys/vicuna-33b-v1.3@int8', 'lmsys/vicuna-33b-v1.3'\n",
    "                    ]\n",
    "name2device = {'gpt-j-6B': 0, #'models/vicuna/vicuna-7b': 8, 'models/vicuna/vicuna-13b': 8,  \n",
    "               'vicuna-7b-v1.3': 0, 'vicuna-13b-v1.3': 0, 'vicuna-33b-v1.3': [0]}\n",
    "for model_name in llama_model_names[:0] + gpt_model_names[-1:]:\n",
    "    if model_name in models: continue\n",
    "    with Timer(model_name):\n",
    "        model_cls = AutoModelForCausalLM #if any(s in model_name for s in ['gpt', 'fairseq-dense']) else T5ForConditionalGeneration\n",
    "        _cache_dir = cache_dir# .replace('/nas/', '/nas2/') if 'gpt' not in model_name else cache_dir\n",
    "        dst = model_name.split('@')[-1] if '@' in model_name else 'cuda'\n",
    "        model_name = model_name.replace('/cpu', '').replace('/int8', '')\n",
    "        _model_name = model_name.split('/')[-1]\n",
    "        kwargs = dict(cache_dir=_cache_dir, proxies=proxies, low_cpu_mem_usage=True)\n",
    "        if dst == 'cpu':\n",
    "            model = model_cls.from_pretrained(model_name, **kwargs)\n",
    "        else:  # fp16 or int8 on GPU\n",
    "            device = name2device[_model_name]\n",
    "            device_map = get_device_map(device=device, **name2mapping[_model_name]) if isinstance(device, Iterable) else None\n",
    "            dtype_kwargs = dict(load_in_8bit=True) if dst == 'int8' else dict(torch_dtype=torch.float16)\n",
    "            revision_kwargs = dict(revision='float16') if _model_name == 'gpt-j-6B' else {}\n",
    "            model = model_cls.from_pretrained(model_name, device_map=device_map, **dtype_kwargs, **revision_kwargs, **kwargs)\n",
    "            if device_map is None: model = model.to(device)\n",
    "#         elif model_name.endswith('/int8'):\n",
    "#             model_family = _model_name.split('/')[-1].rsplit('-', 1)[0]  # e.g. 'gpt-j-6B' -> 'gpt-j' \n",
    "#             if model_family.startswith('vicuna-'): model_family = 'vicuna'  # e.g. 'vicuna-7b-v1.3' -> 'vicuna-7b'\n",
    "#             if _model_name == 'lmsys/vicuna-33b-v1.3':\n",
    "#                 device_map = get_device_map(model_name='model', emb_name='embed_tokens', layer_name='layers', n_layers=60, \n",
    "#                     ln_name='norm', head_name='lm_head', devices=device)\n",
    "#             else:\n",
    "#                 body_head = {'gpt-j': ('transformer', 'lm_head'), 'vicuna': ('model', 'lm_head'),\n",
    "#                          'gpt-neox': ('gpt_neox', 'embed_out')}[model_family]\n",
    "#                 device_map = {body_head[0]: device, body_head[1]: device}\n",
    "#             model = model_cls.from_pretrained(_model_name, device_map=device_map, load_in_8bit=True, **kwargs)\n",
    "#         else:  # fp16 GPU\n",
    "#             device_map = get_device_map(model_name='model', emb_name='embed_tokens', layer_name='layers', n_layers=60, \n",
    "#                 ln_name='norm', head_name='lm_head', devices=device) if _model_name == 'lmsys/vicuna-33b-v1.3' else None\n",
    "#             model = model_cls.from_pretrained(_model_name, device_map=device_map, torch_dtype=torch.float16, **kwargs)\n",
    "#             if device_map is None: model = model.to(device)\n",
    "        if hasattr(model.config, 'use_cache'): model.config.use_cache = False  # save GPU mem\n",
    "        # to avoid slow loading of AutoTokenizer->TokenizerFast\n",
    "        tokenizer_cls = LlamaTokenizer if 'vicuna' in model_name else GPT2Tokenizer\n",
    "        tokenizer = tokenizer_cls.from_pretrained(model_name, cache_dir=_cache_dir)\n",
    "        unify(model)\n",
    "        models[model_name] = model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "21c8cd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there was a little girl named Alice. She lived in a small village with her parents and siblings.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "openai.api_key = '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'\n",
    "proxy_key = \"brd-customer-hl_c1b0ccff-zone-openai2-ip-178.171.126.110:sf23ma3ozhu3@zproxy.lum-superproxy.io:22225\"\n",
    "openai.proxy = {\"http\": 'http://'+proxy_key, \"https\": 'https://' + proxy_key}\n",
    "#open('/nas/xd/projects/openai_api_keys.txt').readlines()[4].split()[0]\n",
    "response = openai.Completion.create(engine='text-davinci-003', prompt='Once upon a time',\n",
    "    max_tokens=20, temperature=0, echo=True, logprobs=5)\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c64283f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_model(engine):\n",
    "    def forward(input_ids):#, attention_mask=None):\n",
    "        text = tokenizer.decode(input_ids[0])\n",
    "        response = openai.Completion.create(engine=engine, prompt=text, max_tokens=0, echo=True, logprobs=5)\n",
    "        return Outputs(logits=response.choices[0].logprobs)\n",
    "    return forward\n",
    "    \n",
    "tokenizer0 = GPT2Tokenizer.from_pretrained('gpt2', cache_dir=cache_dir)\n",
    "engines = ['text-curie-001', 'davinci', 'text-davinci-001', 'text-davinci-002', 'text-davinci-003', 'code-davinci-002'] #+ \\\n",
    "#     ['curie', 'curie:2020-05-03', 'curie-instruct-beta', 'text-curie-001'] + \\\n",
    "#     ['davinci', 'davinci:2020-05-03', 'davinci-instruct-beta', 'davinci-instruct-beta:2.0.0', 'text-davinci-001', 'text-davinci-002']\n",
    "for engine in engines:\n",
    "    if engine not in models: models[engine] = get_openai_model(engine), tokenizer0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bc28755",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = gpt_model_names[-1]  # gpt_model_names/llama_model_names/engines\n",
    "assert not model_name.endswith('/int8'), model_name\n",
    "model, tokenizer = models[model_name]\n",
    "model_name_gpu = model_name.replace('/cpu', '/int8') if model_name.endswith('/cpu') else model_name# + '/int8'\n",
    "model_gpu = models[model_name_gpu][0] if model_name_gpu in models else model  # for prediction rather than attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b77b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = model.transformer.h\n",
    "for i, b in enumerate(blocks): b.layer = i\n",
    "ln_f = model.transformer.ln_f\n",
    "L, H, embed_dim = len(blocks), blocks[0].attn.num_heads, blocks[0].attn.embed_dim\n",
    "\n",
    "# we = model.transformer.wte.weight.data\n",
    "# wu = model.lm_head.weight.data\n",
    "\n",
    "# es = [we]\n",
    "# for b in blocks[:1]: es.append(es[-1] + mlp_forward(b, es[-1]))\n",
    "# model.es = es\n",
    "# weBTAs = [es[i].T @ es[i] for i in range(2)]\n",
    "# model.weBTAs = weBTAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f29d2b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 52)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L, H #/ (28 * 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daa5e12a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloning LlamaDecoderLayer0.ln_1 to cuda:7 ... done 0:00:08.822839\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.076373\n",
      "cloning LlamaDecoderLayer1.ln_1 to cuda:7 ... done 0:00:00.000597\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.074782\n",
      "cloning LlamaDecoderLayer2.ln_1 to cuda:7 ... done 0:00:00.000787\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.069161\n",
      "cloning LlamaDecoderLayer3.ln_1 to cuda:7 ... done 0:00:00.000630\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.065352\n",
      "cloning LlamaDecoderLayer4.ln_1 to cuda:7 ... done 0:00:00.000555\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.077830\n",
      "cloning LlamaDecoderLayer5.ln_1 to cuda:7 ... done 0:00:00.000581\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.083993\n",
      "cloning LlamaDecoderLayer6.ln_1 to cuda:7 ... done 0:00:00.000544\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.062661\n",
      "cloning LlamaDecoderLayer7.ln_1 to cuda:7 ... done 0:00:00.000608\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.064646\n",
      "cloning LlamaDecoderLayer8.ln_1 to cuda:7 ... done 0:00:00.000644\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.070572\n",
      "cloning LlamaDecoderLayer9.ln_1 to cuda:7 ... done 0:00:00.000749\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.068460\n",
      "cloning LlamaDecoderLayer10.ln_1 to cuda:7 ... done 0:00:00.000764\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.062356\n",
      "cloning LlamaDecoderLayer11.ln_1 to cuda:7 ... done 0:00:00.000730\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.066188\n",
      "cloning LlamaDecoderLayer12.ln_1 to cuda:7 ... done 0:00:00.001049\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.061522\n",
      "cloning LlamaDecoderLayer13.ln_1 to cuda:7 ... done 0:00:00.000734\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.078405\n",
      "cloning LlamaDecoderLayer14.ln_1 to cuda:7 ... done 0:00:00.000666\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.082241\n",
      "cloning LlamaDecoderLayer15.ln_1 to cuda:7 ... done 0:00:00.000700\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.061204\n",
      "cloning LlamaDecoderLayer16.ln_1 to cuda:7 ... done 0:00:00.000623\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.067383\n",
      "cloning LlamaDecoderLayer17.ln_1 to cuda:7 ... done 0:00:00.000639\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.066116\n",
      "cloning LlamaDecoderLayer18.ln_1 to cuda:7 ... done 0:00:00.000604\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.052917\n",
      "cloning LlamaDecoderLayer19.ln_1 to cuda:7 ... done 0:00:00.000687\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.062949\n",
      "cloning LlamaDecoderLayer20.ln_1 to cuda:7 ... done 0:00:00.000592\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.052097\n",
      "cloning LlamaDecoderLayer21.ln_1 to cuda:7 ... done 0:00:00.000631\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.052751\n",
      "cloning LlamaDecoderLayer22.ln_1 to cuda:7 ... done 0:00:00.000685\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.053114\n",
      "cloning LlamaDecoderLayer23.ln_1 to cuda:7 ... done 0:00:00.000861\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.051488\n",
      "cloning LlamaDecoderLayer24.ln_1 to cuda:7 ... done 0:00:00.000577\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.066796\n",
      "cloning LlamaDecoderLayer25.ln_1 to cuda:7 ... done 0:00:00.000595\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.065946\n",
      "cloning LlamaDecoderLayer26.ln_1 to cuda:7 ... done 0:00:00.000614\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.058053\n",
      "cloning LlamaDecoderLayer27.ln_1 to cuda:7 ... done 0:00:00.000668\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.050107\n",
      "cloning LlamaDecoderLayer28.ln_1 to cuda:7 ... done 0:00:00.000590\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.049160\n",
      "cloning LlamaDecoderLayer29.ln_1 to cuda:7 ... done 0:00:00.000561\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.057570\n",
      "cloning LlamaDecoderLayer30.ln_1 to cuda:7 ... done 0:00:00.000583\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.058981\n",
      "cloning LlamaDecoderLayer31.ln_1 to cuda:7 ... done 0:00:00.000586\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.054541\n",
      "cloning LlamaDecoderLayer32.ln_1 to cuda:7 ... done 0:00:00.000524\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.049836\n",
      "cloning LlamaDecoderLayer33.ln_1 to cuda:7 ... done 0:00:00.000617\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.050407\n",
      "cloning LlamaDecoderLayer34.ln_1 to cuda:7 ... done 0:00:00.000545\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.051151\n",
      "cloning LlamaDecoderLayer35.ln_1 to cuda:7 ... done 0:00:00.000472\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.060627\n",
      "cloning LlamaDecoderLayer36.ln_1 to cuda:7 ... done 0:00:00.000601\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.051380\n",
      "cloning LlamaDecoderLayer37.ln_1 to cuda:7 ... done 0:00:00.000595\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.055665\n",
      "cloning LlamaDecoderLayer38.ln_1 to cuda:7 ... done 0:00:00.000619\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.050265\n",
      "cloning LlamaDecoderLayer39.ln_1 to cuda:7 ... done 0:00:00.000717\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.070440\n",
      "cloning LlamaDecoderLayer40.ln_1 to cuda:7 ... done 0:00:00.000727\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.077579\n",
      "cloning LlamaDecoderLayer41.ln_1 to cuda:7 ... done 0:00:00.000487\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.078698\n",
      "cloning LlamaDecoderLayer42.ln_1 to cuda:7 ... done 0:00:00.000584\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.071526\n",
      "cloning LlamaDecoderLayer43.ln_1 to cuda:7 ... done 0:00:00.000545\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.071115\n",
      "cloning LlamaDecoderLayer44.ln_1 to cuda:7 ... done 0:00:00.000795\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.076846\n",
      "cloning LlamaDecoderLayer45.ln_1 to cuda:7 ... done 0:00:00.000783\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.064268\n",
      "cloning LlamaDecoderLayer46.ln_1 to cuda:7 ... done 0:00:00.000533\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.072243\n",
      "cloning LlamaDecoderLayer47.ln_1 to cuda:7 ... done 0:00:00.000605\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.071284\n",
      "cloning LlamaDecoderLayer48.ln_1 to cuda:7 ... done 0:00:00.000437\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.071084\n",
      "cloning LlamaDecoderLayer49.ln_1 to cuda:7 ... done 0:00:00.000574\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.068235\n",
      "cloning LlamaDecoderLayer50.ln_1 to cuda:7 ... done 0:00:00.000568\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.069342\n",
      "cloning LlamaDecoderLayer51.ln_1 to cuda:7 ... done 0:00:00.000629\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.079270\n",
      "cloning LlamaDecoderLayer52.ln_1 to cuda:7 ... done 0:00:00.000587\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.071136\n",
      "cloning LlamaDecoderLayer53.ln_1 to cuda:7 ... done 0:00:00.000471\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.068674\n",
      "cloning LlamaDecoderLayer54.ln_1 to cuda:7 ... done 0:00:00.000688\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.071372\n",
      "cloning LlamaDecoderLayer55.ln_1 to cuda:7 ... done 0:00:00.000570\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.049809\n",
      "cloning LlamaDecoderLayer56.ln_1 to cuda:7 ... done 0:00:00.000557\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.048838\n",
      "cloning LlamaDecoderLayer57.ln_1 to cuda:7 ... done 0:00:00.000515\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.050104\n",
      "cloning LlamaDecoderLayer58.ln_1 to cuda:7 ... done 0:00:00.000829\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.050270\n",
      "cloning LlamaDecoderLayer59.ln_1 to cuda:7 ... done 0:00:00.000571\n",
      "cloning LlamaAttention.out_proj to cuda:7 ... done 0:00:00.051490\n",
      "cloning LlamaModel.ln_f to cuda:7 ... done 0:00:00.000642\n",
      "cloning LlamaForCausalLM.lm_head to cuda:7 ... done 0:00:00.256306\n",
      "mem_usage before / after clone_model_to: [0, 0, 654] / [5477, 5570, 6224]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:7')\n",
    "_ = clone_model_to(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f9e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediary_heads = [(8, 1), (12, 10), (13, 13)]\n",
    "circuit_ends = {\n",
    "    'thing->type': ([(15, 8), (21, 5)], [(5, 12), (7, 2)]),\n",
    "    'thing->capability': ([(13, 15)], [(6, 5), (3, 7), (5, 12)]),\n",
    "    'capital->country': ([(19, 12)], [(5, 12)]), # inverse 3-7 by nrk \n",
    "    'opposite': ([(16, 14)], [(7, 9)]),\n",
    "    'fr->en': ([(16, 15), (21, 14)], [(5, 12)]),\n",
    "    'copy': ([(16, 7)], [(8, 7), (6, 2)]), # (1, 7), (3, 12), (6, 10)\n",
    "    # did->does 6-2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6eb024",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicting_heads, relating_heads = defaultdict(list), defaultdict(list)\n",
    "for taskname, (pred_heads, rel_heads) in circuit_ends.items():\n",
    "    for pred_head in pred_heads: predicting_heads[pred_head].append(taskname)\n",
    "    for rel_head in rel_heads: relating_heads[rel_head].append(taskname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "07ed2095",
   "metadata": {},
   "outputs": [],
   "source": [
    "for block in blocks: remove_composed_heads(block.attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "0df73ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blocks[4].attn.composed_heads = [((4, 8), (4, 6))]; blocks[4].attn.ranges_i = ['ans]->*']  # opposite\n",
    "# blocks[6].attn.composed_heads = [('ans]->ans0]', (6, 2))]; blocks[6].attn.ranges_i = ['ans]->*']  # opposite\n",
    "# blocks[1].attn.composed_heads = [('ans]->ans0]', (1, 7))]; blocks[1].attn.ranges_i = ['ans]->*']  # opposite\n",
    "# blocks[8].attn.composed_heads = [('ans]->ans0]', (8, 7))]; blocks[8].attn.ranges_i = ['ans]->*']  # opposite\n",
    "# blocks[6].attn.composed_heads = [((4, 8), (6, 10))]; blocks[6].attn.ranges_i = ['ans]->*']  # opposite\n",
    "# blocks[8].attn.composed_heads = [((7, 2), (8, 7))]\n",
    "# blocks[6].attn.composed_heads = [((7, 2), (6, 2))]\n",
    "# blocks[4].attn.composed_heads = [((3, 12), (4, 8))]\n",
    "# blocks[3].attn.composed_heads = [((3, 12), (3, 6))]\n",
    "self = blocks[11].attn; self.composed_heads = [('bos->query]', (11, 12))]; self.ranges_i = ['bos->*']\n",
    "qk_head = (13, 7)\n",
    "for ov_head in [(21, 5), (20, 5), (19, 14), (15, 8)]:\n",
    "    self = blocks[ov_head[0]].attn; self.composed_heads = [(qk_head, ov_head)]; self.ranges_i = ['bos->*']\n",
    "# compose_all_heads(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fb0fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "relating_heads = [(6, 2), (8, 7), (7, 2), (5, 12)]#(7, 9)]\n",
    "intermediary_heads = [(8, 1), (12, 10), (13, 13)]\n",
    "predicting_heads = [(13, 7), (16, 7), (15, 8), (21, 5)]#, (16, 14)]\n",
    "for circuit in product(relating_heads, intermediary_heads, predicting_heads):\n",
    "    eigv_pos = plot_eigv(weightprod(model, list(circuit), 'e vo vo qk e', weBTA=model.weBTAs[0]), plot=False)[0]\n",
    "    print(circuit, eigv_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fb34c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with gzip.open(f'results/results-genders_of_persons-types_of_things.pkl.gz', 'wb') as f:\n",
    "#     pickle.dump({k: result2dict(r) for k, r in results.items()}, f)\n",
    "# with gzip.open(f'results.pkl.gz', 'rb') as f: results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fa6edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_key = keys[0]; res_key\n",
    "fpath = f'results/{res_key}_attn_attrs.npz'\n",
    "np.savez_compressed(fpath, *dump_attn_attrs_to_arrays(root, result.data_tuples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04901ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "_root = deepcopy(root)\n",
    "def fn(node): node.data = asdict(node.data)\n",
    "traverse_tree(_root, fn, include_dummy=True)\n",
    "pickle.dump(_root, gzip.open(f'results/{res_key}_tree.pkl.gz', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "706055f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cachier.cache_dir = '~/.cachier/.openai_utils.query_openai'\n",
    "tasks = [\n",
    "#     (lambda: [TreeSet(types_of_things).use(['equal']), TreeSet(types_of_things).use(['child'])], MlM_gen,\n",
    "#      lambda *args, **kwargs: '', lambda q, _: f\"{q} is\",\n",
    "#     ), \n",
    "#     (lambda: [TreeSet(country2capital).use(['equal']), TreeSet(country2capital).use(['child'])], MlM_gen,\n",
    "#      lambda *args, **kwargs: '', lambda q, _: f\"{q} is\",\n",
    "#     ), \n",
    "#     (lambda: [TreeSet(do2did).use(['equal']), TreeSet(do2did).use(['child'])], MlM_gen,\n",
    "#      lambda *args, **kwargs: '', lambda q, _: f\"{q} is\",\n",
    "#     ), \n",
    "# #     (lambda: [TreeSet(pasttenses_of_verbs).use(['equal']), TreeSet(pasttenses_of_verbs).use(['child'])], MlM_gen,\n",
    "# #      lambda *args, **kwargs: '', lambda q, _: f\"Today I {q}. Yesterday I\",\n",
    "# #     ), \n",
    "#     (lambda: [TreeSet(word2capitalized).use(['equal']), TreeSet(word2capitalized).use(['child'])], MlM_gen,\n",
    "#      lambda *args, **kwargs: '', lambda q, _: f\"{q} is\",\n",
    "#     ), \n",
    "#     (lambda: [TreeSet(letter2uppercase).use(['equal']), TreeSet(letter2uppercase).use(['child'])], MlM_gen,\n",
    "#      lambda *args, **kwargs: '', lambda q, _: f\"{q} is\",\n",
    "#     ), \n",
    "    \n",
    "    \n",
    "#     (lambda: [TreeSet(genders_of_persons).use(['equal', 'child', 'sibling']), TreeSet(genders_of_persons).use(['equal', 'child', 'sibling'])], MlM_gen, None, None,\n",
    "#     ), \n",
    "#     (lambda: [TreeSet(types_of_things).use(['equal', 'child', 'sibling']), TreeSet(types_of_things).use(['equal', 'child', 'sibling'])], MlM_gen, None, None,\n",
    "#     ), \n",
    "#     (lambda: [TreeSet(countries_of_cities).use(['equal', 'child', 'sibling']), TreeSet(countries_of_cities).use(['equal', 'child', 'sibling'])], MlM_gen, None, None,\n",
    "#     ),\n",
    "#     (lambda: fork_vocab(TreeSet(capabilities_of_things), [['equal', 'child', 'sibling']] * 2), MlM_gen, None, None,\n",
    "#     ), \n",
    "#     (lambda: fork_vocab(SymSet(person_adjs), [['equal'], ['opposite']]), MlM_gen, None, None,\n",
    "#     ), \n",
    "#     (lambda: fork_vocab(PoSet(temporal_poset), [['equal'], ['prev']]), MlM_gen, None, None,\n",
    "#     ), \n",
    "#     (lambda: fork_vocab(PoSet(temporal_poset), [['equal'], ['next']]), MlM_gen, None, None,\n",
    "#     ), \n",
    "#     (lambda: [TreeSet(types_of_things).use(['equal']), TreeSet(types_of_things).use(['equal', 'child'])], partial(MlM_gen, cxt_sample_fn=enumerate_sample, query=1),\n",
    "#      partial(_cxt2str, item2str=lambda i, _: [f\"{i[0]} has {i[1]}\", f\"{the_(i[1])} is {i[0]}'s\"]), lambda q, _: f\"{q}\", \" likes\"\n",
    "#     ),\n",
    "    (lambda: [TreeSet(genders_of_persons).use(['equal', 'child', 'sibling']), TreeSet(types_of_things).use(['child', 'equal', 'sibling'])], MlM_gen,\n",
    "     partial(_cxt2str, item2str=lambda i, _: [f\"{i[0]} has {a_(i[1])}.\", f\"{_be(the_(i[1]))} {i[0]}'s.\"]), lambda q, _: f\"{the_(q)} has\",\n",
    "    ), # t: 21-5, 15-8, 19. p: 16-7, 18-5, [3-12, 13-7]. p+: 16-7, 16-0. 13-7:induction head qk, thing->type ov\n",
    "    (lambda: [TreeSet(genders_of_persons).use(['equal', 'child', 'sibling']), TreeSet(countries_of_cities).use(['child', 'equal', 'sibling'])], MlM_gen,\n",
    "     partial(_cxt2str, item2str=lambda i, _: [f\"{i[0]} likes {i[1]}.\", f\"{i[1]} attracts {the_(i[0], uppercase=False)}.\"]), lambda q, _: f'{the_(q)} wants to go to',\n",
    "    ), # t: 19-12 >> 16-10 = 12-7\n",
    "    (lambda: [TreeSet(genders_of_persons).use(['equal', 'child', 'sibling']), TreeSet(capabilities_of_things).use(['child'])], MlM_gen,\n",
    "     partial(_cxt2str, item2str=lambda i, _: [f\"{i[0]} has {a_(i[1])}.\", f\"{_be(the_(i[1]))} {i[0]}'s.\"]), lambda q, _: f\"{the_(q)} has\"\n",
    "    ),\n",
    "#     (lambda: [TreeSet(genders_of_persons).use('equal'), SymSet(person_adjs).use('equal')], MlM_gen,\n",
    "#      partial(_cxt2str, item2str=lambda i, _: [f\"{i[0]} is {i[1]}\", f\"{i[1].capitalize()} is {i[0]}\"]), lambda q, _: f\"Yes, {q} looks\", \" like\"\n",
    "#     ),\n",
    "    (lambda: [TreeSet(genders_of_persons).use(['equal', 'child', 'sibling']), SymSet(person_adjs).use(['opposite'])], MlM_gen,\n",
    "     partial(_cxt2str,item2str=lambda i, _: [f\"{i[0]} is {i[1]}.\", f\"{capitalize(i[1])} {i[0]}.\"]), lambda q, _: f\"{the_(q)} is\",\n",
    "    ), # t: 16-14, somewhat 14-7 # verbose acc: gpj-j > curie-001 > davinci-001 > gpt-neox!? abstract acc: gpt-neox > gpt-j. all poor (inc. davinci-002!)\n",
    "#     (lambda: [TreeSet(genders_of_persons).use('equal'), PoSet(temporal_posets).use('equal')], MlM_gen,\n",
    "#      partial(_cxt2str, item2str=lambda i, _: [f'{i[0]} arrived {wrap_noun2(i[1])}', f'{wrap_noun2(i[1]).capitalize()} arrived {i[0]}']), lambda q, _: f\"So {q}'s arrival time\", ' is'\n",
    "#     ),\n",
    "    (lambda: [TreeSet(genders_of_persons).use(['equal', 'child', 'sibling']), PoSet(temporal_poset).use(['prev'])], MlM_gen,\n",
    "     partial(_cxt2str, item2str=lambda i, _: [f'{i[0]} arrived {prep_(i[1])}.', f'{capitalize(prep_(i[1]))} arrived {i[0]}.']), lambda q, _: f'{the_(q)} arrived'\n",
    "    ),\n",
    "    (lambda: [TreeSet(genders_of_persons).use(['equal', 'child', 'sibling']), PoSet(temporal_poset).use(['next'])], MlM_gen,\n",
    "     partial(_cxt2str, item2str=lambda i, _: [f'{i[0]} arrived {prep_(i[1])}.', f'{capitalize(prep_(i[1]))} arrived {i[0]}.']), lambda q, _: f'{the_(q)} arrived'\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "722c0ef4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.equal][cxt_len=3,rev_item2str]\n",
      " ┌@[1,4,5,7,8,11,12,13,17,18] 26-19,27-6,22-40,29-39,25-27,17-61,23-29,33-63,34-47,22-2 B->A0 44\n",
      " ├@[0,2,3,6,14,15,16,19] 25-m,28-m,24-m,30-m,26-m,15-m,10-m,29-m B->B 40\n",
      " ├@[9,10] 35-38,42-7 unk 0\n",
      " ├@1 26-19 92 B->A0 85/37/-4.8 attn/ans0s\n",
      " ├@4 27-6 83 B->A0 95/38/-6.9 attn/ans0s\n",
      " │                                       ┌@[2,3,4,6,8] 18-m,19-29,21-60,16-m,17-m B->B 44\n",
      " │                                       ├@[0,5,7] 11-49,19-53,17-61 B->A0 32\n",
      " │                                       ├@[1,9] 15-38,14-39 B->Q 10\n",
      " │                                       ├@2 18-m 92\n",
      " │                                       ├@3 19-29 75 B->B 60/57/-5.9\n",
      " │                                       ├@4 21-60 72 B->B 81/83/-7.8\n",
      " ├@5 22-40 80 B->A0 97/56/-6.1 attn/ans0s┤\n",
      " │                                       ├@6 16-m 53\n",
      " │                                       ├@8 17-m 47\n",
      " │                                       ├@0 11-49 100 B->A0 92/42/-5.0\n",
      " │                                       ├@5 19-53 56 B->A0 90/38/-5.3\n",
      " │                                       ├@7 17-61 52 B->A0 74/23/-4.6\n",
      " │                                       ├@1 15-38 93 B->Q 54/45/-4.1\n",
      " │                                       └@9 14-39 44 B->Q 51/29/-4.2\n",
      " ├@7 29-39 73 B->A0 91/33/-7.5 attn/ans0s\n",
      " │                                       ┌@[1,3,4,6,9] 21-60,19-29,20-m,18-m,22-m B->B 41\n",
      " │                                       ├@[0,2,7,10] 11-49,19-53,9-5,16-20 B->A0 27\n",
      " │                                       ├@[5,8] 15-38,15-0 B->Q 9\n",
      " │                                       ├@1 21-60 94 B->B 79/83/-7.2\n",
      " │                                       ├@3 19-29 75 B->B 50/57/-5.7\n",
      " │                                       ├@4 20-m 73\n",
      " │                                       ├@6 18-m 62\n",
      " ├@8 25-27 72 B->A0 98/51/-5.8 attn/ans0s┤\n",
      " │                                       ├@9 22-m 41\n",
      " │                                       ├@0 11-49 100 B->A0 88/42/-4.8\n",
      " │                                       ├@2 19-53 80 B->A0 92/38/-5.2\n",
      " │                                       ├@7 9-5 50 B->A0 23/5/-6.3\n",
      " │                                       ├@10 16-20 41 B->A0 43/11/-4.6\n",
      " │                                       ├@5 15-38 67 B->Q 50/45/-4.4\n",
      " │                                       └@8 15-0 41 B->Q 47/48/-4.4\n",
      " ┤\n",
      " ├@11 17-61 68 B->A0 81/23/-4.0 attn/ans0s\n",
      " │                                        ┌@[3,4,5,9] 15-38,11-35,15-0,14-30 B->Q 31\n",
      " │                                        ├@[2,6,8] 14-39,11-49,12-52 B->A0 27\n",
      " │                                        ├@:2 21-60,19-29 B->B 17\n",
      " │                                        ├@[7] 11-50 B->T 10\n",
      " │                                        ├@3 15-38 89 B->Q 41/45/-4.3\n",
      " │                                        ├@4 11-35 62 B->Q 83/64/-5.0\n",
      " │                                        ├@5 15-0 61 B->Q 47/48/-4.2\n",
      " ├@12 23-29 68 B->A0 94/48/-5.1 attn/ans0s┤\n",
      " │                                        ├@9 14-30 42 B->Q 85/66/-5.1\n",
      " │                                        ├@2 14-39 89 B->A0 40/13/-3.9\n",
      " │                                        ├@6 11-49 53 B->A0 87/42/-5.0\n",
      " │                                        ├@8 12-52 43 B->A0 68/22/-3.9\n",
      " │                                        ├@0 21-60 100 B->B 81/83/-7.4\n",
      " │                                        ├@1 19-29 90 B->B 58/57/-5.3\n",
      " │                                        └@7 11-50 49 B->T 64/63/-4.7\n",
      " ├@13 33-63 66 B->A0 70/19/-9.3 attn/ans0s\n",
      " ├@17 34-47 58 B->A0 70/19/-8.0 attn/ans0s\n",
      " ├@18 22-2 56 B->A0 92/33/-6.5 attn/ans0s\n",
      " ├@113 17-28 15 B->A0/61 attn/ans0s\n",
      " ├@139 19-1 12 B->A0/57 attn/ans0s\n",
      " ├@165 19-54 10 B->A0/59 attn/ans0s\n",
      " ├@2806 26-57 -20 B->A0/59 attn/ans0s\n",
      " ├@2853 23-54 -78 B->A0/60 attn/ans0s\n",
      " ├@0 25-m 100\n",
      " ├@2 28-m 90\n",
      " ├@3 24-m 88\n",
      " ├@6 30-m 80\n",
      " ├@14 26-m 64\n",
      " ├@15 15-m 60\n",
      " ├@16 10-m 59\n",
      " ├@19 29-m 55\n",
      " ├@9 35-38 69 B->Q- 0/1/-8.3 attn\n",
      " ├@10 42-7 69 B->A0+ 0/0/-11.5 attn/ans0s\n",
      " └@[5,8,12,113,139,165]  B->A0 attn/ans0s\n"
     ]
    }
   ],
   "source": [
    "print(key); print_tree(r.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e7bc57d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.equal][cxt_len=3]\n",
      " ┌@[1,4,5,7,8,11,12,13,17,18] 26-19,27-6,22-40,29-39,25-27,17-61,23-29,33-63,34-47,22-2 B->A0 44\n",
      " ├@[0,2,3,6,14,15,16,19] 25-m,28-m,24-m,30-m,26-m,15-m,10-m,29-m B->B 40\n",
      " ├@[9,10] 35-38,42-7 unk 0\n",
      " ├@1 26-19 92 B->A0 85/37/6/-4.8 attn/ans0s\n",
      " ├@4 27-6 83 B->A0 95/38/23/-6.9 attn/ans0s\n",
      " ├@5 22-40 80 B->A0 97/56/62/-6.1 attn/ans0s\n",
      " ├@7 29-39 73 B->A0 91/33/16/-7.5 attn/ans0s\n",
      " ├@8 25-27 72 B->A0 98/51/23/-5.8 attn/ans0s\n",
      " ├@11 17-61 68 B->A0 81/23/3/-4.0 attn/ans0s\n",
      " ├@12 23-29 68 B->A0 94/48/50/-5.1 attn/ans0s\n",
      " ├@13 33-63 66 B->A0 70/19/1/-9.3 attn/ans0s\n",
      " ├@17 34-47 58 B->A0 70/19/-22/-8.0 attn/ans0s\n",
      " ├@18 22-2 56 B->A0 92/33/-5/-6.5 attn/ans0s\n",
      " ├@113 17-28 15 B->A0/61/78 attn/ans0s\n",
      " ├@139 19-1 12 B->A0/57/60 attn/ans0s\n",
      " ├@165 19-54 10 B->A0/59/56 attn/ans0s\n",
      " ├@2806 26-57 -20 B->A0/59/14 attn/ans0s\n",
      " ├@2853 23-54 -78 B->A0/60/52 attn/ans0s\n",
      " ├@0 25-m 100\n",
      " ├@2 28-m 90\n",
      " ├@3 24-m 88\n",
      " ├@6 30-m 80\n",
      " ├@14 26-m 64\n",
      " ├@15 15-m 60\n",
      " ├@16 10-m 59\n",
      " ├@19 29-m 55\n",
      " ├@9 35-38 69 B->Q- 0/1/-31/-8.3 attn\n",
      " ├@10 42-7 69 B->A0+ 0/0/0/-11.5 attn/ans0s\n",
      " ┤\n",
      " │                            ┌@[1,2,4,5,9] 21-60,19-29,20-m,18-m,17-m B->B 47\n",
      " │                            ├@[3,8] 11-49,17-61 B->A0 27\n",
      " │                            ├@[0,6,7] 15-38,14-39,15-0 B->Q 14\n",
      " │                            ├@1 21-60 92 B->B 87/83/53/-7.5\n",
      " │                            ├@2 19-29 90 B->B 60/57/23/-5.5\n",
      " │                            ├@4 20-m 82\n",
      " │                            ├@5 18-m 72\n",
      " │                            ├@9 17-m 40\n",
      " │                            ├@3 11-49 87 B->A0 93/42/19/-4.9\n",
      " │                            ├@8 17-61 41 B->A0 75/23/3/-4.5\n",
      " │                            ├@0 15-38 100 B->Q 49/45/30/-4.2\n",
      " │                            ├@6 14-39 70 B->Q 41/29/26/-4.0\n",
      " │                            ├@7 15-0 47 B->Q 50/48/39/-4.3\n",
      " ├22-40,23-29 B->A0 attn/ans0s┤\n",
      " │                            │                ┌@[0,6,8] 11-49 100,17-61 48,17-19 42 B->A0 25\n",
      " │                            │                ├@[3,5,9] 18-m 62,19-29 53,12-63 41 B->B 16\n",
      " │                            │                ├@[1,2,7] 15-38 81,14-39 75,15-0 42 B->Q 10\n",
      " │                            │                ├@[4] 9-5 57 unk 0\n",
      " │                            │                ├@0 11-49 100 B->A0 80/42/19/-5.3\n",
      " │                            │                ├@6 17-61 48 B->A0 61/23/3/-4.5\n",
      " │                            │                ├@8 17-19 42 B->A0 4/1/3/-7.9\n",
      " │                            ├21-60,19-29 B->B┤\n",
      " │                            │                ├@3 18-m 62\n",
      " │                            │                ├@5 19-29 53 B->B 41/57/23/-5.8\n",
      " │                            │                ├@9 12-63 41 B->B 4/4/0/-6.3\n",
      " │                            │                ├@1 15-38 81 B->Q 37/45/30/-4.4\n",
      " │                            │                ├@2 14-39 75 B->Q 30/29/26/-4.2\n",
      " │                            │                ├@7 15-0 42 B->Q 35/48/39/-4.5\n",
      " │                            │                └@4 9-5 57 B->A] 19/63/43\n",
      " │                            │          ┌@[1,2,4,6] 9-33 75,10-61 60,12-35 41,11-38 40 Q->A0 12\n",
      " │                            │          ├@[3] 11-50 56 Q->T 6\n",
      " │                            │          ├@[5] 10-54 41 Q->Q 5\n",
      " │                            │          ├@[0] 12-63 100 Q->T+ 1\n",
      " │                            │          ├@1 9-33 75 Q->A0 43/50/13/-5.6\n",
      " │                            └15-38 B->Q┤\n",
      " │                                       ├@2 10-61 60 Q->A0 34/31/9/-5.1\n",
      " │                                       ├@4 12-35 41 Q->A0 1/1/2/-5.5\n",
      " │                                       ├@6 11-38 40 Q->A0 7/10/-14/-5.9\n",
      " │                                       ├@3 11-50 56 Q->T 42/94/21/-6.6\n",
      " │                                       ├@5 10-54 41 Q->Q 35/32/-2/-5.1\n",
      " │                                       └@0 12-63 100 Q->T+ 6/7/-13/-5.0\n",
      " │                                 ┌@[1,4] 11-m,9-m B->B 25\n",
      " │                                 ├@[0,2,3,7] 15-38,14-39,15-0,11-35 25 B->Q 17\n",
      " │                                 ├@[8] 17-61 24 B->A0 12\n",
      " │                                 ├@[6] 11-50 B->T 9\n",
      " │                                 ├@[5] 9-5 unk 0\n",
      " │                                 ├@1 11-m 62\n",
      " └17-28,19-1,19-54 B->A0 attn/ans0s┤\n",
      "                                   ├@4 9-m 40\n",
      "                                   ├@0 15-38 100 B->Q 29/45/30/-4.2\n",
      "                                   ├@2 14-39 58 B->Q 30/29/26/-4.1\n",
      "                                   ├@3 15-0 46 B->Q 37/48/39/-4.4\n",
      "                                   ├@6 11-50 33 B->T 44/63/19/-4.7\n",
      "                                   └@5 9-5 35 B->A] 19/63/43\n"
     ]
    }
   ],
   "source": [
    "print(key); print_tree(r.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19f62b01",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.equal][cxt_len=3]\n",
      " ┌@[1,4,5,7,8,11,12,13,17,18] 26-19,27-6,22-40,29-39,25-27,17-61,23-29,33-63,34-47,22-2 B->A0 44\n",
      " ├@[0,2,3,6,14,15,16,19] 25-m,28-m,24-m,30-m,26-m,15-m,10-m,29-m B->B 40\n",
      " ├@[9,10] 35-38,42-7 unk 0\n",
      " ├@1 26-19 92 B->A0 85/37/45/-4.8 attn/ans0s\n",
      " ├@4 27-6 83 B->A0 95/38/32/-6.9 attn/ans0s\n",
      " ├@5 22-40 80 B->A0 97/56/74/-6.1 attn/ans0s\n",
      " ├@5 22-40 80 B->A0 97/56/74/-6.1 attn:B->~<s>\n",
      " ├@7 29-39 73 B->A0 91/33/71/-7.5 attn/ans0s\n",
      " ├@7 29-39 73 B->A0 91/33/71/-7.5 attn:B->~<s>\n",
      " ├@8 25-27 72 B->A0 98/51/31/-5.8 attn/ans0s\n",
      " ├@11 17-61 68 B->A0 81/23/-19/-4.0 attn/ans0s\n",
      " ├@12 23-29 68 B->A0 94/48/75/-5.1 attn/ans0s\n",
      " ├@12 23-29 68 B->A0 94/48/75/-5.1 attn:B->~<s>\n",
      " ├@13 33-63 66 B->A0 70/19/6/-9.3 attn/ans0s\n",
      " ├@17 34-47 58 B->A0 70/19/-66/-8.0 attn/ans0s\n",
      " ├@18 22-2 56 B->A0 92/33/15/-6.5 attn/ans0s\n",
      " ├@113 17-28 15 B->A0/61/100 attn/ans0s\n",
      " ├@139 19-1 12 B->A0/57/75 attn/ans0s\n",
      " ├@165 19-54 10 B->A0/59/88 attn/ans0s\n",
      " ├@2806 26-57 -20 B->A0/59/19 attn/ans0s\n",
      " ├@2853 23-54 -78 B->A0/60/80 attn/ans0s\n",
      " ├@0 25-m 100\n",
      " ├@2 28-m 90\n",
      " ├@3 24-m 88\n",
      " ├@6 30-m 80\n",
      " ├@14 26-m 64\n",
      " ├@15 15-m 60\n",
      " ├@16 10-m 59\n",
      " ├@19 29-m 55\n",
      " ├@9 35-38 69 B->Q- 0/1/-3072/-8.3 attn/example\n",
      " ├@10 42-7 69 B->A0+ 0/0/-759039/-11.5 attn/ans0s\n",
      " ┤\n",
      " │                                  ┌@[1,7,9,10] 11-49,19-53,9-5,17-61 B->A0 35\n",
      " │                                  ├@[0,3,4,5] 21-60,19-29,20-m,18-m B->B 34\n",
      " │                                  ├@[2,6,8] 15-38,14-39,15-0 B->Q 14\n",
      " │                                  ├@1 11-49 99 B->A0 92/42/62/-4.8\n",
      " │                                  ├@1 11-49 99 B->A0 92/42/62/-4.8 attn:B->~<s>\n",
      " │                                  ├@1 11-49 99 B->A0 92/42/62/-4.8 attn/ans0s\n",
      " │                                  ├@7 19-53 58 B->A0 93/38/14/-5.2\n",
      " │                                  ├@9 9-5 45 B->A0 25/5/35/-6.1\n",
      " │                                  ├@10 17-61 43 B->A0 76/23/-19/-4.4\n",
      " │                                  ├@0 21-60 100 B->B 91/83/83/-7.4\n",
      " │                                  ├@0 21-60 100 B->B 91/83/83/-7.4 attn:B->~<s>\n",
      " │                                  ├@3 19-29 90 B->B 62/57/12/-5.6\n",
      " │                                  ├@4 20-m 84\n",
      " │                                  ├@5 18-m 73\n",
      " │                                  ├@2 15-38 93 B->Q 50/45/30/-4.2\n",
      " │                                  ├@6 14-39 59 B->Q 42/29/88/-4.1\n",
      " │                                  ├@6 14-39 59 B->Q 42/29/88/-4.1 attn:B->~<s>\n",
      " │                                  ├@6 14-39 59 B->Q 42/29/88/-4.1 attn/example\n",
      " │                                  ├@8 15-0 48 B->Q 53/48/65/-4.3\n",
      " │                                  ├@8 15-0 48 B->Q 53/48/65/-4.3 attn:B->~<s>\n",
      " │                                  ├@8 15-0 48 B->Q 53/48/65/-4.3 attn/example\n",
      " │                                  │           ┌@:5 0-m 100,5-m,7-m,9-39,6-m A0->A0 84\n",
      " │                                  ├11-49 B->A0┤\n",
      " │                                  │           └@0 0-m 100\n",
      " │                                  │                      ┌@[0,1,3,4] 7-10 100,10-52 85,10-55 71,10-54 61 B->Q 43\n",
      " │                                  │                      ├@[2] 9-21 75 unk 0\n",
      " │                                  │                      ├@0 7-10 100 B->Q 87/92/-5/-5.9\n",
      " │                                  ├11-49 B->A0 attn/ans0s┤\n",
      " │                                  │                      ├@1 10-52 85 B->Q 39/14/47/-3.3\n",
      " │                                  │                      ├@3 10-55 71 B->Q 58/88/-10/-7.3\n",
      " │                                  │                      ├@4 10-54 61 B->Q 32/58/-33/-6.6\n",
      " │                                  │                      └@2 9-21 75 B->A] 21/83\n",
      " │                                  │                        ┌@[0,1,2,4] 10-16 100,9-42 89,9-21 55,9-23 47 B->A] 50\n",
      " │                                  │                        ├@[3] 10-52 49 B->Q 6\n",
      " │                                  │                        ├@0 10-16 100 B->A] 80/78\n",
      " │                                  ├11-49 B->A0 attn:B->~<s>┤\n",
      " │                                  │                        ├@1 9-42 89 B->A] 83/74\n",
      " │                                  │                        ├@2 9-21 55 B->A] 87/83\n",
      " │                                  │                        ├@4 9-23 47 B->A] 0/0\n",
      " │                                  │                        └@3 10-52 49 B->Q 26/14/47/-3.4\n",
      " ├22-40,25-27,23-29 B->A0 attn/ans0s┤\n",
      " │                                  │          ┌@[2,4,6,7,9] 11-49 84,12-52 53,9-5 39,17-61 38,16-21 38 B->A0 36\n",
      " │                                  │          ├@[0,8] 19-29 100,0-m 38 B->B 16\n",
      " │                                  │          ├@[1,3,5] 15-38 96,14-39 69,15-0 40 B->Q 12\n",
      " │                                  │          ├@2 11-49 84 B->A0 81/42/62/-5.5\n",
      " │                                  │          ├@4 12-52 53 B->A0 54/22/68/-4.1\n",
      " │                                  │          ├@4 12-52 53 B->A0 54/22/68/-4.1 attn:B->~<s>\n",
      " │                                  │          ├@4 12-52 53 B->A0 54/22/68/-4.1 attn/ans0s\n",
      " │                                  │          ├@6 9-5 39 B->A0 17/5/35/-6.4\n",
      " │                                  ├21-60 B->B┤\n",
      " │                                  │          ├@7 17-61 38 B->A0 61/23/-19/-4.6\n",
      " │                                  │          ├@9 16-21 38 B->A0 51/27/76/-5.4\n",
      " │                                  │          ├@9 16-21 38 B->A0 51/27/76/-5.4 attn:B->~<s>\n",
      " │                                  │          ├@9 16-21 38 B->A0 51/27/76/-5.4 attn/ans0s\n",
      " │                                  │          ├@0 19-29 100 B->B 41/57/12/-5.8\n",
      " │                                  │          ├@8 0-m 38\n",
      " │                                  │          ├@1 15-38 96 B->Q 40/45/30/-4.4\n",
      " │                                  │          ├@3 14-39 69 B->Q 32/29/88/-4.2\n",
      " │                                  │          └@5 15-0 40 B->Q 41/48/65/-4.5\n",
      " │                                  │                       ┌@[0,2,3,5] 18-23 100,0-m 57,13-9 54,17-m 44 B->B 37\n",
      " │                                  │                       ├@[1,6,8] 15-0 63,10-40 38,19-44 B->Q 23\n",
      " │                                  │                       ├@[4,7] 12-4 46,9-15 30 B->A] 9\n",
      " │                                  │                       ├@[9] 11-49 B->A0 4\n",
      " │                                  │                       ├@0 18-23 100 B->B 84/84/26/-5.9\n",
      " │                                  │                       ├@2 0-m 57\n",
      " │                                  ├21-60 B->B attn:B->~<s>┤\n",
      " │                                  │                       ├@3 13-9 54 B->B 53/40/50/-5.4\n",
      " │                                  │                       ├@5 17-m 44\n",
      " │                                  │                       ├@1 15-0 63 B->Q 60/48/65/-3.6\n",
      " │                                  │                       ├@6 10-40 38 B->Q 43/45/11/-5.4\n",
      " │                                  │                       ├@4 12-4 46 B->A] 84/90\n",
      " │                                  │                       └@7 9-15 30 B->A] 1/1\n",
      " │                                  │                     ┌@[0,2,6] 9-33 100,10-61 68,12-52 43 Q->A0 17\n",
      " │                                  │                     ├@[1,3] 12-63 95,11-50 63 Q->T 8\n",
      " │                                  │                     ├@[5] 11-35 45 Q->Q 4\n",
      " │                                  │                     ├@[4] 9-39 45 unk 0\n",
      " │                                  │                     ├@0 9-33 100 Q->A0 48/50/23/-5.4\n",
      " │                                  ├15-38,14-39,15-0 B->Q┤\n",
      " │                                  │                     ├@2 10-61 68 Q->A0 40/31/9/-4.8\n",
      " │                                  │                     ├@6 12-52 43 Q->A0 29/17/60/-4.5\n",
      " │                                  │                     ├@1 12-63 95 Q->T 25/78/42/-5.2\n",
      " │                                  │                     ├@3 11-50 63 Q->T 41/94/24/-7.0\n",
      " │                                  │                     ├@5 11-35 45 Q->Q 31/33/49/-4.9\n",
      " │                                  │                     └@4 9-39 45 Q->T+ 0/0/-5349/-8.1\n",
      " │                                  │                            ┌@:5 0-m 100,12-m 62,11-m 51,8-m 32,5-m B->B 71\n",
      " │                                  │                            ├@[5] 9-10 B->A] 10\n",
      " │                                  │                            ├@[6] 12-55 B->A0 8\n",
      " │                                  ├14-39,15-0 B->Q attn/example┤\n",
      " │                                  │                            ├@0 0-m 100\n",
      " │                                  │                            ├@1 12-m 62\n",
      " │                                  │                            ├@2 11-m 51\n",
      " │                                  │                            └@3 8-m 32\n",
      " │                                  │                            ┌@[0,1,3,5] 0-m 100,5-m,13-9,12-m B->B 52\n",
      " │                                  │                            ├@[6] 10-40 B->Q 13\n",
      " │                                  └14-39,15-0 B->Q attn:B->~<s>┤\n",
      " │                                                               ├@[2] 9-10 B->A] 11\n",
      " │                                                               ├@[4] 9-0 unk 0\n",
      " │                                                               └@0 0-m 100\n",
      " │                              ┌@[0,1,3,5,7,8] 20-m,18-23,21-60,17-m,14-m,19-m B->B 58\n",
      " │                              ├@[2,4,6] 12-4,9-5,9-42 B->A] 23\n",
      " │                              ├@[9] 15-0 B->Q 7\n",
      " │                              ├@0 20-m 100\n",
      " │                              ├@1 18-23 99 B->B 83/84/26/-5.8\n",
      " │                              ├@3 21-60 79 B->B 78/83/83/-5.9\n",
      " │                              ├@5 17-m 62\n",
      " │                              ├@7 14-m 55\n",
      " │                              ├@8 19-m 50\n",
      " │                              ├@2 12-4 88 B->A] 81/90\n",
      " │                              ├@4 9-5 62 B->A] 65/63\n",
      " │                              ├@6 9-42 61 B->A] 84/74\n",
      " │                              ├@9 15-0 46 B->Q 54/48/65/-4.1\n",
      " │                              │                   ┌@[2,4] 4-53 81,9-39 60 A]->A0] 31\n",
      " │                              │                   ├@[0,1,3] 8-21 100,8-46 82,8-47 64 A]->A0+ 30\n",
      " │                              │                   ├@2 4-53 81 A]->A0] 77/87/0/-8.5\n",
      " │                              ├12-4,9-5,9-42 B->A]┤\n",
      " │                              │                   ├@4 9-39 60 A]->A0] 77/90/0/-7.5\n",
      " │                              │                   ├@0 8-21 100 A]->A0+ 78/80/0/-8.9\n",
      " │                              │                   ├@1 8-46 82 A]->A0+ 72/80/0/-6.8\n",
      " │                              │                   └@3 8-47 64 A]->A0+ 1/2/0/-9.7\n",
      " └22-40,23-29 B->A0 attn:B->~<s>┤\n",
      "                                │                ┌@[0,2,3,5,6,7,8] 12-4 100,15-42 59,9-42 59,17-19 49,9-5 43,8-47 42,9-23 40 B->A] 40\n",
      "                                │                ├@[1,4] 16-20 72,11-49 52 B->A0 6\n",
      "                                │                ├@[9] 10-40 38 unk 0\n",
      "                                │                ├@0 12-4 100 B->A] 67/90\n",
      "                                │                ├@2 15-42 59 B->A] 79/87\n",
      "                                │                ├@3 9-42 59 B->A] 73/74\n",
      "                                ├18-23,21-60 B->B┤\n",
      "                                │                ├@5 17-19 49 B->A] 58/59\n",
      "                                │                ├@6 9-5 43 B->A] 64/63\n",
      "                                │                ├@7 8-47 42 B->A] 64/70\n",
      "                                │                ├@8 9-23 40 B->A] 0/0\n",
      "                                │                ├@1 16-20 72 B->A0 13/11/-141/-3.8\n",
      "                                │                ├@4 11-49 52 B->A0 40/42/62/-3.6\n",
      "                                │                └@9 10-40 38 B->Q- 37/44/9/-4.0\n",
      "                                │         ┌@[1,2,5] 12-4 87,0-m 63,10-40 59 Q->Q 15\n",
      "                                │         ├@[0,4,6] 9-39 100,12-63 62,10-0 59 Q->T 12\n",
      "                                │         ├@[3] 8-55 63 Q->T+ 6\n",
      "                                │         ├@1 12-4 87 Q->Q 0/0/-18315/-10.9\n",
      "                                │         ├@2 0-m 63\n",
      "                                └15-0 B->Q┤\n",
      "                                          ├@5 10-40 59 Q->Q 2/4/-160/-6.9\n",
      "                                          ├@0 9-39 100 Q->T 43/72/14/-8.4\n",
      "                                          ├@4 12-63 62 Q->T 38/78/42/-6.8\n",
      "                                          ├@6 10-0 59 Q->T 4/9/-122/-4.8\n",
      "                                          └@3 8-55 63 Q->T+ 38/68/5/-7.0\n"
     ]
    }
   ],
   "source": [
    "print(key); print_tree(r.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514194bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = {}\n",
    "def fn(node): nodes[node2key(node)] = node\n",
    "traverse_tree(r.root, fn)\n",
    "print(nodes.keys())\n",
    "node = nodes['22-40 attn/ans0s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b113734",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}; key = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38c1bccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dt in r.data_tuples: dt[-1].attn_attr.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "22ec8124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "646"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "969b3ea4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "g2c[MlM_gen][types_of_things.TreeSet.neg_child,genders_of_persons.TreeSet.equal][cxt_len=3]\n",
      "Kimberly has a football. Sharon has a basketball. Kenneth has an elephant. Who does not like not a kind of ball? Kenneth? True\n",
      "Sandra has pizza. Kevin has a hamburger. Kimberly has purple. Who does not like not a kind of food? Kimberly? True\n",
      "Richard has a peach. Brian has vodka. Sarah has coffee. Who does not like not a kind of drink? Sarah? False\n",
      "\n",
      "g2c[MlM_gen][genders_of_persons.TreeSet.neg_sibling,types_of_things.TreeSet.equal][cxt_len=3,rev_item2str]\n",
      "The laptop is Mary's. The rabbit is Deborah's. The plum is George's. Barbara does not like plum? True\n",
      "The spaghetti is James's. The plum is William's. The jersey is Barbara's. Kevin does not like jersey? True\n",
      "The monkey is Patricia's. The whiskey is Charles's. The car is George's. Anthony does not like car? False\n",
      "\n",
      "MlM_gen[genders_of_persons.TreeSet.equal,countries_of_cities.TreeSet.child][cxt_len=3]\n",
      "David likes London. Sharon likes Saint Petersburg. Barbara likes Milan. Barbara wanna go to the city in Italy\n",
      "Donna likes New Delhi. Michael likes Madrid. John likes Bangkok. John wanna go to the city in Thailand\n",
      "Steven likes Berlin. Anthony likes Washington, D.C. Thomas likes Manchester. Thomas wanna go to the city in the United Kingdom\n",
      "\n",
      "g2c[MlM_gen][person_adjs.SymSet.opposite,genders_of_persons.TreeSet.sibling][cxt_len=3,rev_item2str]\n",
      "Passive Sharon. Interesting Ronald. Cowardly Sandra. Who is the opposite of uninteresting? Dorothy? False\n",
      "Tall Dorothy. Unfriendly Mark. Loyal Donald. Who is the opposite of short? Daniel? False\n",
      "Reliable Linda. Generous Richard. Strong Deborah. Who is the opposite of stingy? Anthony? True\n",
      "\n",
      "rm_query[MlM_gen][genders_of_persons.TreeSet.neg_child,temporal_poset.PoSet.next][cxt_len=3]\n",
      "Thomas arrived at 5 o'clock. Michael arrived at 9 o'clock. Donna arrived at 11 o'clock. Which is different? The time just after 10 o'clock\n",
      "Sarah arrived in autumn. Carol arrived in winter. Steven arrived in summer. Which is different? The season just after spring\n",
      "Donna arrived on Tuesday. Sarah arrived on Thursday. John arrived on Friday. Which is different? The day just after Thursday\n",
      "\n",
      "rm_query[MlM_gen][types_of_things.TreeSet.neg_child,types_of_things.TreeSet.child][cxt_len=3]\n",
      "There are whiskey, tea, black. Which is different? A kind of color\n",
      "There are a car, tea, a cocktail. Which is different? A kind of vehicle\n",
      "There are pizza, meat, sheep. Which is different? A kind of animal\n",
      "\n",
      "MlM_gen[genders_of_persons.TreeSet.neg_sibling,temporal_poset.PoSet.prev][cxt_len=3]\n",
      "Steven arrived at 4 o'clock. Mary arrived at 5 o'clock. Jennifer arrived at 10 o'clock. Karen did not arrive the time just before 5 o'clock\n",
      "Helen arrived at 7 o'clock. Sharon arrived at 5 o'clock. Patricia arrived at 4 o'clock. Sharon did not arrive the time just before 6 o'clock\n",
      "Kenneth arrived in July. Ruth arrived in September. David arrived in February. Donald did not arrive the month just before October\n",
      "\n",
      "g2c[MlM_gen][genders_of_persons.TreeSet.sibling,types_of_things.TreeSet.child][cxt_len=3]\n",
      "George has a jersey. Sarah has a beetle. Michelle has a lime. Michael likes a kind of fruit? False\n",
      "Daniel has a mango. Jeff has a bus. Laura has a sweater. Sandra likes a kind of clothing? True\n",
      "Robert has a steak. Lisa has a squirrel. Betty has an iPad. Thomas likes a kind of food? True\n",
      "\n",
      "MlM_gen[temporal_poset.PoSet.prev,genders_of_persons.TreeSet.child][cxt_len=3]\n",
      "Maria arrived on Monday. Ronald arrived on Tuesday. Mark arrived on Thursday. Who arrived the day just before Tuesday? the girl\n",
      "Sharon arrived on Monday. Thomas arrived on Wednesday. David arrived on Friday. Who arrived the day just before Tuesday? the girl\n",
      "Kevin arrived at 10 o'clock. Patricia arrived at 4 o'clock. Kenneth arrived at 5 o'clock. Who arrived the time just before 5 o'clock? the girl\n",
      "\n",
      "g2c[MlM_gen][genders_of_persons.TreeSet.neg_child,capabilities_of_things.TreeSet.child][cxt_len=3,rev_item2str]\n",
      "The abacus is Brian's. The pan is Kenneth's. The pen is Mary's. Boys do not have the thing that can write? True\n",
      "The plane is Donald's. The telegraph is Betty's. The dagger is Richard's. Boys do not have the thing that can communicate? True\n",
      "The gun is Karen's. The jeep is George's. The bicycle is Lisa's. Girls do not have the thing that can ride? False\n"
     ]
    }
   ],
   "source": [
    "for res_key, result in sample(list(results.items()), 10):\n",
    "    print('\\n'+res_key)\n",
    "    print('\\n'.join(result.texts[0].strip('\\n').split('\\n')[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "327abb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "del results[res_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afe0ced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout = sys.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a697e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁animal', '▁fruit', '▁drink', '▁food', '▁weapon', '▁insect', '▁vehicle', '▁cl', '▁sport', '▁musical']\n"
     ]
    }
   ],
   "source": [
    "prefix = ' ' if isinstance(tokenizer, GPT2Tokenizer) else ''  # LlamaTokenizer\n",
    "ids = [tokenizer.encode(prefix + word, add_special_tokens=False)[0] for word in types_of_things().keys()]\n",
    "print(tokenizer.convert_ids_to_tokens(ids))\n",
    "logits_bias = torch.zeros(model.lm_head.weight.size(0))\n",
    "logits_bias[ids] = 1. if isinstance(tokenizer, GPT2Tokenizer) else 3.  # LlamaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24b01583",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gpu = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f13e0c0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.child][cxt_len=3] == \n",
      "< William has a wolf. Dorothy has spaghetti. Steven has a jersey. >. Steven has a kind of clothing\n",
      "< Carol has a lemon. David has sheep. Michael has cherries. >. David has a kind of animal\n",
      "< Mark has spaghetti. Steven has a shotgun. Linda has grapes. >. Mark has a kind of food\n",
      "1.1149751444657643 0.7037037037037037 0.4438796296296296\n",
      "attribute_tree ... In attribute_tree: attribute_step , topk=20 ... done 0:00:01.317329\n",
      "In _add_node: add @0 19-m 100\n",
      "In _add_node: add @1 21-m 78\n",
      "In _add_node: add @5 20-m 46\n",
      "In _add_node: add @8 18-9 42 B->B 45/18/85/-4.1\n",
      "In _add_node: add @8 18-9 42 B->B 45/18/85/-4.1 attn:B->~<s>\n",
      "In _add_node: add @11 25-13 32 B->B 56/21/1/-4.0\n",
      "In _add_node: add @12 16-m 32\n",
      "In _add_node: add @2 20-5 53 B->A0 82/33/82/-3.8 attn/ans0s\n",
      "In _add_node: add @2 20-5 53 B->A0 82/33/82/-3.8 attn:B->~<s>\n",
      "In _add_node: add @3 21-5 50 B->A0 59/19/69/-3.9 attn/ans0s\n",
      "In _add_node: add @3 21-5 50 B->A0 59/19/69/-3.9 attn:B->~<s>\n",
      "In _add_node: add @4 19-14 48 B->A0 75/25/75/-4.1 attn/ans0s\n",
      "In _add_node: add @4 19-14 48 B->A0 75/25/75/-4.1 attn:B->~<s>\n",
      "In _add_node: add @6 21-14 45 B->A0 47/11/-176/-3.5 attn/ans0s\n",
      "In _add_node: add @7 13-7 43 B->A0 95/68/79/-3.8 attn/ans0s\n",
      "In _add_node: add @7 13-7 43 B->A0 95/68/79/-3.8 attn:B->~<s>\n",
      "In _add_node: add @9 15-8 37 B->A0 90/43/90/-3.5 attn/ans0s\n",
      "In _add_node: add @9 15-8 37 B->A0 90/43/90/-3.5 attn:B->~<s>\n",
      "In _add_node: add @10 13-13 32 B->A]^ 97/88 attn/example\n",
      "In _add_node: add @[0,1,5,8,11,12,13,15,16,18] 19-m,21-m,20-m,18-9,25-13,16-m,24-10 29,22-m 27,18-m 27,24-7 23 B->B 46\n",
      "In _add_node: add @[2,3,4,6,7,9,14,17,19] 20-5,21-5,19-14,21-14,13-7,15-8,16-15 29,17-13 24,15-15 21 B->A0 34\n",
      "In _add_node: add @[10] 13-13 B->A]^ 6\n",
      "done 0:00:03.354690\n"
     ]
    }
   ],
   "source": [
    "# logger = TeeLogger('predict2.out', 'a')\n",
    "nrows, k_shot = 12, 3; cxt_len = 3; save_results = True\n",
    "batch_size = 12; verbose = False #not save_results or batch_size <= 8\n",
    "rel1_kwargs = {'x_f': None}  # {'x_f': _s, 'y_f': a_, 'skip_inv_f':False}\n",
    "for task,        rel0_i, rel1_i, do_swap_qa, do_negate, do_rm_query, rev_item2str, do_g2c in product(\n",
    "    tasks[0:1], [0],[0],[False,],  [False],[False],[False],[False]):\n",
    "#     tasks[:1],range(3),range(3),[False,],[False,True],[False,True],[False,True],[False,True]):\n",
    "    seed(42)\n",
    "    args = dict(cxt_len=cxt_len, rev_item2str=rev_item2str, abstract=False)\n",
    "    trans_args = dict(rel0_i=rel0_i, rel1_i=rel1_i, rel1_kwargs=rel1_kwargs, do_swap_qa=do_swap_qa, do_negate=do_negate,\n",
    "                      do_rm_query=do_rm_query, do_g2c=do_g2c)\n",
    "    task = transform_and_validate_task(task, **trans_args, **args)\n",
    "    if task is None: continue\n",
    "    res_key = f'{task2str(task)}[{args2str(args)}]'  # {composed_heads2str(model)}\n",
    "    print(f'\\n== {res_key} == {args2str(trans_args)}')\n",
    "#     if key is not None and res_key != key: continue\n",
    "    r = results[res_key] if save_results and res_key in results else None\n",
    "#     if r is not None: print('duplicate task!'); continue \n",
    "    r = generate_and_predict_batch(model if save_results else model_gpu, tokenizer, task, nrows, k_shot, batch_size,\n",
    "            logits_bias=None, custom_forward=save_results, result=r, verbose=verbose, **args)\n",
    "    if save_results: results[res_key] = r\n",
    "    else: continue\n",
    "\n",
    "    if r.root is None: r.root = add_node(None, layer=L, label_type='labels')\n",
    "    r.root = attribute_tree_on(r.data_tuples, model, r.root, -1, topk=10, k_shot=k_shot, mix=True, device=None, verbose=True)\n",
    "# logger.__del__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c696fb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(3+9)*12 bad order, rm color device, rm things, seed 42 1.5064196586608887 0.6203703703703703 0.37714814814814823\n",
    "(3+9)*12 bad order, rm color device,            seed 42 1.159108007947604 0.6574074074074074 0.42780555555555555\n",
    "(3+9)*12 bad order,                             seed 42 1.3327981928984325 0.6481481481481481 0.42299074074074067\n",
    "(3+9)*12            rm color device,            seed 42 1.114751656850179 0.7037037037037037 0.44380555555555556\n",
    "(3+9)*12                                        seed 42 1.3617003957430522 0.6666666666666666 0.4164907407407408\n",
    "\n",
    "(3+9)*12 logits_bias, bad order, rm color device, rm things,seed 42 1.5064196586608887 0.6574074074074074 0.4634444444444445\n",
    "(3+9)*12 logits_bias, bad order, rm color device,          seed 42 1.159108007947604 0.6759259259259259 0.5086944444444444\n",
    "(3+9)*12 logits_bias, bad order                            seed 42 1.3327981928984325 0.6759259259259259 0.5191388888888889\n",
    "(3+9)*12 logits_bias,            rm color device,          seed 42 1.114751656850179 0.7129629629629629 0.526574074074074\n",
    "(3+9)*12 logits_bias                                       seed 42 1.3617003957430522 0.7037037037037037 0.5125555555555555\n",
    "\n",
    "(3+9)*64 logits_bias, bad order, rm color device 1.3556777220219374 0.6597222222222222 0.4862256944444445\n",
    "(3+9)*64 logits_bias,            rm color device 1.3825375027954578 0.6493055555555556 0.48517361111111107\n",
    "(3+9)*64 logits_bias, bad order, rm color device, seed 42 1.3336960999295115 0.6805555555555556 0.49423958333333334\n",
    "(3+9)*64 logits_bias, bad order,                  seed 42 1.4599321372807026 0.6579861111111112 0.47406597222222224\n",
    "(3+9)*64 logits_bias, bad order, rm color device, rm things, seed 42 1.4292480954900384 0.65625 0.48714583333333333\n",
    "# (3+9)*64 types_of_things2,logits_bias, bad_order, rm color device 2.0301878917962313 0.5138888888888888 0.3369496527777777\n",
    "# (3+9)*64 types_of_things2,logits_bias, bad_order, rm color device seed 42 1.9500237852334976 0.5503472222222222 0.3563472222222222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2e95a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.child][cxt_len=3]\n",
      " ┌@[0,1,5,8,11,12,13,15,16,18] 19-m,21-m,20-m,18-9,25-13,16-m,24-10 29,22-m 27,18-m 27,24-7 23 B->B 46\n",
      " ├@[2,3,4,6,7,9,14,17,19] 20-5,21-5,19-14,21-14,13-7,15-8,16-15 29,17-13 24,15-15 21 B->A0 34\n",
      " ├@[10] 13-13 B->A]^ 6\n",
      " ├@0 19-m 100\n",
      " ├@1 21-m 78\n",
      " ├@5 20-m 46\n",
      " ├@8 18-9 42 B->B 45/18/85/-4.1\n",
      " ├@8 18-9 42 B->B 45/18/85/-4.1 attn:B->~<s>\n",
      " ├@11 25-13 32 B->B 56/21/1/-4.0\n",
      " ├@12 16-m 32\n",
      " ├@2 20-5 53 B->A0 82/33/82/-3.8 attn/ans0s\n",
      " ┤\n",
      " ├@2 20-5 53 B->A0 82/33/82/-3.8 attn:B->~<s>\n",
      " ├@3 21-5 50 B->A0 59/19/69/-3.9 attn/ans0s\n",
      " ├@3 21-5 50 B->A0 59/19/69/-3.9 attn:B->~<s>\n",
      " ├@4 19-14 48 B->A0 75/25/75/-4.1 attn/ans0s\n",
      " ├@4 19-14 48 B->A0 75/25/75/-4.1 attn:B->~<s>\n",
      " ├@6 21-14 45 B->A0 47/11/-176/-3.5 attn/ans0s\n",
      " ├@7 13-7 43 B->A0 95/68/79/-3.8 attn/ans0s\n",
      " ├@7 13-7 43 B->A0 95/68/79/-3.8 attn:B->~<s>\n",
      " ├@9 15-8 37 B->A0 90/43/90/-3.5 attn/ans0s\n",
      " ├@9 15-8 37 B->A0 90/43/90/-3.5 attn:B->~<s>\n",
      " └@10 13-13 32 B->A]^ 97/88 attn/example\n"
     ]
    }
   ],
   "source": [
    "print(res_key); print_tree(r.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42b8dc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.child][cxt_len=3]\n",
      " ┌@[0,2,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19] 59-4,37-m,57-m,29-3,53-m,30-m,36-m,50-m,39-m,56-m,34-m,33-m,55-m,35-m,29-m 28,27-m 28,32-m 28 B->B 83\n",
      " ├@[1,3,6] 28-8,34-16,35-8 B->A0 10\n",
      " ├@0 59-4 100 B->B 81/65/27/-5.0\n",
      " ├@2 37-m 44\n",
      " ├@4 57-m 42\n",
      " ├@5 29-3 37 B->B 33/13/21/-4.4\n",
      " ├@7 53-m 34\n",
      " ├@8 30-m 34\n",
      " ├@9 36-m 34\n",
      " ├@10 50-m 34\n",
      " ├@11 39-m 34\n",
      " ├@12 56-m 33\n",
      " ├@13 34-m 32\n",
      " ├@14 33-m 31\n",
      " ├@15 55-m 30\n",
      " ├@16 35-m 30\n",
      " ├@1 28-8 72 B->A0 84/57/31/-4.7 attn/ans0s\n",
      " ├@3 34-16 44 B->A0 31/13/-67/-3.8 attn/ans0s\n",
      " ├@6 35-8 37 B->A0 67/19/-16/-4.1 attn/ans0s\n",
      " ┤\n",
      " │                     ┌@[0,1,3,4,5,6] 15-0,18-1,21-11,19-28,24-27,17-32 B->Q 39\n",
      " │                     ├@[2,7,8] 18-13,19-33,15-47 B->A0 25\n",
      " │                     ├@0 15-0 100 B->Q 60/29/9/-3.3\n",
      " │                     ├@1 18-1 91 B->Q 65/26/66/-3.7\n",
      " │                     ├@1 18-1 91 B->Q 65/26/66/-3.7 attn:B->~<s>\n",
      " │                     ├@1 18-1 91 B->Q 65/26/66/-3.7 attn/example\n",
      " │                     ├@1 18-1 91 B->Q 65/26/66/-3.7 attn\n",
      " │                     ├@3 21-11 78 B->Q 75/37/45/-4.1\n",
      " │                     ├@3 21-11 78 B->Q 75/37/45/-4.1 attn:B->~<s>\n",
      " │                     ├@3 21-11 78 B->Q 75/37/45/-4.1 attn/example\n",
      " │                     ├@3 21-11 78 B->Q 75/37/45/-4.1 attn\n",
      " │                     ├@4 19-28 73 B->Q 56/18/-94/-3.9\n",
      " │                     ├@5 24-27 71 B->Q 26/19/79/-4.0\n",
      " ├28-8 B->A0 attn/ans0s┤\n",
      " │                     ├@5 24-27 71 B->Q 26/19/79/-4.0 attn:B->~<s>\n",
      " │                     ├@5 24-27 71 B->Q 26/19/79/-4.0 attn/example\n",
      " │                     ├@5 24-27 71 B->Q 26/19/79/-4.0 attn\n",
      " │                     ├@6 17-32 57 B->Q 65/17/60/-4.2\n",
      " │                     ├@6 17-32 57 B->Q 65/17/60/-4.2 attn:B->~<s>\n",
      " │                     ├@6 17-32 57 B->Q 65/17/60/-4.2 attn/example\n",
      " │                     ├@6 17-32 57 B->Q 65/17/60/-4.2 attn\n",
      " │                     ├@2 18-13 80 B->A0 49/31/63/-4.2 attn/ans0s\n",
      " │                     ├@2 18-13 80 B->A0 49/31/63/-4.2 attn:B->~<s>\n",
      " │                     ├@7 19-33 56 B->A0 52/24/74/-5.2 attn/ans0s\n",
      " │                     ├@7 19-33 56 B->A0 52/24/74/-5.2 attn:B->~<s>\n",
      " │                     ├@8 15-47 51 B->A0 80/34/69/-5.1 attn/ans0s\n",
      " │                     └@8 15-47 51 B->A0 80/34/69/-5.1 attn:B->~<s>\n",
      " │         ┌@[0,1,2,4,5,6,9,13,14,15,16,18,19] 19-24,18-18,28-8,25-1,25-33,34-16,25-2,23-12,28-33,24-6,34-31 29,21-38 27,15-34 26 B->A0 38\n",
      " │         ├@[3,7,8,10,11,12,17] 29-3,45-m,34-m,30-m,37-m,50-m,47-m 28 B->B 33\n",
      " │         ├@0 19-24 100 B->A0 72/48/79/-3.8 attn/ans0s\n",
      " │         ├@0 19-24 100 B->A0 72/48/79/-3.8 attn:B->~<s>\n",
      " │         ├@1 18-18 82 B->A0 79/74/72/-4.4 attn/ans0s\n",
      " │         ├@1 18-18 82 B->A0 79/74/72/-4.4 attn:B->~<s>\n",
      " │         ├@2 28-8 76 B->A0 68/57/31/-5.2 attn/ans0s\n",
      " │         ├@4 25-1 58 B->A0 61/26/39/-3.6 attn/ans0s\n",
      " │         ├@5 25-33 49 B->A0 73/60/25/-4.5 attn/ans0s\n",
      " │         ├@6 34-16 45 B->A0 23/13/-67/-3.9 attn/ans0s\n",
      " │         ├@9 25-2 38 B->A0 70/48/40/-4.7 attn/ans0s\n",
      " └59-4 B->B┤\n",
      "           ├@9 25-2 38 B->A0 70/48/40/-4.7 attn:B->~<s>\n",
      "           ├@13 23-12 32 B->A0 57/52/69/-5.6 attn/ans0s\n",
      "           ├@13 23-12 32 B->A0 57/52/69/-5.6 attn:B->~<s>\n",
      "           ├@14 28-33 32 B->A0 58/26/18/-4.1 attn/ans0s\n",
      "           ├@15 24-6 31 B->A0 55/17/17/-4.9 attn/ans0s\n",
      "           ├@3 29-3 62 B->B 28/13/21/-4.4\n",
      "           ├@7 45-m 45\n",
      "           ├@8 34-m 41\n",
      "           ├@10 30-m 37\n",
      "           ├@11 37-m 36\n",
      "           └@12 50-m 34\n"
     ]
    }
   ],
   "source": [
    "print(res_key); print_tree(r.root)  # vicuna-33b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c6cb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.3561700880527496 0.6666666666666666 0.40170370370370373\n",
    "1.172130400935809 0.7222222222222222 0.4628611111111111\n",
    "1.1529395828644435 0.7314814814814815 0.47151851851851856 # + 19-14\n",
    "0.8755234579245249 0.7870370370370371 0.5257685185185186  # golden B->Q\n",
    "0.34410187726219493 0.8703703703703703 0.7918055555555557  # equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "aaac0ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.child][cxt_len=3]_B->Q]:11-12_13-7:15-8,19-14,20-5,21-5\n",
      " ┌@[0,3,4,5,7] 21-5,20-5,15-8,19-14,13-7 28 B->A0 49\n",
      " ├@[1,2,6,8,9] 19-m,21-m,20-m,18-9 26,18-m 22 B->B 45\n",
      " ├@0 21-5 100 B->A0 97/75/72/-5.8 attn/ans0s\n",
      " ├@0 21-5 100 B->A0 97/75/72/-5.8 attn:B->~<s>\n",
      " ├@3 20-5 49 B->A0 96/75/72/-5.4 attn/ans0s\n",
      " ├@3 20-5 49 B->A0 96/75/72/-5.4 attn:B->~<s>\n",
      " ┤\n",
      " ├@4 15-8 44 B->A0 96/75/72/-4.5 attn/ans0s\n",
      " ├@4 15-8 44 B->A0 96/75/72/-4.5 attn:B->~<s>\n",
      " ├@5 19-14 42 B->A0 94/75/72/-5.5 attn/ans0s\n",
      " ├@5 19-14 42 B->A0 94/75/72/-5.5 attn:B->~<s>\n",
      " ├@1 19-m 70\n",
      " ├@2 21-m 55\n",
      " └@6 20-m 35\n"
     ]
    }
   ],
   "source": [
    "print(res_key); print_tree(r.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "95b804a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ┌@[0,3,4,5,8] 21-5,20-5,15-8,19-14,13-7 28 B->A0 48\n",
      " ├@[1,2,6,7,9] 19-m,21-m,20-m,18-9 29,18-m 24 B->B 45\n",
      " ├@0 21-5 100 B->A0 95/64/78/-5.4 attn/ans0s\n",
      " ├@0 21-5 100 B->A0 95/64/78/-5.4 attn:B->~<s>\n",
      " ├@3 20-5 46 B->A0 95/64/78/-4.9 attn/ans0s\n",
      " ├@3 20-5 46 B->A0 95/64/78/-4.9 attn:B->~<s>\n",
      " ┤\n",
      " ├@4 15-8 43 B->A0 94/64/78/-4.2 attn/ans0s\n",
      " ├@4 15-8 43 B->A0 94/64/78/-4.2 attn:B->~<s>\n",
      " ├@5 19-14 41 B->A0 92/64/78/-5.0 attn/ans0s\n",
      " ├@5 19-14 41 B->A0 92/64/78/-5.0 attn:B->~<s>\n",
      " ├@1 19-m 73\n",
      " ├@2 21-m 58\n",
      " └@6 20-m 39\n"
     ]
    }
   ],
   "source": [
    "print_tree(r.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "ea9d3a0f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ┌@[0,1,2,4,9] 19-m,21-m,20-m,18-9,18-m B->B 47\n",
      " ├@[3,5,6,7,8] 21-5,19-14,13-7,20-5,15-8 B->A0 41\n",
      " ├@0 19-m 100\n",
      " ├@1 21-m 77\n",
      " ├@2 20-m 56\n",
      " ├@4 18-9 42 B->B 47/18/82/-4.0\n",
      " ├@4 18-9 42 B->B 47/18/82/-4.0 attn:B->~<s>\n",
      " ├@9 18-m 34\n",
      " ├@3 21-5 54 B->A0 60/19/83/-3.8 attn/ans0s\n",
      " ├@3 21-5 54 B->A0 60/19/83/-3.8 attn:B->~<s>\n",
      " ├@5 19-14 41 B->A0 82/20/46/-4.4 attn/ans0s\n",
      " ├@5 19-14 41 B->A0 82/20/46/-4.4 attn:B->~<s>\n",
      " │                                         ┌@:3 11-12,9-5,12-14 B->Q 39\n",
      " │                                         ├@[3,4] 10-3,11-9 B->A0 32\n",
      " │                                         ├@0 11-12 100 B->Q 55/24/30/-3.7\n",
      " │                                         ├@1 9-5 70 B->Q 80/39/28/-4.0\n",
      " ├@6 13-7 41 B->A0 94/64/78/-4.0 attn/ans0s┤\n",
      " │                                         ├@2 12-14 63 B->Q 50/17/29/-4.8\n",
      " │                                         ├@3 10-3 37 B->A0 73/19/92/-3.5 attn/ans0s\n",
      " │                                         ├@3 10-3 37 B->A0 73/19/92/-3.5 attn:B->~<s>\n",
      " │                                         ├@4 11-9 31 B->A0 71/27/96/-4.4 attn/ans0s\n",
      " │                                         └@4 11-9 31 B->A0 71/27/96/-4.4 attn:B->~<s>\n",
      " │                                           ┌@[0,2] 9-14,8-1 B->A]^ 36\n",
      " │                                           ├@[1,3] 11-12,10-11 B->Q 17\n",
      " │                                           ├@[4] 11-4 B->Q- 4\n",
      " │                                           ├@0 9-14 100 B->A]^ 86/80\n",
      " │                                           ├@2 8-1 95 B->A]^ 92/90\n",
      " ├@6 13-7 41 B->A0 94/64/78/-4.0 attn:B->~<s>┤\n",
      " │                                           ├@1 11-12 95 B->Q 48/24/30/-4.1\n",
      " │                                           ├@3 10-11 86 B->Q 30/29/56/-3.9\n",
      " │                                           ├@3 10-11 86 B->Q 30/29/56/-3.9 attn:B->~<s>\n",
      " │                                           ├@3 10-11 86 B->Q 30/29/56/-3.9 attn/example\n",
      " │                                           ├@3 10-11 86 B->Q 30/29/56/-3.9 attn\n",
      " │                                           └@4 11-4 84 B->Q- 10/6/-68/-4.1\n",
      " ┤\n",
      " │                                         ┌@[0,1,3,5] 13-7,15-8,17-13,13-2 B->A0 49\n",
      " │                                         ├@[2,4,6] 18-9,14-9,15-1 B->B 18\n",
      " │                                         ├@0 13-7 100 B->A0 93/64/78/-3.9 attn/ans0s\n",
      " │                                         ├@1 15-8 59 B->A0 90/39/93/-3.8 attn/ans0s\n",
      " │                                         ├@3 17-13 41 B->A0 68/26/82/-3.9 attn/ans0s\n",
      " │                                         ├@3 17-13 41 B->A0 68/26/82/-3.9 attn:B->~<s>\n",
      " ├@7 20-5 39 B->A0 80/32/73/-3.9 attn/ans0s┤\n",
      " │                                         ├@5 13-2 33 B->A0 62/21/58/-4.7 attn/ans0s\n",
      " │                                         ├@5 13-2 33 B->A0 62/21/58/-4.7 attn:B->~<s>\n",
      " │                                         ├@2 18-9 53 B->B 49/18/82/-4.1\n",
      " │                                         ├@4 14-9 37 B->B 46/25/59/-5.4\n",
      " │                                         ├@4 14-9 37 B->B 46/25/59/-5.4 attn:B->~<s>\n",
      " │                                         ├@6 15-1 32 B->B 28/11/88/-3.8\n",
      " │                                         └@6 15-1 32 B->B 28/11/88/-3.8 attn:B->~<s>\n",
      " │                                           ┌@[0,2,3,6] 8-1,13-13,12-10,9-14 B->A]^ 51\n",
      " │                                           ├@[1,4,5] 0-m,16-m,14-9 B->B 33\n",
      " │                                           ├@0 8-1 100 B->A]^ 93/90\n",
      " │                                           ├@2 13-13 67 B->A]^ 96/85\n",
      " ├@7 20-5 39 B->A0 80/32/73/-3.9 attn:B->~<s>┤\n",
      " │                                           ├@3 12-10 58 B->A]^ 87/80\n",
      " │                                           ├@6 9-14 34 B->A]^ 79/80\n",
      " │                                           ├@1 0-m 71\n",
      " │                                           ├@4 16-m 48\n",
      " │                                           └@5 14-9 37 B->B 30/25/59/-3.9\n",
      " │                                         ┌@[0,3] 13-7,11-9 B->A0 31\n",
      " │                                         ├@[1,4] 14-9,14-12 B->B 18\n",
      " │                                         ├@[2] 12-14 B->Q 12\n",
      " │                                         ├@0 13-7 100 B->A0 90/64/78/-4.9 attn/ans0s\n",
      " ├@8 15-8 39 B->A0 89/39/93/-3.5 attn/ans0s┤\n",
      " │                                         ├@3 11-9 45 B->A0 60/27/96/-4.5 attn/ans0s\n",
      " │                                         ├@1 14-9 53 B->B 43/25/59/-5.8\n",
      " │                                         ├@4 14-12 43 B->B 37/13/90/-4.5\n",
      " │                                         ├@4 14-12 43 B->B 37/13/90/-4.5 attn:B->~<s>\n",
      " │                                         └@2 12-14 46 B->Q 49/17/29/-4.9\n",
      " │                                           ┌@[0,2,4] 8-1,13-13,9-14 B->A]^ 55\n",
      " │                                           ├@[1] 6-2 B->B^ 17\n",
      " │                                           ├@[3] 11-8 unk 0\n",
      " │                                           ├@0 8-1 100 B->A]^ 94/90\n",
      " └@8 15-8 39 B->A0 89/39/93/-3.5 attn:B->~<s>┤\n",
      "                                             ├@2 13-13 69 B->A]^ 95/85\n",
      "                                             ├@4 9-14 44 B->A]^ 85/80\n",
      "                                             ├@1 6-2 77 B->B^ 86/82\n",
      "                                             └@3 11-8 59 B->Q 1/2/-183/-5.1\n"
     ]
    }
   ],
   "source": [
    "print_tree(r.root)  # child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "a2496f46",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ┌@[0,2,3,4,5,6,8,9] 16-7,16-0,21-14,18-5,20-8,13-7,19-14,21-13 B->A0 75\n",
      " ├@[1,7] 24-10,18-9 B->B 17\n",
      " ├@0 16-7 100 B->A0 96/44/61/-3.3 attn/ans0s\n",
      " ├@0 16-7 100 B->A0 96/44/61/-3.3 attn:B->~<s>\n",
      " ├@2 16-0 74 B->A0 96/36/85/-3.4 attn/ans0s\n",
      " ├@2 16-0 74 B->A0 96/36/85/-3.4 attn:B->~<s>\n",
      " ├@3 21-14 57 B->A0 92/31/20/-3.7 attn/ans0s\n",
      " ├@4 18-5 52 B->A0 94/39/83/-3.5 attn/ans0s\n",
      " ├@4 18-5 52 B->A0 94/39/83/-3.5 attn:B->~<s>\n",
      " ├@5 20-8 49 B->A0 90/23/51/-3.8 attn/ans0s\n",
      " ├@5 20-8 49 B->A0 90/23/51/-3.8 attn:B->~<s>\n",
      " ├@6 13-7 45 B->A0 92/49/61/-3.2 attn/ans0s\n",
      " ├@6 13-7 45 B->A0 92/49/61/-3.2 attn:B->~<s>\n",
      " ├@8 19-14 38 B->A0 89/15/52/-4.2 attn/ans0s\n",
      " ├@8 19-14 38 B->A0 89/15/52/-4.2 attn:B->~<s>\n",
      " ├@9 21-13 33 B->A0 93/28/45/-3.9 attn/ans0s\n",
      " ├@9 21-13 33 B->A0 93/28/45/-3.9 attn:B->~<s>\n",
      " ├@1 24-10 94 B->B 89/86/79/-4.9\n",
      " ├@1 24-10 94 B->B 89/86/79/-4.9 attn:B->~<s>\n",
      " ├@7 18-9 40 B->B 80/39/64/-3.6\n",
      " ├@7 18-9 40 B->B 80/39/64/-3.6 attn:B->~<s>\n",
      " ┤\n",
      " │                               ┌@[0,1,5] 11-12,9-5,14-9 B->Q 39\n",
      " │                               ├@[2,3] 13-7,13-2 B->A0 31\n",
      " │                               ├@[4] 13-11 B->A0+ 10\n",
      " │                               ├@0 11-12 100 B->Q 91/69/46/-4.0\n",
      " │                               ├@0 11-12 100 B->Q 91/69/46/-4.0 attn:B->~<s>\n",
      " │                               ├@0 11-12 100 B->Q 91/69/46/-4.0 attn/example\n",
      " │                               ├@0 11-12 100 B->Q 91/69/46/-4.0 attn\n",
      " │                               ├@1 9-5 59 B->Q 95/65/-20/-4.8\n",
      " │                               ├@5 14-9 33 B->Q 45/32/-49/-6.0\n",
      " │                               ├@2 13-7 47 B->A0 84/49/61/-3.8 attn/ans0s\n",
      " │                               ├@3 13-2 46 B->A0 86/40/67/-5.0 attn/ans0s\n",
      " │                               ├@3 13-2 46 B->A0 86/40/67/-5.0 attn:B->~<s>\n",
      " │                               ├@4 13-11 43 B->A0+ 42/10/70/-4.9\n",
      " │                               ├@4 13-11 43 B->A0+ 42/10/70/-4.9 attn:B->~<s>\n",
      " │                               ├@4 13-11 43 B->A0+ 42/10/70/-4.9 attn/ans0s\n",
      " │                               ├@4 13-11 43 B->A0+ 42/10/70/-4.9 attn\n",
      " │                               │          ┌@[0,3] 10-7 100,7-6 34 Q->T+ 24\n",
      " │                               │          ├@[1] 8-7 93 Q->T 19\n",
      " │                               │          ├@[2] 9-5 53 Q->Q 19\n",
      " │                               ├11-12 B->Q┤\n",
      " │                               │          ├@0 10-7 100 Q->T+ 37/37/7/-5.0\n",
      " │                               │          ├@3 7-6 34 Q->T+ 47/40/-2/-4.3\n",
      " │                               │          ├@1 8-7 93 Q->T 71/76/39/-4.8\n",
      " │                               │          └@2 9-5 53 Q->Q 74/33/27/-4.8\n",
      " │                               │               ┌@:2 9-14 100,8-1 80 B->A]^ 49\n",
      " │                               │               ├@[3] 0-m 45 B->B 26\n",
      " │                               │               ├@[2] 9-5 53 B->Q 23\n",
      " │                               │               ├@0 9-14 100 B->A]^ 97/88\n",
      " │                               │               ├@1 8-1 80 B->A]^ 97/95\n",
      " │                               │               ├@3 0-m 45\n",
      " │                               ├11-12 B->Q attn┤\n",
      " │                               │               ├@2 9-5 53 B->Q 91/65/-20/-4.7\n",
      " │                               │               │               ┌@:2 4-6 100,7-6 81 A]->A0+ 52\n",
      " │                               │               │               ├@[2] 6-2 80 A]->A0] 28\n",
      " │                               │               └9-14,8-1 B->A]^┤\n",
      " │                               │                               ├@0 4-6 100 A]->A0+ 85/83/0/-8.3\n",
      " │                               │                               ├@1 7-6 81 A]->A0+ 72/55/0/-6.4\n",
      " │                               │                               └@2 6-2 80 A]->A0] 82/84/0/-9.0\n",
      " ├16-7,16-0,18-5 B->A0 attn/ans0s┤\n",
      " │                               │                       ┌@:2 9-14 100,8-1 83 B->A]^ 49\n",
      " │                               │                       ├@[2] 9-5 63 B->Q 23\n",
      " │                               │                       ├@[3] 8-7 53 B->B^ 17\n",
      " │                               │                       ├@0 9-14 100 B->A]^ 97/88\n",
      " │                               │                       ├@1 8-1 83 B->A]^ 97/95\n",
      " │                               │                       ├@2 9-5 63 B->Q 90/65/-20/-5.2 attn/example\n",
      " │                               │                       ├@3 8-7 53 B->B^ 69/57\n",
      " │                               ├11-12 B->Q attn/example┤\n",
      " │                               │                       │               ┌@[1,2] 7-6 84,4-6 79 A]->A0+ 51\n",
      " │                               │                       │               ├@[0] 6-2 100 A]->A0] 29\n",
      " │                               │                       ├9-14,8-1 B->A]^┤\n",
      " │                               │                       │               ├@1 7-6 84 A]->A0+ 70/55/0/-6.4\n",
      " │                               │                       │               ├@2 4-6 79 A]->A0+ 84/83/0/-8.2\n",
      " │                               │                       │               └@0 6-2 100 A]->A0] 84/84/0/-8.7\n",
      " │                               │                       │         ┌@[2] 0-m 50 B->B 33\n",
      " │                               │                       │         ├@[0] 6-2 100 B->B^ 13\n",
      " │                               │                       │         ├@[1] 4-6 53 B->A]^ 6\n",
      " │                               │                       └8-7 B->B^┤\n",
      " │                               │                                 ├@2 0-m 50\n",
      " │                               │                                 ├@0 6-2 100 B->B^ 38/66\n",
      " │                               │                                 └@1 4-6 53 B->A]^ 17/21\n",
      " │                               │                       ┌@[1,2] 6-2 92,8-7 79 B->B^ 34\n",
      " │                               │                       ├@[0] 8-1 100 B->A]^ 24\n",
      " │                               │                       ├@[3] 9-5 52 B->Q 17\n",
      " │                               │                       ├@1 6-2 92 B->B^ 69/66\n",
      " │                               │                       ├@2 8-7 79 B->B^ 68/57\n",
      " │                               │                       ├@0 8-1 100 B->A]^ 97/95\n",
      " │                               │                       ├@3 9-5 52 B->Q 68/65/-20/-5.8\n",
      " │                               └11-12 B->Q attn:B->~<s>┤\n",
      " │                                                       │          ┌@[1,2] 7-6 54,5-4 33 A]->A0+ 32\n",
      " │                                                       │          ├@[0] 6-2 100 A]->A0] 31\n",
      " │                                                       ├8-1 B->A]^┤\n",
      " │                                                       │          ├@1 7-6 54 A]->A0+ 75/55/0/-6.3\n",
      " │                                                       │          ├@2 5-4 33 A]->A0+ 19/14/0/-4.6\n",
      " │                                                       │          └@0 6-2 100 A]->A0] 88/84/0/-8.2\n",
      " │                                                       │             ┌@[0,2] 4-0 100,4-3 81 B->A]^ 16\n",
      " │                                                       │             ├@[1] 6-2 86 B->B^ 12\n",
      " │                                                       └6-2,8-7 B->B^┤\n",
      " │                                                                     ├@0 4-0 100 B->A]^ 38/50\n",
      " │                                                                     ├@2 4-3 81 B->A]^ 9/22\n",
      " │                                                                     └@1 6-2 86 B->B^ 34/66\n",
      " │                                 ┌@[0,1,2,5] 9-14,8-1,15-5,13-13 B->A]^ 59\n",
      " │                                 ├@[4] 6-2 B->B^ 12\n",
      " │                                 ├@[3] 14-9 B->B 8\n",
      " │                                 ├@0 9-14 100 B->A]^ 95/88\n",
      " │                                 ├@1 8-1 80 B->A]^ 97/95\n",
      " │                                 ├@2 15-5 75 B->A]^ 78/63\n",
      " │                                 ├@5 13-13 57 B->A]^ 85/61\n",
      " │                                 ├@4 6-2 59 B->B^ 66/66\n",
      " │                                 ├@3 14-9 71 B->B 44/24/64/-3.2\n",
      " └16-7,16-0,18-5 B->A0 attn:B->~<s>┤\n",
      "                                   ├@3 14-9 71 B->B 44/24/64/-3.2 attn:B->~<s>\n",
      "                                   │                          ┌@[0,3] 6-2 100,8-7 49 A]->A0] 33\n",
      "                                   │                          ├@[1,2] 4-6 71,7-6 68 A]->A0+ 31\n",
      "                                   │                          ├@[4] 12-m 48 A]->A] 20\n",
      "                                   │                          ├@0 6-2 100 A]->A0] 84/84/0/-8.3\n",
      "                                   └9-14,8-1,15-5,13-13 B->A]^┤\n",
      "                                                              ├@3 8-7 49 A]->A0] 80/75/0/-6.2\n",
      "                                                              ├@1 4-6 71 A]->A0+ 83/83/0/-8.0\n",
      "                                                              ├@2 7-6 68 A]->A0+ 68/55/0/-6.3\n",
      "                                                              └@4 12-m 48\n"
     ]
    }
   ],
   "source": [
    "print_tree(r.root)  # equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4ef8f8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'19-12,16-0 B->Q attn:B->~<s>'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node = r.root.children[-2]; node.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43029b30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_attn_attrs(r.data_tuples[:4], model, tokenizer, node, topi=[1], attn_patterns=['B->R'], k_shot=k_shot, mix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca05a826",
   "metadata": {},
   "outputs": [],
   "source": [
    "== MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.child][cxt_len=2,rev_item2str] == \n",
    "< The fox is David's. The meat is Barbara's. >. Barbara likes a kind of food\n",
    "< The cocktail is Christopher's. The peach is Karen's. >. Karen likes a kind of fruit\n",
    "< The phone is Elizabeth's. The duck is Kevin's. >. Elizabeth likes a kind of electronics\n",
    "< The pig is Anthony's. The black is Thomas's. >. Thomas likes a kind of color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "a1ad6893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Ranges(bos=(5, 6), ans=(6, 7), ans0=None, query=(1, 2), tgt=None, rel=(4, 5), sep=None, ans0s=None, example=(1, 7)),\n",
       " Ranges(bos=(13, 14), ans=(14, 15), ans0=None, query=(8, 10), tgt=None, rel=(12, 13), sep=None, ans0s=None, example=(8, 15))]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.data_tuples[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd472242",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.3859229083172977 0.875 | # equal\n",
    "0.4348010057583451 0.8402777777777778  # equal <>\n",
    "1.247647002339363 0.6944444444444444  # 7+9\n",
    "\n",
    "2.3866494596004486 0.4513888888888889  # gpt-j\n",
    "1.6911428906023502 0.5972222222222222  # gpt-j <>\n",
    "1.4658961072564125 0.625  # gpt-j <.>\n",
    "1.9864061176776886 0.4444444444444444  # vicuna-7b\n",
    "1.1515736505389214 0.6805555555555556  # vicuna-7b <>\n",
    "1.504320003092289 0.5902777777777778  # vicuna-7b <.>\n",
    "1.1335462369024754 0.6527777777777778  # vicuna-13b\n",
    "0.8600838650017977 0.7013888888888888  # vicuna-136 <>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0f3ae644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlM_gen[genders_of_persons.TreeSet.equal,types_of_things.TreeSet.child][cxt_len=1,abstract]\n",
      " ┌@[1,4,7] 19-m,21-m,20-m B->B 47\n",
      " ├@[0,2,3,5,8] 21-5,15-8,20-5,19-14,14-7 B->A0 47\n",
      " ├@[6,9] 18-9,17-13 B->A0+ 17\n",
      " ├@1 19-m 91\n",
      " ├@4 21-m 52\n",
      " ├@7 20-m 37\n",
      " ├@0 21-5 100 B->A0 83/62/54/-2.0 attn/ans0s\n",
      " ├@0 21-5 100 B->A0 83/62/54/-2.0 attn:B->~<s>\n",
      " ├@0 21-5 100 B->A0 83/62/54/-2.0 attn attr_k\n",
      " ├@2 15-8 65 B->A0 86/78/44/-1.4 attn/ans0s\n",
      " ├@2 15-8 65 B->A0 86/78/44/-1.4 attn attr_k\n",
      " ├@3 20-5 56 B->A0 90/54/30/-2.3 attn/ans0s\n",
      " ├@3 20-5 56 B->A0 90/54/30/-2.3 attn attr_k\n",
      " ├@5 19-14 50 B->A0 93/53/12/-2.1 attn/ans0s\n",
      " ├@5 19-14 50 B->A0 93/53/12/-2.1 attn attr_k\n",
      " ├@8 14-7 36 B->A0 74/50/31/-1.5 attn/ans0s\n",
      " ├@8 14-7 36 B->A0 74/50/31/-1.5 attn attr_k\n",
      " ├@159 2-11 0 B->A0/98/3 attn/ans0s\n",
      " ├@159 2-11 0 B->A0/98/3 attn:B->~<s>\n",
      " ├@159 9-5 0 B->A0/74/4 attn/ans0s\n",
      " ├@159 9-5 0 B->A0/74/4 attn:B->~<s>\n",
      " ├@159 1-10 0 B->A0/72/-18 attn/ans0s\n",
      " ├@159 1-10 0 B->A0/72/-18 attn:B->~<s>\n",
      " ├@159 10-3 0 B->A0/72/11 attn/ans0s\n",
      " ├@159 10-3 0 B->A0/72/11 attn:B->~<s>\n",
      " ├@6 18-9 41 B->A0+ 74/21/10/-2.4 attn/ans0s\n",
      " ├@6 18-9 41 B->A0+ 74/21/10/-2.4 attn attr_k\n",
      " ├@9 17-13 35 B->A0+ 48/37/57/-2.1 attn/ans0s\n",
      " ├@9 17-13 35 B->A0+ 48/37/57/-2.1 attn:B->~<s>\n",
      " ├@9 17-13 35 B->A0+ 48/37/57/-2.1 attn attr_k\n",
      " ┤\n",
      " │                                ┌@:8 10-11,6-4,12-14,4-3,7-1,11-14,9-14,14-9 A0->A0 9\n",
      " │                                ├@0 10-11 100 A0->A0 12/17/-105/-2.9\n",
      " │                                ├@1 6-4 67 A0->A0 2/2/-773/-5.1\n",
      " │                                ├@2 12-14 62 A0->A0 7/6/-338/-3.9\n",
      " ├21-5,15-8,20-5 B->A0 attn attr_k┤\n",
      " │                                ├@3 4-3 57 A0->A0 0/1/-1973/-6.6\n",
      " │                                ├@4 7-1 52 A0->A0 14/21/-21/-2.4\n",
      " │                                ├@5 11-14 51 A0->A0 1/3/-25/-4.8\n",
      " │                                ├@6 9-14 47 A0->A0 4/7/-160/-4.0\n",
      " │                                └@7 14-9 47 A0->A0 32/22/-114/-2.5\n",
      " │                               ┌@[1,2,3,7] 8-1,13-13,12-10,9-14 B->A]^ 41\n",
      " │                               ├@[0,4,5] 0-m,18-m,16-m B->B 38\n",
      " │                               ├@[6] 6-2 B->B^ 12\n",
      " │                               ├@1 8-1 75 B->A]^ 86/84\n",
      " │                               ├@2 13-13 54 B->A]^ 87/83\n",
      " ├21-5,15-8,20-5 B->A0 attn/ans0s┤\n",
      " │                               ├@3 12-10 51 B->A]^ 81/71\n",
      " │                               ├@7 9-14 37 B->A]^ 74/85\n",
      " │                               ├@0 0-m 100\n",
      " │                               ├@4 18-m 50\n",
      " │                               ├@5 16-m 43\n",
      " │                               └@6 6-2 38 B->B^ 97/88\n",
      " │                       ┌@[0,1,2,4,5,7] 13-13,8-1,12-10,4-3,6-3,9-2 B->A]^ 67\n",
      " │                       ├@[3] 0-m B->B 13\n",
      " │                       ├@[6] 6-2 B->B^ 12\n",
      " │                       ├@0 13-13 100 B->A]^ 95/83\n",
      " │                       ├@1 8-1 93 B->A]^ 86/84\n",
      " └21-5 B->A0 attn:B->~<s>┤\n",
      "                         ├@2 12-10 84 B->A]^ 85/71\n",
      "                         ├@4 4-3 43 B->A]^ 87/82\n",
      "                         ├@5 6-3 41 B->A]^ 93/86\n",
      "                         ├@7 9-2 39 B->A]^ 91/86\n",
      "                         ├@3 0-m 62\n",
      "                         └@6 6-2 39 B->B^ 98/88\n"
     ]
    }
   ],
   "source": [
    "print(res_key); print_tree(r.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a03ba5b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ┌@[0,1,3,4,5,6,7,8] 16-7,16-0,20-8,13-7,21-13 26,18-13 26,19-14 24,23-14 23 B->A0 75\n",
      " ├@[2,9] 24-10,18-9 21 B->B 14\n",
      " ├@0 16-7 100 B->A0 97/60/69/-3.3 attn/ans0s\n",
      " ├@0 16-7 100 B->A0 97/60/69/-3.3 attn:B->~<s>\n",
      " ├@0 16-7 100 B->A0 97/60/69/-3.3 attn attr_k\n",
      " ├@1 16-0 65 B->A0 97/45/70/-3.3 attn/ans0s\n",
      " ├@1 16-0 65 B->A0 97/45/70/-3.3 attn:B->~<s>\n",
      " ├@1 16-0 65 B->A0 97/45/70/-3.3 attn attr_k\n",
      " ├@3 20-8 34 B->A0 92/25/78/-4.2 attn/ans0s\n",
      " ├@3 20-8 34 B->A0 92/25/78/-4.2 attn:B->~<s>\n",
      " ├@3 20-8 34 B->A0 92/25/78/-4.2 attn attr_k\n",
      " ├@4 13-7 31 B->A0 90/45/1/-3.1 attn/ans0s\n",
      " ├@4 13-7 31 B->A0 90/45/1/-3.1 attn attr_k\n",
      " ├@13 14-6 15 B->A0/70/74 attn/ans0s\n",
      " ├@13 14-6 15 B->A0/70/74 attn:B->~<s>\n",
      " ├@475 20-0 -51 B->A0/61/72 attn/ans0s\n",
      " ├@475 20-0 -51 B->A0/61/72 attn:B->~<s>\n",
      " ├@2 24-10 58 B->B 84/86/94/-4.9\n",
      " ├@2 24-10 58 B->B 84/86/94/-4.9 attn:B->~<s>\n",
      " │                           ┌@[0,1,2,3,5] 10-11,12-12,14-9,10-4,11-12 A0->T+ 39\n",
      " │                           ├@[4] 0-m A0->A0 18\n",
      " │                           ├@0 10-11 100 A0->T+ 64/52/39/-3.9\n",
      " │                           ├@1 12-12 76 A0->T+ 46/29/74/-3.1\n",
      " │                           ├@1 12-12 76 A0->T+ 46/29/74/-3.1 attn:B->~<s>\n",
      " │                           ├@1 12-12 76 A0->T+ 46/29/74/-3.1 attn/example\n",
      " │                           ├@2 14-9 74 A0->T+ 39/29/39/-4.6\n",
      " │                           ├@3 10-4 72 A0->T+ 40/22/63/-5.9\n",
      " │                           ├@3 10-4 72 A0->T+ 40/22/63/-5.9 attn:B->~<s>\n",
      " │                           ├@3 10-4 72 A0->T+ 40/22/63/-5.9 attn/example\n",
      " │                           ├@5 11-12 65 A0->T+ 47/27/44/-2.8\n",
      " │                           ├@4 0-m 67\n",
      " ├16-7,16-0 B->A0 attn attr_k┤\n",
      " │                           │                    ┌@[0,2] 9-5 100,8-1 54 T+->T 11\n",
      " │                           │                    ├@[1,3,4] 8-7 62,6-2 49,10-7 35 T+->T+ 2\n",
      " │                           │                    ├@0 9-5 100 T+->T 53/77/14/-2.8\n",
      " │                           ├@[0,1,2,3,5]  A0->T+┤\n",
      " │                           │                    ├@2 8-1 54 T+->T 0/0/-2827/-7.6\n",
      " │                           │                    ├@1 8-7 62 T+->T+ 2/2/-185/-4.9\n",
      " │                           │                    ├@3 6-2 49 T+->T+ 1/1/41/-6.5\n",
      " │                           │                    └@4 10-7 35 T+->T+ 1/1/-511/-7.0\n",
      " │                           │                              ┌@:4 9-m 100,8-m 84,0-m 65,7-m 61 A0->A0 100\n",
      " │                           │                              ├@0 9-m 100\n",
      " │                           ├12-12,10-4 A0->T+ attn/example┤\n",
      " │                           │                              ├@1 8-m 84\n",
      " │                           │                              ├@2 0-m 65\n",
      " │                           │                              └@3 7-m 61\n",
      " │                           │                              ┌@:4 8-2 100,8-13 51,8-15 39,4-3 39 unk 0\n",
      " │                           │                              ├@0 8-2 100 A0->T 0/1/-54/nan\n",
      " │                           └12-12,10-4 A0->T+ attn:B->~<s>┤\n",
      " │                                                          ├@1 8-13 51 A0->T 0/0/-30/nan\n",
      " │                                                          ├@2 8-15 39 A0->T 0/0/-263/nan\n",
      " │                                                          └@3 4-3 39 A0->T 0/0/-189/nan\n",
      " ┤\n",
      " │                          ┌@[0,1,2,5] 11-12,11-9,9-5,12-14 30 B->Q 55\n",
      " │                          ├@[3,4] 13-11,13-7 B->A0 20\n",
      " │                          ├@0 11-12 100 B->Q 91/76/54/-4.2\n",
      " │                          ├@0 11-12 100 B->Q 91/76/54/-4.2 attn:B->~<s>\n",
      " │                          ├@0 11-12 100 B->Q 91/76/54/-4.2 attn/example\n",
      " │                          ├@1 11-9 56 B->Q 79/38/-62/-3.3\n",
      " │                          ├@2 9-5 49 B->Q 88/63/52/-4.4\n",
      " │                          ├@2 9-5 49 B->Q 88/63/52/-4.4 attn:B->~<s>\n",
      " │                          ├@2 9-5 49 B->Q 88/63/52/-4.4 attn/example\n",
      " │                          ├@3 13-11 37 B->A0 29/12/79/-5.2 attn/ans0s\n",
      " │                          ├@3 13-11 37 B->A0 29/12/79/-5.2 attn:B->~<s>\n",
      " │                          ├@4 13-7 31 B->A0 76/45/1/-3.6 attn/ans0s\n",
      " │                          │                           ┌@:4 11-12 100,11-9 56,9-5 47,12-14 B->Q 62\n",
      " │                          │                           ├@[4] 12-2 B->B 10\n",
      " │                          │                           ├@0 11-12 100 B->Q 88/76/54/-4.3\n",
      " │                          ├13-11,13-7 B->A0 attn/ans0s┤\n",
      " │                          │                           ├@0 11-12 100 B->Q 88/76/54/-4.3 attn/example\n",
      " │                          │                           ├@1 11-9 56 B->Q 72/38/-62/-3.4\n",
      " │                          │                           ├@2 9-5 47 B->Q 85/63/52/-4.7\n",
      " │                          │                           └@2 9-5 47 B->Q 85/63/52/-4.7 attn/example\n",
      " ├16-7,16-0 B->A0 attn/ans0s┤\n",
      " │                          │                        ┌@:3 9-14 100,8-1 69,4-0 45 B->A]^ 56\n",
      " │                          │                        ├@[3] 6-2 43 B->B^ 17\n",
      " │                          │                        ├@[4] 11-11 41 unk 0\n",
      " │                          │                        ├@0 9-14 100 B->A]^ 97/90\n",
      " │                          ├13-11 B->A0 attn:B->~<s>┤\n",
      " │                          │                        ├@1 8-1 69 B->A]^ 98/97\n",
      " │                          │                        ├@2 4-0 45 B->A]^ 86/82\n",
      " │                          │                        ├@3 6-2 43 B->B^ 86/83\n",
      " │                          │                        └@4 11-11 41 B->Q- 12/7/43/-5.9\n",
      " │                          │                   ┌@[1,3] 10-7 85,7-6 Q->T+ 25\n",
      " │                          │                   ├@[2] 9-5 50 Q->Q 21\n",
      " │                          │                   ├@[0] 8-7 100 Q->T 18\n",
      " │                          │                   ├@1 10-7 85 Q->T+ 49/50/54/-4.7\n",
      " │                          ├11-12,11-9,9-5 B->Q┤\n",
      " │                          │                   ├@1 10-7 85 Q->T+ 49/50/54/-4.7 attn:B->~<s>\n",
      " │                          │                   ├@1 10-7 85 Q->T+ 49/50/54/-4.7 attn/example\n",
      " │                          │                   ├@2 9-5 50 Q->Q 80/47/29/-5.6\n",
      " │                          │                   └@0 8-7 100 Q->T 66/69/46/-4.7\n",
      " │                          │                           ┌@[0,1,3] 8-1 100,9-14 70,7-6 36 B->A]^ 70\n",
      " │                          │                           ├@[2] 0-m 65 B->B 25\n",
      " │                          │                           ├@0 8-1 100 B->A]^ 98/97\n",
      " │                          ├11-12,9-5 B->Q attn/example┤\n",
      " │                          │                           ├@1 9-14 70 B->A]^ 98/90\n",
      " │                          │                           ├@3 7-6 36 B->A]^ 85/78\n",
      " │                          │                           └@2 0-m 65\n",
      " │                          │                           ┌@[1,2] 6-2 72,8-7 57 B->B^ 42\n",
      " │                          │                           ├@[0] 8-1 100 B->A]^ 25\n",
      " │                          │                           ├@[3] 7-1 47 B->Q 5\n",
      " │                          └11-12,9-5 B->Q attn:B->~<s>┤\n",
      " │                                                      ├@1 6-2 72 B->B^ 91/83\n",
      " │                                                      ├@2 8-7 57 B->B^ 78/61\n",
      " │                                                      ├@0 8-1 100 B->A]^ 98/97\n",
      " │                                                      └@3 7-1 47 B->Q 22/12/34/-3.7\n",
      " │                            ┌@[0,2,3,5] 9-14,15-5,8-1,13-13 B->A]^ 63\n",
      " │                            ├@[4] 6-2 B->B^ 15\n",
      " │                            ├@[1] 14-9 B->B 12\n",
      " │                            ├@0 9-14 100 B->A]^ 98/90\n",
      " │                            ├@2 15-5 71 B->A]^ 88/69\n",
      " │                            ├@3 8-1 68 B->A]^ 98/97\n",
      " │                            ├@5 13-13 59 B->A]^ 95/83\n",
      " │                            ├@4 6-2 67 B->B^ 90/83\n",
      " │                            ├@1 14-9 75 B->B 71/36/76/-3.5\n",
      " │                            ├@1 14-9 75 B->B 71/36/76/-3.5 attn:B->~<s>\n",
      " │                            │                          ┌@[0,4] 6-2 100,8-7 51 A]->A0] 35\n",
      " │                            │                          ├@[1,3] 4-6 68,7-6 52 A]->A0+ 28\n",
      " │                            │                          ├@[2] 12-m 55 A]->A] 21\n",
      " │                            │                          ├@0 6-2 100 A]->A0] 89/82/0/-8.2\n",
      " │                            ├9-14,15-5,8-1,13-13 B->A]^┤\n",
      " │                            │                          ├@4 8-7 51 A]->A0] 83/79/0/-6.4\n",
      " │                            │                          ├@1 4-6 68 A]->A0+ 87/87/0/-8.0\n",
      " │                            │                          ├@3 7-6 52 A]->A0+ 52/34/0/-6.0\n",
      " │                            │                          └@2 12-m 55\n",
      " ├16-7,16-0 B->A0 attn:B->~<s>┤\n",
      " │                            │         ┌@:4 9-14 100,13-13 95,8-1 84,12-10 63 B->A]^ 58\n",
      " │                            │         ├@[4] 13-11 62 unk 0\n",
      " │                            │         ├@0 9-14 100 B->A]^ 73/90\n",
      " │                            │         ├@1 13-13 95 B->A]^ 71/83\n",
      " │                            ├14-9 B->B┤\n",
      " │                            │         ├@2 8-1 84 B->A]^ 75/97\n",
      " │                            │         ├@3 12-10 63 B->A]^ 67/88\n",
      " │                            │         ├@4 13-11 62 B->A0 12/12/79/-6.1\n",
      " │                            │         └@4 13-11 62 B->A0 12/12/79/-6.1 attn/ans0s\n",
      " │                            │                      ┌@[0,3] 8-1 100,4-3 62 B->A]^ 31\n",
      " │                            │                      ├@[1] 7-1 70 B->Q 5\n",
      " │                            │                      ├@[4] 4-1 58 B->B^ 4\n",
      " │                            │                      ├@[2] 10-1 69 B->B 4\n",
      " │                            │                      ├@0 8-1 100 B->A]^ 99/97\n",
      " │                            ├14-9 B->B attn:B->~<s>┤\n",
      " │                            │                      ├@3 4-3 62 B->A]^ 53/46\n",
      " │                            │                      ├@1 7-1 70 B->Q 23/12/34/-3.8\n",
      " │                            │                      ├@4 4-1 58 B->B^ 6/13\n",
      " │                            │                      ├@2 10-1 69 B->B 13/11/60/-4.3\n",
      " │                            │                      └@2 10-1 69 B->B 13/11/60/-4.3 attn:B->~<s>\n",
      " │                            │         ┌@[0] 4-6 100 B->B^ 10\n",
      " │                            │         ├@[1] 5-5 99 B->A0+ 7\n",
      " │                            │         ├@0 4-6 100 B->B^ 21/15\n",
      " │                            └6-2 B->B^┤\n",
      " │                                      ├@1 5-5 99 B->A0+ 14/12/58/-5.9\n",
      " │                                      ├@1 5-5 99 B->A0+ 14/12/58/-5.9 attn:B->~<s>\n",
      " │                                      └@1 5-5 99 B->A0+ 14/12/58/-5.9 attn/ans0s\n",
      " │                       ┌@[0,3,5,8] 13-13,8-1,12-10,7-6 B->A]^ 42\n",
      " │                       ├@[1,2] 21-m,0-m B->B 23\n",
      " │                       ├@[4,6] 8-7,6-2 B->B^ 19\n",
      " │                       ├@[7] 13-11 unk 0\n",
      " │                       ├@0 13-13 100 B->A]^ 92/83\n",
      " │                       ├@3 8-1 67 B->A]^ 97/97\n",
      " │                       ├@5 12-10 62 B->A]^ 94/88\n",
      " ├24-10 B->B attn:B->~<s>┤\n",
      " │                       ├@8 7-6 41 B->A]^ 88/78\n",
      " │                       ├@1 21-m 81\n",
      " │                       ├@2 0-m 75\n",
      " │                       ├@4 8-7 64 B->B^ 71/61\n",
      " │                       ├@6 6-2 55 B->B^ 93/83\n",
      " │                       ├@7 13-11 41 B->A0 13/12/79/-6.2\n",
      " │                       └@7 13-11 41 B->A0 13/12/79/-6.2 attn/ans0s\n",
      " │          ┌@[0,1,2,3,4,5,7,8] 16-7,16-0,14-6 19,16-12 14,18-13 13,13-7 11,17-9 10,21-13 9 B->A0 80\n",
      " │          ├@[6] 18-9 10 unk 0\n",
      " │          ├@0 16-7 100 B->A0 96/60/69/-3.3 attn/ans0s\n",
      " └24-10 B->B┤\n",
      "            ├@0 16-7 100 B->A0 96/60/69/-3.3 attn attr_k\n",
      "            ├@1 16-0 37 B->A0 96/45/70/-3.9 attn/ans0s\n",
      "            └@1 16-0 37 B->A0 96/45/70/-3.9 attn attr_k\n"
     ]
    }
   ],
   "source": [
    "print_tree(r.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b55fcb64",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ġanimal 0.0 {'Ġto': 0.2, 'Ġthe': 0.047, 'Ġspaghetti': 0.032} \t Kenneth has a taxi. Linda has a gorilla. Elizabeth has spaghetti. Linda likes animal Ġvehicle:2.389 *Ġanimal:6.922 Ġfood:9.609\n",
      " Ġvehicle 0.0 {'Ġa': 0.054, 'Ġto': 0.043, 'Ġanimal': 0.029} \t Kenneth has jeans. Maria has pink. George has a car. George likes vehicle Ġclothing:7.414 Ġcolor:8.742 *Ġvehicle:7.629\n",
      " Ġclothing 0.002 {'Ġvehicle': 0.367, 'Ġanimal': 0.18, 'Ċ': 0.038} \t Susan has a steak. John has shoes. Kenneth has spaghetti. John likes clothing Ġfood:12.891 *Ġclothing:10.219 Ġfood:12.891\n",
      " Ġsport 0.09 {'Ċ': 0.159, 'Ġsport': 0.09, 'Ġa': 0.082} \t Deborah has a mouse. Steven has a mango. Sarah has a football. Sarah likes sport Ġanimal:11.578 Ġfruit:10.188 *Ġsport:13.695\n",
      " Ġanimal 0.093 {'Ġfood': 0.179, 'Ċ': 0.108, 'Ġanimal': 0.093} \t Sarah has Jeep. Jennifer has sheep. Elizabeth has spaghetti. Jennifer likes animal Ġvehicle:13.648 *Ġanimal:14.266 Ġfood:14.922\n",
      " Ġdrink 0.017 {'Ġanimal': 0.13, 'Ġclothing': 0.127, 'Ġfruit': 0.083} \t Kevin has an apple. Lisa has coffee. Linda has sheep. Lisa likes drink Ġfruit:14.664 *Ġdrink:13.070 Ġanimal:15.109\n",
      "*Ġvehicle 0.259 {'Ġvehicle': 0.259, 'Ġanimal': 0.07, 'Ġsport': 0.069} \t Michelle has a car. Elizabeth has a beetle. Mary has a donkey. Michelle likes vehicle *Ġvehicle:15.664 Ġinsect:11.219 Ġanimal:14.359\n",
      " Ġelectronics 0.005 {'Ġsport': 0.337, 'Ġcomputer': 0.089, 'Ġclothing': 0.066} \t David has a laptop. Michael has a baseball. Kimberly has a basketball. David likes electronics *Ġelectronics:12.008 Ġsport:16.250 Ġsport:16.250\n",
      "3.109206438064575 0.2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x240 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ġclothing 0.0 {'Ġto': 0.158, 'Ġhis': 0.043, 'Ġthe': 0.043} \t Joseph has an apricot. John has T-shirt. Daniel has a hamburger. John likes clothing Ġfruit:9.930 *Ġclothing:5.422 Ġfood:10.484\n",
      " Ġcolor 0.023 {'Ġred': 0.113, 'Ġclothing': 0.057, 'Ġa': 0.043} \t Laura has a mango. Donna has a rabbit. Ronald has red. Ronald likes color Ġfruit:11.859 Ġanimal:8.766 *Ġcolor:12.305\n",
      " Ġsport 0.003 {'Ċ': 0.209, 'Ġa': 0.051, 'Ġto': 0.039} \t Carol has a basketball. Deborah has a handgun. Betty has an iPad. Carol likes sport *Ġsport:10.219 Ġweapon:6.715 Ġelectronics:11.438\n",
      " Ġweapon 0.002 {'Ġwhiskey': 0.094, 'Ġsport': 0.079, 'Ġdrink': 0.074} \t Anthony has a gun. Maria has purple. Ronald has whiskey. Anthony likes weapon *Ġweapon:9.820 Ġcolor:12.969 Ġdrink:13.664\n",
      " Ġelectronics 0.008 {'Ġcolor': 0.203, 'Ġtechnology': 0.047, 'Ġgadget': 0.017} \t Jeff has a handgun. Christopher has a smartphone. Jason has gray. Christopher likes electronics Ġweapon:9.789 *Ġelectronics:11.336 Ġcolor:14.547\n",
      "*Ġfruit 0.432 {'Ġfruit': 0.432, 'Ġberries': 0.068, 'Ġfood': 0.055} \t Anthony has T-shirt. Donna has a cat. William has blackberries. William likes fruit Ġclothing:11.766 Ġanimal:10.734 *Ġfruit:16.609\n",
      " Ġcolor 0.086 {'Ġclothing': 0.102, 'Ġcolor': 0.086, 'Ġfashion': 0.082} \t Edward has a jersey. Sandra has white. Brian has shoes. Sandra likes color Ġclothing:14.727 *Ġcolor:14.555 Ġclothing:14.727\n",
      "*Ġfruit 0.126 {'Ġfruit': 0.126, 'Ġanimal': 0.097, 'Ġsport': 0.096} \t Linda has an apricot. Edward has a guitar. Joseph has a gorilla. Linda likes fruit *Ġfruit:14.977 Ġmusic:14.234 Ġanimal:14.719\n",
      "3.324155330657959 0.4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x240 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3.216680884361267, 0.5)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_predictions_by_data_tuples(model, tokenizer, r.data_tuples, k_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3eb1a35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11-12,9-5 B->Q attn:B->~<s>'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node = r.root.children[-4].children[-1]; node.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e7f37f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_attn_attrs(r.data_tuples[:1], model, tokenizer, node, topi=[1], attn_patterns=['B->B'], k_shot=k_shot+4, mix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435f910b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for data_tuple in data_tuples[:3]:\n",
    "    plot_attn_attr(data_tuple, model, tokenizer, node, 13, 7, attn_patterns=['bos->ans0]'], k_shot=0, plot_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835266e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = node.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce14dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); print('\\n'.join(result.texts[-1].split('\\n')[:1]))\n",
    "node = result.node = add_node(node, topi=[0,1,2,3,4])#layer=11, head=12, attn_pattern='bos->query]', label_type='argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f4dd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(genders_of_persons.TreeSet.equal, types_of_things.TreeSet.child) (cxt_len=3)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aebe41",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for data_tuple in data_tuples[:3]:\n",
    "    plot_attn_attr(data_tuple, model, tokenizer, node, 13, 7, attn_patterns=['bos->ans0]'], k_shot=0, plot_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0701ae6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:3], model, tokenizer, node, topi=[0,1,2], k_shot=k_shot, mix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409bc0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = result.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d23ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); print('\\n'.join(result.texts[-1].split('\\n')[:1]))\n",
    "node = result.node = add_node(node, topi=[0,1,2])#, attn_pattern='bos->query]', label_type='argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e179ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0,1,2,3,4,5])#attn_pattern='bos->ans0]', label_type='argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badcf5b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "key = 'MlM_gen(genders_of_persons.TreeSet.equal, types_of_things.TreeSet.equal) (cxt_len=3)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363fbf25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for data_tuple in data_tuples[:]:\n",
    "    plot_attn_attr(data_tuple, model, tokenizer, node, 11, 12, attn_patterns=['bos->query]'], k_shot=0, plot_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91db824e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:3], model, tokenizer, node, topi=[0,1], k_shot=k_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f897ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = result.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07867280",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); print('\\n'.join(result.texts[-1].split('\\n')[:1]))\n",
    "node = result.node = add_node(node, topi=[0,1,2,3,4,5])#, label_type='argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20113f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0])#, attn_pattern='bos->query]', label_type='argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568fca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for head_chain in product([(8, 7), (6, 2)], [(13, 13), (9, 14), (12, 10)], [(16, 7)]):\n",
    "    print(head_chain, plot_eigv(weightprod(model, list(head_chain), 'e vo vo qk e', weBTA=model.weBTAs[0]), plot=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e0b598",
   "metadata": {},
   "source": [
    "### person_adjs.opposite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b7d463",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cbe1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=3, abstract=0)_4-6/6-10->4-8_1-7/6-2/8-7->7-9'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd48aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:3], model, tokenizer, node, topi=[0,1,2], k_shot=k_shot, mix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8a9671",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = result.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41bbb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0,1])#, label_type='argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485bccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=3, abstract=0)_4-6qk->4-8_6-2qk->7-9'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5d093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = node.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e64a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0,1,2,3], head_attr_fn=get_head_mlp_attr, k_shot=k_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4ed844",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0,1,2,3]) #label_type='argmax_attn_labels', attn_pattern='bos->query]') # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa60022",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=3, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f031a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = node.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50dc477",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0], head_attr_fn=get_head_mlp_attr, k_shot=k_shot)  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f131da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0,1], head_attr_fn=get_head_mlp_attr)#label_type='argmax_attn_labels', attn_pattern='bos->query]') # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64dce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.equal) (cxt_len=3, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9ba16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0,1,4,5], k_shot=k_shot)  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807a0cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "forked_node_k.k_node = q_node; forked_node_k.model = model\n",
    "del forked_node_k.k_node; del forked_node_k.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd81ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forked_node.k_node = k_node; forked_node.model = model\n",
    "del forked_node.k_node; del forked_node.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75612c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = node.parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30875b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0,1,2,3]) #label_type='attn_labels', attn_pattern='bos->query]', step=0, attribute_k=True) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a6332",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.equal) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cd8143",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0,1,2], head_attr_fn=get_head_mlp_attr, k_shot=k_shot)  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ed26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdf2869",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0], k_shot=k_shot)  # head_attr_fn=get_head_mlp_attr, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e03775",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0,2], head_attr_fn=get_head_mlp_attr, k_shot=k_shot, mix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86219f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0,1,2,3], head_attr_fn=get_head_mlp_attr, k_shot=k_shot, mix=True)  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65baa7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_tuple in data_tuples[:4]: plot_attn_attr(data_tuple, model, tokenizer, node, 7, 9, attn_patterns=['bos->ans0]'], k_shot=k_shot, plot_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3713a89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = node.children[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17929199",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0,1,2], head_attr_fn=get_head_mlp_attr)# label_type='attn_labels')  # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079866a0",
   "metadata": {},
   "source": [
    "### thing->type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342b97df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691139e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.equal) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155c3d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0,1], head_attr_fn=get_head_mlp_attr, k_shot=k_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e1fc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "node.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f94d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0,2,4], head_attr_fn=get_head_mlp_attr)#, label_type='argmax_attn_labels')  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03ffba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.parent) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95222719",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_tuple in data_tuples[:4]: plot_attn_attr(data_tuple, model, tokenizer, node, 16, 7, attn_patterns=['bos->ans0]'], k_shot=k_shot, plot_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014caa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0,1,2,3], head_attr_fn=get_head_mlp_attr, k_shot=k_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae8689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = node.parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9476640",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = result.node = add_node(node, layer=16, head=7, topi=[0], head_attr_fn=get_head_mlp_attr)#, label_type=f'argmax_attn_labels')  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f07fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0], head_attr_fn=get_head_mlp_attr)#, label_type=f'argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb4e419",
   "metadata": {},
   "source": [
    "### fr->en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0101f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d156659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, en2fr.TreeSet.parent) (cxt_len=1, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result, topk=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c870a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = result.node = add_node(node, topi=[0,1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07ef9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_head_chains(model, get_head2scores(node));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b752617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, en2fr.TreeSet.parent) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result, topk=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e9bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples, model, tokenizer, node, topi=[0,1,2], k_shot=k_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697be2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,1,2], label_type='argmax_attn_labels')  # head_attr_fn=get_head_mlp_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b8bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_head_chains(model, get_head2scores(result.root.children[1].children[0].children[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68713987",
   "metadata": {},
   "source": [
    "### did->does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83926d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38f701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, does2did.TreeSet.parent) (cxt_len=1, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result, topk=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b511c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node.parent.parent.parent, topi=[0,1], head_attr_fn=get_head_mlp_attr, mix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb9f0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text, input_ids, labels, ranges, *args, o in data_tuples:\n",
    "    show_predictions(tokenizer, *args, logits=o.logits, labels=labels, k_shot=k_shot, topk=3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9790bcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.node = result.node.parent.parent.parent\n",
    "result.node = result.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657592c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[1,0,2,7], head_attr_fn=get_head_mlp_attr, label_type='attn_labels')  # head_attr_fn=get_head_mlp_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb091b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_tuple in data_tuples:\n",
    "    plot_attn_attr(data_tuple, model, tokenizer, node, 17, 16, attn_patterns=None, k_shot=0, plot_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0c3bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_circuit(model, tokenizer, result.task, node.parent, topi=[0,1,6,7,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27296b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0, 1, 2], k_shot=k_shot)  # head_attr_fn=get_head_mlp_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0185b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, does2did.TreeSet.equal) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result, topk=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e7c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0, 7], head_attr_fn=get_head_mlp_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6460cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3de5818",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_head_chains(model, get_head2scores(node));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01df267",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, does2did.TreeSet.parent) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result, topk=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b619a4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,1,2,3], label_type='attn_labels')  # head_attr_fn=get_head_mlp_attr, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a102409",
   "metadata": {},
   "source": [
    "### thing->capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb25f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d207a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, capabilities_of_things.TreeSet.parent) (cxt_len=1, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689b07c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_circuit(model, tokenizer, result.task, node, topi=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8d310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_circuit(model, tokenizer, result.task, node, topi=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0541f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759696a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, capabilities_of_things.TreeSet.equal) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc85adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[2,1,3,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd405a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_head_chains(model, get_head2scores(node));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8615ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, capabilities_of_things.TreeSet.parent) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f2e785",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text, input_ids, labels, ranges, *args, o in data_tuples:\n",
    "    loss, top1_corrects, answer_probs, candidate_probs = show_predictions(\n",
    "        tokenizer, *args, logits=o.logits, labels=labels, loss_reduction='mean',\n",
    "        candidates=None, k_shot=k_shot, topk=3, verbose=True)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854622df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node.parent.parent.parent, topi=[0], k_shot=k_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4126b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_attrs(data_tuples[:4], model, tokenizer, node, topi=[0, 1, 2, 3], k_shot=k_shot, plot_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d60291",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[1,2,0], label_type='argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04c9c89",
   "metadata": {},
   "source": [
    "### capital->country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f5c5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb37da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, country2capital.TreeSet.parent) (cxt_len=1, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ffef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_circuit(model, tokenizer, result.task, node, topi=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd05881",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28882636",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, country2capital.TreeSet.equal) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63db07d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060f0c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, country2capital.TreeSet.parent) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0cebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,1,2])#, label_type='argmax_attn_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8261a178",
   "metadata": {},
   "source": [
    "### person_adjs.opposite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d291a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423b3633",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=1, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ebe210",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542c29d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.equal) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a0c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66abd13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, person_adjs.SymSet.opposite) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a226df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,])#, label_type='attn_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d8dd04",
   "metadata": {},
   "source": [
    "### thing->type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d50e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, result in results.items(): print(f\"{key}: {result.mean_loss:.3f}, {result.mean_acc}\")  # old full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45e7be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.parent) (cxt_len=1, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe516f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94799e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.equal) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b745c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0, 1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414c7caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'MlM_gen(persons.EqSet.equal, types_of_things.TreeSet.parent) (cxt_len=2, abstract=0)'; result = results[key]\n",
    "node, data_tuples = show_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819f6256",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key); node = add_node_to_result(result, topi=[0,1,2])#, label_type='attn_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e68100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed(1234); torch.cuda.empty_cache()\n",
    "model_names = ['EleutherAI/gpt-j-6B/cpu', 'EleutherAI/gpt-neox-20b', #'EleutherAI/gpt-neox-20b/cpu', \n",
    "               'text-curie-001', 'text-davinci-001', 'text-davinci-002'][:1]\n",
    "metrics = dict(losses=defaultdict(list), accuracies=defaultdict(list))\n",
    "\n",
    "def batch_predict(model, tokenizer):\n",
    "    return [predict(model, tokenizer, text, examples, k_shot=k_shot, custom_forward=False, # avoid computing head_inputs\n",
    "                    bos_token=bos_token, eos_token=eos_token, verbose=len(model_names) == 1)[1]\n",
    "            for text, examples in zip(texts, all_examples)]\n",
    "    \n",
    "with Timer('pmapped batch_predict'):\n",
    "    parallel = len(model_names) > 1\n",
    "    pool = Pool(len(model_names)) if parallel else itertools  # with Pool(len(model_names)) as pool:\n",
    "    results = pool.starmap(batch_predict, [models[model_name] for model_name in model_names])\n",
    "    if parallel: pool.close(); pool.join()\n",
    "            \n",
    "# query2acc, query2loss = defaultdict(list), defaultdict(list)\n",
    "for model_name, r in zip(model_names, results):\n",
    "    _, tokenizer = models[model_name]\n",
    "    for i, (loss, top1_corrects, answer_indices, answer_probs, candidate_probs) in enumerate(r):#.get()\n",
    "        acc = top1_corrects[k_shot:] # np.array(top1_corrects[k_shot:]).mean()\n",
    "        metrics['losses'][model_name].append(loss); metrics['accuracies'][model_name].append(acc)\n",
    "        if batch_size == 1: print(model_name, loss, acc)\n",
    "#         queries = [e[1] for e in _examples_list[i]][k_shot:]\n",
    "#         for q, a, l in zip(queries, acc, loss): query2acc[q].append(float(a)); query2loss[q].append(l)\n",
    "# print(sorted([(q, np.array(v).mean()) for q, v in query2acc.items()], key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89581697",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in ['accuracies', 'losses']:\n",
    "    for model_name in model_names[:]:\n",
    "        print(metric, model_name, np.array(metrics[metric][model_name]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf1f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp(a, b):\n",
    "    print(a.dtype, a.size(), b.dtype, b.size())\n",
    "    print('allclose:', torch.allclose(a, b), 'equal:', torch.equal(a, b))\n",
    "    print((a == b).float().mean())\n",
    "    print((a - b).float().abs().mean(), a.float().abs().mean(), b.float().abs().mean())\n",
    "#     print((a - b).max(), (a - b).min())\n",
    "#     print(a[a - b == (a - b).max()])\n",
    "#     print(a[a - b == (a - b).min()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc4497",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# text, _examples = texts[0], _examples_list[0]\n",
    "torch.cuda.empty_cache()\n",
    "if True: #def predict2(model, tokenizer, text, _examples):\n",
    "    examples, input_ids, tokens, bos_indices, eos_indices, answers, labels = make_data_tuple(\n",
    "        text, tokenizer, k_shot=k_shot, bos_token=bos_token, eos_token=eos_token)\n",
    "    candidates = [[tokenizer.encode(' ' + token)[0] for token in cands[0]] for _, _, cands, _ in _examples]\n",
    "    with torch.no_grad():\n",
    "        with Timer(): o0 = model(input_ids.to(model.device), output_attentions=True, output_hidden_states=True)\n",
    "        with Timer(): o1 = forward0(model, input_ids.to(model.device), labels=labels.to(model.device),\n",
    "                by_head=['head_input0', 'head_output0'], attn_weights=None, output_hidden_states=True)\n",
    "        for o in [o0, o1]:\n",
    "            logits = o.logits\n",
    "            if isinstance(logits, torch.Tensor): logits = logits.to('cpu').float()# softmax on cpu needs float32\n",
    "            loss, top1_corrects, answer_probs, candidate_probs = show_predictions(\n",
    "                examples, tokenizer, logits, bos_indices, eos_indices, answers, labels, loss_reduction='none',\n",
    "                candidates=candidates, k_shot=k_shot, topk=3, verbose=True)\n",
    "            print('\\n')\n",
    "#     return loss, top1_corrects, answer_probs, candidate_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a74c135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a661b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in ['accuracies', 'losses']:\n",
    "    for model_name in model_names[:]:\n",
    "        print(metric, model_name, np.array(metrics[metric][model_name]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aaa1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in ['accuracies', 'losses']:\n",
    "    for model_name in model_names[:]:\n",
    "        print(metric, model_name, np.array(metrics[metric][model_name])[:,:27].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cba876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in ['accuracies', 'losses']:\n",
    "    _ = plt.figure(figsize=(10, 3));\n",
    "    for model_name in model_names[:2]:\n",
    "        plt.plot(np.array(metrics[metric][model_name])[:].mean(0), label=f'{model_name}');\n",
    "    _ = plt.legend();  _ = plt.title(metric); _ = plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60515185",
   "metadata": {},
   "outputs": [],
   "source": [
    "time2prep = {tuple(clock_of_day): 'at', tuple(days_of_week): 'on', tuple(months): 'in'}\n",
    "def lookup_item2str(item, vocab=None):\n",
    "    if vocab[0] in [clock_of_day, days_of_week, months]:\n",
    "        prep = time2prep[tuple(vocab[0])]\n",
    "        return f'{item[1]} came {prep} {item[0]}'\n",
    "    elif vocab[0] == digits:\n",
    "        return f'{item[1]} is {item[0]}'\n",
    "def lookup_query2str(query, vocab=None, rel_name=None):\n",
    "    if vocab[0] in [clock_of_day, days_of_week, months]:\n",
    "        prep = time2prep[tuple(vocab[0])]\n",
    "        prep = {'prev': 'just before', 'next': 'just after', 'same': prep}[rel_name]\n",
    "        return f'Who came {prep} {query}?'\n",
    "    elif vocab[0] == digits:\n",
    "        prep = {'prev': 'a year younger than', 'next': 'a year younger than', 'same': ''}[rel_name]\n",
    "        return f'Who is {prep} {query}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed9c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Aaren is a boy. Harlow is a girl.\n",
    "Harlow called Aaren.\n",
    "Harlow: \"Are you a girl?\"\n",
    "Aaren: \"'''\n",
    "model_name = 'EleutherAI/gpt-j-6B'\n",
    "model, tokenizer = models[model_name]\n",
    "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "logits = model(input_ids.to(getattr(model, 'device', 'cpu'))).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e43fb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_topk(*logits[0][-1].softmax(-1).topk(5), indices_fn=tokenizer.convert_ids_to_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3d4809",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prob_dist(logits.top_logprobs[-1], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5780be",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'The capital of Canada is'\n",
    "input_ids = tokenizer(text, return_tensors='pt').input_ids\n",
    "list(zip(tokenizer.convert_ids_to_tokens(input_ids[0]), input_ids[0].numpy()))\n",
    "outputs = model.generate(input_ids, max_length=10)\n",
    "tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9c689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nrows = 5; k_shot = nrows // 2 + 1\n",
    "# for pairs in [drop_first_and_last, ]:\n",
    "nrows = 6;  k_shot = 3\n",
    "for pairs in reversible_transformations + irreversible_transformations:\n",
    "    seps = [' -> ', '->'] if random.random() < 0.5 else ['->', ' -> ']\n",
    "    # seps = [' -> ', ' -> ']\n",
    "    samples = ['\\n' + '\\n'.join(a + seps[0] + b for a, b in sample(pairs, nrows)) + '\\n']\n",
    "    for s in samples: data_tuples.append(list(make_data_tuple(s, tokenizer, k_shot=k_shot, bos_token=tokenizer.tokenize(seps[0])[0])))\n",
    "    samples = ['\\n' + '\\n'.join(b + seps[1] + a for a, b in sample(pairs, nrows)) + '\\n' if pairs in reversible_transformations else \n",
    "                '\\n' + '\\n'.join(a + seps[1] + b for a, b in sample(pairs, nrows)) + '\\n']\n",
    "    for s in samples: data_tuples.append(list(make_data_tuple(s, tokenizer, k_shot=k_shot, bos_token=tokenizer.tokenize(seps[1])[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2f807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sys.path.insert(0, '/nas/xd/projects/ec')\n",
    "# from child_utils import loadPBETasks, retrieveJSONTasks\n",
    "# challenge, challengeCheating = loadPBETasks('/nas/xd/projects/ec/PBE_Strings_Track')\n",
    "# challenge2, challengeCheating2 = loadPBETasks('/nas/xd/projects/ec/data/sygus')\n",
    "# tasks = retrieveJSONTasks(\"/nas/xd/projects/ec/data/list_tasks.json\")\n",
    "# tasks2 = retrieveJSONTasks(\"/nas/xd/projects/ec/data/list_tasks2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ff8618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxy_utils import get_examples_behind, get_examples_before, get_examples_query_before, \\\n",
    "    get_examples_query_behid, get_examples_query_repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432fcd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reversible_transformations = [list(digit2cardinal.items()), noun2adj, lxy, verb_form, country2capital, en2fr, antonyms]\n",
    "irreversible_transformations = [capabilities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59cbab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc67151",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for model_name, (model, tokenizer) in models.items():\n",
    "    if any(model_name.startswith(s) for s in ['gpt2-', 'KoboldAI/fairseq-dense', 'text-davinci-001', ]): continue\n",
    "    if not model_name == 'EleutherAI/gpt-j-6B': continue\n",
    "    if not isinstance(model, types.FunctionType): _ = model.eval()\n",
    "    with Timer(model_name): outputs = model(**inputs)\n",
    "    options_ids_list = [[tokenizer.encode(' ' + option)[0] for option in options] for cxt, query, options, ans in _examples]\n",
    "    mask_logits_fn = partial(mask_logits, indices=bos_indices, kept_ids=options_ids_list)\n",
    "    loss, all_top1_correct = show_predictions(text, examples, tokenizer, outputs.logits, bos_indices, eos_indices, answers, labels,\n",
    "                    mask_logits_fn=None, topk=3, loss_reduction='mean', show_range=range(k_shot, len(examples)), sep='\\t')\n",
    "    print(loss, all_top1_correct, '\\n')\n",
    "    losses.append(loss.item() if hasattr(loss, 'item') else loss)\n",
    "    if model_name == 'EleutherAI/gpt-j-6B': break\n",
    "print(sum(losses) / len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc90b0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "relational_functions = [prev(), next()]\n",
    "rel_fns = [prevs, nexts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92834550",
   "metadata": {},
   "source": [
    "**TODO: read children books for more posets**  \n",
    "**TODO: Prompt gpt3 to elicit the posets it knows**  \n",
    "$x \\to f(x)$ where $f \\in \\{\\text{prev/next in posets of numbers/letters/months/days, antonym, hypernym, hyponym, ...}\\}$  \n",
    "$x \\to f^2(x)$  \n",
    "one poset or mixed posets  \n",
    "$x, f(x).~y \\to Ff^{[-1]}(y)$ one poset or mixed posets  \n",
    "$x, f^k(x).~y \\to Ff^{[-1]}(y)~/Ff^{[-]k}(y)$  \n",
    "$x, f(f(x))~/f(f(x)), x \\to f(x)$ in between, the simplest form of sequence completion  \n",
    "$x, f(x) \\to Gf$ where $Gf \\in \\{<, >\\}$  \n",
    "$x, f(x); y, g(y) \\to Ff \\stackrel{?}{=} g^{[-1]}$ where $\\text{output} \\in \\{\\text{True}, \\text{False}\\}$  \n",
    "sort\n",
    "\n",
    "There is a *natural* monotone map/functor $F$ between posets/sets $A$ and $B$.  Compose the computation (set operations, sorting etc.) between $A$ and $B$ with $F$ to make harder tasks.  \n",
    "$P(A) ,P(B) \\to F(P(A)) \\setminus ~/ \\cap ~/ \\triangle P(B)$. Harder form of set difference/intersection.  \n",
    "$P(A) \\to F(\\text{sorted}(P(A)))$. Harder form of sorting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504ae9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17373019",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total, n_valid = 192, 64\n",
    "n_train = n_total - n_valid\n",
    "\n",
    "input_strs = [make_input_str(tasks[4], nrows=4, ncols=5) for __ in range(n_total)]\n",
    "for s in sample(input_strs, 3): print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d6edbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(s.count('Yes') for s in input_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f80b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CHILDDataset(input_strs[:-n_valid], tokenizer)\n",
    "eval_dataset = CHILDDataset(input_strs[-n_valid:], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3185653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_total == 1:\n",
    "    inputs = tokenizer.encode_plus(text, return_tensors='pt')\n",
    "    inputs = prepare_inputs(inputs, model.device)\n",
    "    outputs = model(**inputs, output_attentions=False)\n",
    "\n",
    "    # assert inputs.input_ids.size(0) == 1\n",
    "    input_ids = inputs.input_ids\n",
    "    logits = outputs.logits\n",
    "\n",
    "    bsz = input_ids.size(0); assert bsz == 1\n",
    "    labels = torch.ones_like(input_ids) * (-100)\n",
    "    for bi in range(bsz):\n",
    "        bos_indices = (input_ids[bi] == bos_id).nonzero().squeeze(1)\n",
    "        eos_indices = (input_ids[bi] == eos_id).nonzero()[-nrows:].squeeze(1)\n",
    "        for i, (example, bos_i, eos_i) in enumerate(zip(examples, bos_indices.tolist(), eos_indices.tolist())):\n",
    "            print(' ' + make_example_str(example))\n",
    "            ans_ids = input_ids[bi, bos_i + 1: eos_i]\n",
    "            if i >= 2: labels[bi, bos_i: eos_i - 1] = ans_ids\n",
    "            ans_prob_dist = logits[bi, bos_i: eos_i - 1].softmax(-1)\n",
    "            ans_probs = ans_prob_dist[torch.arange(ans_prob_dist.size(0)), ans_ids]\n",
    "            ans_tokens = tokenizer.convert_ids_to_tokens(ans_ids)\n",
    "            for ans_id, ans_token, ans_prob, dist in zip(ans_ids, ans_tokens, numpy(ans_probs, decimals=3), ans_prob_dist):\n",
    "                top1_correct = (dist.argmax() == ans_id).item()\n",
    "                print(('*' if top1_correct else ' ') + ans_token, ans_prob, \n",
    "                      show_topk(*dist.topk(5), indices_fn=tokenizer.convert_ids_to_tokens)) \n",
    "    loss = nn.CrossEntropyLoss()(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "    loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"./models/model_name\", \n",
    "    overwrite_output_dir=True, do_train=True, do_eval=True,\n",
    "    per_device_train_batch_size=16, per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01, adam_beta2=0.98, adam_epsilon=1e-6,\n",
    "    lr_scheduler_type='constant', learning_rate=5e-3, num_train_epochs=4,\n",
    "    logging_strategy ='epoch', evaluation_strategy ='epoch', save_steps=0,\n",
    "    no_cuda=True, report_to='none',  # to avoid report to wandb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c7d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, training_args, train_dataset=train_dataset, eval_dataset=eval_dataset,\n",
    "                  optimizers=(create_optimizer(model, training_args), None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37a9874",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.place_model_on_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4b3eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prev(elem):\n",
    "    i, v = elem\n",
    "    return _l[i - 1] if i > 0 else None\n",
    "\n",
    "false = lambda *_: False\n",
    "true  = lambda *_: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721cb66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Element = namedtuple('Element', 'index value')\n",
    "_l = 'A B C B'.split()\n",
    "n = len(_l)\n",
    "# l = [Element._make(e) for e in enumerate(l)]\n",
    "l = seq(_l)\n",
    "l = l.enumerate().map(Element._make)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f22f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "l.map(lambda x: {'B': 'D'}.get(x, x))\n",
    "\n",
    "l.filter(lambda x: get_prev(x) == 'B').select(_.value)\n",
    "\n",
    "find_fn = _.index == 1\n",
    "l.filter(find_fn).select(_.value).map(lower)\n",
    "\n",
    "find_fn = _.value == 'C'\n",
    "l.filter(find_fn).select(_.index)\n",
    "\n",
    "# move x to first\n",
    "update_filter = _.value == 'C'\n",
    "get_new = lambda x: -1\n",
    "l.map(lambda x: Element(update_fn(x, 'index'), x.value)).order_by(_.index).select(_.value)\n",
    "\n",
    "# swap first and last\n",
    "update_filter = true\n",
    "get_new = lambda x: {0: n - 1, n - 1: 0}.get(x.index, x.index)\n",
    "l.map(lambda x: Element(update_fn(x, 'index'), x.value)).order_by(_.index).select(_.value)\n",
    "\n",
    "# get inbetween == drop_while + take_while?\n",
    "\n",
    "# update by index to its prev\n",
    "update_filter = _.index == 1\n",
    "get_new = lambda x: get_prev(x)\n",
    "def update_fn(x, update_field): return get_new(x) if update_filter(x) else getattr(x, update_field)\n",
    "l.map(lambda x: Element(x.index, update_fn(x, 'value')))\n",
    "\n",
    "# if two adjacent elements by indices are equal\n",
    "l.filter(lambda x: x.index in [0, 1]).select(_.value).distinct().len() == 1\n",
    "\n",
    "seq('A B C B C'.split()).group_by(_).select(_[1]).flatten()\n",
    "\n",
    "# count occurance till current\n",
    "seq('A B A C B A'.split()).inits().reverse().tail().map(lambda x: x.filter(_ == x.last()).len())\n",
    "\n",
    "# find special\n",
    "seq('A B A A'.split()).count_by_value().filter(_[1] == 1).select(_[0])\n",
    "\n",
    "# generalized find special\n",
    "seq('A A B C C D D'.split()).group_by(_).map(lambda x: (x[0], len(x[1]))).filter(_[1] == 1).select(_[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
