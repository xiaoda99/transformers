{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "os.environ['HF_HOME'] = '/raid/xd/.cache/torch'\n",
    "from types import MethodType\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, OrderedDict, Counter, namedtuple\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "from itertools import chain, product, combinations, cycle\n",
    "import math\n",
    "from functools import reduce, partial\n",
    "from collections.abc import Iterable\n",
    "import pickle, gzip\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "from sklearn.manifold import TSNE, MDS\n",
    "from sklearn.decomposition import PCA\n",
    "import einops\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data.sampler import RandomSampler, Sampler, SequentialSampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# sys.path.insert(0, '/nas/xd/projects/transformers/src')\n",
    "# from transformers.data.data_collator import DataCollator, default_data_collator\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from transformers import RobertaForMaskedLM, RobertaTokenizer, GPT2LMHeadModel, GPT2Tokenizer, GPTNeoForCausalLM\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Attention\n",
    "from transformers.models.gpt_neo.modeling_gpt_neo import GPTNeoSelfAttention\n",
    "from transformers.models.gptj.modeling_gptj import GPTJAttention, GPTJBlock\n",
    "from transformers.models.xglm.modeling_xglm import XGLMAttention\n",
    "\n",
    "# from transformers import HfArgumentParser, Trainer, TrainingArguments, set_seed\n",
    "# from transformers.trainer_utils import EvaluationStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/nas/xd/projects/pptree')\n",
    "from pptree import Node, print_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from child_utils import *\n",
    "from common_utils import *\n",
    "from model_utils import *\n",
    "from weight_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "cache_dir = '/nas/xd/.cache/torch/transformers/'  # for models besides t5-3b/11b\n",
    "proxies = {'http': '192.168.50.1:1081'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"EleutherAI/gpt-neo-1.3B\"\n",
    "for model_name in ['gpt2-large', \n",
    "            'gpt2-xl', 'EleutherAI/gpt-neo-1.3B',  # = babbage\n",
    "            'EleutherAI/gpt-j-6B', 'KoboldAI/fairseq-dense-6.7B', # = curie \n",
    "            'KoboldAI/fairseq-dense-13B']:\n",
    "    if model_name not in models:\n",
    "        with Timer(model_name):\n",
    "            model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=cache_dir)  \n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "            models[model_name] = model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using mask_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "# model_name = 'gpt2-large'  # medium / large /xl\n",
    "model_name = 'EleutherAI/gpt-j-6B/cpu' # gpt-j-6B, gpt-neo-1.3B/2.7B\n",
    "model, tokenizer = models[model_name]\n",
    "_ = model.eval()\n",
    "\n",
    "masked_lm = tokenizer.mask_token is not None and len(tokenizer.additional_special_tokens) == 0\n",
    "if masked_lm:\n",
    "    mask_token = tokenizer.mask_token  # '<mask>' for roberta\n",
    "elif len(tokenizer.additional_special_tokens) > 0:\n",
    "    mask_token = tokenizer.additional_special_tokens[0]  # '<extra_id_0>' for t5\n",
    "else:\n",
    "    mask_token = ''  # for gpt2\n",
    "if masked_lm: nlp = pipeline('fill-mask', model=model, tokenizer=tokenizer, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for block in model.transformer.h: _ = block.attn.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for block in model.transformer.h: _ = block.attn.to('cpu')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "unify(model)\n",
    "blocks = model.transformer.h\n",
    "attn0 = blocks[0].attn\n",
    "ln_f = model.transformer.ln_f\n",
    "L, H, embed_dim = len(blocks), attn0.num_heads, attn0.embed_dim\n",
    "\n",
    "we = model.transformer.wte.weight.data\n",
    "wu = model.lm_head.weight.data\n",
    "\n",
    "es = [we]\n",
    "for b in blocks[:1]: es.append(es[-1] + mlp_forward(b, es[-1]))\n",
    "model.es = es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "weBTAs = [es[i].T @ es[i] for i in range(2)]\n",
    "# weBTAs = [e.to(attn0.k_proj.weight.device) for e in weBTAs]\n",
    "# weBTAs = [e.to('cpu') for e in weBTAs]\n",
    "model.weBTAs = weBTAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "config = model.config\n",
    "for block in model.transformer.h[8:]:\n",
    "    # block.ln_1_gpu = nn.LayerNorm(config.n_embd, eps=config.layer_norm_epsilon)\n",
    "    # block.attn_gpu = type(block.attn)(config)\n",
    "    # if my_isinstance(block.attn, GPTJAttention): # need unify for other models\n",
    "    #     block.attn_gpu.num_heads = block.attn_gpu.num_attention_heads\n",
    "    block.mlp_gpu = type(block.mlp)(config.n_inner if config.n_inner is not None else 4 * config.n_embd, config)\n",
    "    for name in ['mlp']: # ['ln_1', 'attn']:\n",
    "        _ = getattr(block, name + '_gpu').load_state_dict(getattr(block, name).state_dict())\n",
    "        _ = getattr(block, name + '_gpu').to(device)\n",
    "        setattr(block, name + '_cpu', getattr(block, name))\n",
    "    block.ln_2_gpu, block.ln_2_cpu = block.ln_1_gpu, block.ln_1_cpu\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_heads = list(product(range(L), range(H)))\n",
    "all_heads_by_layer = [(l, None) for l in range(L)]\n",
    "def heads_in_layers(layer_start, layer_stop, H=H): return list(product(range(layer_start, layer_stop), range(H)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = o.attentions[12][0, 10]\n",
    "sim = torch.einsum('lhij->lh', (torch.cat(o.attentions) + 1e-9).log() * a * torch.ones_like(a).tril())\n",
    "list(zip(*topk_md(sim, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 10\n",
    "for text, examples, inputs, tokens, bos_indices, eos_indices, answers, labels, o, attn_attr in data_tuples[:1]:\n",
    "    for k in range(H // 4):\n",
    "        # print(layer, k * 2, k * 2 + 1)\n",
    "        fig, axs = plt.subplots(1, 4, sharex=False, sharey=False, figsize=(20, 5))\n",
    "        h = k * 4 + 0; plot_attn(o.attentions[l][0, h], tokens, ax=axs[0])\n",
    "        h = k * 4 + 1; plot_attn(o.attentions[l][0, h], tokens, ax=axs[1])\n",
    "        h = k * 4 + 2; plot_attn(o.attentions[l][0, h], tokens, ax=axs[2])\n",
    "        h = k * 4 + 3; plot_attn(o.attentions[l][0, h], tokens, ax=axs[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amplification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_tuples, verbose=False, **kwargs):\n",
    "    losses = []\n",
    "    # self_attrs = []; all_attentions2 = []; intermediary_head_outputs = []\n",
    "    outputs = []\n",
    "    for data_tuple in data_tuples[:]:\n",
    "        text, examples, inputs, tokens, bos_indices, eos_indices, answers, labels = data_tuple[:8]\n",
    "        # loss, _ = show_predictions(text, examples, tokenizer, o.logits, bos_indices, eos_indices, answers, labels, \n",
    "        #             topk=3, loss_reduction='mean', show_range=range(k_shot, len(examples)), sep='\\t', verbose=verbose)\n",
    "        # if verbose: print('loss =', loss)\n",
    "        \n",
    "        from_layer, hidden_states = None, None\n",
    "        # if ({'intermediary_heads', 'special_head'} & set(kwargs.keys())) and len(data_tuple) > 8:\n",
    "        #     o = data_tuple[8]\n",
    "        #     from_layer = kwargs['intermediary_heads'][0][0]\n",
    "        #     hidden_states = o.hidden_states[from_layer]\n",
    "        with torch.no_grad():\n",
    "            o = forward(model, inputs, labels=labels, attribute_layer=from_layer, hidden_states=hidden_states, **kwargs)\n",
    "        loss2, _ = show_predictions(text, examples, tokenizer, o.logits, bos_indices, eos_indices, answers, labels, \n",
    "                    topk=3, loss_reduction='mean', show_range=range(k_shot, len(examples)), sep='\\t', verbose=verbose)\n",
    "        if verbose: print('loss2 =', loss2, '\\n')\n",
    "        losses.append(loss2.item())\n",
    "        # if hasattr(o, 'self_attrs'): self_attrs.append(o.self_attrs)\n",
    "        # if hasattr(o, 'all_attentions2'): all_attentions2.append(o.all_attentions2)\n",
    "        # if hasattr(o, 'intermediary_head_outputs'): intermediary_head_outputs.append(o.intermediary_head_outputs)\n",
    "        outputs.append(o)\n",
    "        if len({'intermediary_heads', 'special_head'} & set(kwargs.keys())) == 0:\n",
    "            del data_tuple[8:]; data_tuple.append(o)\n",
    "    losses = torch.Tensor(losses)\n",
    "    print('losses =', losses)\n",
    "    return losses.mean(), outputs # self_attrs, all_attentions2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hds = Heads()\n",
    "hds.QKov = [(3, 11), (3, 6), (4, 8), (6, 10)] # [5, 4] K-comp heads / type-2 relating heads\n",
    "hds.KQQK = hds.kqovOV = [(1, 7), (6, 7), (6, 2), (8, 7), (10, 7)] # same qk heads / type-1 relating heads\n",
    "hds.kqOVov = [(8, 1), (12, 10), (13, 13),] # (8, 0), (9, 14), (15, 7), (16, 7), (11, 0)] # intermediary heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relating_heads = hds.QKov + hds.kqovOV[1:]; print(relating_heads)\n",
    "# intermediary_heads = hds.kqOVov[:]\n",
    "# predicting_heads = heads_in_layers(9, L) #KQovov\n",
    "# relating_heads = [(1, 7), (3, 11), (3, 6), (4, 8), (5, 4), (6, 10), (6, 7), (6, 2), (8, 7), (10, 7)] # + 5-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = data_tuples[2]\n",
    "tokens, o = t[3], t[-1]\n",
    "plot_attn(o.attentions[13][0, 2], tokens=tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test(model, data_tuples, verbose=True, device=device, to_gpu_layer=8, mlp_to_gpu=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = tensor([0.8525, 1.0014, 0.8600]) tensor(0.9046)\n",
    "\n",
    "relating_heads=[], intermediary_heads=hds.kqOVov[1:2], predicting_heads=heads_in_layers(13, L),\n",
    "        intm_head_multipliers=[2.], hq_multiplier=10., multipliers=[1.5, 0], self_attr_threshold=5.\n",
    "losses = tensor([0.9319, 0.8513, 0.7590]) tensor(0.8474)\n",
    "\n",
    "relating_heads=[], intermediary_heads=hds.kqOVov[0:2], predicting_heads=heads_in_layers(13, L),\n",
    "        intm_head_multipliers=[2., 2.], hq_multiplier=10., multipliers=[1.5, 0], self_attr_threshold=5.\n",
    "losses = tensor([0.9237, 0.8758, 0.6133]) tensor(0.8043)\n",
    "\n",
    "relating_heads=[], intermediary_heads=hds.kqOVov[0:3], predicting_heads=heads_in_layers(13, L),\n",
    "        intm_head_multipliers=[2., 2., 2], hq_multiplier=10., multipliers=[1.5, 0], self_attr_threshold=5.\n",
    "losses = tensor([1.0008, 0.7892, 0.6062]) tensor(0.7987)\n",
    "\n",
    "\n",
    "relating_heads=[], intermediary_heads=hds.kqOVov[1:2], predicting_heads=heads_in_layers(13, L),\n",
    "        intm_head_multipliers=[2., ], hq_multiplier=10., multipliers=[1., 0], self_attr_threshold=5.\n",
    "losses = tensor([0.9127, 0.9094, 0.6992]) tensor(0.8404)\n",
    "\n",
    "relating_heads=[], intermediary_heads=hds.kqOVov[0:2], predicting_heads=heads_in_layers(13, L),\n",
    "        intm_head_multipliers=[2., 2.,], hq_multiplier=10., multipliers=[1., 0], self_attr_threshold=5.\n",
    "losses = tensor([0.9268, 0.8078, 0.5017]) tensor(0.7454)    \n",
    "\n",
    "relating_heads=[], intermediary_heads=hds.kqOVov[0:3], predicting_heads=heads_in_layers(13, L),\n",
    "        intm_head_multipliers=[2., 2., 2], hq_multiplier=10., multipliers=[1., 0], self_attr_threshold=5.\n",
    "losses = tensor([0.8701, 0.7224, 0.3972]) tensor(0.6632)\n",
    "\n",
    "relating_heads=[], intermediary_heads=hds.kqOVov[0:3], predicting_heads=heads_in_layers(13, L),\n",
    "        intm_head_multipliers=[3., 3., 3.], hq_multiplier=10., multipliers=[1., 0], self_attr_threshold=5.\n",
    "losses = tensor([1.0411, 0.5965, 0.2770]) tensor(0.6382)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicting_heads = [(13, 2), (14, 6), (16, 6), (22, 14)]# (17, 9), (18, 13)]\n",
    "intermediary_heads = hds.kqOVov #[(8, 0), (8, 1), (8, 3), (9, 0), (9, 14), (11, 4), (11, 9), (12, 10)]\n",
    "# intermediary_heads = [(8, 0), (8, 1), (9, 14), (12, 10)]\n",
    "loss, outputs = test(model, data_tuples, verbose=False, device=device, mlp_to_gpu=True,\n",
    "        relating_heads=[], intermediary_heads=hds.kqOVov[1:2], predicting_heads=heads_in_layers(13, L),\n",
    "        intm_head_multipliers=[2, ], hq_multiplier=4., multipliers=[0, 1.5], self_attr_threshold=5., exit_layer=None\n",
    ")\n",
    "print(loss)\n",
    "# sa = torch.stack(sa)  # pad(torch.stack(sa), 1, L, pad_left=True) # blnmri\n",
    "# all_attentions2 = pad(torch.stack(all_attentions2), 1, L, pad_left=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intm_head_outputs = [o.intermediary_head_outputs for o in outputs]\n",
    "intm_head_outputs[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_softmax(logits, local=1):\n",
    "    logits = logits - 1e9 * (torch.ones_like(logits).triu(diagonal=1) + local * torch.ones_like(logits).tril(diagonal=-6))\n",
    "    return logits.softmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_hqs = [o.cat_hqs for o in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediary_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi = 0\n",
    "l, h = predicting_heads[1]; print(l, h)\n",
    "tokens, labels, o = data_tuples[bi][3], data_tuples[bi][7], data_tuples[bi][8]\n",
    "hk = blocks[l].ln_1(o.hidden_states[l])\n",
    "plot_attn(o.attentions[l][0, h][labels[0] != -100], tokens=tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intm_head_indices = [0, 1, 2]; print([intermediary_heads[hi] for hi in intm_head_indices])\n",
    "hq = cat_hqs[bi][l][3:, -1:].sum((0, 1)).unsqueeze(0)  # mrie->ie->bie\n",
    "aw = attn_forward(blocks[l], hq, hk, hk)[1][0, h][labels[0] != -100]\n",
    "plot_attn(aw, tokens=tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intm_head_indices = [0, 1, 2]; print([intermediary_heads[hi] for hi in intm_head_indices])\n",
    "hq = cat_hqs[bi][l][intm_head_indices, :8].sum((0, 1)).unsqueeze(0)  # mrie->ie->bie\n",
    "aw = attn_forward(blocks[l], hq, hk, hk)[1][0, h][labels[0] != -100]\n",
    "plot_attn(aw, tokens=tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa[:, :, :, -1] = 0\n",
    "if sa.size(-2) == 1: sa = sa.squeeze(-2)  # blnm1i-> blnmi\n",
    "Counter([tuple(head) for head in (sa > 20).nonzero()[:, 1:4].tolist()]).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sa[:, :, :, 0:-1].amax((-3, -2))  # blnmri->blni\n",
    "Counter([tuple(head) for head in (a > 8).nonzero()[:, 1:3].tolist()]).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eigv(weightprod(model, [(8, 7), (12, 10), (14, 6)], 'e vo vo qk e', weBTA=weBTAs[0], absorb_ln=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eigv(weightprod(model, [(3, 3), (12, 10), (13, 9)], 'e vo vo qk e', weBTA=weBTAs[0], absorb_ln=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eigv(weightprod(model, [(13, 2), (14, 6)], 'e vo qk e', weBTA=weBTAs[0], absorb_ln=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l, h = 6, 2\n",
    "i = 2\n",
    "t = data_tuples[i]\n",
    "tokens, o = t[3], t[-1]\n",
    "plot_attn(o.attentions[l][0, h], tokens=tokens)\n",
    "# plot_attn(all_attentions2[i][l][0, h], tokens=tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sa[:, :, :, :-1, :]\n",
    "plt.hist(x[(x != 0) & (x < 1000)].view(-1).numpy(), bins=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = sa[:, :, :, 0:3, :].amax((-3, -2)).reshape(-1), a[:, :].reshape(-1)\n",
    "x, y = x[(x != 0) & (x > 0)], y[(x != 0) & ( x > 0)]\n",
    "_=plt.plot(x, y, '.');\n",
    "pearsonr(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[data_tuple[0] for data_tuple in data_tuples]\n",
    "a = []\n",
    "for data_tuple in data_tuples[:]:\n",
    "    text, examples, inputs, tokens, bos_indices, eos_indices, answers, labels = data_tuple[:8]\n",
    "    head_mask = torch.ones(L, 1, H, labels.size(-1))  # 11ni\n",
    "    _ = head_mask.requires_grad_(True)\n",
    "    o = forward(model, inputs, labels=labels, head_mask=head_mask)\n",
    "    a.append(torch.autograd.grad(-o.loss, head_mask)[0].squeeze(1)[..., (labels != -100)[0]]) # l1ni->lni'\n",
    "    show_predictions(text, examples, tokenizer, o.logits, bos_indices, eos_indices, answers, labels, \n",
    "                    topk=3, loss_reduction='mean', show_range=range(k_shot, len(examples)), sep='\\t')\n",
    "a = torch.stack(a)  # blni'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros(L, H, *self_attrs.size()[-2:])\n",
    "a[tuple(zip(*predicting_heads))] = self_attrs\n",
    "self_attrs = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sattr = self_attrs[:, :, 1, 6:10]\n",
    "# pattern = ' '.join(['l n', ' '.join([f'd{i}' for i in range(sattr.ndim - 2)])]) + ' -> l n' # l n [d0 [d1]] -> l n\n",
    "# sattr = einops.reduce(sattr, pattern, 'sum')\n",
    "sattr = sum_except(sattr, (0, 1))\n",
    "x, y = sattr[sattr != 0], attr.head[sattr != 0]\n",
    "_=plt.plot(x, y, '.')\n",
    "pearsonr(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row, col = 2, 4\n",
    "mask = torch.ones(self_attrs.size()[-2:]); mask[-1, -2:] = 0\n",
    "top_attrs = torch.stack([self_attrs[head] * mask for head in \n",
    "    zip(*topk_md(self_attrs[:, :, :-1, :].sum((-2, -1)), row*col)[:2])])\n",
    "top_attrs = rearrange(top_attrs, '(row col) m r -> (row m) (col r)', row=row, col=col)\n",
    "xticklabels=[f'{l}-{h}' for l, h in relating_heads] + ['a', 'm']\n",
    "yticklabels=[f'{l}-{h}' for l, h in intermediary_heads] + ['o']\n",
    "plt.figure(figsize=(20, 5));\n",
    "ax = sns.heatmap(top_attrs, xticklabels=xticklabels * col, yticklabels=yticklabels * row);\n",
    "_ = ax.set_yticklabels(ax.get_ymajorticklabels(), rotation=0);\n",
    "ax.tick_params(top=True, right=False, labeltop=True, labelright=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "12-10*3,\n",
    "0.47\n",
    "\n",
    "12-10*3, threshold=5., base_multiplier=1.5\n",
    "tensor([0.0230, 0.0119, 1.2052, 0.2945, 0.0157, 0.0597, 0.0702, 0.5085, 0.2899,\n",
    "        0.0326, 0.0408, 1.1831, 0.0516, 0.6363, 0.5234, 2.5790, 0.0979, 0.5943])\n",
    "tensor(0.4565)\n",
    "12-10*3, threshold=3., base_multiplier=1.5\n",
    "tensor([0.0227, 0.0109, 1.2108, 0.2642, 0.0151, 0.0506, 0.0595, 0.5087, 0.3540,\n",
    "        0.0263, 0.0336, 1.1175, 0.0426, 0.7020, 0.5188, 2.5127, 0.0997, 0.4610])\n",
    "tensor(0.4450)\n",
    "12-10*3, threshold=1., base_multiplier=1.5\n",
    "tensor([0.0216, 0.0131, 1.2596, 0.3078, 0.0212, 0.0453, 0.0745, 0.7034, 0.2971,\n",
    "        0.0242, 0.0579, 0.9990, 0.0391, 0.7800, 0.4985, 2.7309, 0.1179, 0.4555])\n",
    "tensor(0.4693)\n",
    "\n",
    "12-10*1, threshold=5., base_multiplier=1.5\n",
    "tensor([0.0280, 0.0179, 1.5402, 0.6329, 0.0368, 0.1095, 0.1551, 0.9999, 0.4408,\n",
    "        0.0323, 0.0402, 0.8825, 0.0553, 0.5654, 0.6607, 2.1981, 0.1345, 0.7474])\n",
    "tensor(0.5154)\n",
    "12-10*1, threshold=10., base_multiplier=1.5\n",
    "tensor([0.0276, 0.0188, 1.5444, 0.5967, 0.0475, 0.0998, 0.1569, 1.0300, 0.4510,\n",
    "        0.0330, 0.0390, 0.8318, 0.0685, 0.6363, 0.7036, 2.2156, 0.1415, 0.7441])\n",
    "tensor(0.5214)\n",
    "12-10*1, threshold=10., base_multiplier=2.0\n",
    "tensor([0.0272, 0.0174, 1.5211, 0.5767, 0.0467, 0.0894, 0.1517, 0.9618, 0.4449,\n",
    "        0.0375, 0.0390, 0.8318, 0.0626, 0.6357, 0.7095, 2.2156, 0.1410, 0.7165])\n",
    "tensor(0.5126)\n",
    "\n",
    "12-10*3, threshold=5., base_multiplier=1.5 opt\n",
    "tensor([0.0239, 0.0128, 1.1290, 0.2517, 0.0170, 0.0526, 0.0707, 0.5806, 0.3219,\n",
    "        0.0238, 0.0440, 0.9224, 0.0427, 0.7748, 0.5562, 2.6125, 0.1175, 0.4395])\n",
    "tensor(0.4441)\n",
    "\n",
    "8-1*1, threshold=5., base_multiplier=1.5 opt\n",
    "tensor([0.0287, 0.0160, 1.5901, 0.6175, 0.0296, 0.0746, 0.1242, 0.9194, 0.5042,\n",
    "        0.0330, 0.0492, 0.7875, 0.0552, 0.6154, 0.6522, 2.2360, 0.1363, 0.6757])\n",
    "tensor(0.5080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, data_tuples, special_head=(12, 10), wv=wv1, wo=wo1*0, special_head_multiplier=2.,\n",
    "    multiplied_layers=range(13, L), attr_threshold=5., base_multiplier=1.5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Head geometry visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ws(model, ws, w2i, w_type, start_layer, end_layer, H):\n",
    "    offset = len(w2i)\n",
    "    dL = end_layer - start_layer\n",
    "    n_ws = dL * H\n",
    "    w_types = [w_type] * n_ws\n",
    "    layers, heads = np.unravel_index(range(n_ws), (dL, H))\n",
    "    layers = layers + start_layer\n",
    "    w2i.update(OrderedDict(zip(\n",
    "        zip(w_types, layers, heads),  # key, e.g. ('o', 2, 11)\n",
    "        range(offset, offset + n_ws))))  # value, e.g. 0+43\n",
    "    w_idx, transpose = ['q', 'k', 'v', 'o'].index(w_type), w_type == 'o'\n",
    "    _ws = torch.cat([get_head_weights(model, l, transpose=transpose)[w_idx] for l in range(start_layer, end_layer)])  # l*nde->(ln)de\n",
    "    ws = _ws if ws is None else torch.cat([ws, _ws])\n",
    "    return ws, w2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws, w2i = None, OrderedDict()\n",
    "ws, w2i = add_ws(model, ws, w2i, 'o', 0, 13+1, H)\n",
    "ws, w2i = add_ws(model, ws, w2i, 'q', 9, L, H)\n",
    "ws, w2i = add_ws(model, ws, w2i, 'v', 8, 13+1, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_distance, distance = get_affinities(ws, ws)\n",
    "tsne = TSNE(n_components=2, metric='precomputed')\n",
    "result = tsne.fit_transform(_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = plt.figure(figsize=(20, 10))\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "for cond, color in [([i for (m_type, l, h), i in w2i.items() if m_type == 'o' and l < 8], 'g'),\n",
    "                    ([i for (m_type, l, h), i in w2i.items() if m_type == 'q' and 12 < l < 24], 'r')]:\n",
    "    _ = plt.scatter(x=result[:, 0][cond], y=result[:, 1][cond], marker='.', color=color)\n",
    "# _ = ax.scatter(x=result[:, 0], y=result[:, 1], marker='.')\n",
    "\n",
    "for w_type, l, h in [('v', 12, 10), ('v', 8, 1), ('v', 8, 0), ('v', 8, 15), ('v', 11, 1),\n",
    "                    ('o', 12, 10), ('o', 8, 1), ('o', 8, 0), ('o', 8, 15), ('o', 11, 1)]:\n",
    "    i = w2i[(w_type, l, h)]\n",
    "    _ = ax.annotate(f'{w_type}-{l}-{h}', (result[i, 0], result[i, 1]), color='g' if w_type == 'v' else 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ov_mask = einops.repeat(torch.BoolTensor([True, False]), 'b -> b l n', l=L, n=H)\n",
    "qk_mask = einops.repeat(torch.BoolTensor([False, True]), 'b -> b l n', l=L, n=H)\n",
    "# gt_l0_mask = einops.repeat(torch.ones(L, L) - torch.tril(torch.ones(L, L)) * 1, 'l0 l1 ->l0 n0 l1 n1 k', n0=H, n1=H, k=2).bool()\n",
    "gt_l0_mask = einops.repeat(torch.ones(L, L) - torch.tril(torch.ones(L, L)) * 1, 'l0 l1 ->l0 n0 l1 n1', n0=H, n1=H).bool()\n",
    "def layer_mask(l): mask = torch.zeros(L, H).bool(); mask[l] = True; return mask\n",
    "\n",
    "mask = torch.zeros(2, L, H).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_outputs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=plt.hist(qk_score[mask[1]].numpy(), bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hds.kqovOV += [(3, 9), (4, 6), (13, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(20, 12));\n",
    "x, y = eigvs.eqke[..., 0], pos_score\n",
    "mask0 = layer_mask(range(1, 20)) & (y < 0.1) & (x > 0.)\n",
    "_ = plt.plot(x[mask0], y[mask0], '.')\n",
    "for l, h in mask0.nonzero().numpy():\n",
    "    if True or (l, h) in hds.kqovOV: _ = plt.annotate(f'{l}-{h}', (x[l, h], y[l, h]), color='b' if (l, h) in hds.kqovOV else 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hds.kqOVov  # for ov, 16-7 is good, 11-0 is very good. but for qk, 16-7 is worse than 15-7, 11-0 is the worst!\n",
    "# 15-7 is bad\n",
    "# 16-7 is good, kqOVOV composable with 13-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t00, t01, t11 = eigvs.evoove, eigvs.ekqovove, eigvs.eqkkqe\n",
    "t00, t01, t11 = eigvs.evoove, eigvs.ekqOVove[(15, 5)], eigvs.eqkkqe\n",
    "# t00, t01, t11 = eigvs.evoove, eigvs.ekqovovove[((l0, h0), (l1, h1))], eigvs.eqkkqe\n",
    "eigvs4 = small_to_big_pairwise_sim_tensor(t00, t01, t11)\n",
    "qk_score = [eigvs.eqke[..., 0], eigvs.uovE][1]\n",
    "l1 = 15\n",
    "mask[0] = layer_mask(range(2, l1)) #& (pos_score < 0.05) & (eigvs.eqke[...,0] > 0.5)\n",
    "mask[1] = layer_mask(range(l1 + 1, L)) & (eigvs.uovE > 0.5) & (pos_score < 0.1)\n",
    "embed_outputs['ekqovove'] = [embed_by_pairwise_sim_tensor(eigvs4[..., i], mask) for i in [0, 1]] + [mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = embed_outputs['ekqovove']; use_reality = 0\n",
    "result, mask = outputs[int(use_reality)], outputs[-1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 12))\n",
    "ov_score = [eigvs.eqke[...,0], pos_score][1]\n",
    "qk_score = [eigvs.eqke[..., 0], eigvs.uovE, pos_score][1]\n",
    "_ = plt.scatter(*tuple(result[0, mask[0]].T), marker='o', c=ov_score[mask[0]], cmap='viridis_r')\n",
    "_ = plt.scatter(*tuple(result[1, mask[1]].T), marker='v', c=qk_score[mask[1]], cmap='Reds')\n",
    "for l, h in mask[0].nonzero().numpy():\n",
    "    if (l, h) in hds.kqovOV: _ = ax.annotate(f'{l}-{h}', result[0, l, h], color='b')\n",
    "# k_comp_heads, same_qk_heads = [(6, 10), (5, 4), (3, 11)], [(8, 7), (6, 2), (1, 7), (6, 7), (8, 13), (10, 7)]  # (4, 0), (3, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todo_heads = [(18, 5), (19, 6), (18, 13), (14, 6), (19, 1), (17, 1), (19, 0), (17, 9),\n",
    "              (17, 5), (15, 5), (13, 9)]\n",
    "# 14-6 bad\n",
    "# 15-5 strange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigvs4 = small_to_big_pairwise_sim_tensor(eigvs.voov, eigvs.qkov, eigvs.qkkq)\n",
    "eigvs4 = small_to_big_pairwise_sim_tensor(eigvs.evoove, eigvs.eqkove, eigvs.eqkkqe)\n",
    "# eigvs4 = small_to_big_pairwise_sim_tensor(eigvs.evoove, eigvs.eqkove, eigvs.eqkkqe)\n",
    "mask = ov_mask & layer_mask(range(1, 20)) | qk_mask & layer_mask(range(3, 20))\n",
    "embed_outputs['eqkove'] = [embed_by_pairwise_sim_tensor(eigvs4[..., i], mask) for i in [0, 1]] + [mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(head, pos_score[head], eigvs.uovE[head], v) for head, v in \n",
    "     get_knn(eigvs.eqkove[..., use_reality] * gt_l0_mask, [(10, 4),], topk=10, sim_threshold=0.8).items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l, h = 13, 13; eigvs.uovE[l, h]; add_rows(topk_md(eigvs.eqkove[:, :, l, h, 0], 10), pos_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l, h = 16, 7; eigvs.uovE[l, h]; add_rows(topk_md(eigvs.eqkove[:, :, l, h, 0], 10), pos_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = embed_outputs['eqkove']; use_reality = 0\n",
    "result, mask = outputs[int(use_reality)], outputs[-1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 12))\n",
    "ov_score = [eigvs.uovE, pos_score][1]  # rescale(qk[:, :, 1], 0.4).numpy()\n",
    "qk_score = eigvs.eqke[..., 0]\n",
    "_ = plt.scatter(*tuple(result[0, mask[0]].T), marker='o', c=ov_score[mask[0]], cmap='Reds')#  'RdYlBu_r')\n",
    "_ = plt.scatter(*tuple(result[1, mask[1]].T), marker='v', c=qk_score[mask[1]], cmap='BrBG')\n",
    "for b, l, h in (mask & (pos_score > 0.3)).nonzero().numpy():\n",
    "    # if (l, h) not in [(1, 0), (2, 11), (12, 12)]: continue\n",
    "    if b == 0: _ = ax.annotate(f'{l}-{h}', result[b, l, h], color='r' if b==0 else 'm', alpha=pos_score[l, h].item())\n",
    "# cond = qk_score > 0.8\n",
    "# # https://datavizpyr.com/connect-paired-points-with-lines-scatter-plot-matplotlib/\n",
    "# x, y = zip(result[0][mask[0] & cond].T, result[1][mask[1] & cond].T)\n",
    "# _=plt.plot(torch.stack(x), torch.stack(y), color='k', alpha=0.2)\n",
    "# for (l, h), v in list(get_knn(eigvs.eqkove[..., use_reality] * gt_l0_mask, [(10, 4), (2, 11), (3, 5)]).items()) + [((11, 0), 1)]:\n",
    "#     _ = ax.annotate(f'{l}-{h}', result[1, l, h], color='b', alpha=1 or rescale(v, 0.9))\n",
    "#     _ = ax.annotate(f'{l}-{h}', result[0, l, h], color='g', alpha=1 or rescale(v, 0.9))\n",
    "for (l, h) in todo_heads[:0] + hds.kqOVov[:3] + [(11, 0)]:\n",
    "    alpha = 1 if (l, h) in hds.kqOVov[:3] else 0.5\n",
    "    _ = ax.annotate(f'{l}-{h}', result[1, l, h], color='g', alpha=alpha)\n",
    "    _ = ax.annotate(f'{l}-{h}', result[0, l, h], color='k', alpha=alpha)\n",
    "for (l, h) in [(10, 11), (7, 11), (10, 14), (9, 9)]: _ = ax.annotate(f'{l}-{h}', result[0, l, h], color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvs4 = small_to_big_pairwise_sim_tensor(eigvs.evoove, eigvs.eqkove, eigvs.eqkkqe)\n",
    "mask = qk_mask & layer_mask(range(3, 16))\n",
    "result0 = embed_by_pairwise_sim_tensor(eigvs4[..., 0], mask)\n",
    "result1 = embed_by_pairwise_sim_tensor(eigvs4[..., 1], mask)\n",
    "embed_outputs['eqkkqe'] = (result0, result1, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=plt.hist(qk_score[mask[1]].numpy(), bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = embed_outputs['eqkkqe']; use_reality = 0\n",
    "result, mask = outputs[int(use_reality)], outputs[-1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 12))\n",
    "qk_score = qk[...,0]\n",
    "_ = plt.scatter(*tuple(result[1][mask[1]].T), marker='o', c=qk_score[mask[1]], cmap='RdBu_r')\n",
    "for l, h in heads.KQQK:\n",
    "    _ = ax.annotate(f'{l}-{h}', result[1, l, h], color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = weightprod(model, [(2, 11), (3, 5)], 'vo ov', return_ws=True)\n",
    "rws = [torch.randn_like(w) for w in ws]\n",
    "i = 2; A, B = reduce(torch.matmul, rws[:i]), reduce(torch.matmul, rws[i:])\n",
    "denorm = A.norm() * B.norm()\n",
    "(A @ B).norm() / denorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_pos_heads = [(2, 11), (3, 5), (12, 12), (10, 4)]\n",
    "top_same_qk_heads = [(1, 7), (3, 9), (6, 2), (7, 9), (8, 7), (8, 13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvs.qk = compute_eigvs(model, [all_heads_by_layer], 'kq')\n",
    "eigvs.eqke = compute_eigvs(model, [all_heads_by_layer], 'e kq e', weBTA=weBTAs[0])\n",
    "eigvs.uovE = eigv_positivity[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hds.KQovov = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head2 = (22, 14)\n",
    "if head2 not in hds.KQovov:\n",
    "    hds.KQovov[head2] = (eigvs.uovE[head2], torch.Tensor([plot_eigv(prod, plot=False)[0] for _, prod in \n",
    "                            iweightprod(model, [hds.kqovOV[:-2], (12, 10), head2], 'e vo vo qk e', weBTA=weBTAs[0])]))\n",
    "    print(hds.KQovov[head2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_cols(set(hds.KQovov.keys()) - set(KQovov), [eigvs.uovE, pos_score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kqovovov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head1 = hds.kqOVov[1]; print(head1)\n",
    "\n",
    "KQovov_cond = (eigvs.uovE > 0.6) & (pos_score < 0.1)\n",
    "KQovov = [tuple(head) for head in (layer_mask(range(head1[0] + 1, L)) & KQovov_cond).nonzero().numpy()]\n",
    "\n",
    "vs = compute_eigvs(model, [hds.kqovOV[:4], head1, KQovov], 'e vo vo qk e', weBTA=weBTAs[0])[..., 0]\n",
    "x = vs[vs != 0]; x.mean(); _=plt.hist(x.numpy(), bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = compute_eigvs(model, [hds.QKov, head1, KQovov], 'e vo vo qk e', weBTA=weBTAs[0])[..., 0]\n",
    "nrows, ncols = 1, len(hds.QKov); fig, axs = plt.subplots(nrows, ncols, sharey=True, sharex=True, figsize=(12, 1.5))\n",
    "for i, head in enumerate(hds.QKov):\n",
    "    # print(head)\n",
    "    x = vs[head][vs[head] != 0]\n",
    "    ax = axs[i]\n",
    "    _=ax.hist(x.numpy(), bins=20); _=ax.set_title(f'{head} {round(x.mean().item(), 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head0 = hds.QKov[3]; print(head0)\n",
    "hds.kqovOV[:4]\n",
    "torch.Tensor([plot_eigv(prod, plot=False)[0] for head, prod in iweightprod(model, [head0, hds.kqovOV[:4]], 'e vo ov e', weBTA=weBTAs[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = compute_eigvs(model, [heads_in_layers(0, head0[0]), head0, head1, KQovov], 'e vo vo vo qk e', weBTA=weBTAs[0])[..., 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols = 2, 5; fig, axs = plt.subplots(nrows, ncols, sharex=True, sharey=True, figsize=(12, 4))\n",
    "for i, head_1 in enumerate(zip(*topk_md(vs.sum(dim=(-2, -1)), 10)[:2])):\n",
    "    print(head_1, pos_score[head_1],\n",
    "        torch.Tensor([plot_eigv(prod, plot=False)[0] for head, prod in iweightprod(\n",
    "            model, [head_1, head0, hds.kqovOV[:4]], 'e vo vo ov e', weBTA=weBTAs[0])]))\n",
    "    x = vs[head_1][vs[head_1] != 0]\n",
    "    ax = axs[i // ncols, i % ncols]\n",
    "    _=ax.hist(x.numpy(), bins=20)\n",
    "    _=ax.set_title(f'{head_1} {round(x.mean().item(), 4)}')#; plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affinity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_affinities = torch.zeros((L, L, H, H))\n",
    "affinities = torch.zeros((L, L, H, H))\n",
    "for l0 in tqdm(range(0, l1)):\n",
    "    for l2 in range(l1 + 1, L):\n",
    "        if True:\n",
    "        # with Timer(f'layer{l0}-layer{l2}'):\n",
    "            wv0, wo0 = get_head_weights(model, l0, transpose=True)[2:]\n",
    "            wq2, wk2 = get_head_weights(model, l2, transpose=True)[:2]\n",
    "            wv0, wo0, wq2, wk2 = wv0.to('cuda'), wo0.to('cuda'), wq2.to('cuda'), wk2.to('cuda')\n",
    "            with torch.no_grad():\n",
    "                a, na = get_affinities3(wv0 @ wo0, _wvo, wq2 @ wk2.transpose(-2, -1))\n",
    "            a, na = a.to('cpu'), na.to('cpu')\n",
    "            _affinities[l0, l2] = a.squeeze(1)  # m1o->mo\n",
    "            affinities[l0, l2] = na.squeeze(1)  # m1o->mo\n",
    "\n",
    "_affinities, affinities = rearrange(_affinities, 'k l m n -> k m l n'), rearrange(affinities, 'k l m n -> k m l n')\n",
    "np.savez_compressed(f'affinities{l1}-{h1}.npz', a=_affinities.numpy(), na=affinities.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(f'affinities{l1}-{h1}.npz')\n",
    "affinities = torch.Tensor(data['na'])\n",
    "# topk_md(torch.einsum('kmln->km', affinities), 20)  # klmn->km/ln\n",
    "# fig, ax = plt.subplots(figsize=(20, 10))\n",
    "# _ = sns.heatmap(rearrange(affinities[: l1, :, l1 + 1: L], 'l0 h0 l2 h2 -> (l0 h0) (l2 h2)'), ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(l, h, v, eigv_positivity[l, h]) for l, h, v in zip(*topk_md(torch.einsum('kmln->ln', affinities), 10))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(l, h, v, eigv_positivity[l, h], k_comp_max[l, h]) for l, h, v in zip(*topk_md(torch.einsum('kmln->km', affinities), 20))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[((l, h), count, eigv_positivity[l, h]) for (l, h), count in Counter(\n",
    "    zip(*np.unravel_index(affinities.view(-1).topk(200).indices, affinities.size())[:2])).most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l0, h0, l2, h2 in zip(*np.unravel_index(affinities.view(-1).topk(100).indices, affinities.size())):\n",
    "    if True: #(l0, h0) == (8, 7) and (l2, h2) == (22, 5):\n",
    "        wv0, wo0 = get_head_weights(model, l0, h0, transpose=True)[2:]\n",
    "        wq2, wk2 = get_head_weights(model, l2, h2, transpose=True)[:2]\n",
    "        q, kT = (wv0 @ wo0 @ wv1 @ wo1 @ wq2), wk2.T\n",
    "        eigv_pos = plot_eigv((kT @ q).eig()[0], plot=False)\n",
    "        print(f'{l0}-{h0}, {l2}-{h2}', eigv_pos, eigv_positivity[l2, h2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na0 = get_ov_affinities(model, l1, wv1, wo1, range(l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i, f'{l0}-{h0}', k_comp_max[l0, h0], eigv_positivity[l0, h0], pos_heads2val.get((l0, h0)))\n",
    "    for i, (l0, h0) in enumerate(zip(*topk_md(na0, 10)[:2]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_heads2=40\n",
    "na2 = get_qk_affinities(model, l1, wv1, wo1, range(l1 + 1, L))\n",
    "heads2 = list(zip(*topk_md(na2, n_heads2)[:2]))\n",
    "# heads2 = [(3, 11), (8, 1), (12, 10), (13, 13), (14, 6), (15, 7), (16, 7)]\n",
    "# heads2 = [(13, 2), (14, 6), (16, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l0, h0 in heads0:\n",
    "    wq0, wk0 = get_head_weights(model, l0, h0, transpose=True)[:2]\n",
    "    ln0 = blocks[l0].ln_1\n",
    "    print(l0, h0, eigv_positivity[l0, h0], get_eigv_pos(wk0.T @ wq0), get_eigv_pos((_e[1] @ wk0).T @ (_e[1] @ wq0)), get_eigv_pos((ln0(_e[1]) @ wk0).T @ (ln0(_e[1]) @ wq0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_attr(topk_md(na0, 100, zipped=True), [eigv_positivity_noln[:, :, [0, 2]], pos_score, k_comp_wmean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_heads0=20\n",
    "# na0 = get_qk_affinities(model, l1, wv1, wo1, range(l1 + 1, L))\n",
    "# na0 = get_ov_affinities(model, l1, wv1, wo1, range(l1))\n",
    "# heads0 = list(zip(*topk_md(na0, n_heads0)[:2]))\n",
    "heads0 = [(3, 6), (3, 11), (4, 8), (6, 10)]\n",
    "# heads0 = [(4, 1), (6, 15), (8, 13), (10, 1)]  # eigv_pos012 < -0.8\n",
    "# heads0 = [(3, 6), (3, 12), (4, 6), (4, 0), (6, 10), (8, 1)] # k_comp_wmean > 0.2\n",
    "# heads0 = [(1, 7), (3, 9), (6, 2), (6, 7), (8, 7), (10, 7)] # k_comp_wmean < 0.2 and eigv_pos > 0, i.e. the good ones\n",
    "heads2 = [(13, 2), (14, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigv_pos012 = compute_eigv_pos012(model, l1, h1, wv1, wo1, heads0, heads2,\n",
    "    eigv_positivity, heads_1=None, use_ln=True, _e=_e[0], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del compute_eigv_pos012\n",
    "from model_utils import compute_eigv_pos012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigv_pos012 = compute_eigv_pos012(model, l1, h1, wv1, wo1, [(6, 10)], heads2,\n",
    "    eigv_positivity, heads_1=[(5, 1)], use_ln=True, _e=_e[0], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1, h1 = 12, 10; wv1, wo1 = get_head_weights(model, l1, h1, transpose=True)[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_attr([(l0, h0, l2, h2, torch.Tensor(eigv_pos)) for (l0, h0, l2, h2), eigv_pos in eigv_positivity012[l1, h1].items()\n",
    "    if pos_score[l0, h0] < 0.2 and k_comp_wmean_ln[l0, h0] > 0.2], eigv_positivity_noln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = zip(*[(eigv_pos[1], pos_score[l0, h0]) for (l0, h0, l2, h2), eigv_pos in eigv_positivity012[l1, h1].items()\n",
    "    if pos_score[l0, h0] < 0.045 and k_comp_wmean_ln[l0, h0] < 0.2])\n",
    "_ = plt.figure(figsize=(20, 10)); _ = plt.scatter(x, y, marker='.', alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(x, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intermediary_heads = 100\n",
    "# n_heads0, n_heads2 = 20, 40  # gpt2-large\n",
    "# n_heads0, n_heads2 = 15, 30  # gpt-j\n",
    "n_heads0, n_heads2 = 100, 40  # gpt-j\n",
    "# eigv_positivity012 = {}\n",
    "# maybe_intermediary_heads = list(zip(*topk_md(k_comp_max, n_intermediary_heads)[:2]))\n",
    "# maybe_intermediary_heads = [(l1, h1) for l1, h1 in maybe_intermediary_heads if 0 < l1 < L - 1]\n",
    "maybe_intermediary_heads = [(12, 10)] # [(8, 1), (13, 13)]\n",
    "# maybe_intermediary_heads = list(zip(*topk_md(conductivity, 20)[:2]))\n",
    "for l1, h1 in (maybe_intermediary_heads):\n",
    "    wv1, wo1 = get_head_weights(model, l1, h1, transpose=True)[2:]\n",
    "    na0 = get_ov_affinities(model, l1, wv1, wo1, range(l1))\n",
    "    heads0 = list(zip(*topk_md(na0, n_heads0)[:2]))\n",
    "    na2 = get_qk_affinities(model, l1, wv1, wo1, range(l1 + 1, L))\n",
    "    heads2 = list(zip(*topk_md(na2, n_heads2)[:2]))\n",
    "    eigv_pos012 = compute_eigv_pos012(model, l1, h1, wv1, wo1, heads0, heads2, \n",
    "        eigv_positivity, use_ln=True, _e=_e[0], verbose=False)\n",
    "    eigv_positivity012[l1, h1] = eigv_pos012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigv_positivity012_ln = eigv_positivity012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with gzip.open(f'eigv_positivity012_{model_name.split(\"/\")[-1]}.pkl.gz', 'wb') as f:\n",
    "#     pickle.dump(eigv_positivity012, f)\n",
    "with gzip.open(f'eigv_positivity012_{model_name.split(\"/\")[-1]}.pkl.gz', 'rb') as f:\n",
    "    eigv_positivity012 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conductivity = torch.zeros(L, H)\n",
    "for l, h in eigv_positivity012:\n",
    "    conductivity[l, h] = get_conductivity(eigv_positivity012, l, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, affinity_val, eigv_pos_ov, k_comp = zip(*[(f'{l}-{h}', v, eigv_positivity[l, h, 1].item(), k_comp_max[l, h].item()) \n",
    "        for l, h, v in zip(*topk_md(na2, 50))])\n",
    "# plt.figure(figsize=(16, 10))\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "_ = plt.scatter(x=eigv_pos_ov, y=k_comp, marker='.', alpha=affinity_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional heads & K-compositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "_ = plt.scatter(x=eigv_positivity[:, :, 1].view(-1), y=k_comp_max.view(-1), marker='.')#, alpha=affinity_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_score = get_positional_score(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_heads = topk_md(pos_score, 60, zipped=True) # 60 for gpt-j\n",
    "positional_heads = sorted(positional_heads, key=lambda x: x[-1], reverse=True)  # sorted by value\n",
    "positional_heads = sorted(positional_heads, key=lambda x: x[0]) # then by layer\n",
    "positional_heads\n",
    "pos_heads2val = OrderedDict(((l, h), v) for l, h, v in positional_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l, h, v in sorted(positional_heads, key=lambda x: x[-1], reverse=True):\n",
    "    wv, wo = get_head_weights(model, l, h, transpose=True)[2:]\n",
    "    print(f'{l}-{h}', v, eigv_positivity[l, h], get_eigv_pos(wo @ wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1, h1 = 12, 10; wv1, wo1 = get_head_weights(model, l1, h1, transpose=False)[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_heads = [(l, h) for l in range(l1//2, l1) for h in range(H)]\n",
    "heads0 = [(l, h) for l, h, _ in positional_heads]\n",
    "# heads0 = set(all_heads) - set(heads0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs0, wos0 = zip(*[get_head_weights(model, l, h, transpose=True)[2:] for l, h in heads0])\n",
    "wvs0 = rearrange(list(wvs0), 'b e d -> b e d')\n",
    "wos0 = rearrange(list(wos0), 'b d e -> b d e')\n",
    "# heads0_outputs = rearrange([blocks[l].ln_1(_e[1]) for l, _ in heads0], 'b v e -> b v e')\n",
    "heads0_outputs = rearrange([_e[0] for l, _ in heads0], 'b v e -> b v e')\n",
    "heads0_outputs = heads0_outputs @ wvs0 @ wos0  # bve,bed,bde->bve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_compositions = torch.zeros(L, H, len(heads0))\n",
    "for l1 in tqdm(range(L)):\n",
    "    # ln_e = blocks[l1].ln_1(_e[1])\n",
    "    # ln_heads0_outputs = blocks[l1].ln_1(heads0_outputs)\n",
    "    ln_e = _e[0]\n",
    "    ln_heads0_outputs = heads0_outputs\n",
    "    for h1 in range(H):\n",
    "        if l1 == 0:\n",
    "            eigv_pos = [0. for _ in range(len(heads0))]\n",
    "        else:\n",
    "            wq1, wk1, wv1, wo1 = get_head_weights(model, l1, h1, transpose=True)\n",
    "            q = ln_e @ wq1\n",
    "            k = ln_heads0_outputs @ wk1\n",
    "            M = k.transpose(-2, -1) @ q   # bdv,vd->bdd\n",
    "            eigv_pos = [get_eigv_pos(m) for m in M]\n",
    "            eigv_pos = [ep if l < l1 else 0. for ep, (l, _) in zip(eigv_pos, heads0)]\n",
    "        k_compositions[l1, h1] = torch.Tensor(eigv_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_k_comp([(3, 11), (4, 8), (6, 10), (12, 10)], k_compositions_noln, pos_heads2val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heads = [all_heads, all_heads]\n",
    "get_l1_start = lambda l: 0\n",
    "pattern, weBTA = 'vo kq', None\n",
    "# pattern, weBTA = 'e vo kq e', weBTAs[0]\n",
    "# pattern, weBTA = 'E vo kq E', weBTAs[1]\n",
    "with torch.no_grad(): _eigvs = compute_eigvs(model, heads, pattern, weBTA=weBTA, get_l1_start=get_l1_start)\n",
    "rpattern = pattern.replace(' ', '')[::-1]\n",
    "np.savez_compressed(f'{model_name.split(\"/\")[-1]}/eigvs_{rpattern}.npz', d=_eigvs.half())\n",
    "eigvs[rpattern] = _eigvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1, h1 = 8, 7\n",
    "# l1, h1 = 6, 2\n",
    "_eigvs = compute_eigvs(model, [(l1, h1), k_comp_heads, all_heads], 'e vo ov ov e', weBTA=weBTAs[0], l1_range_fn=lambda l0: range(0, l0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eigv(weightprod(model, [(6, 7), (6, 2)], 'e vo ov e', weBTA=weBTAs[0]), start_i=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l0, h0 = 4, 8\n",
    "eigvs.evoove[l0, h0, l1, h1]\n",
    "add_rows(topk_md(_eigvs[l0, h0, :, :, 0], 5), pos_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvs = Eigovs()\n",
    "for pattern in ['voov', 'qkkq', 'qkov']:\n",
    "    for we_str in ['', 'e', 'E']:\n",
    "        _pattern = we_str + pattern + we_str\n",
    "        setattr(eigvs, _pattern, torch.Tensor(np.load(f'{model_name.split(\"/\")[-1]}/eigvs_{_pattern}.npz')['d']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpattern = 'qkkq'\n",
    "# rpattern = 'voov'\n",
    "# rpattern = 'qkov'\n",
    "_eigvs = torch.Tensor(np.load(f'{model_name.split(\"/\")[-1]}/eigvs_{rpattern + \"_fro\"}.npz')['d'])\n",
    "if rpattern == rpattern[::-1]: _eigvs = complete_tril(_eigvs)\n",
    "setattr(eigvs, rpattern + '_fro', _eigvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,10))\n",
    "x, y = eigvs.qkov[..., 0].view(-1), eigvs.qkov_fro[..., 0].view(-1)\n",
    "# x, y = x[x ]\n",
    "_ = plt.hist(x.numpy(), bins=40); plt.show()\n",
    "_ = plt.hist(y.numpy(), bins=40); plt.show()\n",
    "_ = plt.scatter(x, y, '.', alpha=0.05); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpattern = 'ekqOVove'\n",
    "if not hasattr(eigvs, rpattern): setattr(eigvs, rpattern, {})\n",
    "for l, h in todo_heads + [(12, 10)]:\n",
    "# for l, h in hds.kqOVov:\n",
    "#     if (l, h) not in [(11, 0)]: continue\n",
    "    getattr(eigvs, rpattern)[(l, h)] = torch.Tensor(np.load(f'{model_name.split(\"/\")[-1]}/eigvs_{rpattern}_{l}-{h}.npz')['d'])\n",
    "# rpattern = 'ekqovovove'\n",
    "# if not hasattr(eigvs, rpattern): setattr(eigvs, rpattern, {})\n",
    "# l1, h1 = 12, 10\n",
    "# for (l0, h0) in [(3, 11), (6, 10)]:\n",
    "#     key = ((l0, h0), (l1, h1))\n",
    "#     if key not in getattr(eigvs, rpattern):\n",
    "#         getattr(eigvs, rpattern)[key] = torch.Tensor(np.load(f'{model_name.split(\"/\")[-1]}/eigvs_{rpattern}_{l0}-{h0}_{l1}-{h1}.npz')['d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = q @ v.T[0]\n",
    "show_topk(*u.topk(40, largest=True), indices_fn=tokenizer.convert_ids_to_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_head_idx(l0, h0):\n",
    "    i= None\n",
    "    for i, (l, h, _) in  enumerate(positional_heads):\n",
    "        if (l, h) == (l0, h0): return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(f'k_compositions_noln_{model_name.split(\"/\")[-1]}.npz', k_compositions=np.array(k_compositions), positional_heads=positional_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = np.load(f\"k_compositions_{model_name.split('/')[-1]}.npz\")\n",
    "# k_compositions, positional_heads = torch.Tensor(d['k_compositions']), d['positional_heads']\n",
    "# k_compositions[k_compositions == -1] = 0\n",
    "# k_comp_max = k_compositions.max(-1)[0]\n",
    "# positional_heads = [[int(l), int(h), v] for l, h, v in positional_heads]\n",
    "# pos_heads2val = OrderedDict(((l, h), v) for l, h, v in positional_heads)\n",
    "k_comp_wmean = torch.einsum('lnk,k->ln', k_compositions, torch.Tensor(list(pos_heads2val.values()))) / \\\n",
    "    ((k_compositions != 0).sum(-1) + 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigv_positivity_noln = compute_eigv_positivity(model, L, H, use_ln=False)\n",
    "# np.savez(f'eigv_positivity_noln_{model_name.split(\"/\")[-1]}.npz', a=eigv_positivity_noln.numpy())\n",
    "data = np.load(f\"eigv_positivity_{model_name.split('/')[-1]}.npz\")\n",
    "eigv_positivity_ov, eigv_positivity_qk = torch.Tensor(data['ov']), torch.Tensor(data['qk'])\n",
    "eigv_positivity = rearrange([torch.Tensor(data['qk']), torch.Tensor(data['ov'])], 'k l n -> l n k') # k=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret QK/OV circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['EleutherAI/gpt-j-6B/cpu', 'EleutherAI/gpt-j-6B/int8'])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50400, 4096])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wu.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(-0.4488914906978607, 0.9882122874259949)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# head+mlp[0]ov circuit, 2-gram ov 15-3, NE (esp. places) qk 4-4, x->num qk 6-15\n",
    "# prev ov: 13-9, next num ov: 14-13, next word ov: 13-4, prepend space ov: 18-3/17-10, isa ov: 14-7, antonym ov: 16-14, copy ov 13-2\n",
    "# NE qk 6-9 who also has copy-like ov\n",
    "# subword num->whole word num qk and suffix token copy ov 3-6\n",
    "# 4-3: lower-layer 8-1 12-10 like head\n",
    "# 10-4: x->adv ov, e.g. including, resulting, subsequently, therefore\n",
    "# 8-13: place NE qk\n",
    "# **8-7: coref resolution qk, also very interesting ov\n",
    "# 6-2: same qk\n",
    "# 10-7: copy and next fused ov\n",
    "# 4-1: num, name and place qk\n",
    "# 24-11: copy ov, esp. num, prepend space\n",
    "# 22-14: suffix token copy ov\n",
    "# 21-8: copy ov, 1st letter to upper\n",
    "# 22-5: copy ov, prepend space, 1st letter to lower, to original form\n",
    "# 23-2: prefix token copy ov, prepend space, 1st letter to lower\n",
    "# 3-9: subword->whole word qk for word completion\n",
    "# 8-2: same qk; 7-9 year and place qk; 7-2 type->instance qk, dual to isa ov 14-7, can be used for coref resolution\n",
    "# 7-14: x->NE qk; 6-1: x->adv/adj qk; 6-0: x->noun qk; special token and symbol qk 1-7\n",
    "# next num qk 3-12 (work with prev ov), + 2-11 = same qk!; x->suffix qk 7-6 + 2-11\n",
    "# prev word+num qk 3-3 (work with next ov), general qk 3-11\n",
    "layer, head = 7, 9\n",
    "wq, wk, wv, wo = get_head_weights(model, layer, head, transpose=True)\n",
    "# layer0, head0 = 8, 7; wv0, wo0 = get_head_weights(model, layer0, head0, transpose=True)[2:]\n",
    "# if layer0 is not None: ek = blocks[layer].ln_1(blocks[layer0].ln_1(_e) @ wv0 @ wo0)\n",
    "\n",
    "e = blocks[layer].ln_1(es[1])\n",
    "\n",
    "qk = True\n",
    "if qk:\n",
    "    # e @ wq @ wk @ e\n",
    "    A, B = e @ wq, e @ wk\n",
    "    m = A @ B.T\n",
    "else:\n",
    "    # @ wv @ wo @ wu.T\n",
    "    A, B = wu @ wo.T, e @ wv  #  wu, ln_f(e @ wv @ wo)  # slow for eig\n",
    "    m = wu @ ln_f(B @ wo).T  # a little better than A @ B.T\n",
    "plot_eigv((B.T @ A).eig()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = m.mean(), m.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(24800)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(tensor(7213), tensor(4442))"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = m > mean + std * 4.5\n",
    "b.sum()\n",
    "b.max(1).values.sum(), b.max(0).values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -- juven -- [('', 4), ('-', 3), ('', 3)]\n",
      "  -- Bra -- [('utonium', 3), ('plugins', 0)]\n",
      "  -- alse -- [('', 4), ('-', 2), ('', 0)]\n",
      "  -- Lavrov -- [('', 0)]\n",
      "  -- Wake -- [('umbledore', 3)]\n",
      "  -- === -- [('', 0)]\n",
      "  -- gorge -- [('Depths', 0)]\n",
      "  -- Liverpool -- [('Liverpool', 1)]\n",
      "  -- Minion -- [('Computer', 1), ('Staff', 0)]\n",
      "  -- count -- [('-+-+', 2), ('', 0)]\n",
      "  -- Slaughter -- [('.-', 0)]\n",
      "  -- bung -- [('Gamergate', 10), ('bledon', 10), ('Assange', 8), ('Awakens', 7), ('Spawn', 7), ('Joker', 6), ('LEGO', 6), ('bender', 6), ('Bridgewater', 6), ('window', 5), ('Wheel', 5), ('Winnipeg', 4), ('waterfront', 4), ('backdoor', 4), ('Baseball', 3), ('Pirate', 3), ('MLB', 3), ('Barnes', 3), ('Bengals', 3), ('dumped', 3), ('Battlefield', 3), ('Dock', 3), ('Barnett', 3), ('assembly', 3), ('spherical', 3), ('Gaming', 3), ('Warehouse', 3), ('Borderlands', 3), ('clubhouse', 3), ('Sports', 2), ('Packers', 2), ('akespeare', 2), ('basketball', 2), ('wheel', 2), ('Window', 2), ('Streamer', 2), ('coral', 2), ('Greenland', 2), ('Lego', 2), ('Reef', 2), ('waterproof', 2), ('Mayweather', 2), ('Minecraft', 2), ('gewater', 2), ('Applications', 2), ('dumps', 2), ('docks', 2), ('corruption', 2), ('ancouver', 1), ('dump', 1), ('Montreal', 1), ('ournaments', 1), ('Sports', 1), ('Bangladesh', 1), ('BU', 1), ('ipeg', 1), ('prostitution', 1), ('Games', 1), ('PvP', 1), (\"').\", 1), ('andro', 1), ('dumping', 1), ('Wenger', 1), ('Orioles', 1), ('iceberg', 1), ('deck', 1), ('aquatic', 1), ('builder', 1), ('Hearthstone', 1), ('Sphere', 1), ('parachute', 1), ('Assets', 1), ('Wonderland', 1), ('Outdoor', 1), ('Clojure', 1), ('Liverpool', 1), ('GamerGate', 1), ('Ballard', 1), ('Graveyard', 1), ('Feldman', 1), ('snowball', 1), ('GAME', 1), ('SPORTS', 1), ('waterways', 1), ('spawn', 1), ('abilia', 1), ('Shattered', 1), ('Parliament', 0), ('Game', 0), ('baseball', 0), ('door', 0), ('\").', 0), ('homosexual', 0), ('sentenced', 0), ('ergus', 0), ('outdoor', 0), ('Hockey', 0), ('thereum', 0), ('recreational', 0), ('WikiLeaks', 0), ('Ethereum', 0), ('Westminster', 0), ('warehouse', 0), ('Kavanaugh', 0), ('Skyrim', 0), ('legalization', 0), ('gallery', 0), ('Around', 0), (')].', 0), ('Opening', 0), ('Cork', 0), ('leground', 0), ('Bahrain', 0), ('Marijuana', 0), (')).', 0), ('GAME', 0), ('garment', 0), ('Asset', 0), ('Environment', 0), ('Hive', 0), ('pattern', 0), ('aquarium', 0), ('raping', 0), ('ositories', 0), ('baseman', 0), ('garments', 0), ('shuffle', 0), ('Spawn', 0), ('drivers', 0), ('Marketplace', 0), ('Pipeline', 0), ('stadiums', 0), ('contractual', 0), ('Database', 0), ('Marlins', 0), ('Configuration', 0), ('OPEN', 0), ('Parliamentary', 0), ('boxer', 0), ('spawning', 0), ('Throw', 0), ('dump', 0), ('bribe', 0), ('Hendricks', 0), ('arijuana', 0), ('Correction', 0), ('interchangeable', 0), ('warehouses', 0), ('Released', 0), ('Coinbase', 0), ('Asset', 0), ('Pebble', 0), ('PVC', 0), ('Wallet', 0), ('Barn', 0), ('properties', 0), ('stitching', 0), ('potion', 0), ('Lens', 0), ('Paddock', 0)]\n",
      "  -- iphate -- [('-', 0), ('.-', 0)]\n",
      "  -- Stone -- [('Minecraft', 1)]\n",
      "  -- Tart -- [('Minecraft', 0)]\n",
      "  -- Bengal -- [('Beng', 1)]\n",
      "  -- elligence -- [('', 1)]\n",
      "  -- uesday -- [('.-', 7), ('-', 4), ('', 2)]\n",
      "  -- oenix -- [('', 8), ('-', 5), (\"'-\", 1)]\n",
      "  -- Zion -- [('Bitcoin', 8), ('Israeli', 7), ('Bitcoin', 4), ('bitcoin', 4), ('iblical', 4), ('Israeli', 3), ('bitcoins', 3), ('Bitcoins', 3), ('Python', 3), ('Israelis', 2), ('biblical', 2), ('cryptocurrencies', 2), ('Biblical', 2), ('bitcoin', 2), ('Earthquake', 2), ('Python', 1), ('earthquake', 1), ('python', 1), ('Palestinian', 1), ('python', 0), ('', 0), ('earthquakes', 0)]\n",
      "  -- hash -- [('', 1), ('-', 0)]\n",
      "  -- athom -- [('-', 1)]\n",
      "  -- WIN -- [('WINDOWS', 1)]\n",
      "  -- unk -- [('', 2), ('-', 1)]\n",
      "  -- Unt -- [('contraception', 0)]\n",
      "  -- Chris -- [('', 1)]\n",
      "  -- Vegeta -- [('Goku', 0)]\n",
      "  -- Thu -- [('night', 0)]\n",
      "  -- Brach -- [('inburgh', 4), ('uberty', 0)]\n",
      "  -- Alloy -- [('melting', 5), ('metallic', 2), ('metals', 1), ('Metallic', 1), ('Minecraft', 1), ('ensional', 0), ('utonium', 0)]\n",
      "  -- Econom -- [('', 1)]\n",
      "  -- Sketch -- [('Graphics', 0)]\n",
      "  -- ossier -- [('-', 6), ('', 5), ('', 4), ('--', 0)]\n",
      "  -- legates -- [('-', 0), ('.-', 0)]\n",
      "  -- NAME -- [('', 1)]\n",
      "  -- ...... -- [('\"},\"', 2), ('..........', 1), ('---------', 1), ('iversal', 0), ('.....', 0), ('..............', 0), ('\\\\/\\\\/', 0)]\n",
      "  -- colonial -- [('-', 2), ('', 0)]\n",
      "  -- wom -- [('contraceptive', 13), ('contraceptives', 12), ('contraception', 11), ('abortions', 8), ('menstrual', 7), ('Abortion', 7), ('abortion', 5), ('pregnancies', 4), ('imester', 4), ('regnancy', 3), ('pregnancy', 2), ('circumcision', 2), ('abortion', 2), ('chromosomes', 2), ('childbirth', 2), ('miscarriage', 2), ('pregnant', 1), ('menstru', 1), ('circumcised', 1), ('raped', 0), ('Female', 0), ('HPV', 0), ('breastfeeding', 0)]\n",
      "  -- --+ -- [('', 4), ('-', 3), ('', 3), ('.-', 2), (\"'-\", 2), ('', 1), ('\"-', 0)]\n",
      "  -- financial -- [('-', 0), ('', 0)]\n",
      "  -- nor -- [('.-', 2), ('-', 0), ('', 0)]\n",
      "  -- wastewater -- [('flush', 1)]\n",
      "  -- Sapp -- [('prostitution', 3), ('entanyl', 1), ('oneliness', 0)]\n",
      "  -- cloak -- [('textile', 3), ('aunder', 1), ('laund', 0), ('Jacket', 0)]\n",
      "  -- ogyn -- [('.-', 0), ('', 0)]\n",
      "  -- dig -- [('', 0)]\n",
      "  -- Airlines -- [('flight', 2), ('Flight', 0)]\n",
      "  -- aptop -- [('-', 3), ('', 2)]\n",
      "  --  -- [('masturbation', 2), ('Minecraft', 0)]\n",
      "  -- Bible -- [('iblical', 2), ('ospels', 1), ('scripture', 0), ('scriptures', 0), ('bible', 0), ('Scriptures', 0)]\n"
     ]
    }
   ],
   "source": [
    "sample_all_top_entries(tokenizer, m, b, transpose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lowering': 35, 'lows': 34, 'lowly': 33, 'socioeconomic': 32, 'underside': 32, 'lowest': 32, 'low': 31, 'Low': 31, 'relegation': 29, 'underwater': 29, 'borderline': 28, 'Elementary': 28, 'lowered': 28, 'moderation': 27, 'underdog': 27, 'ankle': 27, 'miser': 27, 'Low': 27, 'AHL': 26, 'lowers': 26}\n"
     ]
    }
   ],
   "source": [
    "# for country, (capital,) in country2capital().items():\n",
    "print(lookup_top_entries(tokenizer, m, 'high'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = _m  # q->k, output->input\n",
    "m = _m.T  # k->q, input->output\n",
    "values, indices = m.topk(25, largest=True)\n",
    "\n",
    "indices_fn = tokenizer.convert_ids_to_tokens\n",
    "for i in values.abs().mean(1).topk(500).indices.tolist():\n",
    "    print(indices_fn(i), show_topk(values[i][:6], indices[i][:6], indices_fn=indices_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8490"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8490"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8490"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8490"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs, inputs, values = topk_md(m, 10000)\n",
    "pairs = list(zip(tokenizer.convert_ids_to_tokens(outputs), tokenizer.convert_ids_to_tokens(inputs)))\n",
    "pairs = [(o.replace('', '').lower(), i.replace('', '').lower()) for o, i in pairs]; len(pairs)\n",
    "# https://stackoverflow.com/questions/480214/how-do-i-remove-duplicates-from-a-list-while-preserving-order\n",
    "pairs = list(dict.fromkeys(pairs)); len(pairs)\n",
    "if remove_similar:\n",
    "    n0 = len(pairs)\n",
    "    pairs = [(o, i) for o, i in pairs if o != i]; len(pairs)\n",
    "    pairs = [(o, i) for o, i in pairs if not o.startswith(i)]; len(pairs)\n",
    "    pairs = [(o, i) for o, i in pairs if not i.startswith(o)]; len(pairs)\n",
    "    n1 = len(pairs)\n",
    "    \n",
    "# sorted(pairs, key=lambda x: x[0])\n",
    "# d = defaultdict(list)\n",
    "# for o, i in pairs: d[o].append(i)\n",
    "# for k, v in sorted(d.items(), key=lambda x: len(x[1]), reverse=True): print(k); print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 826,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(dict_keys(['revital', 'rebuild', 'reinstated', 'reorgan', 'redesign', 'restored', 'support', 'Leadership', 'mourning', 'rebuilding', 'restoring', 'restructuring', 'revived', 'reforms', 'resusc', 'revive', 'rebuilt', 'rich', 'restoration', 'resurrect']),\n",
       " dict_values([16.688, 14.742, 14.5, 14.442, 14.387, 14.135, 13.959, 13.836, 13.745, 13.539, 13.537, 13.343, 13.006, 12.91, 12.886, 12.857, 12.748, 12.718, 12.704, 12.53]))"
      ]
     },
     "execution_count": 826,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(dict_keys(['analysts', 'generals', 'Sold', 'analyst', 'Intelligence', 'intelligence', 'testing', 'doctors', 'physicians', 'tactical', 'testers', 'Analy', 'tests', 'soldiers', 'racist', 'clinicians', 'analy', 'diagn', 'spec', 'armed']),\n",
       " dict_values([1.737, 1.704, 1.59, 1.492, 1.486, 1.467, 1.457, 1.438, 1.425, 1.407, 1.405, 1.403, 1.403, 1.396, 1.395, 1.391, 1.39, 1.384, 1.384, 1.372]))"
      ]
     },
     "execution_count": 826,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['car', 'bus', 'tractor', 'airplane', 'ship', 'bicycle', 'truck', 'train', 'motorbike', 'helicopter', 'carriage', \n",
    "                'subway', 'taxi', 'van', 'boat']\n",
    "# words = types_of_things()['']\n",
    "words = ['van']\n",
    "all_ids = [tokenizer.encode(' ' + word) for word in words]\n",
    "_v, _v0 = zip(*[[m.T[ids[0]] for m in [_m, _m0]] for ids in all_ids if len(ids) == 1])\n",
    "[(word, tokenizer.tokenize(' ' + word)) for word, ids in zip(words, all_ids) if len(ids) != 1]\n",
    "for v in [_v, _v0]:\n",
    "    d = show_topk(*torch.stack(v).mean(0).topk(20), indices_fn=indices_fn); (d.keys(), d.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types of animal: lion, tiger, goose, horse, squirrel, goat\n",
      "Types of drink: beer, juice, soda, whiskey, cocktail, tea\n",
      "Types of food: pizza, cake, hamburger, burger, bread, steak\n",
      "Types of weapon: handgun, revolver, pistol, cannon, shotgun, grenade\n",
      "Types of color: yellow, green, black, pink, red, gray\n"
     ]
    }
   ],
   "source": [
    "for typ, things in types_of_things().items():\n",
    "    print(f\"Types of {typ}: {', '.join(sample(things, 6))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 1; k_shot = 0\n",
    "# text = 'The Space Needle is in the city of Seattle.'\n",
    "# text = 'Megan Rapinoe plays the sport of soccer.'\n",
    "text = 'When Mary and John went to the store, John gave a drink to Mary.'\n",
    "input_ids = data_tuples[0][1]\n",
    "attn_mask = torch.ones(input_ids.size(1), input_ids.size(1)) * (-1e9)\n",
    "attn_mask[:, [1, 3]] = 0\n",
    "attn_mask = attn_mask.tril()\n",
    "data_tuples = [predict(model, tokenizer, text, None, k_shot=k_shot, bos_token='to', eos_token=None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if model_name == 'EleutherAI/gpt-neox-20b': model, _ = models[model_name] # switch back from cpu to gpu model\n",
    "data_tuples = [predict(model, tokenizer, text, examples, k_shot=k_shot, bos_token=bos_token, eos_token=eos_token)[0]\n",
    "    for text, examples in zip(texts, all_examples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_md(get_head_matching_scores(data_tuples, 'bos->ans0]', k_shot=k_shot), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_heads = topk_md(attn_mll, 1, transpose=True)#[2:4]\n",
    "for l, h, v in top_heads:\n",
    "    print(l, h, v)\n",
    "    for text, input_ids, labels, ranges, *args, o, attn_attr in data_tuples:\n",
    "        print(text[:10])\n",
    "        aw = o.attentions[l][0, h]\n",
    "        bos_indices = args[1]; ystart = bos_indices[k_shot]; ystop = aw.size(0)\n",
    "        tokens = [t.replace('', '').replace('', '-'*12) for t in tokenizer.convert_ids_to_tokens(input_ids[0])]\n",
    "        plot_attn(aw, tokens, ystart=None, ystop=None, topk=int(len(ranges) * 1.5),\n",
    "            figsize=(20, 20), fontsize=9, transpose=True, use_imshow=False)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si = -1\n",
    "attribute_k = False\n",
    "root = node = Node('[-1] root'); node.data = AttrData(step=si, label_type='argmax_labels')\n",
    "nodes = {}; nodes[si] = node; print_tree(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# si = 0\n",
    "parent = nodes[si]#.parent.children[0]\n",
    "print(parent.name)\n",
    "attr = parent.data.attr\n",
    "topk_md(attr.head, 10) # list(zip(*topk_md(attr.head, 10)))\n",
    "topk_md(attr.mlp, 5) # list(zip(*topk_md(attr.mlp, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head/mlp\n",
    "topi = [0, 1, 2]\n",
    "layer, head = topk_md(attr.head, 10, transpose=True)[:2][topi][:2] if type(topi) == int \\\n",
    "    else np.array(topk_md(attr.head, 10)[:2])[:, topi]\n",
    "# layer, head = list(zip(*topi_md(attr.mlp, 10)))[topi][0], None\n",
    "label_type = [None, 'labels', 'argmax_labels', 'argmax_attn_labels', 'attn_labels'][-1]\n",
    "attribute_k = False\n",
    "if si == -1: assert label_type is not None # in ['labels', 'argmax_labels', 'argmax_attn_labels', 'attn_labels']\n",
    "else: label_type = None\n",
    "data = AttrData(step=si + 1, topi=topi, layer=layer, head=head, label_type=label_type, \n",
    "    attribute_k=label_type in ['argmax_attn_labels', 'attn_labels'] and attribute_k)\n",
    "print(data2str(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "si += 1\n",
    "node = Node(data2str(data), parent); node.data = data; nodes[si] = node\n",
    "print([dt[0] for dt in data_tuples], k_shot)\n",
    "nodes[si].name = '*' + nodes[si].name\n",
    "print_tree(root)\n",
    "nodes[si].name = nodes[si].name[1:]  # strip prepending '*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "attrs, attrs2 = [], []#; node = nodes[si]\n",
    "for text, input_ids, labels, ranges, *_, o in data_tuples:\n",
    "    fns = path2fns(node, root, partial(node2fn, model=model, outputs=o, labels=labels))\n",
    "    (output_layer, _labels) = (node.data.layer, None) if len(fns) > 0 else (L, labels)\n",
    "    if _labels is not None and root.data.label_type == 'argmax_labels':\n",
    "        _labels = get_argmax_labels(model, o.hidden_states[-2], _labels)\n",
    "    to_layer = max(output_layer) if isinstance(output_layer, Iterable) else output_layer\n",
    "    fwd_fn = partial(sum_forward, outputs=o, labels=_labels, output_layer=output_layer)\n",
    "    keys = ['embed_mask', 'mlp_mask', 'attn_weights']\n",
    "    x = OrderedDict((key, get_x(key, o, to_layer=to_layer)) for key in keys)\n",
    "    attr, ys, logits = attribute(fwd_fn, model, x, fns, num_points=4 if attribute_k else 7) \n",
    "    # fwd_fn = partial(sum_forward, outputs=o, labels=_labels, reduce_fn=torch.cat, scaled=False)\n",
    "    attr2 = attr #attribute2(fwd_fn, model, x, fns)\n",
    "\n",
    "    attrs.append(attr); attrs2.append(attr2)\n",
    "    o.attn_attr[node.name] = attr.attn # associate non-averageable attn attr to current node. tricky\n",
    "        \n",
    "print(f'attribution step {si} results')\n",
    "attr = reduce_objects(attrs, ['head', 'neuron', 'mlp']); attr2 = reduce_objects(attrs2, ['head', 'mlp'])\n",
    "plot_attr(attr, attr2)\n",
    "pd.concat([to_df(*topk_md(a[: to_layer], min(to_layer, 10)))\n",
    "    for a in [attr.head, attr2.head, attr.mlp, attr2.mlp]], axis=1)\n",
    "node.data.attr = attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ap, topk in zip(attn_patterns_by_step[1], [1, 1]):\n",
    "    # if ap != 'ans]->ans0]': continue\n",
    "    print(ap)\n",
    "    for head in topk_md(scores[ap], topk, transpose=True):\n",
    "        plot_attns(data_tuples, tokenizer, *head, attn_pattern=ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l, h, v in topk_md(node.data.attr.head, 3, transpose=True):\n",
    "    print(l, h, v)#, get_head_rank(attr2.head, l, h))#, eigv_positivity[l, h], pos_score[l, h])\n",
    "    for text, input_ids, labels, ranges, *args, o in data_tuples[:4]:\n",
    "        attn_attr = o.attn_attr\n",
    "        fns = path2fns(node, partial(node2fn, model=model, outputs=o, labels=labels))\n",
    "        fwd_fn = partial(sum_forward, outputs=o, output_layer=l)\n",
    "        _labels = labels if len(fns) == 0 else None\n",
    "        # _labels = get_argmax_labels(model, o.hidden_states[-2], _labels)\n",
    "        fn = partial(head_forward, layer=l, head=h, attn_weights=o.attentions[l], labels=_labels) \\\n",
    "            if h >= 0 else partial(mlp_forward, layer=l, labels=_labels)\n",
    "        keys = ['embed_mask', 'mlp_mask', 'attn_weights']\n",
    "        x = OrderedDict((key, get_x(key, o, to_layer=l)) for key in keys)\n",
    "        _, ys, logits = attribute(fwd_fn, model, x, [fn] + fns, num_points=3, forward_only=True); print(ys)\n",
    "        if iterable(logits): logits = sum(logits)\n",
    "        if logits.size(-1) == model.lm_head.out_features:  # lm_logits\n",
    "            _ = show_predictions(tokenizer, *args, logits=logits[-1:], labels=_labels, topk=4, sep='\\t')\n",
    "        # elif logits.size(-1) == input_ids.size(1): # attn_logits, bij\n",
    "        #     plot_attn(logits[-1].softmax(dim=-1), tokens, figsize=(5, 5))  # bnij->ij\n",
    "        #     plot(logits[-1, -3, :13])\n",
    "\n",
    "        if h == -1: continue\n",
    "        attn, aa = o.attentions[l][0, h], attn_attr[node.name][l, h]\n",
    "        bos_indices = args[1]; ystart = (node.data.step <= 0)*bos_indices[k_shot]; ystop = aa.size(0)\n",
    "        # fig, axs = plt.subplots(1, 2, sharex=False, sharey=False, figsize=(20, 10*(ystop-ystart)/aa.size(0)))\n",
    "        fig, axs = plt.subplots(1, 2, sharex=False, sharey=False, figsize=(40*(ystop-ystart)/aa.size(0), 20))\n",
    "        tokens = [t.replace('', '').replace('', '-'*12) for t in tokenizer.convert_ids_to_tokens(input_ids[0])]\n",
    "        y_pos, x_pos, _ = topk_md(aa, k=nrows-k_shot)\n",
    "        if True: #with Timer():\n",
    "            for ax, a in zip(axs, [attn, aa]):\n",
    "                plot_attn(a, tokens, ax=ax, ystart=ystart, ystop=ystop, y_pos=y_pos, x_pos=x_pos,\n",
    "                fontsize=9, transpose=True, use_imshow=False)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group0 = [(1, 7), (6, 2), (8, 7)]; group1 = [(3, 6), (3, 11), (4, 8), (6, 10)]\n",
    "neuron = attr.neuron\n",
    "for (l0, h0), (l1, h1) in product(group0, group1):\n",
    "    print(f'{l0}-{h0}, {l1}-{h1}', nn.CosineSimilarity(0)(neuron[l0, h0].mean(0), neuron[l1, h1].mean(0)))\n",
    "print()\n",
    "for (l0, h0), (l1, h1) in combinations(group0, 2):\n",
    "    print(f'{l0}-{h0}, {l1}-{h1}', nn.CosineSimilarity(0)(neuron[l0, h0].mean(0), neuron[l1, h1].mean(0)))\n",
    "print()\n",
    "for (l0, h0), (l1, h1) in combinations(group1, 2):\n",
    "    print(f'{l0}-{h0}, {l1}-{h1}', nn.CosineSimilarity(0)(neuron[l0, h0].mean(0), neuron[l1, h1].mean(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = nodes[i].data.attr\n",
    "for l, h, v in zip(*topk_md(attr.head, 1)):\n",
    "    # if l != 14: continue\n",
    "    print(l, h, v, get_head_rank(attr2.head, l, h))\n",
    "    for text, examples, inputs, tokens, bos_indices, eos_indices, answers, labels, o, attn_attr in data_tuples[1:2]:\n",
    "        x = OrderedDict((key, get_x(key, o, to_layer=l)) for key in keys)\n",
    "        fwd_fn = partial(sum_forward, outputs=o)\n",
    "        fn = partial(head_forward, layer=l, head=h, attn_weights=o.attentions[l],\n",
    "                            labels=labels if len(fns) == 0 else None)\n",
    "        post_fwd_fn = compose_forward_fns([fn] + fns, scaled=True)\n",
    "        _, ys, logits = attribute(fwd_fn, model, x, post_fwd_fn, num_points=3, batch_size=3); print(ys)\n",
    "        if logits.size(-1) == model.lm_head.out_features:\n",
    "            show_predictions(text, examples, tokenizer, logits[-1:], bos_indices, eos_indices, answers, labels, \n",
    "                topk=4, show_range=range(k_shot, len(examples)), sep='\\t')\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2, sharex=False, sharey=False, figsize=(20, 10))\n",
    "        aa = attn_attr[nodes[i].name][l, h]\n",
    "        # attn_labels = aa / (aa.sum(-1, keepdim=True) + 1e-9)  # ij->i1\n",
    "        for ax, a in zip(axs, [o.attentions[l][0, h], aa, ]):\n",
    "            plot_attn(a, tokens, ax=ax)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attn_weights\n",
    "attrs = []\n",
    "for attribute_layer in range(27):\n",
    "    forward_fn = partial(forward, inputs=inputs, labels=labels, loss_reduction='per_example_mean', attribute_layer=attribute_layer)\n",
    "    x = {'head_mask': torch.ones(1, H, o.hidden_states[0].size(1))}\n",
    "    def get_y(outputs): return -outputs.loss\n",
    "    attr, ys = attribute(forward_fn, x, get_y, num_points=8)\n",
    "    ys\n",
    "    attrs.append(attr)\n",
    "    \n",
    "head_attr2 = rearrange([attr['head_mask'] for attr in attrs], 'l n i -> l n i')\n",
    "head_attr2 = torch.einsum('lni->ln', head_attr2)\n",
    "list(zip(*topk_md(head_attr2, 10)))\n",
    "\n",
    "# attn_weights\n",
    "for attribute_layer, attribute_head, __ in list(zip(*topk_md(head_attr, 10)))[:3]: # heads 27-17, 17-4, 22-13\n",
    "    forward_fn = partial(forward, inputs=inputs, labels=labels, loss_reduction='per_example_mean', attribute_layer=attribute_layer)\n",
    "    x = {'attn_weights': o.attentions[attribute_layer]}\n",
    "    def get_y(outputs): return -outputs.loss\n",
    "    attr, ys = attribute(forward_fn, x, get_y)\n",
    "    # ys\n",
    "    print(attribute_layer, attribute_head)\n",
    "    plot_attn(attr['attn_weights'][attribute_head], tokens, figsize=(5, 5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "headsinduction heads  \n",
    "induction headsattn_weightsheadsQ-compostion or K-composition with induction heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2induction head17-4K-composition heads\n",
    "layer, head, _ = list(zip(*topk_md(head_attr, 10)))[1]\n",
    "layer, head\n",
    "aw_label = binarize(attn_attr[layer, head])\n",
    "wq, wk = get_head_weights(layer, head)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head_output\n",
    "query = torch.einsum('bie,de->bid', o.hidden_states[layer], wq)\n",
    "head_outputs = rearrange(list(o.head_outputs), 'l 1 n i e -> 1 l n i e')[:, :layer]\n",
    "key = torch.einsum('blnje,de->blnjd', head_outputs, wk)\n",
    "attn_logits = torch.einsum('bid,blnjd->lnij', query, key) # b==1\n",
    "# i j l n -> n_label l n -> ln\n",
    "attn_head_attr = rearrange(attn_logits, 'l n i j -> i j l n')[aw_label == 1].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.heatmap(attn_head_attr)\n",
    "list(zip(*topk_md(attn_head_attr, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attn_weights\n",
    "# h2: a higher-layer (induction) head (layer, head)\n",
    "# h1: lower-layer heads forming K-composition with h2\n",
    "# i: h2 query position, j: h2 key position, k: h1 query position\n",
    "head_inputs_ = rearrange(list(o.head_inputs), 'l 1 n j e -> l n j e')[:layer]\n",
    "attentions_ = attentions[:layer]\n",
    "if True: # faster version\n",
    "    key = head_inputs_ @ wk.T  # lnje,de->lnjd\n",
    "    lnkj_attn_logits = torch.einsum('bkd,lnjd->lnkj', query, key) # b==1\n",
    "    lnkij_attn_logits = torch.einsum('lnij,lnkj->lnkij', attentions_, j_attn_logits)\n",
    "else: # slower version, but easier to understand (similar to unseal)\n",
    "    lnije = torch.einsum('lnij,lnje->lnije', attentions_[:layer], head_inputs_)\n",
    "    key = lnije @ wk.T  # lnije,de->lnijd    \n",
    "    lnkij_attn_logits = torch.einsum('bkd,lnijd->lnkij', query, key)  # b==1\n",
    "# kij means k attends i in higher layer, i attends j in lower layer\n",
    "attn_attn_attr = torch.einsum('lnkij,ki->lnij', lnkij_attn_logits, aw_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l, h, v in zip(*topk_md(attn_head_attr, 10)):\n",
    "    print(l, h, v)\n",
    "    fig, axs = plt.subplots(1, 3, sharex=False, sharey=False, figsize=(15, 5))\n",
    "    for ax, a in zip(axs, [attentions[l, h], attn_attn_attr[l, h], binarize(attn_attn_attr[l, h])]):\n",
    "        plot_attn(a, tokens, ax=ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune intermediary heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = defaultdict(int)\n",
    "pairs = []\n",
    "for l0, h0, l2, h2 in zip(*np.unravel_index(affinities.view(-1).topk(500).indices, affinities.size())):\n",
    "    if d[(l0, h0)] < 10:\n",
    "        d[(l0, h0)] += 1\n",
    "        pairs.append(((l0, h0), (l2, h2)))\n",
    "        if len(pairs) == 100: break\n",
    "Counter([(l0, h0) for (l0, h0), (l2, h2) in pairs]).most_common()\n",
    "random.shuffle(pairs)\n",
    "train_set, val_set = pairs[:-20], pairs[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_forward(head_pairs, wv1, wo1, alpha=0.1, compute_eigv=False):\n",
    "    wvs0, wos0, wqs2, wks2 = zip(*[get_head_weights(model, l0, h0, transpose=True)[2:] +\n",
    "                                get_head_weights(model, l2, h2, transpose=True)[:2] \n",
    "                                for (l0, h0), (l2, h2) in head_pairs])\n",
    "    wvs0, wos0 = rearrange(list(wvs0), 'b e d -> b e d'), rearrange(list(wos0), 'b d e -> b d e')\n",
    "    wqs2, wks2 = rearrange(list(wqs2), 'b e d -> b e d'), rearrange(list(wks2), 'b e d -> b e d')\n",
    "    wvs0, wos0, wqs2, wks2 = wvs0.to(device), wos0.to(device), wqs2.to(device), wks2.to(device)\n",
    "    wvo1 = wv1 @ wo1\n",
    "    q, kT = wvs0 @ wos0 @ wvo1 @ wqs2, wks2.transpose(-2, -1)\n",
    "    comp_norm = (q @ kT).norm(dim=(-2, -1)).mean()\n",
    "    # loss = -comp_norm / wvo1.norm()\n",
    "    loss = -(comp_norm - alpha * wvo1.norm())\n",
    "    eigvs = [plot_eigv(m.eig()[0], plot=False) for m in kT @ q] if compute_eigv else None\n",
    "    return loss, comp_norm, eigvs\n",
    "    \n",
    "def eval(dataset, wv1, wo1, bsz=8, compute_eigv=False, e=None, wu=None):\n",
    "    losses, eigvs, comp_norms = [], [], []\n",
    "    for i in range(len(dataset) // bsz):\n",
    "        loss, comp_norm, _eigvs = w_forward(dataset[i * bsz: (i + 1) * bsz], wv1, wo1, compute_eigv=compute_eigv)\n",
    "        losses.append(loss.item())\n",
    "        comp_norms.append(comp_norm.item())\n",
    "        if compute_eigv: eigvs += _eigvs\n",
    "    if compute_eigv:\n",
    "        print(torch.Tensor(eigvs))\n",
    "        # e = model.transformer.h[l1].ln_1(_e)\n",
    "        A, B = wu @ wo1.T.to('cpu'), e @ wv1.to('cpu')\n",
    "        print('wvo1 eigv_pos =', plot_eigv((B.T @ A).eig()[0], plot=False))\n",
    "    return round(sum(losses) / len(losses), 4), round(sum(comp_norms) / len(comp_norms), 4), round((wv1 @ wo1).norm().item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "wv1, wo1 = get_head_weights(model, l1, h1, transpose=True)[2:]\n",
    "wv1, wo1 = wv1.detach().clone(), wo1.detach().clone()\n",
    "wv1, wo1 = wv1.to(device), wo1.to(device)\n",
    "_ = wv1.requires_grad_(True); _ = wo1.requires_grad_(True)\n",
    "optimizer = optim.AdamW([wv1, wo1], lr=1e-4)\n",
    "bsz, eval_bsz = 8, 4\n",
    "# test(model, data_tuples)\n",
    "# test(model, data_tuples, replaced_head=(l1, h1), wv=wv1.to('cpu'), wo=wo1.to('cpu'))\n",
    "# test(model, data_tuples, replaced_head=(l1, h1), wv=wv1.to('cpu'), wo=2*wo1.to('cpu'))\n",
    "with torch.no_grad(): print('Epoch', -1, 'train', eval(train_set, wv1, wo1), \n",
    "                        'val', eval(val_set, wv1, wo1, bsz=eval_bsz, compute_eigv=True, e=e, wu=wu))\n",
    "for epoch in range(2):\n",
    "    random.shuffle(train_set)\n",
    "    for i in tqdm(range(len(train_set) // bsz)):\n",
    "        optimizer.zero_grad()\n",
    "        loss = w_forward(train_set[i * bsz: (i + 1) * bsz], wv1, wo1)[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    with torch.no_grad(): print('Epoch', epoch, 'train', eval(train_set, wv1, wo1), \n",
    "                            'val', eval(val_set, wv1, wo1, bsz=eval_bsz, compute_eigv=True, e=e, wu=wu),)\n",
    "                            # test(model, data_tuples, replaced_head=(l1, h1), wv=wv1.to('cpu'), wo=wo1.to('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_attrs, all_yss = {}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qk_forward(model, outputs, layer, head, aw_label, attr_x, **mask_kwarges):\n",
    "    ln = blocks[layer].ln_1\n",
    "    kwargs = {x: ln(outputs.hidden_states[layer]) for x in ['hq', 'hk', 'hv']}\n",
    "    kwargs[attr_x] = scaled_ln(ln, sum_forward(model, outputs, **mask_kwarges).hidden_states[0], scale=0.01) # attr_x in ['hq', 'hk']\n",
    "    aw = attn_forward(blocks[layer], **kwargs)[1][:, head]\n",
    "    aw_label_sum = torch.einsum('ij->', aw_label)\n",
    "    # print('aw_label_sum =', aw_label_sum)\n",
    "    mean_prob = torch.einsum('bij,ij->b', aw, aw_label) / aw_label_sum\n",
    "    mean_logprob = torch.einsum('bij,ij->b', (aw + 1e-8).log(), aw_label) / aw_label_sum\n",
    "    print('mean_prob =', mean_prob)\n",
    "    print('mean_logprob =', mean_logprob)\n",
    "    return mean_prob, mean_logprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ig attribution\n",
    "pred_attn = False\n",
    "keys = ['aw'] #  'attn_out', 'head_out', 'attn_output', 'ffn_output'\n",
    "keys2 = [] #['head_output', 'attn_output']\n",
    "layer_range = (0, layer1) if pred_attn else (0, layer_out)\n",
    "attrs, grads = defaultdict(list), defaultdict(list)\n",
    "num_points, batch_size = 5, 5\n",
    "    \n",
    "for i in tqdm(range(*layer_range)):\n",
    "    am = get_attn_module(blocks[i])\n",
    "    scaled_emb, step, grad = {}, {}, {}\n",
    "    embs = [getattr(o, keys[0])[i]]\n",
    "    if len(embs) == 1 and keys[0] != 'aw': all_embs[task_name][keys[0]] = embs[0][0]\n",
    "        \n",
    "    for key, emb in zip(keys, embs):\n",
    "        scaled_emb[key], step[key] = scaled_input(emb, num_points)\n",
    "        _ = scaled_emb[key].requires_grad_(True)\n",
    "        grad[key] = None\n",
    "    if i == layer0: ys = []\n",
    "    for j in range(0, num_points, batch_size):\n",
    "        sliced_scaled_emb = [scaled_emb[key][j: j + batch_size] for key in keys]\n",
    "#         for key in keys2: setattr(am if key in ['head_output'] else blocks[i], key, None)\n",
    "        outputs = forward(am, keys, values=sliced_scaled_emb, exit_module=blocks[layer1+1] if pred_attn else None)\n",
    "        y = globalize(outputs.attentions[layer2])[:, head2, src, tgt] if pred_attn else outputs.logits.softmax(-1)[:, src, pred_label]\n",
    "#         h1 = ln1(outputs.hidden_states[12])\n",
    "#         y = tgt_attn_loss(h1, _attn1, key0, residual=None, temperature=20)\n",
    "        if i == layer0: ys.append(y)\n",
    "#         if keys2:\n",
    "#             sliced_scaled_emb2 = [getdelattr(am if key in ['head_output'] else blocks[i], key) for key in keys2]\n",
    "#             sliced_scaled_emb += sliced_scaled_emb2\n",
    "#             if j == num_points - batch_size: step.update({key: emb[-1:]/num_points for key, emb in zip(keys2, sliced_scaled_emb2)})\n",
    "        sliced_grads = torch.autograd.grad(y.flatten().unbind(), sliced_scaled_emb)\n",
    "        for gi, key in enumerate(keys + keys2):\n",
    "            sliced_grad = sliced_grads[gi].sum(dim=0, keepdim=True)\n",
    "            grad[key] = sliced_grad if key not in grad or grad[key] is None else grad[key] + sliced_grad\n",
    "    for key in keys + keys2:\n",
    "        attr = grad[key] * step[key]\n",
    "        attrs[key].append(attr.data)\n",
    "        grads[key].append(grad[key].data)\n",
    "\n",
    "if len(keys) == 1:\n",
    "    key = keys[0]\n",
    "    all_attrs[task_name][key + str(int(pred_attn))] = torch.cat([globalize(a) for a in attrs[key]]) \\\n",
    "        if key == 'aw' else attrs[key][0][0]\n",
    "#     for key in keys2: attrs[key] = torch.cat(attrs[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs, yss = all_attrs[key], all_yss[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlosses = [(ys[0] - ys[-1]).item() for ys in yss]\n",
    "np.array(dlosses)\n",
    "_ = plt.bar(range(len(dlosses)), dlosses, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nattrs = [attr / abs(dloss) for attr, dloss in zip(attrs, dlosses)]\n",
    "nattrs = [attr / attr.abs().mean() for attr in attrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_nattrs = torch.cat([nattr.mean(dim=-1) for nattr in nattrs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.heatmap(mean_nattrs, cbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l, h = 6, 6\n",
    "# attn = o.attentions[l][0, h]\n",
    "attn = attrs[l][0, h]\n",
    "plot_attn(attn, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QK circuit: $W_E^T W_Q^T W_K W_E$  \n",
    "OV circuit: $W_U W_O W_V W_E$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_eigenvalues(evs, ncols=4):\n",
    "    fig, axs = plt.subplots(H // ncols, ncols, sharex=True, sharey=True, figsize=(20, 5))\n",
    "    for i, (e, v) in enumerate(evs):\n",
    "        e = e.detach().numpy()\n",
    "        _ = axs[i // ncols][i % ncols].plot(e[:,0], e[:,1], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WQK, WOV = [], []\n",
    "for l in tqdm(range(L)):\n",
    "    WQK.append([combine_weights(get_head_weights(l, h), qk=True) for h in range(H)])\n",
    "    WOV.append([combine_weights(get_head_weights(l, h), qk=False) for h in range(H)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WQK = [[combine_weights(get_head_weights(l, h), qk=True) for h in range(H)] for l in tqdm(range(L))]\n",
    "WOV = [[combine_weights(get_head_weights(l, h), qk=False) for h in range(H)] for l in tqdm(range(L))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rwqk2, rwov1 = torch.rand(hidden_size, hidden_size) * 10, torch.rand(hidden_size, hidden_size) * 100\n",
    "\n",
    "# rwq, rwk = torch.rand(hidden_size // H, hidden_size)*10, torch.rand(hidden_size // H, hidden_size)\n",
    "# rwo, rwv = torch.rand(hidden_size, hidden_size // H), torch.rand(hidden_size // H, hidden_size)*100\n",
    "# rwqk2, rwov1 = rwq.t().mm(rwk), rwo.mm(rwv)\n",
    "\n",
    "# rwqk2.mm(rwov1).norm() / (rwqk2.norm() * rwov1.norm())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-composition: $\\text{Id} \\otimes A^{h_{-1}} \\otimes (W_E^T W_{QK}^h W_{OV}^{h_{-1}} W_E)$, measured by Frobenius norm ratio: $||W_{QK}^{h_2}W_{OV}^{h_1}||_F \\mathbin{/} (||W_{QK}^{h_2}||_F ||W_{OV}^{h_1}||_F)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = 3\n",
    "kcomp3 = np.array([[[(WQK[l][h2].mm(WOV[l-dl][h1]).norm() / (WQK[l][h2].norm() * WOV[l-dl][h1].norm())).item() \n",
    "          for h1 in range(H)] for h2 in range(H)] for l in tqdm(range(dl, L))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(a): a = a.detach().numpy(); plt.plot(a[:,0], a[:,1], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains = [\n",
    "    [(4, 14), (3, 3)],  # 0.24024388\n",
    "    [(5, 4), (2, 2)],  # 0.21996385\n",
    "    [(5, 4), (3, 7)],  # 0.31488344\n",
    "    [(6, 6), (3, 3)],  # 0.27304175\n",
    "    [(6, 6), (5, 3)],  # 0.12567882\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(l2, h2), (l1, h1) = chains[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = WQK[l2][h2].mm(WOV[l1][h1]).eig()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e[:10] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = WOV[l2][h2].eig()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = kcomp3[2]; ind = np.unravel_index(a.argmax(), a.shape); ind, a[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kcomp = np.array(kcomp)\n",
    "sns.heatmap(kcomp, cbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wov_evs = [torch.eig(combine_weights(get_head_weights(3, h), qk=False, with_embedding=True, BA=True)) for h in tqdm(range(H))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eigenvalues(wov_evs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_eu = w_e.matmul(w_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(layer): return lambda x: blocks[layer].mlp(blocks[layer].ln_2(x))\n",
    "def mlp0(layer): return lambda x: blocks[layer].mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attn(layer): return lambda x: blocks[layer].attn(blocks[layer].ln_1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_e2 = w_e * 50\n",
    "w_eu2 = (w_e2 + mlp0(L-1)(w_e2)).matmul(w_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grad attribution\n",
    "pred_attn = False\n",
    "keys = ['aw'] #  'attn_out', 'head_out', 'attn_output', 'ffn_output'\n",
    "keys2 = [] #['head_output', 'attn_output']\n",
    "layer_range = (0, layer1) if pred_attn else (0, layer_out)\n",
    "attrs, grads = defaultdict(list), defaultdict(list)\n",
    "num_points, batch_size = 5, 5\n",
    "    \n",
    "for i in tqdm(range(*layer_range)):\n",
    "    am = get_attn_module(blocks[i])\n",
    "    scaled_emb, step, grad = {}, {}, {}\n",
    "    embs = [getattr(o, keys[0])[i]]\n",
    "    if len(embs) == 1 and keys[0] != 'aw': all_embs[task_name][keys[0]] = embs[0][0]\n",
    "        \n",
    "    for key, emb in zip(keys, embs):\n",
    "        scaled_emb[key], step[key] = scaled_input(emb, num_points)\n",
    "        _ = scaled_emb[key].requires_grad_(True)\n",
    "        grad[key] = None\n",
    "    if i == layer0: ys = []\n",
    "    for j in range(0, num_points, batch_size):\n",
    "        sliced_scaled_emb = [scaled_emb[key][j: j + batch_size] for key in keys]\n",
    "#         for key in keys2: setattr(am if key in ['head_output'] else blocks[i], key, None)\n",
    "        outputs = forward(am, keys, values=sliced_scaled_emb, exit_module=blocks[layer1+1] if pred_attn else None)\n",
    "        y = globalize(outputs.attentions[layer2])[:, head2, src, tgt] if pred_attn else outputs.logits.softmax(-1)[:, src, pred_label]\n",
    "#         h1 = ln1(outputs.hidden_states[12])\n",
    "#         y = tgt_attn_loss(h1, _attn1, key0, residual=None, temperature=20)\n",
    "        if i == layer0: ys.append(y);\n",
    "#         if keys2:\n",
    "#             sliced_scaled_emb2 = [getdelattr(am if key in ['head_output'] else blocks[i], key) for key in keys2]\n",
    "#             sliced_scaled_emb += sliced_scaled_emb2\n",
    "#             if j == num_points - batch_size: step.update({key: emb[-1:]/num_points for key, emb in zip(keys2, sliced_scaled_emb2)})\n",
    "        sliced_grads = torch.autograd.grad(y.flatten().unbind(), sliced_scaled_emb)\n",
    "        for gi, key in enumerate(keys + keys2):\n",
    "            sliced_grad = sliced_grads[gi].sum(dim=0, keepdim=True)\n",
    "            grad[key] = sliced_grad if key not in grad or grad[key] is None else grad[key] + sliced_grad\n",
    "    for key in keys + keys2:\n",
    "        attr = grad[key] * step[key]\n",
    "        attrs[key].append(attr.data)\n",
    "        grads[key].append(grad[key].data)\n",
    "\n",
    "if len(keys) == 1:\n",
    "    key = keys[0]\n",
    "    all_attrs[task_name][key + str(int(pred_attn))] = torch.cat([globalize(a) for a in attrs[key]]) \\\n",
    "        if key == 'aw' else attrs[key][0][0]\n",
    "#     for key in keys2: attrs[key] = torch.cat(attrs[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn(globalize(attentions[8])[0, 2], figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, token in enumerate(tokens):\n",
    "    if token in ['', '^']: print()\n",
    "    else: print('%2d %s' %(i, token), end='  ')\n",
    "tgt_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = all_attrs[task_name]['aw' + str(int(pred_attn))]\n",
    "a = a / a.view(a.size(0), -1).norm(dim=1)[:, None, None, None] #.view(a.size(0), 1, 1, 1)\n",
    "if not pred_attn:\n",
    "    src_indices, tgt_indices = [src], [tgt]\n",
    "    _a = a[:, :, src_indices, tgt_indices]\n",
    "    values, indices = _a.view(_a.size(0), H, -1).topk(1, dim=-1)\n",
    "    show_top_heads(values, indices, src_indices=src_indices, tgt_indices=tgt_indices)\n",
    "    print()\n",
    "# src_indices = numpy(ans_positions[:])\n",
    "# src_indices = numpy(tgt_positions + 1)\n",
    "# tgt_indices = tgt_positions\n",
    "_a = a[:, :, src_indices, :]\n",
    "values, indices = _a.view(_a.size(0), H, -1).topk(nrows // 2, dim=-1)\n",
    "show_top_heads(values, indices, src_indices=src_indices)#, tgt_indices=tgt_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_heads(values, indices, src_indices=None, tgt_indices=None, topk=15):\n",
    "    val, ind = values.sum(dim=-1).view(-1).topk(topk)\n",
    "    val, ind = numpy(val), unravel_index(ind, values.size()[:-1])\n",
    "    for (l, h), v in zip(ind, val):\n",
    "        _l = l + layer_range[0]\n",
    "        if _l <= 3: continue\n",
    "        top_links = list(zip(unravel_index(indices[l, h], (seq_len, seq_len)), numpy(values[l, h], decimals=3)))\n",
    "        if src_indices is not None: top_links = [([src_indices[_s], _t], _v) for [_s, _t], _v in top_links]\n",
    "        if tgt_indices is not None: top_links = [([_s, tgt_indices[_t]], _v) for [_s, _t], _v in top_links]\n",
    "        top_links = [([_s, _t], _v, numpy(globalize(attentions[_l]) * 100, decimals=1)[0, h, _s, _t]) for [_s, _t], _v in top_links]\n",
    "        _top_links = [([_s, _t], _v, _a) if len(src_indices) > 1 else (_t, _v, _a) for [_s, _t], _v, _a in top_links]\n",
    "        print('%d-%d\\t%.3f' % (_l, h, v), _top_links, end='\\t') \n",
    "        if len(top_links) == 1:\n",
    "            probs = numpy(globalize(attentions[_l])[0, h, src])\n",
    "            for i in cand_range:\n",
    "                if i == tgt: print('*', end='')\n",
    "                print(probs[i], end=' ')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = globalize(attentions[layer2])[:, head2]\n",
    "# a = a.softmax(-1)\n",
    "a = torch.cat([a[:, i - 1: i, i - ncols - 2: i + 1] for i in ans_positions], dim=1)\n",
    "# a = a.softmax(-1)\n",
    "loss = a.view(a.size(0), -1)[:, tgt_positions[1:]].mean(dim=1)\n",
    "print(loss)\n",
    "plot_tgt_attn(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvos = [torch.matmul(*get_head_weights(l, h)[2:]) for l, h in [(11, 8), (12, 18)]]\n",
    "wqk = torch.matmul(*get_head_weights(13, 2)[:2])\n",
    "ww = wvos[0].matmul(wvos[1]).matmul(wqk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww.norm(dim=0).topk(40).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_topk(*aw.view(-1).topk(20, largest=False), indices_fn=indices_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvos2 = [torch.matmul(*get_head_weights(l, h)[2:]) for l, h in [(9, 9), (10, 1), (12, 18)]]\n",
    "ww2 = reduce(torch.matmul, wvos2 + [wqk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output1, out = None, None\n",
    "out_proj_w = self1.out_proj.weight.view(hidden_size, H, -1).permute(1, 2, 0).unsqueeze(0)\n",
    "head_mask = torch.zeros(H, seq_len, seq_len)\n",
    "head_mask[[18,]] = 1\n",
    "# head_mask[:] = 1\n",
    "attn1 = attentions[layer1]\n",
    "_attn1, __attn1 = torch.zeros_like(attn1), torch.zeros_like(attn1)\n",
    "for i in range(0, nrows):\n",
    "    _attn1[:, :, arrow_positions[i], ans_positions[i]] = 1\n",
    "    __attn1[:, :, arrow_positions[i], ans_positions[:i]] = 1 / i if i > 0 else 0\n",
    "    \n",
    "def ffn(layer, x): return blocks[layer].mlp(blocks[layer].ln_2(x))\n",
    "\n",
    "def tgt_attn_loss(h1, attn1, key0, residual=None, attn_output_w=1, apply_softmax=True, temperature=10, \n",
    "                  positions=tgt_positions, plot=False, ax=None):\n",
    "    def get_attn(attn_output):\n",
    "        out = (residual if residual is not None else 0) + attn_output * attn_output_w\n",
    "        if residual is not None: out = out + ffn(layer1, out)\n",
    "        if residual is not None: out = ln2(out)\n",
    "        query = out.matmul(wq2.t()).unsqueeze(2) # (bsz, nrows, d_head) -> (bsz, nrows, 1, d_head), ln2 is omissible\n",
    "        key = key0.matmul(wk2.t()).view(bsz, nrows, ncols + 3, hidden_size // H)\n",
    "        a = (query * key).sum(-1) # (bsz, nrows, ncols + 3)\n",
    "        a[:, :, [-1]] = -1e9\n",
    "        if apply_softmax: a = (a / temperature).softmax(-1)\n",
    "        return a\n",
    "\n",
    "    self1.w = attn1 * head_mask; attn_output1 = self1(h1)[0] - self1.out_proj.bias\n",
    "    a = get_attn(attn_output1[:, arrow_positions])\n",
    "    loss = a.view(a.size(0), -1)[:, positions]\n",
    "    if plot:\n",
    "#         a = a - a.min(dim=2, keepdim=True).values\n",
    "        plot_tgt_attn(a[0], ax=ax)#; print(loss)\n",
    "    return loss.mean()\n",
    "\n",
    "residual = None or hidden_states[layer1][:, arrow_positions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ln(layer): return blocks[layer].ln_1\n",
    "# 10-ffn, 9-11 for find special, 9-11 for AbCD->B/b, 9-11 for ABCD->C\n",
    "# 10-19+ffn+8!, 9-11 for after bracket 5-5/7, 9-11, 10-1+13+ffn+8+19 for in brackets\n",
    "mask = torch.zeros(H, seq_len, 1); mask[11] = 1#; mask[:] = 0 # 11-8, 10-1, 9-11,   9-11/6?->8-17 for 2nd\n",
    "# for i in range(0, nrows): mask[1, ans_positions[i], tgt_positions[i]+1] = 1\n",
    "layer0 = 9\n",
    "self0, ln0 = get_attn_module(blocks[layer0]), blocks[layer0].ln_1\n",
    "\n",
    "h0 = hidden_states[9]*0 + head_outputs[8][:, [17]].sum(1)*1\n",
    "self0.w = attentions[layer0] * mask; attn_output0 = self0((h0), attention_masks[layer0])[0] - self0.out_proj.bias\n",
    "# h1 = hidden_states[9]*0 + head_outputs[11][:, [8]].sum(1)*1 #+ ffn_outputs[10]#+ head_outputs[11][:, [8,]].sum(1)*1\n",
    "# h1 = ln1(h1)\n",
    "h1 = attn_output0\n",
    "key0 = get_ln(10)(hidden_states[10])#; key0.reqires_grad = True; key0.retain_grad()\n",
    "fig, axes = plt.subplots(1, 3, sharey=False, figsize=(2.5 * (ncols + 3) / 9 * 3, 5 * nrows / 24))\n",
    "# loss = tgt_attn_loss(h1, __attn1, key0, residual=None, plot=True, apply_softmax=True, temperature=1, ax=axes[0]); loss\n",
    "# print('after', key0[:, :, 0])\n",
    "[tgt_attn_loss(h1, attn, key0, residual=None,plot=True,temperature=1, positions=tgt_positions[(i>0)*2:],ax=ax).item() \n",
    "    for i, (attn, ax) in enumerate(zip([_attn1, attn1, __attn1], axes))]\n",
    "# if losses[0] > 0.8 and losses[-1] > 0.8: print(layer, head, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_norm(w):\n",
    "    return w.abs().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvo1 = get_combined_w(9, 11) * get_combined_w(12, 18)\n",
    "for layer in [8, ]:\n",
    "    for head in range(H):\n",
    "        wvo = get_combined_w(layer, head)\n",
    "        print('%d-%d %.4f %.4f' % (layer, head, get_weight_norm(wvo.matmul(wvo1)) / get_weight_norm(wvo), get_weight_norm(wvo.matmul(wvo1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "front_chains = [\n",
    "    [[(11, 8), create_mask(ans_positions, tgt_positions)]],\n",
    "    [[(9, 9), create_mask(tgt_positions + 1, tgt_positions)], [(10, 1), create_mask(ans_positions, tgt_positions + 1)]],\n",
    "]\n",
    "rear_chains = [\n",
    "    [[(12, 18), create_mask(arrow_positions, ans_positions)], [(13, 2), None]],\n",
    "    [[(12, 18), create_mask(arrow_positions, ans_positions, accum=True)], [(13, 2), None]],\n",
    "]\n",
    "\n",
    "sum_a = {i: 0 for i in range(len(rear_chains))}\n",
    "fig, axes = plt.subplots(2, 3, sharey=False, figsize=(2.5 * (ncols + 3) / 9 * 3, 5 * nrows / 24 * 2))\n",
    "for j, front_chain in enumerate(front_chains):\n",
    "    l0 = front_chain[0][0][0]\n",
    "    h = h0 = get_ln(l0)(hidden_states[l0])\n",
    "    for (layer, head), mask in front_chain:\n",
    "#         attn = globalize(attentions[layer])[:, head] #if layer in [9] else mask\n",
    "        attn = mask\n",
    "        wvo = get_combined_w(layer, head)\n",
    "        h = attn.matmul(h.matmul(wvo))\n",
    "    for i, rear_chain in enumerate(rear_chains):\n",
    "        (layer, head), mask = rear_chain[0]\n",
    "        attn = mask\n",
    "        wvo = get_combined_w(layer, head)\n",
    "        q = attn.matmul(h.matmul(wvo))\n",
    "        wqk = get_combined_w(*rear_chain[-1][0], qk=True)\n",
    "        q = q.matmul(wqk)[:, arrow_positions].unsqueeze(2)\n",
    "        k = h0.view(h0.size(0), nrows, ncols + 3, hidden_size)\n",
    "        a = q.matmul(k.transpose(-1, -2)).squeeze(2) / 1\n",
    "        a[:, :, [-1]] = -1e9\n",
    "        sum_a[i] = sum_a[i] + a\n",
    "        a = a.softmax(-1)\n",
    "        loss = a.view(a.size(0), -1)[:, tgt_positions[i*2:]].mean()#; print('%.3f' % loss.item(), end=' ')\n",
    "        plot_tgt_attn(a[0], ax=axes[i, j], title='%f' % loss.item())\n",
    "\n",
    "for i in range(len(rear_chains)):\n",
    "    a = sum_a[i]\n",
    "    a = a.softmax(-1)\n",
    "    loss = a.view(a.size(0), -1)[:, tgt_positions[i*2:]].mean()#; print('%.3f' % loss.item(), end=' ')\n",
    "    plot_tgt_attn(a[0], ax=axes[i, 2], title='%f' % loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_sattn, __sattn = torch.zeros(1, seq_len, seq_len), torch.zeros(1, seq_len, seq_len)\n",
    "for i in range(0, nrows):\n",
    "    _sattn[:, arrow_positions[i], tgt_positions[i]] = 1\n",
    "    __sattn[:, arrow_positions[i], tgt_positions[:i]] = 1 / i if i > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww0 = torch.eye(hidden_size)\n",
    "# layer = 9; ln = blocks[layer].ln_1\n",
    "# h0 = key0 = ln(hidden_states[layer])\n",
    "fig, axes = plt.subplots(2, 3, sharey=False, figsize=(2.5 * (ncols + 3) / 9 * 3, 5 * nrows / 24 * 2))\n",
    "for i, attn in enumerate([_sattn, __sattn]):\n",
    "    sum_a = 0\n",
    "    for j, (w, layer) in enumerate([(ww, 11), (ww2, 9)]):\n",
    "        ln = blocks[layer].ln_1\n",
    "        h0 = key0 = ln(hidden_states[layer])\n",
    "        query = attn.matmul(h0)[:, arrow_positions].matmul(w).unsqueeze(2)\n",
    "        key = key0.view(key0.size(0), nrows, ncols + 3, hidden_size)\n",
    "        a = (query * key).sum(-1) / 1\n",
    "        a[:, :, [-1]] = -1e9\n",
    "        sum_a = sum_a + a\n",
    "        a = a.softmax(-1)\n",
    "        loss = a.view(a.size(0), -1)[:, tgt_positions[i*2:]].mean(); print('%.3f' % loss.item(), end=' ')\n",
    "        plot_tgt_attn(a[0], ax=axes[i, j])\n",
    "    a = sum_a.softmax(-1)\n",
    "    loss = a.view(a.size(0), -1)[:, tgt_positions[i*2:]].mean(); print('%.3f' % loss.item(), end=' ')\n",
    "    plot_tgt_attn(a[0], ax=axes[i, 2])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aw = ww * ww.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aw.norm(dim=0).topk(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_outputs[9][0, :, ans_positions].norm(dim=-1).mean(-1).topk(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn(globalize(attentions[9])[0, 6], figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a0 = head_outputs[9][0, 11, ans_positions]\n",
    "a1 = head_outputs[11][0, 8, ans_positions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a0 = attrs['head_output'][9, 11, ans_positions]\n",
    "a1 = attrs['head_output'][11, 8, ans_positions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = nn.CosineSimilarity(dim=1)\n",
    "cos(a0, a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = attrs['attn_output'].sum(-1)\n",
    "attr = attr / attr.view(attr.size(0), -1).norm(dim=1)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(numpy(attr[:, ans_positions]), cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(20, 3))\n",
    "ax = sns.heatmap(numpy(attrs['head_output'].sum(-1)[10]), cbar=False, xticklabels=tokens)\n",
    "_ = ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize=9, rotation=0)\n",
    "ax.tick_params(top=True, right=True, labeltop=True, labelright=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(20, 3))\n",
    "ax = sns.heatmap(numpy(attr), cbar=False, xticklabels=tokens)\n",
    "_ = ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize=9, rotation=0)\n",
    "ax.tick_params(top=True, right=True, labeltop=True, labelright=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn_w = 0\n",
    "results = []\n",
    "for i in range(0, layer1 + 1):\n",
    "    h1 = hidden_states[i] - hidden_states[0]*1\n",
    "    residual = None #or hidden_states[layer1][:, arrow_positions]\n",
    "    losses = [tgt_attn_loss(h1, attn, residual=residual, ffn_w=ffn_w) for attn in [_attn1, attn1]]\n",
    "    results.append(('%d-inp' % i, losses[0], losses[1]))\n",
    "    if i < layer1:\n",
    "        losses = [tgt_attn_loss(h1 + attn_outputs[i], attn, residual=residual, ffn_w=ffn_w) \n",
    "                  for attn in [_attn1, attn1]]\n",
    "        results.append(('%d-attn' % i, losses[0], losses[1]))\n",
    "plot_tgt_attn_losses(*zip(*results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "tgt_h = hidden_states[layer0][0, tgt_positions]\n",
    "h0 = hidden_states[layer0].view(nrows, ncols + 3, hidden_size)\n",
    "for i in range(nrows):\n",
    "    q = tgt_h[0:i].mean(dim=0)\n",
    "    q = ln2(q).matmul(wq2.t())\n",
    "    k = ln2(h0[i]).matmul(wq2.t())\n",
    "#     attn1 = globalize(attentions[layer1]) * head_mask\n",
    "#     attn_output1 = torch.matmul(attn1, _head_output1).sum(1)\n",
    "#     q = ln2(attn_output1[:, arrow_positions[i]]).matmul(wq2.t())\n",
    "#     q = ln2(_attn_output1[:, ans_positions][:, i:i+1].mean(1)).matmul(wq2.t())\n",
    "#     k = key[i]\n",
    "    a.append((q * k).sum(-1).unsqueeze(0))  # == torch.matmul(q, k.t())\n",
    "\n",
    "a = torch.cat(a)\n",
    "a[:, -2:] = -1000000\n",
    "a = a.softmax(-1)\n",
    "plot_tgt_attn(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1, head1 = 12, 18\n",
    "layer0, head0 = 11, 8\n",
    "layer2, head2 = 13, 2  #17-4 for A[B]C->B,A*BC->B, 13-5 for reverse set diff\n",
    "self0, self1, self2 = get_attn_module(blocks[layer0]), get_attn_module(blocks[layer1]), get_attn_module(blocks[layer2])\n",
    "\n",
    "h_mask = torch.ones(hidden_size)\n",
    "h_mask[top_i[0]] = 0\n",
    "\n",
    "ln0, ln1, ln2 = blocks[layer0].ln_1, blocks[layer1].ln_1, blocks[layer2].ln_1\n",
    "# mean, var = forward(blocks[layer2], 'ln1_mean_var')\n",
    "\n",
    "wq0, wk0, wv0, wo0 = get_head_weights(layer0, head0)\n",
    "wq1, wk1, wv1, wo1 = get_head_weights(layer1, head1)\n",
    "wq2, wk2, wv2, wo2 = get_head_weights(layer2, head2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output0, ffn_output0 = forward(blocks[layer0], ['attn_output', 'ffn_output'], exit_module=blocks[layer0],\n",
    "                                    extra_tuples=[(get_attn_module(blocks[layer0]), 'hidden_states_mask', h_mask)])\n",
    "head_output0 = forward(get_attn_module(blocks[layer0]), 'head_output', exit_module=blocks[layer0],\n",
    "                        extra_tuples=[(get_attn_module(blocks[layer0]), 'hidden_states_mask', h_mask)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## h1 = ln1(hidden_states[10]*0 + attn_output0 * 1 + ffn_output0 * 1)\n",
    "h1 = ln1(hidden_states[layer0]*1 + attn_outputs[10]*1 + ffn_outputs[10] * 1 + attn_outputs[11] * 1 + ffn_outputs[11] * 1)\n",
    "\n",
    "self1.head_output, self1.attn_output = None, None\n",
    "self1.w = attentions[layer1]\n",
    "try: _ = self1(h1, attention_mask=attention_masks[layer1])\n",
    "finally:\n",
    "    head_output1, attn_output1 = getdelattr(self1, 'head_output'), getdelattr(self1, 'attn_output')\n",
    "    try_delattr(self1, 'w')\n",
    "\n",
    "query = get_query(self2, ln2(hidden_states[layer1]*0 + attn_output1*1 + attn_outputs[13]*0))\n",
    "# query = get_query(self2, ln2(head_output1[:, [16, 18]].sum(1)))\n",
    "# query = get_query((self2, head_outputs[layer1][:, head1]))\n",
    "# query = get_query(self2, attn_hidden_states[layer2])\n",
    "for layer in [layer0]:#range(layer2 + 1):\n",
    "    key2 = get_key(self2, ln2(hidden_states[layer]))\n",
    "#     key2 = get_key(self2, ln2(attn_outputs[9]))\n",
    "    logits = (query * key2).sum(dim=-1)\n",
    "    print(layer)\n",
    "    _ = test(None, None, logits=logits, always_show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = all_embs[task_name][key]\n",
    "emb_attr = all_attrs[task_name][key + str(int(pred_attn))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer0 = 10\n",
    "# layer, head = 10, 8  # ABC->B, ABC->A(pred_attn<12-18), ABC->C(only pred_attn), find lowercase, set diff2(only pred_attn)\n",
    "layer, head = 12, 18 # 12-16, 12-18, 12-1 ABC->A, ABC,AXC->X, set diff2, set diff\n",
    "layer2, head2 = 13, 2  # ABC->B, ABC->A, ABC->C, ABC,AXC->X, set diff, set diff2(<13-12), find lowercase(<15-8)\n",
    "# layer2, head2 = 15, 8  # 15-8, find lowercase\n",
    "# layer2, head2 = 13, 12  # set diff2, ABC,AXC->X(<13-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = tgt_positions[1:]\n",
    "offsets = [torch.zeros_like(positions) - 1, torch.zeros_like(positions), torch.zeros_like(positions) + 1]\n",
    "labels = numpy(torch.cat(offsets))\n",
    "for layer in range(layer2):\n",
    "    for head in range(H):\n",
    "        emb = numpy(torch.cat([attn_outs[layer][0, head, positions + offset] for offset in offsets]))\n",
    "#         emb = numpy(torch.cat([head_outputs[layer][0, head, positions + offset] for offset in offsets]))\n",
    "        head_output = head_outputs[layer][:, head]\n",
    "        if cluster(emb, labels)[0]:# and test(head_output, always_show=False) is not None:\n",
    "#         if test(head_output, always_show=False) is not None:\n",
    "            visualize_by_pca(emb, labels)\n",
    "#             attn = globalize(attentions[layer])[0, head]\n",
    "#             plot_attn(attn)\n",
    "            print(layer, head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer0, head0 = 10, 1 #11-14  10-1\n",
    "h_mask2 = torch.ones(hidden_size)\n",
    "h_mask2[top_i[:]] = 0\n",
    "\n",
    "attn_mask = torch.ones(H, seq_len, hidden_size // H)\n",
    "# attn_mask[:, :] = 0\n",
    "# attn_mask[8, :] = .1\n",
    "m = get_attn_module(blocks[layer2])\n",
    "outputs = forward(get_attn_module(blocks[layer0]), 'attn_mask', attn_mask, exit_module=blocks[layer2],\n",
    "                 extra_tuples=[(m, 'return_attn_logits', True), #(m, 'hidden_states_mask', h_mask2),\n",
    "#                                (get_attn_module(blocks[10]), 'hidden_states_mask', h_mask2),\n",
    "                               (get_attn_module(blocks[layer1]), 'w', attentions[layer1])\n",
    "                              ])\n",
    "\n",
    "probs0 = outputs.attentions[layer1][0, head1, src, ans_positions[:-1]]\n",
    "probs0, probs0.sum()\n",
    "logits = globalize(outputs.attentions[layer2])[0, head2, src, : src + 1]\n",
    "probs = logits[cand_positions].view(-1, n_candidates).softmax(-1)[:, task_name2idx[task_name]]\n",
    "probs, probs.mean()\n",
    "probs = logits.softmax(-1)[tgt_positions]\n",
    "probs, probs.mean()\n",
    "test(None, None, logits=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = blocks[layer].attn.attention\n",
    "mask = torch.ones(H, seq_len, seq_len)\n",
    "# mask[:, src] = 0\n",
    "mask[:] = 0\n",
    "mask[head, src] = 0.1\n",
    "_ = mask.requires_grad_(True)\n",
    "# m.attn_mask = mask\n",
    "\n",
    "# scaled_attn = attentions[layer] * mask.to(model.device)\n",
    "# _ = scaled_attn.requires_grad_(True)\n",
    "# m.w = scaled_attn\n",
    "try:\n",
    "    with torch.no_grad(): outputs = model(**inputs, output_attentions=True)\n",
    "    attn = outputs.attentions[layer]\n",
    "    _ = plt.figure(figsize=(15, 1))\n",
    "    _ = sns.heatmap(numpy(attn[:, head, src, :]), cbar=False)\n",
    "    print(attn[:, head, src, ans_positions[:-1]])\n",
    "    \n",
    "    attn[:] = 0\n",
    "#     attn[0, head, src] = 0\n",
    "    attn[0, head, src, ans_positions[:-1]] = 0.1 / len(ans_positions[:-1])\n",
    "#     i = random.randint(0, attn.size(3) - 1); i\n",
    "#     attn[0, head, src] = 0.1 / attn.size(3)\n",
    "    print(attn[0, head, src, ans_positions[:-1]])\n",
    "    m.w = attn\n",
    "    with torch.no_grad(): outputs = model(**inputs, output_attentions=True)\n",
    "#     outputs = model(**inputs, output_attentions=True)\n",
    "finally:\n",
    "#     m.attn_mask = None\n",
    "    m.w = None\n",
    "# y = outputs.logits.softmax(-1)[:, src, pred_label]\n",
    "# mask_grad = torch.autograd.grad(torch.unbind(y), mask)[0]\n",
    "# attn_grad = torch.autograd.grad(torch.unbind(y), scaled_attn)[0]\n",
    "    \n",
    "attn = globalize(outputs.attentions[layer2])[0, head2, src]\n",
    "print(show_topk(*attn.topk(5), indices_fn=append_tokens_to_positions))\n",
    "probs = outputs.logits[0, src].softmax(-1)\n",
    "show_topk(*probs.topk(5), indices_fn=tokenizer.convert_ids_to_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_grad[0, head - 2].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_grad.size()\n",
    "attn_grad2.size()\n",
    "(attn_grad2[4:5] - attn_grad).abs().max()\n",
    "attn_grad[0, head, src, ki]\n",
    "attn_grad2[4, head, src, ki]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qh = ln2(hidden_states[layer1]*0 + attn_output1*1 + attn_outputs[13]*1)[:, src:src+1]\n",
    "kh = attn_hidden_states[layer2]\n",
    "# kh = ln2(attn_outputs[9])\n",
    "logits = (qh * kh).sum(dim=-1).squeeze(0)\n",
    "_ = test(None, None, logits=logits, always_show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = {\n",
    "    'find lowercase': '''\n",
    "X C e -> e\n",
    "S f Z -> f\n",
    "K y N -> y\n",
    "q M N -> q\n",
    "u S N -> u\n",
    "S v Y -> v\n",
    "v I J -> v\n",
    "Y a N -> a''',\n",
    "    'AbC->B': '''\n",
    "X C e -> E\n",
    "S f Z -> F\n",
    "K y N -> Y\n",
    "q M N -> Q\n",
    "u S N -> U\n",
    "S v Y -> V\n",
    "g I J -> G\n",
    "Y a N -> A\n",
    "L n J -> N\n",
    "d H I -> D\n",
    "Z r C -> R\n",
    "U S t -> T\n",
    "K r A -> R\n",
    "I G m -> M\n",
    "t O X -> T''',  # failed, but GPT-3 can with low prob\n",
    "    'set diff': '''\n",
    "G L C, G L -> C\n",
    "Y P J, Y P -> J\n",
    "E S A, S A -> E\n",
    "U P W, U P -> W\n",
    "W Z A, W A -> Z\n",
    "Z Q J, Z J -> Q\n",
    "C Y L, Y L -> C\n",
    "C K Z, C Z -> K\n",
    "K O Q, O Q -> K\n",
    "K O N, K N -> O\n",
    "R U P, R P -> U\n",
    "X C J, X C -> J\n",
    "B G V, G V -> B\n",
    "H V L, H V -> L\n",
    "J K M, J M -> K\n",
    "N W K, W K -> N\n",
    "F B D, F B -> D''',\n",
    "    'find majority': '''\n",
    "n d d -> d\n",
    "f f d -> f\n",
    "e b e -> e\n",
    "s q s -> s\n",
    "d d o -> d\n",
    "c e e -> e\n",
    "g t g -> g\n",
    "i i w -> i''', # basically failed\n",
    "    'find special': '''\n",
    "n d d -> n\n",
    "f f d -> d\n",
    "e b e -> b\n",
    "s q s -> q\n",
    "d d o -> o\n",
    "c e e -> c\n",
    "g g t -> t\n",
    "w i i -> w''',  # failed, GPT-3 failed, too\n",
    "    'find special2': '''\n",
    "n d d d -> n\n",
    "f f f d -> d\n",
    "e b e e -> b\n",
    "s s q s -> q\n",
    "d d d o -> o\n",
    "e c e e -> c\n",
    "g g g t -> t\n",
    "w i i i -> w''',  # failed, but GPT-3 can\n",
    "    'ABC,AXC->X': '''\n",
    "D O Q, K O Q -> K\n",
    "K H N, K O N -> O\n",
    "R X P, R U P -> U\n",
    "X C G, X C J -> J\n",
    "Z G V, B G V -> B\n",
    "H V T, H V L -> L\n",
    "J E M, J K M -> K\n",
    "A W K, U W K -> U\n",
    "F B Y, F B D -> D''',\n",
    "    'reverse set diff': '''\n",
    "O Q, K O Q -> K\n",
    "K N, K O N -> O\n",
    "R P, R U P -> U\n",
    "X C, X C J -> J\n",
    "G V, B G V -> B\n",
    "H V, H V L -> L\n",
    "J M, J K M -> K\n",
    "W K, N W K -> N\n",
    "F B, F B D -> D''',\n",
    "    'set diff2': '''\n",
    "Z Y, y -> z\n",
    "K B, b -> k\n",
    "N E, e -> n\n",
    "J S, j -> s\n",
    "O W, o -> w\n",
    "F R, f -> r\n",
    "J S, s -> j\n",
    "N O, o -> n\n",
    "P R, p -> r''',\n",
    "    'find next': '''\n",
    "W S D L, S -> D\n",
    "F M W Q, F -> M\n",
    "T W A V, A -> V\n",
    "U V N M, N -> M\n",
    "S D N O, S -> D\n",
    "A S B T, S -> B\n",
    "H W L Z, H -> W\n",
    "C L J O, J -> O\n",
    "T B A E, B -> A\n",
    "L G C K, L -> G\n",
    "G B S O, G -> B\n",
    "K Y F O, F -> O\n",
    "V Q U S, V -> Q\n",
    "S E Y P, Y -> P\n",
    "X D A U, A -> U\n",
    "T L M N, L -> M\n",
    "U O Y I, O -> Y''',  # failed, GPT-3 failed too\n",
    "    'antonym': '''\n",
    "big -> small\n",
    "low -> high\n",
    "fast -> slow\n",
    "dark -> light\n",
    "long -> short''',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "#     with torch.no_grad(): outputs = model(**inputs, output_attentions=True)\n",
    "#     attn = outputs.attentions[layer]\n",
    "#     print(attn[0, head, src, ans_positions[:-1]])\n",
    "#     attn[0, head, src] = 0\n",
    "#     attn[0, head, src, ans_positions[-8]] = 1\n",
    "#     print(attn[0, head, src, ans_positions[:-1]])\n",
    "#     m.w = attn\n",
    "    with torch.no_grad(): outputs = model(**inputs, output_attentions=True)\n",
    "finally:\n",
    "    m.attn_mask = None\n",
    "#     m.w = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(tensor): return round(tensor.abs().mean().item(), 4)\n",
    "hidden_states.mean(), hidden_states.std()\n",
    "for l in range(layer, layer2):\n",
    "    print(norm(hidden_states), end=' ')\n",
    "    hidden_states = hidden_states + h[l].attn_output\n",
    "    print(norm(h[l].attn_output), norm(hidden_states), hidden_states.mean(), hidden_states.std())\n",
    "    print(norm(hidden_states), end=' ')\n",
    "    hidden_states = hidden_states + h[l].ffn_output\n",
    "    print(norm(h[l].ffn_output), norm(hidden_states), hidden_states.mean(), hidden_states.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_hidden_states = h[layer2].ln_1(hidden_states)\n",
    "try:\n",
    "    with torch.no_grad(): _, attn = am2(am2_hidden_states, am2_attention_mask, output_attentions=True, q_hidden_states=_hidden_states)\n",
    "finally: am2.q_hidden_states = None\n",
    "attn = globalize(attn)\n",
    "attn[0, head2, -1].topk(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(): outputs = model(**inputs, output_attentions=True)\n",
    "attn = globalize(outputs.attentions[layer2])[0, head2, -1]\n",
    "show_topk(*attn.topk(5), indices_fn=append_tokens_to_positions)\n",
    "probs = outputs.logits[0, -1].softmax(-1)\n",
    "show_topk(*probs.topk(5), indices_fn=tokenizer.convert_ids_to_tokens)\n",
    "\n",
    "for l in range(layer, layer + 1):\n",
    "    mask_tgt_indices = [41, 35, 29, 23, 17, 11, 5]\n",
    "    excluded_src_indices = [seq_len - 1] #if l == layer else []\n",
    "    attn = outputs.attentions[l]\n",
    "    if attn.dim() == 5:\n",
    "        attn = attn[:, 0, :, :, -seq_len:] # (bsz, num_blokcs, H, seq_len, window_size + seq_len) -> (bsz, H, seq_len, seq_len)\n",
    "#     for hd in range(H):\n",
    "#         for src_idx in range(seq_len):\n",
    "#             if hd != head and src_idx in excluded_src_indices:\n",
    "#                 attn[:, hd, src_idx] = 0\n",
    "    for hd in range(H):\n",
    "        for src_idx in range(seq_len):\n",
    "            for tgt_idx in range(seq_len):\n",
    "                if hd == head and src_idx not in excluded_src_indices and tgt_idx in mask_tgt_indices:\n",
    "                    attn[:, hd, src_idx, tgt_idx] = 0\n",
    "    h[l].attn.attention.w = outputs.attentions[l]\n",
    "try:\n",
    "    with torch.no_grad(): outputs = model(**inputs, output_attentions=True)\n",
    "finally:\n",
    "    for l in range(layer, layer2):\n",
    "        h[l].attn.attention.w = None\n",
    "attn = globalize(outputs.attentions[layer2])[0, head2, -1]\n",
    "show_topk(*attn.topk(5), indices_fn=append_tokens_to_positions)\n",
    "probs = outputs.logits[0, -1].softmax(-1)\n",
    "show_topk(*probs.topk(5), indices_fn=tokenizer.convert_ids_to_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_attrs = all_attrs['A B C D -> a'].sum(dim=(2, 3))\n",
    "# head_attrs = attrs.sum(dim=(2, 3))\n",
    "\n",
    "values, indices = head_attrs[:, :].view(-1).topk(10)\n",
    "indices = unravel_index(indices, head_attrs.size())\n",
    "top_heads = [(l, h, round(v, 8)) for l, h, v in zip(\n",
    "    indices[0].tolist(), indices[1].tolist(), values.tolist())]\n",
    "top_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode_plus(_text, return_tensors='pt')\n",
    "outputs = model(**inputs, output_attentions=True)\n",
    "\n",
    "logits = outputs.logits if hasattr(outputs, 'logits') else outputs[0]\n",
    "y = logits[0, -1].max()\n",
    "attentions = outputs.attentions if hasattr(outputs, 'attentions') else outputs[-1]\n",
    "for a in attentions: a.retain_grad()\n",
    "model.zero_grad()\n",
    "y.backward()\n",
    "\n",
    "# attns = torch.cat(attentions)\n",
    "grads = torch.cat([a.grad for a in attentions])\n",
    "attrs2 = attns * grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(top_heads)):\n",
    "    layer, head, v, _ = top_heads[i]\n",
    "    if layer in [0, 1, ]: continue\n",
    "#     layer, head, v = 30, 10, 1.\n",
    "    fig, axs = plt.subplots(1,2,sharey=False, figsize=(10 * 2, 10))\n",
    "    for i, (a, _ax) in enumerate(zip([attns, attrs], axs)):\n",
    "        a = a[layer][head].detach().cpu()\n",
    "        a, annot = ((a * 100).long(), True) if i == -1 else (a, False)\n",
    "        res = sns.heatmap(a, square=True, cbar=False, annot=annot, fmt='d', linewidths=0.1, linecolor='grey', \n",
    "                          xticklabels=tokens, yticklabels=tokens, ax=_ax)\n",
    "        _ = res.set_xticklabels(res.get_xmajorticklabels(), fontsize=9+3-2, rotation=0)\n",
    "        _ = res.set_yticklabels(res.get_ymajorticklabels(), fontsize=9+3-2, rotation=0)\n",
    "        _ = plt.xlabel('%d-%d    %.4f' % (layer, head, v), fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows, n_cols = 1, 3\n",
    "fig, axs = plt.subplots(n_rows, n_cols, sharey=False, figsize=(5 * n_cols, 2 * 4 * n_rows))\n",
    "A = [attns, grads, attrs]\n",
    "\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        ax = axs[row][col] if row > 1 else axs[col]\n",
    "        a = A[col][:, :, src,tgt].detach()\n",
    "        if col == 0: a[-1, 0] = 1.\n",
    "#         fig = plt.subplots(1,1,sharey=False, figsize=(5 , 8))\n",
    "        ax = sns.heatmap(a, ax=ax)\n",
    "        ax.tick_params(top=True, labeltop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = outputs.logits if hasattr(outputs, 'logits') else outputs[0]\n",
    "values, indices = logits[0, -1].softmax(dim=-1).topk(5)\n",
    "list(zip(tokenizer.convert_ids_to_tokens(indices), values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode_plus(_text)['input_ids']\n",
    "print(tokenizer.convert_ids_to_tokens(input_ids))\n",
    "outputs = model.generate(torch.LongTensor([input_ids]).to(model.device))\n",
    "print(_text, tokenizer.decode(outputs[0]))\n",
    "\n",
    "input_ids = input_ids[: -3] + input_ids[-2:]\n",
    "print(tokenizer.convert_ids_to_tokens(input_ids))\n",
    "outputs = model.generate(torch.LongTensor([input_ids]).to(model.device))\n",
    "print(_text, tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    'Big is to small as fast is to _',\n",
    "    'Bread is to eat as gun is to _',\n",
    "    'big: small, fast: _',\n",
    "    'bread: eat, gun: _ .',\n",
    "    'flower: fragrant, fire: hot, bread: delicious, gun: _ ',\n",
    "    'Big and small are _ .',\n",
    "    'What is twice 3? _.',\n",
    "    'What is the half 6? _.',\n",
    "    'There is a sequence: 3, 5, 2, 7. The number immediately precedes 5 is _.',  # :)\n",
    "    'There is a sequence: 3, 5, 2, 7. The number immediately follows 5 is _.',  # :(\n",
    "    'There is a sequence: 3, 5, 2, 7. The number between 5 and 7 is _.',\n",
    "    'There is a sequence of numbers: 3, 5, 2, 4. _ is the first number.',\n",
    "    'There is a sequence of numbers: 3, 5, 2. The reversed sequence is _.',\n",
    "    '''There is a sequence of numbers: 5, 1, 6, 3. The second number is 1.\n",
    "There is a sequence of numbers: 3, 7, 2, 4. The second number is _.''',\n",
    "    '''There is a sequence of letters: e, c, b, a. The last letter is a.\n",
    "There is a sequence of letters: f, d, b, g. The last letter is _.''',\n",
    "    '''The uppercase of c is C. The uppercase of f is _.''',\n",
    "    '''The successor of 3 is 4. The successor of 8 is _.''',\n",
    "    '''The successor of 3 is 4. The successor of _ is 6.''',\n",
    "#     '''The predecessor of 3 is 2. The predecessor of 5 is 4. The predecessor of 6 is _''',\n",
    "#     '''The previous integer of 4 is 3. The previous integer of 3 is _.''',\n",
    "#     '''3 minus 1 equals 2. 5 minus 1 equals _.''',\n",
    "    '''If 2 changes to 3, 5 changes to 6, then _ changes to 9''',\n",
    "    '''If 2 changes to 20, 3 changes to 30, then 5 changes to _''',\n",
    "    '''2 -> 3, 4 -> 5, 5 -> 6, 9 -> _.''',\n",
    "    '''3 -> 2, 5 -> 4, 6 -> 5, 9 -> _''',\n",
    "    '''9 -> 8, 7 -> 6, 6 -> 5, 2 -> _.''',\n",
    "    '''3 is to _ as 4 is to 8 and 5 is to 10.''',\n",
    "#     '''6 : _ :: 5 : 10 :: 7 : 14 :: 8 : 16.''',\n",
    "#     '''a is to _ as f is to g, h to i, i to j, s to t.''',\n",
    "#     '''c is to _ as f is to e, h to g, j to i.''',\n",
    "    '''c is to _ as j is to i, h to g, f to e.''',\n",
    "#     '''Twice 3 is 6, twice 4 is _.''',\n",
    "#     '''Half of 4 is 2, half of 6 is _.''',\n",
    "\n",
    "# '''Shall I compare thee to a summer's day?\n",
    "# Thou''',\n",
    "# '''Do not go gentle into that good night,\n",
    "# Old age should burn and rave at close of day;\n",
    "# Rage'''\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "name": "child_analysis.ipynb",
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
